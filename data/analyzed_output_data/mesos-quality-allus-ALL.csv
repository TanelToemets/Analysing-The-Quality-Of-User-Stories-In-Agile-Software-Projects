"id","title","role","means","ends","highlight","kind","subkind","severity","false_positive"
24078,"C Scheduler library should send Call messages to Master Currently, the C library sends different messages to Master instead of a single Call message. To vet the new Call API it should send Call messages. Master should be updated to handle all types of Calls.",NULL,"C Scheduler library should send Call messages to Master Currently, the C library sends different messages to Master instead of a single Call message. To vet the new Call API it should send Call messages. Master should be updated to handle all types of Calls.",NULL,"C Scheduler library should send Call messages to Master Currently, the C library sends different messages to Master instead of a single Call message<span class='highlight-text severity-high'>. To vet the new Call API it should send Call messages. Master should be updated to handle all types of Calls.</span>","minimal","punctuation","high",False
24082,"Testing the new workflow This is a simple test story to try out the new workflow. Unfortunately, testing and getting it to work seems to be something that actually does take up time, so I m tracking this here.",NULL,"Testing the new workflow This is a simple test story to try out the new workflow. Unfortunately, testing and getting it to work seems to be","something that actually does take up time, so I m tracking this here.","Add for who this story is","well_formed","no_role","high",False
24082,"Testing the new workflow This is a simple test story to try out the new workflow. Unfortunately, testing and getting it to work seems to be something that actually does take up time, so I m tracking this here.",NULL,"Testing the new workflow This is a simple test story to try out the new workflow. Unfortunately, testing and getting it to work seems to be","something that actually does take up time, so I m tracking this here.","Testing the new workflow This is a simple test story to try out the new workflow. Unfortunately, testing<span class='highlight-text severity-high'> and </span>getting it to work seems to be something that actually does take up time, so I m tracking this here.","atomic","conjunctions","high",False
24077,"Implement the scheduler endpoint on master Implement the scheduler endpoint on master Implement the scheduler endpoint on master ",NULL,"Implement the scheduler endpoint on master Implement the scheduler endpoint on master Implement the scheduler endpoint on master ",NULL,"Add for who this story is","well_formed","no_role","high",False
24079,"Implement QoS controller Implement QoS controller This is a component of the slave that informs the slave about the possible corrections that need to be performed e.g., shutdown container using recoverable resources . This needs to be integrated with the resource monitor. Need to figure out the metrics used for sending corrections e.g., scheduling latency, usage, informed by We also need to figure out the feedback loop between the QoS controller and the Resource Estimator. class QoSController public monitor ; correction ; ; This is a component of the slave that informs the slave about the possible corrections that need to be performed e.g., shutdown container using recoverable resources . This needs to be integrated with the resource monitor. Need to figure out the metrics used for sending corrections e.g., scheduling latency, usage, informed by We also need to figure out the feedback loop between the QoS controller and the Resource Estimator. class QoSController public monitor ; correction ; ; ",NULL,"Implement QoS controller Implement QoS controller This is a component of the slave that informs the slave about the possible corrections that need to be performed e.g., shutdown container using recoverable resources . This needs to be integrated with the resource monitor. Need to figure out the metrics used for sending corrections e.g., scheduling latency, usage, informed by We also need to figure out the feedback loop between the QoS controller and the Resource Estimator. class QoSController public monitor ; correction ; ; This is a component of the slave that informs the slave about the possible corrections that need to be performed e.g., shutdown container using recoverable resources . This needs to be integrated with the resource monitor. Need to figure out the metrics used for sending corrections e.g., scheduling latency, usage, informed by We also need to figure out the feedback loop between the QoS controller and the Resource Estimator. class QoSController public monitor ; correction ; ; ",NULL,"Add for who this story is","well_formed","no_role","high",False
24079,"Implement QoS controller Implement QoS controller This is a component of the slave that informs the slave about the possible corrections that need to be performed e.g., shutdown container using recoverable resources . This needs to be integrated with the resource monitor. Need to figure out the metrics used for sending corrections e.g., scheduling latency, usage, informed by We also need to figure out the feedback loop between the QoS controller and the Resource Estimator. class QoSController public monitor ; correction ; ; This is a component of the slave that informs the slave about the possible corrections that need to be performed e.g., shutdown container using recoverable resources . This needs to be integrated with the resource monitor. Need to figure out the metrics used for sending corrections e.g., scheduling latency, usage, informed by We also need to figure out the feedback loop between the QoS controller and the Resource Estimator. class QoSController public monitor ; correction ; ; ",NULL,"Implement QoS controller Implement QoS controller This is a component of the slave that informs the slave about the possible corrections that need to be performed e.g., shutdown container using recoverable resources . This needs to be integrated with the resource monitor. Need to figure out the metrics used for sending corrections e.g., scheduling latency, usage, informed by We also need to figure out the feedback loop between the QoS controller and the Resource Estimator. class QoSController public monitor ; correction ; ; This is a component of the slave that informs the slave about the possible corrections that need to be performed e.g., shutdown container using recoverable resources . This needs to be integrated with the resource monitor. Need to figure out the metrics used for sending corrections e.g., scheduling latency, usage, informed by We also need to figure out the feedback loop between the QoS controller and the Resource Estimator. class QoSController public monitor ; correction ; ; ",NULL,"Implement QoS controller Implement QoS controller This is a component of the slave that informs the slave about the possible corrections that need to be performed e<span class='highlight-text severity-high'>.g., shutdown container using recoverable resources . This needs to be integrated with the resource monitor. Need to figure out the metrics used for sending corrections e.g., scheduling latency, usage, informed by We also need to figure out the feedback loop between the QoS controller and the Resource Estimator. class QoSController public monitor ; correction ; ; This is a component of the slave that informs the slave about the possible corrections that need to be performed e.g., shutdown container using recoverable resources . This needs to be integrated with the resource monitor. Need to figure out the metrics used for sending corrections e.g., scheduling latency, usage, informed by We also need to figure out the feedback loop between the QoS controller and the Resource Estimator. class QoSController public monitor ; correction ; ; </span>","minimal","punctuation","high",False
24080,"As a Framework User I want to be able to discover my Task s IP The information exposed by the Framework via the is not publicly resolvable, or resolvable at all . In order to facilitate service discovery via, eg, Marathon UI we want to add the information in endpoint.","As a Framework User","I want to be able to discover my Task s IP The information exposed by the Framework via the is not publicly resolvable, or resolvable at all .","In order to facilitate service discovery via, eg, Marathon UI we want to add the information in endpoint.","As a Framework User I want to be able to discover my Task s IP The information exposed by the Framework via the is not publicly resolvable, or resolvable at all <span class='highlight-text severity-high'>. In order to facilitate service discovery via, eg, Marathon UI we want to add the information in endpoint.</span>","minimal","punctuation","high",False
24080,"As a Framework User I want to be able to discover my Task s IP The information exposed by the Framework via the is not publicly resolvable, or resolvable at all . In order to facilitate service discovery via, eg, Marathon UI we want to add the information in endpoint.","As a Framework User","I want to be able to discover my Task s IP The information exposed by the Framework via the is not publicly resolvable, or resolvable at all .","In order to facilitate service discovery via, eg, Marathon UI we want to add the information in endpoint.","Use the most common template: As a, I want, In order to","uniform","uniform","medium",False
24078,"C Scheduler library should send Call messages to Master Currently, the C library sends different messages to Master instead of a single Call message. To vet the new Call API it should send Call messages. Master should be updated to handle all types of Calls.",NULL,"C Scheduler library should send Call messages to Master Currently, the C library sends different messages to Master instead of a single Call message. To vet the new Call API it should send Call messages. Master should be updated to handle all types of Calls.",NULL,"Add for who this story is","well_formed","no_role","high",False
24082,"Testing the new workflow This is a simple test story to try out the new workflow. Unfortunately, testing and getting it to work seems to be something that actually does take up time, so I m tracking this here.",NULL,"Testing the new workflow This is a simple test story to try out the new workflow. Unfortunately, testing and getting it to work seems to be","something that actually does take up time, so I m tracking this here.","Testing the new workflow This is a simple test story to try out the new workflow<span class='highlight-text severity-high'>. Unfortunately, testing and getting it to work seems to be something that actually does take up time, so I m tracking this here.</span>","minimal","punctuation","high",False
24082,"Testing the new workflow This is a simple test story to try out the new workflow. Unfortunately, testing and getting it to work seems to be something that actually does take up time, so I m tracking this here.",NULL,"Testing the new workflow This is a simple test story to try out the new workflow. Unfortunately, testing and getting it to work seems to be","something that actually does take up time, so I m tracking this here.","Use the most common template: As a, I want, In order to","uniform","uniform","medium",False
24085,"Enable Mesos Agent Node to use arbitrary script module to figure out IP, HOSTNAME Following from MESOS 2902 we want to enable the same functionality in the Mesos Agents too. This is probably best done once we implement the new semantics, as described in MESOS 3142.",NULL,"Enable Mesos Agent Node to use arbitrary script module to figure out IP, HOSTNAME Following from MESOS 2902 we want to enable the same functionality in the Mesos Agents too. This is probably best done once we implement the new semantics, as described in MESOS 3142.",NULL,"Add for who this story is","well_formed","no_role","high",False
24085,"Enable Mesos Agent Node to use arbitrary script module to figure out IP, HOSTNAME Following from MESOS 2902 we want to enable the same functionality in the Mesos Agents too. This is probably best done once we implement the new semantics, as described in MESOS 3142.",NULL,"Enable Mesos Agent Node to use arbitrary script module to figure out IP, HOSTNAME Following from MESOS 2902 we want to enable the same functionality in the Mesos Agents too. This is probably best done once we implement the new semantics, as described in MESOS 3142.",NULL,"Enable Mesos Agent Node to use arbitrary script module to figure out IP, HOSTNAME Following from MESOS 2902 we want to enable the same functionality in the Mesos Agents too<span class='highlight-text severity-high'>. This is probably best done once we implement the new semantics, as described in MESOS 3142.</span>","minimal","punctuation","high",False
24083,"Publish MasterInfo to ZK using JSON Following from MESOS 2340, which now allows Master to correctly decode JSON information published to Zookeeper, we can now enable the Master Leader Contender to serialize it too in JSON.",NULL,"Publish MasterInfo to ZK using JSON Following from MESOS 2340, which now allows Master to correctly decode JSON information published to Zookeeper, we can now enable the Master Leader Contender to serialize it too in JSON.",NULL,"Add for who this story is","well_formed","no_role","high",False
24081,"Create the basic infrastructure to handle scheduler endpoint Create the basic infrastructure to handle scheduler endpoint This is the first basic step in ensuring the basic functionality processing a POST call and returning if all goes well; if not authorized; and if the request is malformed. We ll get more sophisticated as the work progressed eg, supporting functionality processing a POST call and returning if all goes well; if not authorized; and if the request is malformed. We ll get more sophisticated as the work progressed eg, supporting if the content type is not of the right kind .",NULL,"Create the basic infrastructure to handle scheduler endpoint Create the basic infrastructure to handle scheduler endpoint This is the first basic step in ensuring the basic functionality processing a POST call and returning if all goes well; if not authorized; and if the request is malformed. We ll get more sophisticated as the work progressed eg, supporting functionality processing a POST call and returning if all goes well; if not authorized; and if the request is malformed. We ll get more sophisticated as the work progressed eg, supporting if the content type is not of the right kind .",NULL,"Add for who this story is","well_formed","no_role","high",False
24081,"Create the basic infrastructure to handle scheduler endpoint Create the basic infrastructure to handle scheduler endpoint This is the first basic step in ensuring the basic functionality processing a POST call and returning if all goes well; if not authorized; and if the request is malformed. We ll get more sophisticated as the work progressed eg, supporting functionality processing a POST call and returning if all goes well; if not authorized; and if the request is malformed. We ll get more sophisticated as the work progressed eg, supporting if the content type is not of the right kind .",NULL,"Create the basic infrastructure to handle scheduler endpoint Create the basic infrastructure to handle scheduler endpoint This is the first basic step in ensuring the basic functionality processing a POST call and returning if all goes well; if not authorized; and if the request is malformed. We ll get more sophisticated as the work progressed eg, supporting functionality processing a POST call and returning if all goes well; if not authorized; and if the request is malformed. We ll get more sophisticated as the work progressed eg, supporting if the content type is not of the right kind .",NULL,"Create the basic infrastructure to handle scheduler endpoint Create the basic infrastructure to handle scheduler endpoint This is the first basic step in ensuring the basic functionality processing a POST call<span class='highlight-text severity-high'> and </span>returning if all goes well; if not authorized; and if the request is malformed. We ll get more sophisticated as the work progressed eg, supporting functionality processing a POST call and returning if all goes well; if not authorized; and if the request is malformed. We ll get more sophisticated as the work progressed eg, supporting if the content type is not of the right kind .","atomic","conjunctions","high",False
24081,"Create the basic infrastructure to handle scheduler endpoint Create the basic infrastructure to handle scheduler endpoint This is the first basic step in ensuring the basic functionality processing a POST call and returning if all goes well; if not authorized; and if the request is malformed. We ll get more sophisticated as the work progressed eg, supporting functionality processing a POST call and returning if all goes well; if not authorized; and if the request is malformed. We ll get more sophisticated as the work progressed eg, supporting if the content type is not of the right kind .",NULL,"Create the basic infrastructure to handle scheduler endpoint Create the basic infrastructure to handle scheduler endpoint This is the first basic step in ensuring the basic functionality processing a POST call and returning if all goes well; if not authorized; and if the request is malformed. We ll get more sophisticated as the work progressed eg, supporting functionality processing a POST call and returning if all goes well; if not authorized; and if the request is malformed. We ll get more sophisticated as the work progressed eg, supporting if the content type is not of the right kind .",NULL,"Create the basic infrastructure to handle scheduler endpoint Create the basic infrastructure to handle scheduler endpoint This is the first basic step in ensuring the basic functionality processing a POST call and returning if all goes well<span class='highlight-text severity-high'>; if not authorized; and if the request is malformed. We ll get more sophisticated as the work progressed eg, supporting functionality processing a POST call and returning if all goes well; if not authorized; and if the request is malformed. We ll get more sophisticated as the work progressed eg, supporting if the content type is not of the right kind .</span>","minimal","punctuation","high",False
24076,"Use PID namespace to avoid freezing cgroup Use PID namespace to avoid freezing cgroup Use PID namespace to avoid freezing cgroup Use PID namespace to avoid freezing cgroup There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace so that we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code. There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace so that we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code. There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace so that we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code. There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace so that we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code.",NULL,"Use PID namespace to avoid freezing cgroup Use PID namespace to avoid freezing cgroup Use PID namespace to avoid freezing cgroup Use PID namespace to avoid freezing cgroup There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace","so that we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code. There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace so that we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code. There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace so that we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code. There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace so that we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code.","Add for who this story is","well_formed","no_role","high",False
24076,"Use PID namespace to avoid freezing cgroup Use PID namespace to avoid freezing cgroup Use PID namespace to avoid freezing cgroup Use PID namespace to avoid freezing cgroup There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace so that we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code. There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace so that we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code. There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace so that we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code. There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace so that we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code.",NULL,"Use PID namespace to avoid freezing cgroup Use PID namespace to avoid freezing cgroup Use PID namespace to avoid freezing cgroup Use PID namespace to avoid freezing cgroup There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace","so that we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code. There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace so that we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code. There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace so that we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code. There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace so that we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code.","Use PID namespace to avoid freezing cgroup Use PID namespace to avoid freezing cgroup Use PID namespace to avoid freezing cgroup Use PID namespace to avoid freezing cgroup There is some known kernel issue when we freeze the whole cgroup upon OOM<span class='highlight-text severity-high'>. Mesos probably can just use PID namespace so that we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code. There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace so that we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code. There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace so that we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code. There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace so that we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code.</span>","minimal","punctuation","high",False
24076,"Use PID namespace to avoid freezing cgroup Use PID namespace to avoid freezing cgroup Use PID namespace to avoid freezing cgroup Use PID namespace to avoid freezing cgroup There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace so that we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code. There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace so that we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code. There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace so that we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code. There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace so that we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code.",NULL,"Use PID namespace to avoid freezing cgroup Use PID namespace to avoid freezing cgroup Use PID namespace to avoid freezing cgroup Use PID namespace to avoid freezing cgroup There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace","so that we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code. There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace so that we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code. There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace so that we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code. There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace so that we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code.","Use PID namespace to avoid freezing cgroup Use PID namespace to avoid freezing cgroup Use PID namespace to avoid freezing cgroup Use PID namespace to avoid freezing cgroup There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace<span class='highlight-text severity-high'> so that </span>we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code. There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace<span class='highlight-text severity-high'> so that </span>we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code. There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace<span class='highlight-text severity-high'> so that </span>we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code. There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace<span class='highlight-text severity-high'> so that </span>we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code.","minimal","indicator_repetition","high",False
24076,"Use PID namespace to avoid freezing cgroup Use PID namespace to avoid freezing cgroup Use PID namespace to avoid freezing cgroup Use PID namespace to avoid freezing cgroup There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace so that we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code. There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace so that we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code. There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace so that we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code. There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace so that we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code.",NULL,"Use PID namespace to avoid freezing cgroup Use PID namespace to avoid freezing cgroup Use PID namespace to avoid freezing cgroup Use PID namespace to avoid freezing cgroup There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace","so that we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code. There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace so that we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code. There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace so that we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code. There is some known kernel issue when we freeze the whole cgroup upon OOM. Mesos probably can just use PID namespace so that we will only need to kill the init of the pid namespace, instead of freezing all the processes and killing them one by one. But I am not quite sure if this would break the existing code.","Use the most common template: As a, I want, In order to","uniform","uniform","medium",False
24089,"Expose TASK FAILED reason to Frameworks. We now have a message string inside TaskStatus that provides human readable information about TASK FAILED. It would be good to add some structure to the failure reasons, for framework schedulers to act on programmatically. E.g. enum TaskFailure EXECUTOR OOM; SLAVE LOST; etc.. ",NULL,"Expose TASK FAILED reason to Frameworks. We now have a message string inside TaskStatus that provides human readable information about TASK FAILED. It would be good to add some structure to the failure reasons, for framework schedulers to act on programmatically. E.g. enum TaskFailure EXECUTOR OOM; SLAVE LOST; etc.. ",NULL,"Add for who this story is","well_formed","no_role","high",False
24089,"Expose TASK FAILED reason to Frameworks. We now have a message string inside TaskStatus that provides human readable information about TASK FAILED. It would be good to add some structure to the failure reasons, for framework schedulers to act on programmatically. E.g. enum TaskFailure EXECUTOR OOM; SLAVE LOST; etc.. ",NULL,"Expose TASK FAILED reason to Frameworks. We now have a message string inside TaskStatus that provides human readable information about TASK FAILED. It would be good to add some structure to the failure reasons, for framework schedulers to act on programmatically. E.g. enum TaskFailure EXECUTOR OOM; SLAVE LOST; etc.. ",NULL,"Expose TASK FAILED reason to Frameworks<span class='highlight-text severity-high'>. We now have a message string inside TaskStatus that provides human readable information about TASK FAILED. It would be good to add some structure to the failure reasons, for framework schedulers to act on programmatically. E.g. enum TaskFailure EXECUTOR OOM; SLAVE LOST; etc.. </span>","minimal","punctuation","high",False
24090,"Draft design doc for multi role frameworks Create a document that describes the problems with having only single role frameworks and proposes an MVP solution and implementation approach.",NULL,"Draft design doc for multi role frameworks Create a document that describes the problems with having only single role frameworks and proposes an MVP solution and implementation approach.",NULL,"Add for who this story is","well_formed","no_role","high",False
24090,"Draft design doc for multi role frameworks Create a document that describes the problems with having only single role frameworks and proposes an MVP solution and implementation approach.",NULL,"Draft design doc for multi role frameworks Create a document that describes the problems with having only single role frameworks and proposes an MVP solution and implementation approach.",NULL,"Draft design doc for multi role frameworks Create a document that describes the problems with having only single role frameworks<span class='highlight-text severity-high'> and </span>proposes an MVP solution and implementation approach.","atomic","conjunctions","high",False
24084,"As a Developer I want a better way to run shell commands When reviewing the code in r 36425 noticed that there is a better abstraction that is possible to introduce for that will simplify the caller s life. Instead of having to handle all possible outcomes, we propose to refactor as follows Returns the output from running the specified command with the shell. Try std string shell const string command Actually handle the WIFEXITED, WIFSIGNALED here! where the returned string is . And some test driven development world , os shell echo hello world ; Alternatively, the caller can ask to have Try string outAndErr os shell myCmd foo 2 1 ; However, will be ignored by default We don t read standard error by default. EXPECT SOME EQ , os shell echo hello world 1 2 ; We don t even read stderr if something fails to return in Try error . Try string output os shell echo hello world 1 2 false ; hello world ; An analysis of existing usage shows that in almost all cases, the caller only cares ; in fact, the actual exit code is read only once, and even then, in a test case. We believe this will simplify the API to the caller, and will significantly reduce the length and complexity at the calling sites 6 LOC against the current 20 .","As a Developer","I want a better way to run shell commands When reviewing the code in r 36425 noticed that there is a better abstraction that is possible to introduce for that will simplify the caller s life. Instead of having to handle all possible outcomes, we propose to refactor as follows Returns the output from running the specified command with the shell. Try std string shell const string command Actually handle the WIFEXITED, WIFSIGNALED here! where the returned string is . And some test driven development world , os shell echo hello world ; Alternatively, the caller can ask to have Try string outAndErr os shell myCmd foo 2 1 ; However, will be ignored by default We don t read standard error by default. EXPECT SOME EQ , os shell echo hello world 1 2 ; We don t even read stderr if something fails to return in Try error . Try string output os shell echo hello world 1 2 false ; hello world ; An analysis of existing usage shows that in almost all cases, the caller only cares ; in fact, the actual exit code is read only once, and even then, in a test case. We believe this will simplify the API to the caller, and will significantly reduce the length and complexity at the calling sites 6 LOC against the current 20 .",NULL,"As a Developer I want a better way to run shell commands When reviewing the code in r 36425 noticed that there is a better abstraction that is possible to introduce for that will simplify the caller s life. Instead of having to handle all possible outcomes, we propose to refactor as follows Returns the output from running the specified command with the shell. Try std string shell const string command Actually handle the WIFEXITED, WIFSIGNALED here! where the returned string is .<span class='highlight-text severity-high'> and </span>some test driven development world , os shell echo hello world ; Alternatively, the caller can ask to have Try string outAndErr os shell myCmd foo 2 1 ; However, will be ignored by default We don t read standard error by default. EXPECT SOME EQ , os shell echo hello world 1 2 ; We don t even read stderr if something fails to return in Try error . Try string output os shell echo hello world 1 2 false ; hello world ; An analysis of existing usage shows that in almost all cases, the caller only cares ; in fact, the actual exit code is read only once, and even then, in a test case. We believe this will simplify the API to the caller, and will significantly reduce the length and complexity at the calling sites 6 LOC against the current 20 .","atomic","conjunctions","high",False
24084,"As a Developer I want a better way to run shell commands When reviewing the code in r 36425 noticed that there is a better abstraction that is possible to introduce for that will simplify the caller s life. Instead of having to handle all possible outcomes, we propose to refactor as follows Returns the output from running the specified command with the shell. Try std string shell const string command Actually handle the WIFEXITED, WIFSIGNALED here! where the returned string is . And some test driven development world , os shell echo hello world ; Alternatively, the caller can ask to have Try string outAndErr os shell myCmd foo 2 1 ; However, will be ignored by default We don t read standard error by default. EXPECT SOME EQ , os shell echo hello world 1 2 ; We don t even read stderr if something fails to return in Try error . Try string output os shell echo hello world 1 2 false ; hello world ; An analysis of existing usage shows that in almost all cases, the caller only cares ; in fact, the actual exit code is read only once, and even then, in a test case. We believe this will simplify the API to the caller, and will significantly reduce the length and complexity at the calling sites 6 LOC against the current 20 .","As a Developer","I want a better way to run shell commands When reviewing the code in r 36425 noticed that there is a better abstraction that is possible to introduce for that will simplify the caller s life. Instead of having to handle all possible outcomes, we propose to refactor as follows Returns the output from running the specified command with the shell. Try std string shell const string command Actually handle the WIFEXITED, WIFSIGNALED here! where the returned string is . And some test driven development world , os shell echo hello world ; Alternatively, the caller can ask to have Try string outAndErr os shell myCmd foo 2 1 ; However, will be ignored by default We don t read standard error by default. EXPECT SOME EQ , os shell echo hello world 1 2 ; We don t even read stderr if something fails to return in Try error . Try string output os shell echo hello world 1 2 false ; hello world ; An analysis of existing usage shows that in almost all cases, the caller only cares ; in fact, the actual exit code is read only once, and even then, in a test case. We believe this will simplify the API to the caller, and will significantly reduce the length and complexity at the calling sites 6 LOC against the current 20 .",NULL,"As a Developer I want a better way to run shell commands When reviewing the code in r 36425 noticed that there is a better abstraction that is possible to introduce for that will simplify the caller s life<span class='highlight-text severity-high'>. Instead of having to handle all possible outcomes, we propose to refactor as follows Returns the output from running the specified command with the shell. Try std string shell const string command Actually handle the WIFEXITED, WIFSIGNALED here! where the returned string is . And some test driven development world , os shell echo hello world ; Alternatively, the caller can ask to have Try string outAndErr os shell myCmd foo 2 1 ; However, will be ignored by default We don t read standard error by default. EXPECT SOME EQ , os shell echo hello world 1 2 ; We don t even read stderr if something fails to return in Try error . Try string output os shell echo hello world 1 2 false ; hello world ; An analysis of existing usage shows that in almost all cases, the caller only cares ; in fact, the actual exit code is read only once, and even then, in a test case. We believe this will simplify the API to the caller, and will significantly reduce the length and complexity at the calling sites 6 LOC against the current 20 .</span>","minimal","punctuation","high",False
24088,"Add either log rotation or capped size logging for tasks Tasks currently log their output i.e. stdout stderr to files the sandbox on an agent s disk. In some cases, the accumulation of these logs can completely fill up the agent s disk and thereby kill the task or machine. To prevent this, we should either implement a log rotation mechanism or capped size logging. This would be used by executors to control the amount of logs they keep. Master agent logs will not be affected. We will first scope out several possible approaches for log rotation capping in a design document see . Once an approach is chosen, this story will be broken down into some corresponding issues.",NULL,"Add either log rotation or capped size logging for tasks Tasks currently log their output i.e. stdout stderr to files the sandbox on an agent s disk. In some cases, the accumulation of these logs can completely fill up the agent s disk and thereby kill the task or machine. To prevent this, we should either implement a log rotation mechanism or capped size logging. This would be used by executors to control the amount of logs they keep. Master agent logs will not be affected. We will first scope out several possible approaches for log rotation capping in a design document see . Once an approach is chosen, this story will be broken down into some corresponding issues.",NULL,"Add for who this story is","well_formed","no_role","high",False
24088,"Add either log rotation or capped size logging for tasks Tasks currently log their output i.e. stdout stderr to files the sandbox on an agent s disk. In some cases, the accumulation of these logs can completely fill up the agent s disk and thereby kill the task or machine. To prevent this, we should either implement a log rotation mechanism or capped size logging. This would be used by executors to control the amount of logs they keep. Master agent logs will not be affected. We will first scope out several possible approaches for log rotation capping in a design document see . Once an approach is chosen, this story will be broken down into some corresponding issues.",NULL,"Add either log rotation or capped size logging for tasks Tasks currently log their output i.e. stdout stderr to files the sandbox on an agent s disk. In some cases, the accumulation of these logs can completely fill up the agent s disk and thereby kill the task or machine. To prevent this, we should either implement a log rotation mechanism or capped size logging. This would be used by executors to control the amount of logs they keep. Master agent logs will not be affected. We will first scope out several possible approaches for log rotation capping in a design document see . Once an approach is chosen, this story will be broken down into some corresponding issues.",NULL,"Add either log rotation<span class='highlight-text severity-high'> or </span>capped size logging for tasks Tasks currently log their output i.e. stdout stderr to files the sandbox on an agent s disk. In some cases, the accumulation of these logs can completely fill up the agent s disk<span class='highlight-text severity-high'> and </span>thereby kill the task or machine. To prevent this, we should either implement a log rotation mechanism or capped size logging. This would be used by executors to control the amount of logs they keep. Master agent logs will not be affected. We will first scope out several possible approaches for log rotation capping in a design document see . Once an approach is chosen, this story will be broken down into some corresponding issues.","atomic","conjunctions","high",False
24088,"Add either log rotation or capped size logging for tasks Tasks currently log their output i.e. stdout stderr to files the sandbox on an agent s disk. In some cases, the accumulation of these logs can completely fill up the agent s disk and thereby kill the task or machine. To prevent this, we should either implement a log rotation mechanism or capped size logging. This would be used by executors to control the amount of logs they keep. Master agent logs will not be affected. We will first scope out several possible approaches for log rotation capping in a design document see . Once an approach is chosen, this story will be broken down into some corresponding issues.",NULL,"Add either log rotation or capped size logging for tasks Tasks currently log their output i.e. stdout stderr to files the sandbox on an agent s disk. In some cases, the accumulation of these logs can completely fill up the agent s disk and thereby kill the task or machine. To prevent this, we should either implement a log rotation mechanism or capped size logging. This would be used by executors to control the amount of logs they keep. Master agent logs will not be affected. We will first scope out several possible approaches for log rotation capping in a design document see . Once an approach is chosen, this story will be broken down into some corresponding issues.",NULL,"Add either log rotation or capped size logging for tasks Tasks currently log their output i<span class='highlight-text severity-high'>.e. stdout stderr to files the sandbox on an agent s disk. In some cases, the accumulation of these logs can completely fill up the agent s disk and thereby kill the task or machine. To prevent this, we should either implement a log rotation mechanism or capped size logging. This would be used by executors to control the amount of logs they keep. Master agent logs will not be affected. We will first scope out several possible approaches for log rotation capping in a design document see . Once an approach is chosen, this story will be broken down into some corresponding issues.</span>","minimal","punctuation","high",False
