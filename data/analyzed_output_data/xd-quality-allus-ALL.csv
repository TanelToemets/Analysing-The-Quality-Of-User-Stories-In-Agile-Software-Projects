"id","title","role","means","ends","highlight","kind","subkind","severity","false_positive"
26124,"Improve to support classes with inheritance Provide unit tests",NULL,"Improve to support classes with inheritance Provide unit tests",NULL,"Add for who this story is","well_formed","no_role","high",False
26120,"Clean up compiler and javadoc warnings from the build As a developer, I'd like to clean up compiler and javadoc warnings from the build, so we don t see the warnings in build sysout.",NULL,"Clean up compiler and javadoc warnings from the build As a developer, I'd like to clean up compiler and javadoc warnings from the build,","so we don t see the warnings in build sysout.","Add for who this story is","well_formed","no_role","high",False
25501,"Investigate skipped tests in build, enable or remove. We have 13 skipped tests now...",NULL,"Investigate skipped tests in build, enable or remove. We have 13 skipped tests now...",NULL,"Add for who this story is","well_formed","no_role","high",False
26784,"Remove AutoLaunch feature from batch jobs Jobs will be started via trigger. So we won t need the JobTriggerBean.",NULL,"Remove AutoLaunch feature from batch jobs Jobs will be started via trigger.","So we won t need the JobTriggerBean.","Add for who this story is","well_formed","no_role","high",False
25501,"Investigate skipped tests in build, enable or remove. We have 13 skipped tests now...",NULL,"Investigate skipped tests in build, enable or remove. We have 13 skipped tests now...",NULL,"Investigate skipped tests in build, enable<span class='highlight-text severity-high'> or </span>remove. We have 13 skipped tests now...","atomic","conjunctions","high",False
26785,"Parser needs to handle a embedded in a name. Also drop the enhanced portion of the ",NULL,"Parser needs to handle a embedded in a name. Also drop the enhanced portion of the ",NULL,"Add for who this story is","well_formed","no_role","high",False
26120,"Clean up compiler and javadoc warnings from the build As a developer, I'd like to clean up compiler and javadoc warnings from the build, so we don t see the warnings in build sysout.",NULL,"Clean up compiler and javadoc warnings from the build As a developer, I'd like to clean up compiler and javadoc warnings from the build,","so we don t see the warnings in build sysout.","Clean up compiler<span class='highlight-text severity-high'> and </span>javadoc warnings from the build As a developer, I'd like to clean up compiler and javadoc warnings from the build, so we don t see the warnings in build sysout.","atomic","conjunctions","high",False
26120,"Clean up compiler and javadoc warnings from the build As a developer, I'd like to clean up compiler and javadoc warnings from the build, so we don t see the warnings in build sysout.",NULL,"Clean up compiler and javadoc warnings from the build As a developer, I'd like to clean up compiler and javadoc warnings from the build,","so we don t see the warnings in build sysout.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26123,"Ensure proper lifecycle shutdown of processors in and ",NULL,"Ensure proper lifecycle shutdown of processors in and ",NULL,"Add for who this story is","well_formed","no_role","high",False
26125,"Update redis.tar.gz bundled in distribution to be version 3.0.1 RPM scripts will need to change.",NULL,"Update redis.tar.gz bundled in distribution to be version 3.0.1 RPM scripts will need to change.",NULL,"Add for who this story is","well_formed","no_role","high",False
26274,"Port FTP as s c s sink module As a Spring XD developer, I'd like to port modules to build streaming pipeline.",NULL,"Port FTP as s c s sink module As a Spring XD developer, I'd like to port modules to build streaming pipeline.",NULL,"Add for who this story is","well_formed","no_role","high",False
26122,"Review critical sonar warning... ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26122,"Review critical sonar warning... ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26276,"Port Rabbit as s c s source As a s c d developer, I'd like to move to build streaming pipeline.",NULL,"Port Rabbit as s c s source As a s c d developer, I'd like to move to build streaming pipeline.",NULL,"Add for who this story is","well_formed","no_role","high",False
26280,"Create tcp udp load generator script for XD performance testing Create a load generator script which can generate messages at specific 1 Rate 2 Payload 3 Concurrency to a specific tcp udp port where a syslog adapter is listening.",NULL,"Create tcp udp load generator script for XD performance testing Create a load generator script which can generate messages at specific 1 Rate 2 Payload 3 Concurrency to a specific tcp udp port where a syslog adapter is listening.",NULL,"Add for who this story is","well_formed","no_role","high",False
26275,"Port Redis as s c s sink As a Spring XD developer, I'd like to move to build streaming pipeline.",NULL,"Port Redis as s c s sink As a Spring XD developer, I'd like to move to build streaming pipeline.",NULL,"Add for who this story is","well_formed","no_role","high",False
26279,"Upgrade HDP PHD distrubutions As a Spring XD user, I'd like to use the latest releases of .",NULL,"Upgrade HDP PHD distrubutions As a Spring XD user, I'd like to use the latest releases of .",NULL,"Add for who this story is","well_formed","no_role","high",False
26277,"Port gemfire server sink as s c s module As a Spring XD developer, I'd like to move to build streaming pipeline.",NULL,"Port gemfire server sink as s c s module As a Spring XD developer, I'd like to move to build streaming pipeline.",NULL,"Add for who this story is","well_formed","no_role","high",False
25383,"Remove project and module xml to be put in seperate repository AGPL license issues",NULL,"Remove project and module xml to be put in seperate repository AGPL license issues",NULL,"Add for who this story is","well_formed","no_role","high",False
25147,"Standardize handling We should we centrally standardize on date time formats so that we don t create inconsistencies, and follow ISO 8601 internally. Internally we should only work with UTC or make that the default config option . Ultimately, whatever the user sees is just a formatting concern.",NULL,"Standardize handling We should we centrally standardize on date time formats","so that we don t create inconsistencies, and follow ISO 8601 internally. Internally we should only work with UTC or make that the default config option . Ultimately, whatever the user sees is just a formatting concern.","Add for who this story is","well_formed","no_role","high",False
25317,"Add option to xd admin and xd container YARN scripts to allow copying ot HDFS and no execution. ",NULL,"Add option to xd admin and xd container YARN scripts to allow copying ot HDFS and no execution. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25383,"Remove project and module xml to be put in seperate repository AGPL license issues",NULL,"Remove project and module xml to be put in seperate repository AGPL license issues",NULL,"Remove project<span class='highlight-text severity-high'> and </span>module xml to be put in seperate repository AGPL license issues","atomic","conjunctions","high",False
25380,"Error in correlation strategy in aggregator.xml should be Add a test to make sure correlation expressions here work.",NULL,"Error in correlation strategy in aggregator.xml should be Add a test to make sure correlation expressions here work.",NULL,"Add for who this story is","well_formed","no_role","high",False
25382,"should make a better attempt at round robin distribution Currently the index is used globally but applied to a range of candidates that can differ based on the match criteria per invocation.",NULL,"should make a better attempt at round robin distribution Currently the index is used globally but applied to a range of candidates that can differ based on the match criteria per invocation.",NULL,"Add for who this story is","well_formed","no_role","high",False
25500,"Update to Spring Integration 4.0.1 Add messages store optimization to the hdfs dataset ",NULL,"Update to Spring Integration 4.0.1 Add messages store optimization to the hdfs dataset ",NULL,"Add for who this story is","well_formed","no_role","high",False
25717,"Provide Python module to handle I O for implementing a Python shell processor ",NULL,"Provide Python module to handle I O for implementing a Python shell processor ",NULL,"Add for who this story is","well_formed","no_role","high",False
25718,"field value counter should support nested fieldNames for example, when using the twittersearch source module, the hashTags are nested within entities , and the value for hashTags is itself an object with a text field, so the following would be needed to count the actual value of interest tap tweets ",NULL,"field value counter should support nested fieldNames for example, when using the twittersearch","source module, the hashTags are nested within entities , and the value for hashTags is itself an object with a text field, so the following would be needed to count the actual value of interest tap tweets","Add for who this story is","well_formed","no_role","high",False
25718,"field value counter should support nested fieldNames for example, when using the twittersearch source module, the hashTags are nested within entities , and the value for hashTags is itself an object with a text field, so the following would be needed to count the actual value of interest tap tweets ",NULL,"field value counter should support nested fieldNames for example, when using the twittersearch","source module, the hashTags are nested within entities , and the value for hashTags is itself an object with a text field, so the following would be needed to count the actual value of interest tap tweets","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26273,"Test connection pooling on Redis operations ",NULL,"Test connection pooling on Redis operations ",NULL,"Add for who this story is","well_formed","no_role","high",False
25714,"Add support for configurable ZK namespace As a user, I'd like to have the flexibility to change the namespace so that I can isolate ZK metadata based on each tenant profile. ",NULL,"Add support for configurable ZK namespace As a user, I'd like to have the flexibility to change the namespace","so that I can isolate ZK metadata based on each tenant profile.","Add for who this story is","well_formed","no_role","high",False
25714,"Add support for configurable ZK namespace As a user, I'd like to have the flexibility to change the namespace so that I can isolate ZK metadata based on each tenant profile. ",NULL,"Add support for configurable ZK namespace As a user, I'd like to have the flexibility to change the namespace","so that I can isolate ZK metadata based on each tenant profile.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25716,"Update Creating a Custom Source Module doc with a different SI adapter due to Twitter issues uses the SI twittersearch inbound channel adapter, which is no longer going to work once Twitter disallows anonymous searches. Ideally we update the example to use a new version of SI twitter that adds support for this as opposed to the XD workaround. ",NULL,"Update Creating a Custom Source Module doc with a different SI adapter due to Twitter issues uses the SI twittersearch inbound channel adapter, which is no longer going to work once Twitter disallows anonymous searches. Ideally we update the example to use a new version of SI twitter that adds support for this as opposed to the XD workaround. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25716,"Update Creating a Custom Source Module doc with a different SI adapter due to Twitter issues uses the SI twittersearch inbound channel adapter, which is no longer going to work once Twitter disallows anonymous searches. Ideally we update the example to use a new version of SI twitter that adds support for this as opposed to the XD workaround. ",NULL,"Update Creating a Custom Source Module doc with a different SI adapter due to Twitter issues uses the SI twittersearch inbound channel adapter, which is no longer going to work once Twitter disallows anonymous searches. Ideally we update the example to use a new version of SI twitter that adds support for this as opposed to the XD workaround. ",NULL,"Update Creating a Custom Source Module doc with a different SI adapter due to Twitter issues uses the SI twittersearch inbound channel adapter, which is no longer going to work once Twitter disallows anonymous searches<span class='highlight-text severity-high'>. Ideally we update the example to use a new version of SI twitter that adds support for this as opposed to the XD workaround. </span>","minimal","punctuation","high",False
25501,"Investigate skipped tests in build, enable or remove. We have 13 skipped tests now...",NULL,"Investigate skipped tests in build, enable or remove. We have 13 skipped tests now...",NULL,"Investigate skipped tests in build, enable or remove<span class='highlight-text severity-high'>. We have 13 skipped tests now...</span>","minimal","punctuation","high",False
25519,"DefaultContainer should have a default constructor that generates a UUID The current incrementAndGet approach based off redis will not easily be applicable in local model deployment",NULL,"DefaultContainer should have a default constructor that generates a UUID The current incrementAndGet approach based off redis will not easily be applicable in local model deployment",NULL,"Add for who this story is","well_formed","no_role","high",False
25521,"REST endpoint command interface for runtime module deployment properties We need a way to access the deployment properties for the deployed modules. For example runtime module foo.sink.bar 2 ",NULL,"REST endpoint command interface for runtime module deployment properties We need a way to access the deployment properties for the deployed modules. For example runtime module foo.sink.bar 2 ",NULL,"Add for who this story is","well_formed","no_role","high",False
25521,"REST endpoint command interface for runtime module deployment properties We need a way to access the deployment properties for the deployed modules. For example runtime module foo.sink.bar 2 ",NULL,"REST endpoint command interface for runtime module deployment properties We need a way to access the deployment properties for the deployed modules. For example runtime module foo.sink.bar 2 ",NULL,"REST endpoint command interface for runtime module deployment properties We need a way to access the deployment properties for the deployed modules<span class='highlight-text severity-high'>. For example runtime module foo.sink.bar 2 </span>","minimal","punctuation","high",False
25095,"Refactoring to to extends from not ",NULL,"Refactoring to to extends from not ",NULL,"Add for who this story is","well_formed","no_role","high",False
25523,"Detect Invalid Deployment Properties in the Bus Detect properties the bus doesn t support.",NULL,"Detect Invalid Deployment Properties in the Bus Detect properties the bus doesn t support.",NULL,"Add for who this story is","well_formed","no_role","high",False
25094,"Create XDAdmin server to start container launcher This will launch the in future will be able to select from a variety of middleware options.",NULL,"Create XDAdmin server to start container launcher This will launch the in future will be able to select from a variety of middleware options.",NULL,"Add for who this story is","well_formed","no_role","high",False
25522,"Support Partitioning Bus Properties in the RedisMessageBus PR ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25522,"Support Partitioning Bus Properties in the RedisMessageBus PR ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25124,"Small method name refactorings and add Javadoc in batch controllers should be executionsForJob should be instancesForJob The JavaDoc for the class and each method should be more descriptive about their functionality ",NULL,"Small method name refactorings and add Javadoc in batch controllers should be executionsForJob should be instancesForJob The JavaDoc for the class and each method should be more descriptive about their functionality ",NULL,"Add for who this story is","well_formed","no_role","high",False
25124,"Small method name refactorings and add Javadoc in batch controllers should be executionsForJob should be instancesForJob The JavaDoc for the class and each method should be more descriptive about their functionality ",NULL,"Small method name refactorings and add Javadoc in batch controllers should be executionsForJob should be instancesForJob The JavaDoc for the class and each method should be more descriptive about their functionality ",NULL,"Small method name refactorings<span class='highlight-text severity-high'> and </span>add Javadoc in batch controllers should be executionsForJob should be instancesForJob The JavaDoc for the class and each method should be more descriptive about their functionality ","atomic","conjunctions","high",False
25524,"Detect Module Properties for Non existent Modules stream create foo definition bar baz stream deploy foo ",NULL,"Detect Module Properties for Non existent Modules stream create foo definition bar baz stream deploy foo ",NULL,"Add for who this story is","well_formed","no_role","high",False
25527,"Remove unused parser code related to substreams co The XD parser had initial support for substreams, which have been subsumed by composed modules. That legacy code is unused and not needed",NULL,"Remove unused parser code related to substreams co The XD parser had initial support for substreams, which have been subsumed by composed modules. That legacy code is unused and not needed",NULL,"Add for who this story is","well_formed","no_role","high",False
25527,"Remove unused parser code related to substreams co The XD parser had initial support for substreams, which have been subsumed by composed modules. That legacy code is unused and not needed",NULL,"Remove unused parser code related to substreams co The XD parser had initial support for substreams, which have been subsumed by composed modules. That legacy code is unused and not needed",NULL,"Remove unused parser code related to substreams co The XD parser had initial support for substreams, which have been subsumed by composed modules. That legacy code is unused<span class='highlight-text severity-high'> and </span>not needed","atomic","conjunctions","high",False
25527,"Remove unused parser code related to substreams co The XD parser had initial support for substreams, which have been subsumed by composed modules. That legacy code is unused and not needed",NULL,"Remove unused parser code related to substreams co The XD parser had initial support for substreams, which have been subsumed by composed modules. That legacy code is unused and not needed",NULL,"Remove unused parser code related to substreams co The XD parser had initial support for substreams, which have been subsumed by composed modules<span class='highlight-text severity-high'>. That legacy code is unused and not needed</span>","minimal","punctuation","high",False
25525,"New job that executes a Spark job Create OOTB batch job that executes a job on Spark as a tasklet could be something along this job create yarnJob definition sparkjob class SimpleApp ",NULL,"New job that executes a Spark job Create OOTB batch job that executes a job on Spark as a tasklet could be something along this job create yarnJob definition sparkjob class SimpleApp ",NULL,"Add for who this story is","well_formed","no_role","high",False
25526,"Add XmlRootElement to all REST resources Some REST resources lack an XmlRootElement annotation. This causes a JAXB marshalling error when trying to access the API with an Accept header of xml which is the default in most browsers This is a preliminary to XD 1800 which is much more involved , only to fix ugly exception",NULL,"Add XmlRootElement to all REST resources Some REST resources lack an XmlRootElement annotation. This causes a JAXB marshalling error when trying to access the API with an Accept header of xml which is the default in most browsers This is a preliminary to XD 1800 which is much more involved , only to fix ugly exception",NULL,"Add for who this story is","well_formed","no_role","high",False
25526,"Add XmlRootElement to all REST resources Some REST resources lack an XmlRootElement annotation. This causes a JAXB marshalling error when trying to access the API with an Accept header of xml which is the default in most browsers This is a preliminary to XD 1800 which is much more involved , only to fix ugly exception",NULL,"Add XmlRootElement to all REST resources Some REST resources lack an XmlRootElement annotation. This causes a JAXB marshalling error when trying to access the API with an Accept header of xml which is the default in most browsers This is a preliminary to XD 1800 which is much more involved , only to fix ugly exception",NULL,"Add XmlRootElement to all REST resources Some REST resources lack an XmlRootElement annotation<span class='highlight-text severity-high'>. This causes a JAXB marshalling error when trying to access the API with an Accept header of xml which is the default in most browsers This is a preliminary to XD 1800 which is much more involved , only to fix ugly exception</span>","minimal","punctuation","high",False
25578,"Use Boot plugin and IO Platform for versions where possible ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25578,"Use Boot plugin and IO Platform for versions where possible ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25574,"Add configuration files for hornetmq jms provider. See Requires update to gradle 2.1",NULL,"Add configuration files for hornetmq jms provider. See Requires update to gradle 2.1",NULL,"Add for who this story is","well_formed","no_role","high",False
25574,"Add configuration files for hornetmq jms provider. See Requires update to gradle 2.1",NULL,"Add configuration files for hornetmq jms provider. See Requires update to gradle 2.1",NULL,"Add configuration files for hornetmq jms provider<span class='highlight-text severity-high'>. See Requires update to gradle 2.1</span>","minimal","punctuation","high",False
25579,"Investigate why netty 3.7 is in xd lib and not 3.6.6 ",NULL,"Investigate why netty 3.7 is in xd lib and not 3.6.6 ",NULL,"Add for who this story is","well_formed","no_role","high",False
25580,"Improve Logging and mention affected Module When deploying a definition with a container match criteria specified, and no container could be selected the logging is ambiguous and should mention the affected module 11 58 24,089 WARN No currently available containers match criteria somecriteria ",NULL,"Improve Logging and mention affected Module When deploying a definition with a container match criteria specified, and no container could be selected the logging is ambiguous and should mention the affected module 11 58 24,089 WARN No currently available containers match criteria somecriteria ",NULL,"Add for who this story is","well_formed","no_role","high",False
25580,"Improve Logging and mention affected Module When deploying a definition with a container match criteria specified, and no container could be selected the logging is ambiguous and should mention the affected module 11 58 24,089 WARN No currently available containers match criteria somecriteria ",NULL,"Improve Logging and mention affected Module When deploying a definition with a container match criteria specified, and no container could be selected the logging is ambiguous and should mention the affected module 11 58 24,089 WARN No currently available containers match criteria somecriteria ",NULL,"Improve Logging<span class='highlight-text severity-high'> and </span>mention affected Module When deploying a definition with a container match criteria specified, and no container could be selected the logging is ambiguous and should mention the affected module 11 58 24,089 WARN No currently available containers match criteria somecriteria ","atomic","conjunctions","high",False
25576,"Update to Spring Batch 3.0.1 snapshots ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25576,"Update to Spring Batch 3.0.1 snapshots ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25575,"Update to Spring Platform 1.0.1 ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25575,"Update to Spring Platform 1.0.1 ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25577,"Create documentation section on best practices This should include some guidance on setting rabbit message bus paramters relating to prefetch and concurrency. It should also discuss the bypass functionality or reference another section that covers it. We should probably include how to scale out http sources, e.g. the need to use a load balancer.",NULL,"Create documentation section on best practices This should include some guidance on setting rabbit message bus paramters relating to prefetch and concurrency. It should also discuss the bypass functionality or reference another section that covers it. We should probably include how to scale out http sources, e.g. the need to use a load balancer.",NULL,"Add for who this story is","well_formed","no_role","high",False
25577,"Create documentation section on best practices This should include some guidance on setting rabbit message bus paramters relating to prefetch and concurrency. It should also discuss the bypass functionality or reference another section that covers it. We should probably include how to scale out http sources, e.g. the need to use a load balancer.",NULL,"Create documentation section on best practices This should include some guidance on setting rabbit message bus paramters relating to prefetch and concurrency. It should also discuss the bypass functionality or reference another section that covers it. We should probably include how to scale out http sources, e.g. the need to use a load balancer.",NULL,"Create documentation section on best practices This should include some guidance on setting rabbit message bus paramters relating to prefetch<span class='highlight-text severity-high'> and </span>concurrency. It should also discuss the bypass functionality<span class='highlight-text severity-high'> or </span>reference another section that covers it. We should probably include how to scale out http sources, e.g. the need to use a load balancer.","atomic","conjunctions","high",False
25577,"Create documentation section on best practices This should include some guidance on setting rabbit message bus paramters relating to prefetch and concurrency. It should also discuss the bypass functionality or reference another section that covers it. We should probably include how to scale out http sources, e.g. the need to use a load balancer.",NULL,"Create documentation section on best practices This should include some guidance on setting rabbit message bus paramters relating to prefetch and concurrency. It should also discuss the bypass functionality or reference another section that covers it. We should probably include how to scale out http sources, e.g. the need to use a load balancer.",NULL,"Create documentation section on best practices This should include some guidance on setting rabbit message bus paramters relating to prefetch and concurrency<span class='highlight-text severity-high'>. It should also discuss the bypass functionality or reference another section that covers it. We should probably include how to scale out http sources, e.g. the need to use a load balancer.</span>","minimal","punctuation","high",False
25550,"Consolidate REST endpoints for batch resources under jobs currently we have batch and jobs. Everything should move to jobs. See for details.",NULL,"Consolidate REST endpoints for batch resources under jobs currently we have batch and jobs. Everything should move to jobs. See for details.",NULL,"Add for who this story is","well_formed","no_role","high",False
25550,"Consolidate REST endpoints for batch resources under jobs currently we have batch and jobs. Everything should move to jobs. See for details.",NULL,"Consolidate REST endpoints for batch resources under jobs currently we have batch and jobs. Everything should move to jobs. See for details.",NULL,"Consolidate REST endpoints for batch resources under jobs currently we have batch and jobs<span class='highlight-text severity-high'>. Everything should move to jobs. See for details.</span>","minimal","punctuation","high",False
25551,"Refactor StreamServer to an interface and create Redis and Local implementations The current StreamServer depends on Call this RedisStreamServer and extract interface to allow alternate implementations",NULL,"Refactor StreamServer to an interface and create Redis and Local implementations The current StreamServer depends on Call this RedisStreamServer and extract interface to allow alternate implementations",NULL,"Add for who this story is","well_formed","no_role","high",False
25551,"Refactor StreamServer to an interface and create Redis and Local implementations The current StreamServer depends on Call this RedisStreamServer and extract interface to allow alternate implementations",NULL,"Refactor StreamServer to an interface and create Redis and Local implementations The current StreamServer depends on Call this RedisStreamServer and extract interface to allow alternate implementations",NULL,"Refactor StreamServer to an interface<span class='highlight-text severity-high'> and </span>create Redis and Local implementations The current StreamServer depends on Call this RedisStreamServer and extract interface to allow alternate implementations","atomic","conjunctions","high",False
25552,"Tap Fixture refactoring The Tap fixture does not need to inherit from Replace moduleName method with moduleToTap. The current tap syntax is and not as currently implemented by the label fixture. ",NULL,"Tap Fixture refactoring The Tap fixture does not need to inherit from Replace moduleName method with moduleToTap. The current tap syntax is and not as currently implemented by the label fixture. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25552,"Tap Fixture refactoring The Tap fixture does not need to inherit from Replace moduleName method with moduleToTap. The current tap syntax is and not as currently implemented by the label fixture. ",NULL,"Tap Fixture refactoring The Tap fixture does not need to inherit from Replace moduleName method with moduleToTap. The current tap syntax is and not as currently implemented by the label fixture. ",NULL,"Tap Fixture refactoring The Tap fixture does not need to inherit from Replace moduleName method with moduleToTap. The current tap syntax is<span class='highlight-text severity-high'> and </span>not as currently implemented by the label fixture. ","atomic","conjunctions","high",False
25552,"Tap Fixture refactoring The Tap fixture does not need to inherit from Replace moduleName method with moduleToTap. The current tap syntax is and not as currently implemented by the label fixture. ",NULL,"Tap Fixture refactoring The Tap fixture does not need to inherit from Replace moduleName method with moduleToTap. The current tap syntax is and not as currently implemented by the label fixture. ",NULL,"Tap Fixture refactoring The Tap fixture does not need to inherit from Replace moduleName method with moduleToTap<span class='highlight-text severity-high'>. The current tap syntax is and not as currently implemented by the label fixture. </span>","minimal","punctuation","high",False
25553,"Update to use SHDP 2.0.0.RELEASE ",NULL,"Update to use SHDP 2.0.0.RELEASE ",NULL,"Add for who this story is","well_formed","no_role","high",False
25554,"Add option to specify fsUri to hdfs sinks We should have an fsUri parameter for hdfs and hdfs dataset sinks so we can write to different file systems hdfs, webhdfs ",NULL,"Add option to specify fsUri to hdfs sinks We should have an fsUri parameter for hdfs and hdfs dataset sinks","so we can write to different file systems hdfs, webhdfs","Add for who this story is","well_formed","no_role","high",False
26785,"Parser needs to handle a embedded in a name. Also drop the enhanced portion of the ",NULL,"Parser needs to handle a embedded in a name. Also drop the enhanced portion of the ",NULL,"Parser needs to handle a embedded in a name<span class='highlight-text severity-high'>. Also drop the enhanced portion of the </span>","minimal","punctuation","high",False
25554,"Add option to specify fsUri to hdfs sinks We should have an fsUri parameter for hdfs and hdfs dataset sinks so we can write to different file systems hdfs, webhdfs ",NULL,"Add option to specify fsUri to hdfs sinks We should have an fsUri parameter for hdfs and hdfs dataset sinks","so we can write to different file systems hdfs, webhdfs","Add option to specify fsUri to hdfs sinks We should have an fsUri parameter for hdfs<span class='highlight-text severity-high'> and </span>hdfs dataset sinks so we can write to different file systems hdfs, webhdfs ","atomic","conjunctions","high",False
25554,"Add option to specify fsUri to hdfs sinks We should have an fsUri parameter for hdfs and hdfs dataset sinks so we can write to different file systems hdfs, webhdfs ",NULL,"Add option to specify fsUri to hdfs sinks We should have an fsUri parameter for hdfs and hdfs dataset sinks","so we can write to different file systems hdfs, webhdfs","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25555,"Provide error location when tapping inexistent stream module See impacted code at ",NULL,"Provide error location when tapping inexistent stream module See impacted code at ",NULL,"Add for who this story is","well_formed","no_role","high",False
26476,"Add undeployed status for k8s SPI As a developer, I'd like to add state.",NULL,"Add undeployed status for k8s SPI As a developer, I'd like to add state.",NULL,"Add for who this story is","well_formed","no_role","high",False
26477,"Add undeployed status for Mesos SPI As a developer, I'd like to add state.",NULL,"Add undeployed status for Mesos SPI As a developer, I'd like to add state.",NULL,"Add for who this story is","well_formed","no_role","high",False
26480,"Optimize YARN deployer As a developer, I'd like to optimize YARN deployer, so I can deploy stream and the modules part of the definition rapidly.",NULL,"Optimize YARN deployer As a developer, I'd like to optimize YARN deployer,","so I can deploy stream and the modules part of the definition rapidly.","Add for who this story is","well_formed","no_role","high",False
26480,"Optimize YARN deployer As a developer, I'd like to optimize YARN deployer, so I can deploy stream and the modules part of the definition rapidly.",NULL,"Optimize YARN deployer As a developer, I'd like to optimize YARN deployer,","so I can deploy stream and the modules part of the definition rapidly.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26479,"Improve Server Configuration Database Configuration section Make it more clear what drivers need to be copied where. See ",NULL,"Improve Server Configuration Database Configuration section Make it more clear what drivers need to be copied where. See ",NULL,"Add for who this story is","well_formed","no_role","high",False
26479,"Improve Server Configuration Database Configuration section Make it more clear what drivers need to be copied where. See ",NULL,"Improve Server Configuration Database Configuration section Make it more clear what drivers need to be copied where. See ",NULL,"Improve Server Configuration Database Configuration section Make it more clear what drivers need to be copied where<span class='highlight-text severity-high'>. See </span>","minimal","punctuation","high",False
26554,"Add an MQTT Sink ",NULL,"Add an MQTT Sink ",NULL,"Add for who this story is","well_formed","no_role","high",False
26559,"Use wants the ability to persist Trigger Context ",NULL,"Use wants the ability to persist Trigger Context ",NULL,"Add for who this story is","well_formed","no_role","high",False
26556,"The user needs the ability to set up a misfire policy for a Trigger 2 options are 1 Fire the trigger immediate Launch the job when trigger can gather the resources necessary start the job 2 Do nothing Ignore this job fire time and catch this scenario can occur if XD is down or resources threads are not available at the time a job is to be launched. ",NULL,"The user needs the ability to set up a misfire policy for a Trigger 2 options are 1 Fire the trigger immediate Launch the job when trigger can gather the resources necessary start the job 2 Do nothing Ignore this job fire time and catch this scenario can occur if XD is down or resources threads are not available at the time a job is to be launched. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26556,"The user needs the ability to set up a misfire policy for a Trigger 2 options are 1 Fire the trigger immediate Launch the job when trigger can gather the resources necessary start the job 2 Do nothing Ignore this job fire time and catch this scenario can occur if XD is down or resources threads are not available at the time a job is to be launched. ",NULL,"The user needs the ability to set up a misfire policy for a Trigger 2 options are 1 Fire the trigger immediate Launch the job when trigger can gather the resources necessary start the job 2 Do nothing Ignore this job fire time and catch this scenario can occur if XD is down or resources threads are not available at the time a job is to be launched. ",NULL,"The user needs the ability to set up a misfire policy for a Trigger 2 options are 1 Fire the trigger immediate Launch the job when trigger can gather the resources necessary start the job 2 Do nothing Ignore this job fire time<span class='highlight-text severity-high'> and </span>catch this scenario can occur if XD is down<span class='highlight-text severity-high'> or </span>resources threads are not available at the time a job is to be launched. ","atomic","conjunctions","high",False
26558,"User wants the ability to persist the final state of a job success or failure ",NULL,"User wants the ability to persist the final state of a job success or failure ",NULL,"Add for who this story is","well_formed","no_role","high",False
26560,"User wants the ability to persist the state of a Trigger Instance ",NULL,"User wants the ability to persist the state of a Trigger Instance ",NULL,"Add for who this story is","well_formed","no_role","high",False
26561,"User wants the ability to limit the total number of jobs a trigger can have running simultaneously ",NULL,"User wants the ability to limit the total number of jobs a trigger can have running simultaneously ",NULL,"Add for who this story is","well_formed","no_role","high",False
26562,"User wants the ability to limit the total number of jobs running simultaneously ",NULL,"User wants the ability to limit the total number of jobs running simultaneously ",NULL,"Add for who this story is","well_formed","no_role","high",False
26563,"User wants to setup a priority for triggers. In the case that there are not enough resources to fire a trigger, the highest priority will be fired first.",NULL,"User wants to setup a priority for triggers. In the case that there are not enough resources to fire a trigger, the highest priority will be fired first.",NULL,"Add for who this story is","well_formed","no_role","high",False
26563,"User wants to setup a priority for triggers. In the case that there are not enough resources to fire a trigger, the highest priority will be fired first.",NULL,"User wants to setup a priority for triggers. In the case that there are not enough resources to fire a trigger, the highest priority will be fired first.",NULL,"User wants to setup a priority for triggers<span class='highlight-text severity-high'>. In the case that there are not enough resources to fire a trigger, the highest priority will be fired first.</span>","minimal","punctuation","high",False
26564,"User wants the ability to exclude certain days like holidays for a trigger to fire. Commonly called Calendar support ",NULL,"User wants the ability to exclude certain days like holidays for a trigger to fire. Commonly called Calendar support ",NULL,"Add for who this story is","well_formed","no_role","high",False
26564,"User wants the ability to exclude certain days like holidays for a trigger to fire. Commonly called Calendar support ",NULL,"User wants the ability to exclude certain days like holidays for a trigger to fire. Commonly called Calendar support ",NULL,"User wants the ability to exclude certain days like holidays for a trigger to fire<span class='highlight-text severity-high'>. Commonly called Calendar support </span>","minimal","punctuation","high",False
26481,"Add Timestamp to XD Message History I don t recall why this commit was not applied to master but having the timestamp for each step in the history will be useful. See this github issue ",NULL,"Add Timestamp to XD Message History I don t recall why this commit was not applied to master but having the timestamp for each step in the history will be useful. See this github issue ",NULL,"Add for who this story is","well_formed","no_role","high",False
26481,"Add Timestamp to XD Message History I don t recall why this commit was not applied to master but having the timestamp for each step in the history will be useful. See this github issue ",NULL,"Add Timestamp to XD Message History I don t recall why this commit was not applied to master but having the timestamp for each step in the history will be useful. See this github issue ",NULL,"Add Timestamp to XD Message History I don t recall why this commit was not applied to master but having the timestamp for each step in the history will be useful<span class='highlight-text severity-high'>. See this github issue </span>","minimal","punctuation","high",False
26483,"Gradle based multi project build multi project build. look to Spring Framework for source of starting point.",NULL,"Gradle based multi project build multi project build. look to Spring Framework for source of starting point.",NULL,"Add for who this story is","well_formed","no_role","high",False
26483,"Gradle based multi project build multi project build. look to Spring Framework for source of starting point.",NULL,"Gradle based multi project build multi project build. look to Spring Framework for source of starting point.",NULL,"Gradle based multi project build multi project build<span class='highlight-text severity-high'>. look to Spring Framework for source of starting point.</span>","minimal","punctuation","high",False
26482,"Upgrade to SI 4.2.2.GA As a developer, I'd like to upgrade to SI 4.2.2.GA release, so I can leverage the latest improvements.",NULL,"Upgrade to SI 4.2.2.GA As a developer, I'd like to upgrade to SI 4.2.2.GA release,","so I can leverage the latest improvements.","Add for who this story is","well_formed","no_role","high",False
26482,"Upgrade to SI 4.2.2.GA As a developer, I'd like to upgrade to SI 4.2.2.GA release, so I can leverage the latest improvements.",NULL,"Upgrade to SI 4.2.2.GA As a developer, I'd like to upgrade to SI 4.2.2.GA release,","so I can leverage the latest improvements.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26726,"Add Simple Batch Sample to Spring XD Samples repo This example should require no code. Just the basic XML.",NULL,"Add Simple Batch Sample to Spring XD Samples repo This example should require no code. Just the basic XML.",NULL,"Add for who this story is","well_formed","no_role","high",False
26726,"Add Simple Batch Sample to Spring XD Samples repo This example should require no code. Just the basic XML.",NULL,"Add Simple Batch Sample to Spring XD Samples repo This example should require no code. Just the basic XML.",NULL,"Add Simple Batch Sample to Spring XD Samples repo This example should require no code<span class='highlight-text severity-high'>. Just the basic XML.</span>","minimal","punctuation","high",False
26485,"Improve Shell Connection Diagnostics When a problem occurs connecting to admin, we just get even if the connection is successful and some problem occurs when interpreting the result. The exception is eaten. Log an error including the exception. Currently investigating an NPE in DataFlowTemplate line 77.",NULL,"Improve Shell Connection Diagnostics When a problem occurs connecting to admin, we just get even if the connection is successful and some problem occurs when interpreting the result. The exception is eaten. Log an error including the exception. Currently investigating an NPE in DataFlowTemplate line 77.",NULL,"Add for who this story is","well_formed","no_role","high",False
26485,"Improve Shell Connection Diagnostics When a problem occurs connecting to admin, we just get even if the connection is successful and some problem occurs when interpreting the result. The exception is eaten. Log an error including the exception. Currently investigating an NPE in DataFlowTemplate line 77.",NULL,"Improve Shell Connection Diagnostics When a problem occurs connecting to admin, we just get even if the connection is successful and some problem occurs when interpreting the result. The exception is eaten. Log an error including the exception. Currently investigating an NPE in DataFlowTemplate line 77.",NULL,"Improve Shell Connection Diagnostics When a problem occurs connecting to admin, we just get even if the connection is successful<span class='highlight-text severity-high'> and </span>some problem occurs when interpreting the result. The exception is eaten. Log an error including the exception. Currently investigating an NPE in DataFlowTemplate line 77.","atomic","conjunctions","high",False
26485,"Improve Shell Connection Diagnostics When a problem occurs connecting to admin, we just get even if the connection is successful and some problem occurs when interpreting the result. The exception is eaten. Log an error including the exception. Currently investigating an NPE in DataFlowTemplate line 77.",NULL,"Improve Shell Connection Diagnostics When a problem occurs connecting to admin, we just get even if the connection is successful and some problem occurs when interpreting the result. The exception is eaten. Log an error including the exception. Currently investigating an NPE in DataFlowTemplate line 77.",NULL,"Improve Shell Connection Diagnostics When a problem occurs connecting to admin, we just get even if the connection is successful and some problem occurs when interpreting the result<span class='highlight-text severity-high'>. The exception is eaten. Log an error including the exception. Currently investigating an NPE in DataFlowTemplate line 77.</span>","minimal","punctuation","high",False
26727,"DSL Parser should check for invalid stream parameters See ",NULL,"DSL Parser should check for invalid stream parameters See ",NULL,"Add for who this story is","well_formed","no_role","high",False
26565,"The user needs the ability to pause and resume triggers ad hoc. A pause means that a trigger will wait to fire its job until after the pause is removed. It does not apply the misfire behavior. ",NULL,"The user needs the ability to pause and resume triggers ad hoc. A pause means that a trigger will wait to fire its job until after the pause is removed. It does not apply the misfire behavior. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26565,"The user needs the ability to pause and resume triggers ad hoc. A pause means that a trigger will wait to fire its job until after the pause is removed. It does not apply the misfire behavior. ",NULL,"The user needs the ability to pause and resume triggers ad hoc. A pause means that a trigger will wait to fire its job until after the pause is removed. It does not apply the misfire behavior. ",NULL,"The user needs the ability to pause<span class='highlight-text severity-high'> and </span>resume triggers ad hoc. A pause means that a trigger will wait to fire its job until after the pause is removed. It does not apply the misfire behavior. ","atomic","conjunctions","high",False
26565,"The user needs the ability to pause and resume triggers ad hoc. A pause means that a trigger will wait to fire its job until after the pause is removed. It does not apply the misfire behavior. ",NULL,"The user needs the ability to pause and resume triggers ad hoc. A pause means that a trigger will wait to fire its job until after the pause is removed. It does not apply the misfire behavior. ",NULL,"The user needs the ability to pause and resume triggers ad hoc<span class='highlight-text severity-high'>. A pause means that a trigger will wait to fire its job until after the pause is removed. It does not apply the misfire behavior. </span>","minimal","punctuation","high",False
26568,"User wants a list of currently executing jobs ",NULL,"User wants a list of currently executing jobs ",NULL,"Add for who this story is","well_formed","no_role","high",False
26567,"User wants to be able to know what triggers are associated with a job ",NULL,"User wants to be able to know what triggers are associated with a job ",NULL,"Add for who this story is","well_formed","no_role","high",False
26777,"Fix Class Package Tangle Introduced by XD 353 and stopped . ",NULL,"Fix Class Package Tangle Introduced by XD 353 and stopped . ",NULL,"Add for who this story is","well_formed","no_role","high",False
26777,"Fix Class Package Tangle Introduced by XD 353 and stopped . ",NULL,"Fix Class Package Tangle Introduced by XD 353 and stopped . ",NULL,"Fix Class Package Tangle Introduced by XD 353<span class='highlight-text severity-high'> and </span>stopped . ","atomic","conjunctions","high",False
26782,"Make Spring XD buildable with Java 8 JavaDoc issues are causing the build to fail with Java 8",NULL,"Make Spring XD buildable with Java 8 JavaDoc issues are causing the build to fail with Java 8",NULL,"Add for who this story is","well_formed","no_role","high",False
26779,"The xd singlenode script should have execute permissions The xd singlenode script currently has 644 permissions unlike xd admin and xd container which have 755 rwxr xr x 1 mark staff 5899 Aug 26 16 19 xd admin rwxr xr x 1 mark staff 5955 Aug 26 16 19 xd container rw r r 1 mark staff 5919 Aug 26 16 19 xd singlenode ",NULL,"The xd singlenode script should have execute permissions The xd singlenode script currently has 644 permissions unlike xd admin and xd container which have 755 rwxr xr x 1 mark staff 5899 Aug 26 16 19 xd admin rwxr xr x 1 mark staff 5955 Aug 26 16 19 xd container rw r r 1 mark staff 5919 Aug 26 16 19 xd singlenode ",NULL,"Add for who this story is","well_formed","no_role","high",False
26779,"The xd singlenode script should have execute permissions The xd singlenode script currently has 644 permissions unlike xd admin and xd container which have 755 rwxr xr x 1 mark staff 5899 Aug 26 16 19 xd admin rwxr xr x 1 mark staff 5955 Aug 26 16 19 xd container rw r r 1 mark staff 5919 Aug 26 16 19 xd singlenode ",NULL,"The xd singlenode script should have execute permissions The xd singlenode script currently has 644 permissions unlike xd admin and xd container which have 755 rwxr xr x 1 mark staff 5899 Aug 26 16 19 xd admin rwxr xr x 1 mark staff 5955 Aug 26 16 19 xd container rw r r 1 mark staff 5919 Aug 26 16 19 xd singlenode ",NULL,"The xd singlenode script should have execute permissions The xd singlenode script currently has 644 permissions unlike xd admin<span class='highlight-text severity-high'> and </span>xd container which have 755 rwxr xr x 1 mark staff 5899 Aug 26 16 19 xd admin rwxr xr x 1 mark staff 5955 Aug 26 16 19 xd container rw r r 1 mark staff 5919 Aug 26 16 19 xd singlenode ","atomic","conjunctions","high",False
26781,"Fix Package Tangle between o.s.xd.dirt.event and ",NULL,"Fix Package Tangle between o.s.xd.dirt.event and ",NULL,"Add for who this story is","well_formed","no_role","high",False
26783,"Add Spring XD Build Plan for Java 8 to Bamboo This is issue depends on XD 761 ",NULL,"Add Spring XD Build Plan for Java 8 to Bamboo This is issue depends on XD 761 ",NULL,"Add for who this story is","well_formed","no_role","high",False
26784,"Remove AutoLaunch feature from batch jobs Jobs will be started via trigger. So we won t need the JobTriggerBean.",NULL,"Remove AutoLaunch feature from batch jobs Jobs will be started via trigger.","So we won t need the JobTriggerBean.","Remove AutoLaunch feature from batch jobs Jobs will be started via trigger<span class='highlight-text severity-high'>. So we won t need the JobTriggerBean.</span>","minimal","punctuation","high",False
26784,"Remove AutoLaunch feature from batch jobs Jobs will be started via trigger. So we won t need the JobTriggerBean.",NULL,"Remove AutoLaunch feature from batch jobs Jobs will be started via trigger.","So we won t need the JobTriggerBean.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26787,"Shell Add named channel list command User shall have the ability to get a listing of available named channels order by name ascending from the shell Add support to controllers Add tests",NULL,"Shell Add named channel list command User shall have the ability to get a listing of available named channels order by name ascending from the shell Add support to controllers Add tests",NULL,"Add for who this story is","well_formed","no_role","high",False
26786,"Update Batch Job docs to cover triggers as a source ",NULL,"Update Batch Job docs to cover triggers as a source ",NULL,"Add for who this story is","well_formed","no_role","high",False
26792,"Avoid use of module name twice in location when using a custom modules See ",NULL,"Avoid use of module name twice in location when using a custom modules See ",NULL,"Add for who this story is","well_formed","no_role","high",False
26790,"Document router processor module for an example, see comments here ",NULL,"Document router processor module for an example, see comments here ",NULL,"Add for who this story is","well_formed","no_role","high",False
26791,"Documentation for http file processing Put on the guide as a section in an input sources wiki page. ",NULL,"Documentation for http file processing Put on the guide as a section in an input sources wiki page. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25126,"Make deploy false as the default when creating a new job The automatic deployment of the job makes it harder to understand the lifecycle of the job and also does not allow for the opportunity to define any additional deployment metadata for how that job runs, e.g is it partitioned etc.",NULL,"Make deploy false as the default when creating a new job The automatic deployment of the job makes it harder to understand the lifecycle of the job and also does not allow for the opportunity to define any additional deployment metadata for how that job runs, e.g is it partitioned etc.",NULL,"Add for who this story is","well_formed","no_role","high",False
25126,"Make deploy false as the default when creating a new job The automatic deployment of the job makes it harder to understand the lifecycle of the job and also does not allow for the opportunity to define any additional deployment metadata for how that job runs, e.g is it partitioned etc.",NULL,"Make deploy false as the default when creating a new job The automatic deployment of the job makes it harder to understand the lifecycle of the job and also does not allow for the opportunity to define any additional deployment metadata for how that job runs, e.g is it partitioned etc.",NULL,"Make deploy false as the default when creating a new job The automatic deployment of the job makes it harder to understand the lifecycle of the job<span class='highlight-text severity-high'> and </span>also does not allow for the opportunity to define any additional deployment metadata for how that job runs, e.g is it partitioned etc.","atomic","conjunctions","high",False
25129,"Redo Hadoop distribution dependency management The way we now include various Hadoop distributions is cumbersome to maintain. Need a better way of managing and isolating these dependencies on a module level rather than container level.",NULL,"Redo Hadoop distribution dependency management The way we now include various Hadoop distributions is cumbersome to maintain. Need a better way of managing and isolating these dependencies on a module level rather than container level.",NULL,"Add for who this story is","well_formed","no_role","high",False
25129,"Redo Hadoop distribution dependency management The way we now include various Hadoop distributions is cumbersome to maintain. Need a better way of managing and isolating these dependencies on a module level rather than container level.",NULL,"Redo Hadoop distribution dependency management The way we now include various Hadoop distributions is cumbersome to maintain. Need a better way of managing and isolating these dependencies on a module level rather than container level.",NULL,"Redo Hadoop distribution dependency management The way we now include various Hadoop distributions is cumbersome to maintain. Need a better way of managing<span class='highlight-text severity-high'> and </span>isolating these dependencies on a module level rather than container level.","atomic","conjunctions","high",False
25129,"Redo Hadoop distribution dependency management The way we now include various Hadoop distributions is cumbersome to maintain. Need a better way of managing and isolating these dependencies on a module level rather than container level.",NULL,"Redo Hadoop distribution dependency management The way we now include various Hadoop distributions is cumbersome to maintain. Need a better way of managing and isolating these dependencies on a module level rather than container level.",NULL,"Redo Hadoop distribution dependency management The way we now include various Hadoop distributions is cumbersome to maintain<span class='highlight-text severity-high'>. Need a better way of managing and isolating these dependencies on a module level rather than container level.</span>","minimal","punctuation","high",False
25128,"Make Batch Job controllers HATEOAS compliant Currently, the and are not HATEOAS compliant and we need make them so.",NULL,"Make Batch Job controllers HATEOAS compliant Currently, the and are not HATEOAS compliant and we need make them so.",NULL,"Add for who this story is","well_formed","no_role","high",False
25128,"Make Batch Job controllers HATEOAS compliant Currently, the and are not HATEOAS compliant and we need make them so.",NULL,"Make Batch Job controllers HATEOAS compliant Currently, the and are not HATEOAS compliant and we need make them so.",NULL,"Make Batch Job controllers HATEOAS compliant Currently, the<span class='highlight-text severity-high'> and </span>are not HATEOAS compliant and we need make them so.","atomic","conjunctions","high",False
25130,"Integration tests for XD Installer ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25130,"Integration tests for XD Installer ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25131,"Remove use of system property xd.home to define location for install location, rely on environment variable XD HOME This is in the AdminMain and ContainerMain. Can get the environment property directly in java code unless provided explicitly on the command line using xdHomeDir.",NULL,"Remove use of system property xd.home to define location for install location, rely on environment variable XD HOME This is in the AdminMain and ContainerMain. Can get the environment property directly in java code unless provided explicitly on the command line using xdHomeDir.",NULL,"Add for who this story is","well_formed","no_role","high",False
25131,"Remove use of system property xd.home to define location for install location, rely on environment variable XD HOME This is in the AdminMain and ContainerMain. Can get the environment property directly in java code unless provided explicitly on the command line using xdHomeDir.",NULL,"Remove use of system property xd.home to define location for install location, rely on environment variable XD HOME This is in the AdminMain and ContainerMain. Can get the environment property directly in java code unless provided explicitly on the command line using xdHomeDir.",NULL,"Remove use of system property xd<span class='highlight-text severity-high'>.home to define location for install location, rely on environment variable XD HOME This is in the AdminMain and ContainerMain. Can get the environment property directly in java code unless provided explicitly on the command line using xdHomeDir.</span>","minimal","punctuation","high",False
26793,"Support a aware Module Registry It would be nice to be able to have modules that are simply made of Their context xml file Some kind of manifest that expresses dependencies and have the runtime take care of the deps",NULL,"Support a aware Module Registry It would be nice to be able to have modules that are simply made of Their context xml file Some kind of manifest that expresses dependencies and have the runtime take care of the deps",NULL,"Add for who this story is","well_formed","no_role","high",False
26793,"Support a aware Module Registry It would be nice to be able to have modules that are simply made of Their context xml file Some kind of manifest that expresses dependencies and have the runtime take care of the deps",NULL,"Support a aware Module Registry It would be nice to be able to have modules that are simply made of Their context xml file Some kind of manifest that expresses dependencies and have the runtime take care of the deps",NULL,"Support a aware Module Registry It would be nice to be able to have modules that are simply made of Their context xml file Some kind of manifest that expresses dependencies<span class='highlight-text severity-high'> and </span>have the runtime take care of the deps","atomic","conjunctions","high",False
26794,"Support higher level structure for complex module registry See discussion at ",NULL,"Support higher level structure for complex module registry See discussion at ",NULL,"Add for who this story is","well_formed","no_role","high",False
26795,"Build needs to override XD environment variables export XD HOME foo gradle clean test build fails. Need to detected environment variables and override for the build",NULL,"Build needs to override XD environment variables export XD HOME foo gradle clean test build fails. Need to detected environment variables and override for the build",NULL,"Add for who this story is","well_formed","no_role","high",False
26795,"Build needs to override XD environment variables export XD HOME foo gradle clean test build fails. Need to detected environment variables and override for the build",NULL,"Build needs to override XD environment variables export XD HOME foo gradle clean test build fails. Need to detected environment variables and override for the build",NULL,"Build needs to override XD environment variables export XD HOME foo gradle clean test build fails. Need to detected environment variables<span class='highlight-text severity-high'> and </span>override for the build","atomic","conjunctions","high",False
26795,"Build needs to override XD environment variables export XD HOME foo gradle clean test build fails. Need to detected environment variables and override for the build",NULL,"Build needs to override XD environment variables export XD HOME foo gradle clean test build fails. Need to detected environment variables and override for the build",NULL,"Build needs to override XD environment variables export XD HOME foo gradle clean test build fails<span class='highlight-text severity-high'>. Need to detected environment variables and override for the build</span>","minimal","punctuation","high",False
25134,"Add some test coverage to mqtt modules Even though it may be hard to come up with a mqtt broker, an easy test that should be automated is somesource mqtt topic foo with mqtt topics foo somesink And asserting that what is emitted to somesource ends up in somesink. ",NULL,"Add some test coverage to mqtt modules Even though it may be hard to come up with a mqtt broker, an easy test that should be automated is somesource mqtt topic foo with mqtt topics foo somesink And asserting that what is emitted to somesource ends up in somesink. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25134,"Add some test coverage to mqtt modules Even though it may be hard to come up with a mqtt broker, an easy test that should be automated is somesource mqtt topic foo with mqtt topics foo somesink And asserting that what is emitted to somesource ends up in somesink. ",NULL,"Add some test coverage to mqtt modules Even though it may be hard to come up with a mqtt broker, an easy test that should be automated is somesource mqtt topic foo with mqtt topics foo somesink And asserting that what is emitted to somesource ends up in somesink. ",NULL,"Add some test coverage to mqtt modules Even though it may be hard to come up with a mqtt broker, an easy test that should be automated is somesource mqtt topic foo with mqtt topics foo somesink<span class='highlight-text severity-high'> and </span>asserting that what is emitted to somesource ends up in somesink. ","atomic","conjunctions","high",False
25136,"Restore lax command line options Restore foo bar as well as foo bar Validation of values should be done as a separate story",NULL,"Restore lax command line options Restore foo bar as well as foo bar Validation of values should be done as a separate story",NULL,"Add for who this story is","well_formed","no_role","high",False
25133,"Create Shell Integration test fixture for jdbc related sink Would be nice to have some kind of regression testing on the jdbc sink, as it becomes more prominent in XD. Use of an in memory db where we expose eg a JdbcTemplate to assert state",NULL,"Create Shell Integration test fixture for jdbc related sink Would be nice to have some kind of regression testing on the jdbc sink, as it becomes more prominent in XD. Use of an in memory db where we expose eg a JdbcTemplate to assert state",NULL,"Add for who this story is","well_formed","no_role","high",False
25133,"Create Shell Integration test fixture for jdbc related sink Would be nice to have some kind of regression testing on the jdbc sink, as it becomes more prominent in XD. Use of an in memory db where we expose eg a JdbcTemplate to assert state",NULL,"Create Shell Integration test fixture for jdbc related sink Would be nice to have some kind of regression testing on the jdbc sink, as it becomes more prominent in XD. Use of an in memory db where we expose eg a JdbcTemplate to assert state",NULL,"Create Shell Integration test fixture for jdbc related sink Would be nice to have some kind of regression testing on the jdbc sink, as it becomes more prominent in XD<span class='highlight-text severity-high'>. Use of an in memory db where we expose eg a JdbcTemplate to assert state</span>","minimal","punctuation","high",False
25138,"Fix JobRepoTests to use different batch job repo Currently, the JobRepoTests use the same batch job repository that the XD runtime uses. Since the batch job repo doesn t delete the job instances, there would be stale data from this test. ",NULL,"Fix JobRepoTests to use different batch job repo Currently, the JobRepoTests use the same batch job repository that the XD runtime uses. Since the batch job repo doesn t delete the job instances, there would be stale data from this test. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25138,"Fix JobRepoTests to use different batch job repo Currently, the JobRepoTests use the same batch job repository that the XD runtime uses. Since the batch job repo doesn t delete the job instances, there would be stale data from this test. ",NULL,"Fix JobRepoTests to use different batch job repo Currently, the JobRepoTests use the same batch job repository that the XD runtime uses. Since the batch job repo doesn t delete the job instances, there would be stale data from this test. ",NULL,"Fix JobRepoTests to use different batch job repo Currently, the JobRepoTests use the same batch job repository that the XD runtime uses<span class='highlight-text severity-high'>. Since the batch job repo doesn t delete the job instances, there would be stale data from this test. </span>","minimal","punctuation","high",False
25137,"Provide cmdline options validation Wherever they come from cmd line args or ENV VARS , options such as transport, analytics, etc should be validated and issues should be reported to users",NULL,"Provide cmdline options validation Wherever they come from cmd line args or ENV VARS , options such as transport, analytics, etc should be validated and issues should be reported to users",NULL,"Add for who this story is","well_formed","no_role","high",False
25137,"Provide cmdline options validation Wherever they come from cmd line args or ENV VARS , options such as transport, analytics, etc should be validated and issues should be reported to users",NULL,"Provide cmdline options validation Wherever they come from cmd line args or ENV VARS , options such as transport, analytics, etc should be validated and issues should be reported to users",NULL,"Provide cmdline options validation Wherever they come from cmd line args<span class='highlight-text severity-high'> or </span>ENV VARS , options such as transport, analytics, etc should be validated<span class='highlight-text severity-high'> and </span>issues should be reported to users","atomic","conjunctions","high",False
25141,"We no longer validate the hadoopDistro options in the xd scripts We no longer validate the hadoopDistro options in the xd scripts. Seem sthe classes doing this validation were removed for boot. We do this validation in the xd shell script",NULL,"We no longer validate the hadoopDistro options in the xd scripts We no longer validate the hadoopDistro options in the xd scripts. Seem sthe classes doing this validation were removed for boot. We do this validation in the xd shell script",NULL,"Add for who this story is","well_formed","no_role","high",False
25141,"We no longer validate the hadoopDistro options in the xd scripts We no longer validate the hadoopDistro options in the xd scripts. Seem sthe classes doing this validation were removed for boot. We do this validation in the xd shell script",NULL,"We no longer validate the hadoopDistro options in the xd scripts We no longer validate the hadoopDistro options in the xd scripts. Seem sthe classes doing this validation were removed for boot. We do this validation in the xd shell script",NULL,"We no longer validate the hadoopDistro options in the xd scripts We no longer validate the hadoopDistro options in the xd scripts<span class='highlight-text severity-high'>. Seem sthe classes doing this validation were removed for boot. We do this validation in the xd shell script</span>","minimal","punctuation","high",False
25139,"Clear Redis after tests The following keys remain after running the test suite redis 127.0.0.1 6379 keys 1 containers 2 ",NULL,"Clear Redis after tests The following keys remain after running the test suite redis 127.0.0.1 6379 keys 1 containers 2 ",NULL,"Add for who this story is","well_formed","no_role","high",False
25142,"Add documentation about message store to aggregator doco ",NULL,"Add documentation about message store to aggregator doco ",NULL,"Add for who this story is","well_formed","no_role","high",False
25143,"Add bash based scripts of simple module create to ",NULL,"Add bash based scripts of simple module create to ",NULL,"Add for who this story is","well_formed","no_role","high",False
25144,"Add starting of newly build XD server, running of smoketest bash script, and killing of XD server to CI test ",NULL,"Add starting of newly build XD server, running of smoketest bash script, and killing of XD server to CI test ",NULL,"Add for who this story is","well_formed","no_role","high",False
25145,"Create scripts for batch DB creation We need to create a shell script that calls the batch DB creation sql files for the JDBC option selected. ",NULL,"Create scripts for batch DB creation We need to create a shell script that calls the batch DB creation sql files for the JDBC option selected. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25149,"Add jmxPort to list of coerced cmd line options Following merge of XD 1109. See discussion at ",NULL,"Add jmxPort to list of coerced cmd line options Following merge of XD 1109. See discussion at ",NULL,"Add for who this story is","well_formed","no_role","high",False
25149,"Add jmxPort to list of coerced cmd line options Following merge of XD 1109. See discussion at ",NULL,"Add jmxPort to list of coerced cmd line options Following merge of XD 1109. See discussion at ",NULL,"Add jmxPort to list of coerced cmd line options Following merge of XD 1109<span class='highlight-text severity-high'>. See discussion at </span>","minimal","punctuation","high",False
25147,"Standardize handling We should we centrally standardize on date time formats so that we don t create inconsistencies, and follow ISO 8601 internally. Internally we should only work with UTC or make that the default config option . Ultimately, whatever the user sees is just a formatting concern.",NULL,"Standardize handling We should we centrally standardize on date time formats","so that we don t create inconsistencies, and follow ISO 8601 internally. Internally we should only work with UTC or make that the default config option . Ultimately, whatever the user sees is just a formatting concern.","Standardize handling We should we centrally standardize on date time formats so that we don t create inconsistencies, and follow ISO 8601 internally<span class='highlight-text severity-high'>. Internally we should only work with UTC or make that the default config option . Ultimately, whatever the user sees is just a formatting concern.</span>","minimal","punctuation","high",False
25147,"Standardize handling We should we centrally standardize on date time formats so that we don t create inconsistencies, and follow ISO 8601 internally. Internally we should only work with UTC or make that the default config option . Ultimately, whatever the user sees is just a formatting concern.",NULL,"Standardize handling We should we centrally standardize on date time formats","so that we don t create inconsistencies, and follow ISO 8601 internally. Internally we should only work with UTC or make that the default config option . Ultimately, whatever the user sees is just a formatting concern.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25150,"Add profile activation on top of XD 953 ",NULL,"Add profile activation on top of XD 953 ",NULL,"Add for who this story is","well_formed","no_role","high",False
25146,"Update XD to Use SI 3.0.0.M2 ",NULL,"Update XD to Use SI 3.0.0.M2 ",NULL,"Add for who this story is","well_formed","no_role","high",False
25140,"Add port scan and ability to disable to container launcher Spring Boot support port scanning if you set server.port 0 and disable with 1 , so we could make that the default for the container node.",NULL,"Add port scan and ability to disable to container launcher Spring Boot support port scanning if you set server.port 0 and disable with 1 ,","so we could make that the default for the container node.","Add for who this story is","well_formed","no_role","high",False
25140,"Add port scan and ability to disable to container launcher Spring Boot support port scanning if you set server.port 0 and disable with 1 , so we could make that the default for the container node.",NULL,"Add port scan and ability to disable to container launcher Spring Boot support port scanning if you set server.port 0 and disable with 1 ,","so we could make that the default for the container node.","Add port scan<span class='highlight-text severity-high'> and </span>ability to disable to container launcher Spring Boot support port scanning if you set server.port 0 and disable with 1 , so we could make that the default for the container node.","atomic","conjunctions","high",False
25140,"Add port scan and ability to disable to container launcher Spring Boot support port scanning if you set server.port 0 and disable with 1 , so we could make that the default for the container node.",NULL,"Add port scan and ability to disable to container launcher Spring Boot support port scanning if you set server.port 0 and disable with 1 ,","so we could make that the default for the container node.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25168,"add SpEL transform processor It should provide an expression param for SpEL and have a default pass thru of the payload.",NULL,"add SpEL transform processor It should provide an expression param for SpEL and have a default pass thru of the payload.",NULL,"Add for who this story is","well_formed","no_role","high",False
25168,"add SpEL transform processor It should provide an expression param for SpEL and have a default pass thru of the payload.",NULL,"add SpEL transform processor It should provide an expression param for SpEL and have a default pass thru of the payload.",NULL,"add SpEL transform processor It should provide an expression param for SpEL<span class='highlight-text severity-high'> and </span>have a default pass thru of the payload.","atomic","conjunctions","high",False
25170,"Apply Composite GoF pattern to ModuleDefinition ",NULL,"Apply Composite GoF pattern to ModuleDefinition ",NULL,"Add for who this story is","well_formed","no_role","high",False
25171,"Step execution progress Shell command to use coherent Id Instead of using jobExecutionId and stepExecutionId as two separate options for the job execution step progress command, we can have a single option with id mentioned as ",NULL,"Step execution progress Shell command to use coherent Id Instead of using jobExecutionId and stepExecutionId as two separate options for the job execution step progress command, we can have a single option with id mentioned as ",NULL,"Add for who this story is","well_formed","no_role","high",False
25171,"Step execution progress Shell command to use coherent Id Instead of using jobExecutionId and stepExecutionId as two separate options for the job execution step progress command, we can have a single option with id mentioned as ",NULL,"Step execution progress Shell command to use coherent Id Instead of using jobExecutionId and stepExecutionId as two separate options for the job execution step progress command, we can have a single option with id mentioned as ",NULL,"Step execution progress Shell command to use coherent Id Instead of using jobExecutionId<span class='highlight-text severity-high'> and </span>stepExecutionId as two separate options for the job execution step progress command, we can have a single option with id mentioned as ","atomic","conjunctions","high",False
25172,"Fix Tail Source to Use Native Adapter by Default Support all available options",NULL,"Fix Tail Source to Use Native Adapter by Default Support all available options",NULL,"Add for who this story is","well_formed","no_role","high",False
25169,"Update docs for separate control and data transport ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25169,"Update docs for separate control and data transport ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25198,"Align filehdfs batch job defaults with those of corresponding hdfs sink The batch jobs use different defaults compared to some of the sink source modules. filehdfs puts data in a data directory with files named after the stream using a .log file extension. The hdfs sink puts files in an xd streamname directory using .txt as the default file extension. filehdfs needs a more descriptive naming",NULL,"Align filehdfs batch job defaults with those of corresponding hdfs sink The batch jobs use different defaults compared to some of the sink source modules. filehdfs puts data in a data directory with files named after the stream using a .log file extension. The hdfs sink puts files in an xd streamname directory using .txt as the default file extension. filehdfs needs a more descriptive naming",NULL,"Add for who this story is","well_formed","no_role","high",False
25198,"Align filehdfs batch job defaults with those of corresponding hdfs sink The batch jobs use different defaults compared to some of the sink source modules. filehdfs puts data in a data directory with files named after the stream using a .log file extension. The hdfs sink puts files in an xd streamname directory using .txt as the default file extension. filehdfs needs a more descriptive naming",NULL,"Align filehdfs batch job defaults with those of corresponding hdfs sink The batch jobs use different defaults compared to some of the sink source modules. filehdfs puts data in a data directory with files named after the stream using a .log file extension. The hdfs sink puts files in an xd streamname directory using .txt as the default file extension. filehdfs needs a more descriptive naming",NULL,"Align filehdfs batch job defaults with those of corresponding hdfs sink The batch jobs use different defaults compared to some of the sink source modules<span class='highlight-text severity-high'>. filehdfs puts data in a data directory with files named after the stream using a .log file extension. The hdfs sink puts files in an xd streamname directory using .txt as the default file extension. filehdfs needs a more descriptive naming</span>","minimal","punctuation","high",False
25195,"Add documentation for JDBC to HDFS batch job Add docs to section ",NULL,"Add documentation for JDBC to HDFS batch job Add docs to section ",NULL,"Add for who this story is","well_formed","no_role","high",False
25197,"Add paging and sorting to Field Value Counter API see discussion at ",NULL,"Add paging and sorting to Field Value Counter API see discussion at ",NULL,"Add for who this story is","well_formed","no_role","high",False
25197,"Add paging and sorting to Field Value Counter API see discussion at ",NULL,"Add paging and sorting to Field Value Counter API see discussion at ",NULL,"Add paging<span class='highlight-text severity-high'> and </span>sorting to Field Value Counter API see discussion at ","atomic","conjunctions","high",False
25201,"Find and eliminate package level cycles across XD projects ",NULL,"Find and eliminate package level cycles across XD projects ",NULL,"Add for who this story is","well_formed","no_role","high",False
25201,"Find and eliminate package level cycles across XD projects ",NULL,"Find and eliminate package level cycles across XD projects ",NULL,"Find<span class='highlight-text severity-high'> and </span>eliminate package level cycles across XD projects ","atomic","conjunctions","high",False
25200,"Jolokia based aggregator for cluster monitoring ",NULL,"Jolokia based aggregator for cluster monitoring ",NULL,"Add for who this story is","well_formed","no_role","high",False
25196,"Update to Spring Batch 2.2.4 ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25196,"Update to Spring Batch 2.2.4 ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25199,"Fix filejdbc batch job filejdbc throws an exception Could not resolve resource location pattern class path resource cannot be resolved to URL because it does not exist This can be solved by using a prefix Maybe just update the docs? ",NULL,"Fix filejdbc batch job filejdbc throws an exception Could not resolve resource location pattern class path resource cannot be resolved to URL because it does not exist This can be solved by using a prefix Maybe just update the docs? ",NULL,"Add for who this story is","well_formed","no_role","high",False
25220,"Integrate grunt based UI build into the XD s gradle build Blog post seems to be the definitive reference....",NULL,"Integrate grunt based UI build into the XD s gradle build Blog post seems to be the definitive reference....",NULL,"Add for who this story is","well_formed","no_role","high",False
25221,"Investigate if we should use RequreJS with Angular ",NULL,"Investigate if we should use RequreJS with Angular ",NULL,"Add for who this story is","well_formed","no_role","high",False
25222,"Create EC2 AMI for single node install of Apache Hadoop 1.2.1 ",NULL,"Create EC2 AMI for single node install of Apache Hadoop 1.2.1 ",NULL,"Add for who this story is","well_formed","no_role","high",False
25223,"Create EC2 AMI for single node install of Apache Hadoop 2.2.0 ",NULL,"Create EC2 AMI for single node install of Apache Hadoop 2.2.0 ",NULL,"Add for who this story is","well_formed","no_role","high",False
25224,"Create EC2 AMI for single node install of Pivotal HD 1.1 ",NULL,"Create EC2 AMI for single node install of Pivotal HD 1.1 ",NULL,"Add for who this story is","well_formed","no_role","high",False
25225,"Create EC2 AMI for single node install of Cloudera CDH 4.5.0 ",NULL,"Create EC2 AMI for single node install of Cloudera CDH 4.5.0 ",NULL,"Add for who this story is","well_formed","no_role","high",False
25227,"Add option to stop all running XD EC2 instances that match a given naming pattern This functionality should be added as a command line option to the main app in the spring xd ec2 project",NULL,"Add option to stop all running XD EC2 instances that match a given naming pattern This functionality should be added as a command line option to the main app in the spring xd ec2 project",NULL,"Add for who this story is","well_formed","no_role","high",False
25229,"Add stage to Acceptance Test EC2 build plan that runs a basic acceptance test application against the single node deployment Run test application developed in XD 1245 ",NULL,"Add stage to Acceptance Test EC2 build plan that runs a basic acceptance test application against the single node deployment Run test application developed in XD 1245 ",NULL,"Add for who this story is","well_formed","no_role","high",False
26570,"Upgrade to spring data hadoop 1.0.1.RC1 spring data hadoop 1.0.1.RC1 provides flavors for commonly used Hadoop distros versions and we should make use of that.",NULL,"Upgrade to spring data hadoop 1.0.1.RC1 spring data hadoop 1.0.1.RC1 provides flavors for commonly used Hadoop distros versions and we should make use of that.",NULL,"Add for who this story is","well_formed","no_role","high",False
26570,"Upgrade to spring data hadoop 1.0.1.RC1 spring data hadoop 1.0.1.RC1 provides flavors for commonly used Hadoop distros versions and we should make use of that.",NULL,"Upgrade to spring data hadoop 1.0.1.RC1 spring data hadoop 1.0.1.RC1 provides flavors for commonly used Hadoop distros versions and we should make use of that.",NULL,"Upgrade to spring data hadoop 1.0.1.RC1 spring data hadoop 1.0.1.RC1 provides flavors for commonly used Hadoop distros versions<span class='highlight-text severity-high'> and </span>we should make use of that.","atomic","conjunctions","high",False
25230,"Clean shutdown of redis in xd container Need to shutdown cleanly, no exception messages are shown. Order of components in the stream should be shut down from first to last opposite of creation ",NULL,"Clean shutdown of redis in xd container Need to shutdown cleanly, no exception messages are shown. Order of components in the stream should be shut down from first to last opposite of creation ",NULL,"Add for who this story is","well_formed","no_role","high",False
25230,"Clean shutdown of redis in xd container Need to shutdown cleanly, no exception messages are shown. Order of components in the stream should be shut down from first to last opposite of creation ",NULL,"Clean shutdown of redis in xd container Need to shutdown cleanly, no exception messages are shown. Order of components in the stream should be shut down from first to last opposite of creation ",NULL,"Clean shutdown of redis in xd container Need to shutdown cleanly, no exception messages are shown<span class='highlight-text severity-high'>. Order of components in the stream should be shut down from first to last opposite of creation </span>","minimal","punctuation","high",False
25226,"Create EC2 AMI for single node install of Hortonworks Data Platform 1.3 ",NULL,"Create EC2 AMI for single node install of Hortonworks Data Platform 1.3 ",NULL,"Add for who this story is","well_formed","no_role","high",False
26571,"Create JDBC sink we need a JDBC sink for writing to HAWQ using and postgresql JDBC driver ",NULL,"Create JDBC sink we need a JDBC sink for writing to HAWQ using and postgresql JDBC driver ",NULL,"Add for who this story is","well_formed","no_role","high",False
25249,"Add caching to Will likely involve having the module identity type name be part of the OptionsMetadata identity cache key",NULL,"Add caching to Will likely involve having the module identity type name be part of the OptionsMetadata identity cache key",NULL,"Add for who this story is","well_formed","no_role","high",False
25705,"Add acceptance test to include Gemfire use case To enrich acceptance test, I'd like to have basic coverage to evaluate Gemfire use cases. An example would be to ingest data from HTTP source and write it to Gemfire server.",NULL,"Add acceptance test to include Gemfire use case To enrich acceptance test, I'd like to have basic coverage to evaluate Gemfire use cases. An example would be to ingest data from HTTP source and write it to Gemfire server.",NULL,"Add for who this story is","well_formed","no_role","high",False
25705,"Add acceptance test to include Gemfire use case To enrich acceptance test, I'd like to have basic coverage to evaluate Gemfire use cases. An example would be to ingest data from HTTP source and write it to Gemfire server.",NULL,"Add acceptance test to include Gemfire use case To enrich acceptance test, I'd like to have basic coverage to evaluate Gemfire use cases. An example would be to ingest data from HTTP source and write it to Gemfire server.",NULL,"Add acceptance test to include Gemfire use case To enrich acceptance test, I'd like to have basic coverage to evaluate Gemfire use cases. An example would be to ingest data from HTTP source<span class='highlight-text severity-high'> and </span>write it to Gemfire server.","atomic","conjunctions","high",False
25705,"Add acceptance test to include Gemfire use case To enrich acceptance test, I'd like to have basic coverage to evaluate Gemfire use cases. An example would be to ingest data from HTTP source and write it to Gemfire server.",NULL,"Add acceptance test to include Gemfire use case To enrich acceptance test, I'd like to have basic coverage to evaluate Gemfire use cases. An example would be to ingest data from HTTP source and write it to Gemfire server.",NULL,"Add acceptance test to include Gemfire use case To enrich acceptance test, I'd like to have basic coverage to evaluate Gemfire use cases<span class='highlight-text severity-high'>. An example would be to ingest data from HTTP source and write it to Gemfire server.</span>","minimal","punctuation","high",False
25708,"Add acceptance tests for FieldValueCounts and AggregateCounts To enrich acceptance tests, I'd like to have test coverage to evaluate FieldValueCounts and AggregateCounts for a given scenario.",NULL,"Add acceptance tests for FieldValueCounts and AggregateCounts To enrich acceptance tests, I'd like to have test coverage to evaluate FieldValueCounts and AggregateCounts for a given scenario.",NULL,"Add for who this story is","well_formed","no_role","high",False
25708,"Add acceptance tests for FieldValueCounts and AggregateCounts To enrich acceptance tests, I'd like to have test coverage to evaluate FieldValueCounts and AggregateCounts for a given scenario.",NULL,"Add acceptance tests for FieldValueCounts and AggregateCounts To enrich acceptance tests, I'd like to have test coverage to evaluate FieldValueCounts and AggregateCounts for a given scenario.",NULL,"Add acceptance tests for FieldValueCounts<span class='highlight-text severity-high'> and </span>AggregateCounts To enrich acceptance tests, I'd like to have test coverage to evaluate FieldValueCounts and AggregateCounts for a given scenario.","atomic","conjunctions","high",False
25707,"Exclude DB initialization for JDBC sink test To enrich acceptance test, I'd like to lazy initialize DB for JDBC Sink acceptance tests. Check to see if it is already initialized and decide. ",NULL,"Exclude DB initialization for JDBC sink test To enrich acceptance test, I'd like to lazy initialize DB for JDBC Sink acceptance tests. Check to see if it is already initialized and decide. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25215,"XD that has empty MANIFEST file. This build directory also gets copied into the bundle after dist .",NULL,"XD that has empty MANIFEST file. This build directory also gets copied into the bundle after dist .",NULL,"XD that has empty MANIFEST file<span class='highlight-text severity-high'>. This build directory also gets copied into the bundle after dist .</span>","minimal","punctuation","high",False
25707,"Exclude DB initialization for JDBC sink test To enrich acceptance test, I'd like to lazy initialize DB for JDBC Sink acceptance tests. Check to see if it is already initialized and decide. ",NULL,"Exclude DB initialization for JDBC sink test To enrich acceptance test, I'd like to lazy initialize DB for JDBC Sink acceptance tests. Check to see if it is already initialized and decide. ",NULL,"Exclude DB initialization for JDBC sink test To enrich acceptance test, I'd like to lazy initialize DB for JDBC Sink acceptance tests. Check to see if it is already initialized<span class='highlight-text severity-high'> and </span>decide. ","atomic","conjunctions","high",False
25707,"Exclude DB initialization for JDBC sink test To enrich acceptance test, I'd like to lazy initialize DB for JDBC Sink acceptance tests. Check to see if it is already initialized and decide. ",NULL,"Exclude DB initialization for JDBC sink test To enrich acceptance test, I'd like to lazy initialize DB for JDBC Sink acceptance tests. Check to see if it is already initialized and decide. ",NULL,"Exclude DB initialization for JDBC sink test To enrich acceptance test, I'd like to lazy initialize DB for JDBC Sink acceptance tests<span class='highlight-text severity-high'>. Check to see if it is already initialized and decide. </span>","minimal","punctuation","high",False
25709,"Add stress test To enrich acceptance test coverage, I'd like to have stress test scenario that includes ingesting data from HTTP and then writing it to Log sink.",NULL,"Add stress test To enrich acceptance test coverage, I'd like to have stress test scenario that includes ingesting data from HTTP and then writing it to Log sink.",NULL,"Add for who this story is","well_formed","no_role","high",False
25709,"Add stress test To enrich acceptance test coverage, I'd like to have stress test scenario that includes ingesting data from HTTP and then writing it to Log sink.",NULL,"Add stress test To enrich acceptance test coverage, I'd like to have stress test scenario that includes ingesting data from HTTP and then writing it to Log sink.",NULL,"Add stress test To enrich acceptance test coverage, I'd like to have stress test scenario that includes ingesting data from HTTP<span class='highlight-text severity-high'> and </span>then writing it to Log sink.","atomic","conjunctions","high",False
25093,"Migrate to SI Redis Queue and Topic Adapters ",NULL,"Migrate to SI Redis Queue and Topic Adapters ",NULL,"Add for who this story is","well_formed","no_role","high",False
25092,"UI Do not hard code server url Specify the default URL as urlRoot ? location.port ",NULL,"UI Do not hard code server url Specify the default URL as urlRoot ? location.port ",NULL,"Add for who this story is","well_formed","no_role","high",False
25092,"UI Do not hard code server url Specify the default URL as urlRoot ? location.port ",NULL,"UI Do not hard code server url Specify the default URL as urlRoot ? location.port ",NULL,"UI Do not hard code server url Specify the default URL as urlRoot <span class='highlight-text severity-high'>? location.port </span>","minimal","punctuation","high",False
25085,"Create XDContainer class to start stream server Provide optional command line arg to embed the container launcher, aka xd admin server. XDContainer.sh embeddAdmin",NULL,"Create XDContainer class to start stream server Provide optional command line arg to embed the container launcher, aka xd admin server. XDContainer.sh embeddAdmin",NULL,"Add for who this story is","well_formed","no_role","high",False
25085,"Create XDContainer class to start stream server Provide optional command line arg to embed the container launcher, aka xd admin server. XDContainer.sh embeddAdmin",NULL,"Create XDContainer class to start stream server Provide optional command line arg to embed the container launcher, aka xd admin server. XDContainer.sh embeddAdmin",NULL,"Create XDContainer class to start stream server Provide optional command line arg to embed the container launcher, aka xd admin server<span class='highlight-text severity-high'>. XDContainer.sh embeddAdmin</span>","minimal","punctuation","high",False
25088,"Switch module list to horizontal display The module list command currently has a very simplistic two column display of module name, module type . The is not very readable. Switch to a 4 column display Sources, Processors, Sinks, Jobs Additionally, mark composed module e.g. myhttp c ",NULL,"Switch module list to horizontal display The module list command currently has a very simplistic two column display of module name, module type . The is not very readable. Switch to a 4 column display Sources, Processors, Sinks, Jobs Additionally, mark composed module e.g. myhttp c ",NULL,"Add for who this story is","well_formed","no_role","high",False
25088,"Switch module list to horizontal display The module list command currently has a very simplistic two column display of module name, module type . The is not very readable. Switch to a 4 column display Sources, Processors, Sinks, Jobs Additionally, mark composed module e.g. myhttp c ",NULL,"Switch module list to horizontal display The module list command currently has a very simplistic two column display of module name, module type . The is not very readable. Switch to a 4 column display Sources, Processors, Sinks, Jobs Additionally, mark composed module e.g. myhttp c ",NULL,"Switch module list to horizontal display The module list command currently has a very simplistic two column display of module name, module type <span class='highlight-text severity-high'>. The is not very readable. Switch to a 4 column display Sources, Processors, Sinks, Jobs Additionally, mark composed module e.g. myhttp c </span>","minimal","punctuation","high",False
25087,"Fix undeploy of stream with a composed module Create a composed module Create a stream that uses that module Try to undeploy the stream. Kaboom The dispatch is not correctly implemented in ModuleDeployer",NULL,"Fix undeploy of stream with a composed module Create a composed module Create a stream that uses that module Try to undeploy the stream. Kaboom The dispatch is not correctly implemented in ModuleDeployer",NULL,"Add for who this story is","well_formed","no_role","high",False
25087,"Fix undeploy of stream with a composed module Create a composed module Create a stream that uses that module Try to undeploy the stream. Kaboom The dispatch is not correctly implemented in ModuleDeployer",NULL,"Fix undeploy of stream with a composed module Create a composed module Create a stream that uses that module Try to undeploy the stream. Kaboom The dispatch is not correctly implemented in ModuleDeployer",NULL,"Fix undeploy of stream with a composed module Create a composed module Create a stream that uses that module Try to undeploy the stream<span class='highlight-text severity-high'>. Kaboom The dispatch is not correctly implemented in ModuleDeployer</span>","minimal","punctuation","high",False
26572,"Batching JDBC channel adapter we need a batching JDBC channel adapter is not batching statements AFAICT ",NULL,"Batching JDBC channel adapter we need a batching JDBC channel adapter is not batching statements AFAICT ",NULL,"Add for who this story is","well_formed","no_role","high",False
25089,"Kryo Redis Serializer The current XD uses an inadequate is false not currently being used . When porting this to SI, the serializer will be dropped. Suggest creation of Kryo serializer for Messages for when Redis source sinks are created.",NULL,"Kryo Redis Serializer The current XD uses an inadequate is false not currently being used . When porting this to SI, the serializer will be dropped. Suggest creation of Kryo serializer for Messages for when Redis source sinks are created.",NULL,"Add for who this story is","well_formed","no_role","high",False
25089,"Kryo Redis Serializer The current XD uses an inadequate is false not currently being used . When porting this to SI, the serializer will be dropped. Suggest creation of Kryo serializer for Messages for when Redis source sinks are created.",NULL,"Kryo Redis Serializer The current XD uses an inadequate is false not currently being used . When porting this to SI, the serializer will be dropped. Suggest creation of Kryo serializer for Messages for when Redis source sinks are created.",NULL,"Kryo Redis Serializer The current XD uses an inadequate is false not currently being used <span class='highlight-text severity-high'>. When porting this to SI, the serializer will be dropped. Suggest creation of Kryo serializer for Messages for when Redis source sinks are created.</span>","minimal","punctuation","high",False
26616,"Create XD module for syslog tcp reactor Still keep existing one.",NULL,"Create XD module for syslog tcp reactor Still keep existing one.",NULL,"Add for who this story is","well_formed","no_role","high",False
26617,"Check for high CPU usage with syslog tcp reactor module ",NULL,"Check for high CPU usage with syslog tcp reactor module ",NULL,"Add for who this story is","well_formed","no_role","high",False
26618,"Adapt SpringOne 2012 UI code from keynote demo of election results to use XD Existing code ",NULL,"Adapt SpringOne 2012 UI code from keynote demo of election results to use XD Existing code ",NULL,"Add for who this story is","well_formed","no_role","high",False
26619,"Create shell integration tests for stream lifeycle create, delete, deploy streams...",NULL,"Create shell integration tests for stream lifeycle create, delete, deploy streams...",NULL,"Add for who this story is","well_formed","no_role","high",False
26620,"Create shell integration tests for tap lifeycle creating taps, deleting",NULL,"Create shell integration tests for tap lifeycle creating taps, deleting",NULL,"Add for who this story is","well_formed","no_role","high",False
25075,"Reactor based http ingestion When there is support for boostrapping a http server in the reactor project, and inbound SI adapter and associated XD source module should be created.",NULL,"Reactor based http ingestion When there is support for boostrapping a http server in the reactor project, and inbound SI adapter and associated XD source module should be created.",NULL,"Add for who this story is","well_formed","no_role","high",False
25075,"Reactor based http ingestion When there is support for boostrapping a http server in the reactor project, and inbound SI adapter and associated XD source module should be created.",NULL,"Reactor based http ingestion When there is support for boostrapping a http server in the reactor project, and inbound SI adapter and associated XD source module should be created.",NULL,"Reactor based http ingestion When there is support for boostrapping a http server in the reactor project,<span class='highlight-text severity-high'> and </span>inbound SI adapter and associated XD source module should be created.","atomic","conjunctions","high",False
25078,"UI User should be able to launch a job from Deployed jobs page From the Deployed jobs page, user should be able to click on the Launch button on a specific job and specify the Job parameters as key value pairs in the text box and we will convert that into JSON string as JobParameters into JobLaunch request. ",NULL,"UI User should be able to launch a job from Deployed jobs page From the Deployed jobs page, user should be able to click on the Launch button on a specific job and specify the Job parameters as key value pairs in the text box and we will convert that into JSON string as JobParameters into JobLaunch request. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25078,"UI User should be able to launch a job from Deployed jobs page From the Deployed jobs page, user should be able to click on the Launch button on a specific job and specify the Job parameters as key value pairs in the text box and we will convert that into JSON string as JobParameters into JobLaunch request. ",NULL,"UI User should be able to launch a job from Deployed jobs page From the Deployed jobs page, user should be able to click on the Launch button on a specific job and specify the Job parameters as key value pairs in the text box and we will convert that into JSON string as JobParameters into JobLaunch request. ",NULL,"UI User should be able to launch a job from Deployed jobs page From the Deployed jobs page, user should be able to click on the Launch button on a specific job<span class='highlight-text severity-high'> and </span>specify the Job parameters as key value pairs in the text box and we will convert that into JSON string as JobParameters into JobLaunch request. ","atomic","conjunctions","high",False
25079,"UI User should be able to filter the list of executions on the execution tab On clicking the Executions tab, user should see the list of all batch job executions. There should be options to filter job executions by few criteria such as by Job name , execution time etc., ",NULL,"UI User should be able to filter the list of executions on the execution tab On clicking the Executions tab, user should see the list of all batch job executions. There should be options to filter job executions by few criteria such as by Job name , execution time etc., ",NULL,"Add for who this story is","well_formed","no_role","high",False
25079,"UI User should be able to filter the list of executions on the execution tab On clicking the Executions tab, user should see the list of all batch job executions. There should be options to filter job executions by few criteria such as by Job name , execution time etc., ",NULL,"UI User should be able to filter the list of executions on the execution tab On clicking the Executions tab, user should see the list of all batch job executions. There should be options to filter job executions by few criteria such as by Job name , execution time etc., ",NULL,"UI User should be able to filter the list of executions on the execution tab On clicking the Executions tab, user should see the list of all batch job executions<span class='highlight-text severity-high'>. There should be options to filter job executions by few criteria such as by Job name , execution time etc., </span>","minimal","punctuation","high",False
25080,"Jobs list REST endpoint should include status Currently, the jobs definition list REST endpoint doesn t include status on a given job.",NULL,"Jobs list REST endpoint should include status Currently, the jobs definition list REST endpoint doesn t include status on a given job.",NULL,"Add for who this story is","well_formed","no_role","high",False
25083,"Create a reusable responsive UI layout to render the XD PagedResoures in tabular view Create a reusable responsive UI layout to render the PagedResources returned from REST endpoint. As part of this, try upgrading the bootstrap to 3.0.0 and use the responsive styles offered in it.",NULL,"Create a reusable responsive UI layout to render the XD PagedResoures in tabular view Create a reusable responsive UI layout to render the PagedResources returned from REST endpoint. As part of this, try upgrading the bootstrap to 3.0.0 and use the responsive styles offered in it.",NULL,"Add for who this story is","well_formed","no_role","high",False
25083,"Create a reusable responsive UI layout to render the XD PagedResoures in tabular view Create a reusable responsive UI layout to render the PagedResources returned from REST endpoint. As part of this, try upgrading the bootstrap to 3.0.0 and use the responsive styles offered in it.",NULL,"Create a reusable responsive UI layout to render the XD PagedResoures in tabular view Create a reusable responsive UI layout to render the PagedResources returned from REST endpoint. As part of this, try upgrading the bootstrap to 3.0.0 and use the responsive styles offered in it.",NULL,"Create a reusable responsive UI layout to render the XD PagedResoures in tabular view Create a reusable responsive UI layout to render the PagedResources returned from REST endpoint. As part of this, try upgrading the bootstrap to 3.0.0<span class='highlight-text severity-high'> and </span>use the responsive styles offered in it.","atomic","conjunctions","high",False
25083,"Create a reusable responsive UI layout to render the XD PagedResoures in tabular view Create a reusable responsive UI layout to render the PagedResources returned from REST endpoint. As part of this, try upgrading the bootstrap to 3.0.0 and use the responsive styles offered in it.",NULL,"Create a reusable responsive UI layout to render the XD PagedResoures in tabular view Create a reusable responsive UI layout to render the PagedResources returned from REST endpoint. As part of this, try upgrading the bootstrap to 3.0.0 and use the responsive styles offered in it.",NULL,"Create a reusable responsive UI layout to render the XD PagedResoures in tabular view Create a reusable responsive UI layout to render the PagedResources returned from REST endpoint<span class='highlight-text severity-high'>. As part of this, try upgrading the bootstrap to 3.0.0 and use the responsive styles offered in it.</span>","minimal","punctuation","high",False
25082,"Command to show the XML of the job definition ",NULL,"Command to show the XML of the job definition ",NULL,"Add for who this story is","well_formed","no_role","high",False
25084,"Provide an option to pretty print JSON output Probably the cleanest approach is to provide a properties file in the xd config directory that enables this globally, e.g., This will require some refactoring of the plugin, i.e., use DI in streams.xml",NULL,"Provide an option to pretty print JSON output Probably the cleanest approach is to provide a properties file in the xd config directory that enables this globally, e.g., This will require some refactoring of the plugin, i.e., use DI in streams.xml",NULL,"Add for who this story is","well_formed","no_role","high",False
25074,"HDFS ItemWriter Base integration of core HDFS writer functionality with Spring Batch.",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25074,"HDFS ItemWriter Base integration of core HDFS writer functionality with Spring Batch.",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25077,"UI User should be able to get all the job executions on a given job at deployed jobs page On clicking a specific job name in the deployed jobs list, we need to redirect the user to show the list of all the job executions on that job. User should be able to navigate back to the deployed jobs list.",NULL,"UI User should be able to get all the job executions on a given job at deployed jobs page On clicking a specific job name in the deployed jobs list, we need to redirect the user to show the list of all the job executions on that job. User should be able to navigate back to the deployed jobs list.",NULL,"Add for who this story is","well_formed","no_role","high",False
25077,"UI User should be able to get all the job executions on a given job at deployed jobs page On clicking a specific job name in the deployed jobs list, we need to redirect the user to show the list of all the job executions on that job. User should be able to navigate back to the deployed jobs list.",NULL,"UI User should be able to get all the job executions on a given job at deployed jobs page On clicking a specific job name in the deployed jobs list, we need to redirect the user to show the list of all the job executions on that job. User should be able to navigate back to the deployed jobs list.",NULL,"UI User should be able to get all the job executions on a given job at deployed jobs page On clicking a specific job name in the deployed jobs list, we need to redirect the user to show the list of all the job executions on that job<span class='highlight-text severity-high'>. User should be able to navigate back to the deployed jobs list.</span>","minimal","punctuation","high",False
25081,"Add additional REST endpoint that return the XML definition of a job ",NULL,"Add additional REST endpoint that return the XML definition of a job ",NULL,"Add for who this story is","well_formed","no_role","high",False
25099,"Composed of Composed fails at stream deployment time Although composition of a module out of an already composed module seems to work at the module compose level, trying to deploy a stream with that more complex module fails with at at at at at Caused by each module before the last must provide output at at at at at at at ... 63 more",NULL,"Composed of Composed fails at stream deployment time Although composition of a module out of an already composed module seems to work at the module compose level, trying to deploy a stream with that more complex module fails with at at at at at Caused by each module before the last must provide output at at at at at at at ... 63 more",NULL,"Add for who this story is","well_formed","no_role","high",False
25214,"Batch jobs should use application.yml provided connection as default Batch jobs should use application.yml provided connection as default. They now have their own configuration in This config needs to account for any changes made to application.yml settings so the data is written to the batch metadata database by default.",NULL,"Batch jobs should use application.yml provided connection as default Batch jobs should use application.yml provided connection as default. They now have their own configuration in This config needs to account for any changes made to application.yml settings","so the data is written to the batch metadata database by default.","Add for who this story is","well_formed","no_role","high",False
25317,"Add option to xd admin and xd container YARN scripts to allow copying ot HDFS and no execution. ",NULL,"Add option to xd admin and xd container YARN scripts to allow copying ot HDFS and no execution. ",NULL,"Add option to xd admin<span class='highlight-text severity-high'> and </span>xd container YARN scripts to allow copying ot HDFS and no execution. ","atomic","conjunctions","high",False
25099,"Composed of Composed fails at stream deployment time Although composition of a module out of an already composed module seems to work at the module compose level, trying to deploy a stream with that more complex module fails with at at at at at Caused by each module before the last must provide output at at at at at at at ... 63 more",NULL,"Composed of Composed fails at stream deployment time Although composition of a module out of an already composed module seems to work at the module compose level, trying to deploy a stream with that more complex module fails with at at at at at Caused by each module before the last must provide output at at at at at at at ... 63 more",NULL,"Composed of Composed fails at stream deployment time Although composition of a module out of an already composed module seems to work at the module compose level, trying to deploy a stream with that more complex module fails with at at at at at Caused by each module before the last must provide output at at at at at at at <span class='highlight-text severity-high'>... 63 more</span>","minimal","punctuation","high",False
25100,"Add README to be included in root directory of distribution should explain basic layout of the distribution",NULL,"Add README to be included in root directory of distribution should explain basic layout of the distribution",NULL,"Add for who this story is","well_formed","no_role","high",False
25103,"Support short names for types in ModuleOptions The ModuleOptions PR currently uses FQN for types eg java.lang.String Would be nice to have support for short names for common types, both in the properties files and the annotation",NULL,"Support short names for types in ModuleOptions The ModuleOptions PR currently uses FQN for types eg java.lang.String Would be nice to have support for short names for common types, both in the properties files and the annotation",NULL,"Add for who this story is","well_formed","no_role","high",False
25104,"refactor module dependency tracking to be closer to stream deployment see comments on this PR which is part of the code that needs to be refactored ",NULL,"refactor module dependency tracking to be closer to stream deployment see comments on this PR which is part of the code that needs to be refactored ",NULL,"Add for who this story is","well_formed","no_role","high",False
25102,"Upgrade to Spring for Apache Hadoop 1.0.2.RELEASE and Pivotal HD 1.1 Make sure the sinks and jobs work against Pivotal HD 1.1",NULL,"Upgrade to Spring for Apache Hadoop 1.0.2.RELEASE and Pivotal HD 1.1 Make sure the sinks and jobs work against Pivotal HD 1.1",NULL,"Add for who this story is","well_formed","no_role","high",False
25102,"Upgrade to Spring for Apache Hadoop 1.0.2.RELEASE and Pivotal HD 1.1 Make sure the sinks and jobs work against Pivotal HD 1.1",NULL,"Upgrade to Spring for Apache Hadoop 1.0.2.RELEASE and Pivotal HD 1.1 Make sure the sinks and jobs work against Pivotal HD 1.1",NULL,"Upgrade to Spring for Apache Hadoop 1.0.2.RELEASE<span class='highlight-text severity-high'> and </span>Pivotal HD 1.1 Make sure the sinks and jobs work against Pivotal HD 1.1","atomic","conjunctions","high",False
25105,"Create project for model that is common between client and server this would elminate dependencies that are currently in the codebase, such as RESTModuleType and ModuleType enums ModuleOption and ",NULL,"Create project for model that is common between client and server this would elminate dependencies that are currently in the codebase, such as RESTModuleType and ModuleType enums ModuleOption and ",NULL,"Add for who this story is","well_formed","no_role","high",False
25105,"Create project for model that is common between client and server this would elminate dependencies that are currently in the codebase, such as RESTModuleType and ModuleType enums ModuleOption and ",NULL,"Create project for model that is common between client and server this would elminate dependencies that are currently in the codebase, such as RESTModuleType and ModuleType enums ModuleOption and ",NULL,"Create project for model that is common between client<span class='highlight-text severity-high'> and </span>server this would elminate dependencies that are currently in the codebase, such as RESTModuleType and ModuleType enums ModuleOption and ","atomic","conjunctions","high",False
25108,"Add LICENSE to be included in root directory of distribution should contain apache licence",NULL,"Add LICENSE to be included in root directory of distribution should contain apache licence",NULL,"Add for who this story is","well_formed","no_role","high",False
25110,"Enforce consistent naming across CLI options, and method names Enforce consistent naming across CLI options, and method names e.g. see comment on PR 390 In that case, it s delete in one place and destroy in another. There are other cases as well. e.g. see comment on PR 390 In that case, it s delete in one place and destroy in another. There are other cases as well.",NULL,"Enforce consistent naming across CLI options, and method names Enforce consistent naming across CLI options, and method names e.g. see comment on PR 390 In that case, it s delete in one place and destroy in another. There are other cases as well. e.g. see comment on PR 390 In that case, it s delete in one place and destroy in another. There are other cases as well.",NULL,"Add for who this story is","well_formed","no_role","high",False
25110,"Enforce consistent naming across CLI options, and method names Enforce consistent naming across CLI options, and method names e.g. see comment on PR 390 In that case, it s delete in one place and destroy in another. There are other cases as well. e.g. see comment on PR 390 In that case, it s delete in one place and destroy in another. There are other cases as well.",NULL,"Enforce consistent naming across CLI options, and method names Enforce consistent naming across CLI options, and method names e.g. see comment on PR 390 In that case, it s delete in one place and destroy in another. There are other cases as well. e.g. see comment on PR 390 In that case, it s delete in one place and destroy in another. There are other cases as well.",NULL,"Enforce consistent naming across CLI options,<span class='highlight-text severity-high'> and </span>method names Enforce consistent naming across CLI options, and method names e.g. see comment on PR 390 In that case, it s delete in one place and destroy in another. There are other cases as well. e.g. see comment on PR 390 In that case, it s delete in one place and destroy in another. There are other cases as well.","atomic","conjunctions","high",False
25110,"Enforce consistent naming across CLI options, and method names Enforce consistent naming across CLI options, and method names e.g. see comment on PR 390 In that case, it s delete in one place and destroy in another. There are other cases as well. e.g. see comment on PR 390 In that case, it s delete in one place and destroy in another. There are other cases as well.",NULL,"Enforce consistent naming across CLI options, and method names Enforce consistent naming across CLI options, and method names e.g. see comment on PR 390 In that case, it s delete in one place and destroy in another. There are other cases as well. e.g. see comment on PR 390 In that case, it s delete in one place and destroy in another. There are other cases as well.",NULL,"Enforce consistent naming across CLI options, and method names Enforce consistent naming across CLI options, and method names e<span class='highlight-text severity-high'>.g. see comment on PR 390 In that case, it s delete in one place and destroy in another. There are other cases as well. e.g. see comment on PR 390 In that case, it s delete in one place and destroy in another. There are other cases as well.</span>","minimal","punctuation","high",False
25106,"Consider a shared project for POJOs that are shareable betweed model and REST layer ",NULL,"Consider a shared project for POJOs that are shareable betweed model and REST layer ",NULL,"Add for who this story is","well_formed","no_role","high",False
25107,"Create documentation for composed modules ",NULL,"Create documentation for composed modules ",NULL,"Add for who this story is","well_formed","no_role","high",False
25109,"Improve Module Options support note from PR 365 which has been merged providing the initial level of support... Pending issues to be addressed in another PR? complex case default values for complex case, when option is not surfaced back to the module eg suffix in our canonical example plugin provided options and values descriptive defaults instead of actual defaults e.g. use stream name JSR303 Validation ",NULL,"Improve Module Options support note from PR 365 which has been merged providing the initial level of support... Pending issues to be addressed in another PR? complex case default values for complex case, when option is not surfaced back to the module eg suffix in our canonical example plugin provided options and values descriptive defaults instead of actual defaults e.g. use stream name JSR303 Validation ",NULL,"Add for who this story is","well_formed","no_role","high",False
25109,"Improve Module Options support note from PR 365 which has been merged providing the initial level of support... Pending issues to be addressed in another PR? complex case default values for complex case, when option is not surfaced back to the module eg suffix in our canonical example plugin provided options and values descriptive defaults instead of actual defaults e.g. use stream name JSR303 Validation ",NULL,"Improve Module Options support note from PR 365 which has been merged providing the initial level of support... Pending issues to be addressed in another PR? complex case default values for complex case, when option is not surfaced back to the module eg suffix in our canonical example plugin provided options and values descriptive defaults instead of actual defaults e.g. use stream name JSR303 Validation ",NULL,"Improve Module Options support note from PR 365 which has been merged providing the initial level of support<span class='highlight-text severity-high'>... Pending issues to be addressed in another PR? complex case default values for complex case, when option is not surfaced back to the module eg suffix in our canonical example plugin provided options and values descriptive defaults instead of actual defaults e.g. use stream name JSR303 Validation </span>","minimal","punctuation","high",False
25111,"Deployment tab on admin ui lags behind with changes on other pages The deployment tab does not reflect the current state of the jobs. User must hit browser refresh button to make it work.",NULL,"Deployment tab on admin ui lags behind with changes on other pages The deployment tab does not reflect the current state of the jobs. User must hit browser refresh button to make it work.",NULL,"Add for who this story is","well_formed","no_role","high",False
25111,"Deployment tab on admin ui lags behind with changes on other pages The deployment tab does not reflect the current state of the jobs. User must hit browser refresh button to make it work.",NULL,"Deployment tab on admin ui lags behind with changes on other pages The deployment tab does not reflect the current state of the jobs. User must hit browser refresh button to make it work.",NULL,"Deployment tab on admin ui lags behind with changes on other pages The deployment tab does not reflect the current state of the jobs<span class='highlight-text severity-high'>. User must hit browser refresh button to make it work.</span>","minimal","punctuation","high",False
26621,"Create shell integration tests for trigger lifeycle creating triggers, deleting triggers",NULL,"Create shell integration tests for trigger lifeycle creating triggers, deleting triggers",NULL,"Add for who this story is","well_formed","no_role","high",False
25098,"Support composed module deletion Provided it is not currently used in any stream V Attempt to destroy a composed module Should not be supported at all Should not be supported if involved in at least one stream EB?, MF! Should be supported and have no other consequences whatsoever see IV EB? Should be supported and invalidate destroy streams involving it ",NULL,"Support composed module deletion Provided it is not currently used in any stream V Attempt to destroy a composed module Should not be supported at all Should not be supported if involved in at least one stream EB?, MF! Should be supported and have no other consequences whatsoever see IV EB? Should be supported and invalidate destroy streams involving it ",NULL,"Add for who this story is","well_formed","no_role","high",False
25098,"Support composed module deletion Provided it is not currently used in any stream V Attempt to destroy a composed module Should not be supported at all Should not be supported if involved in at least one stream EB?, MF! Should be supported and have no other consequences whatsoever see IV EB? Should be supported and invalidate destroy streams involving it ",NULL,"Support composed module deletion Provided it is not currently used in any stream V Attempt to destroy a composed module Should not be supported at all Should not be supported if involved in at least one stream EB?, MF! Should be supported and have no other consequences whatsoever see IV EB? Should be supported and invalidate destroy streams involving it ",NULL,"Support composed module deletion Provided it is not currently used in any stream V Attempt to destroy a composed module Should not be supported at all Should not be supported if involved in at least one stream EB?, MF! Should be supported<span class='highlight-text severity-high'> and </span>have no other consequences whatsoever see IV EB? Should be supported and invalidate destroy streams involving it ","atomic","conjunctions","high",False
25098,"Support composed module deletion Provided it is not currently used in any stream V Attempt to destroy a composed module Should not be supported at all Should not be supported if involved in at least one stream EB?, MF! Should be supported and have no other consequences whatsoever see IV EB? Should be supported and invalidate destroy streams involving it ",NULL,"Support composed module deletion Provided it is not currently used in any stream V Attempt to destroy a composed module Should not be supported at all Should not be supported if involved in at least one stream EB?, MF! Should be supported and have no other consequences whatsoever see IV EB? Should be supported and invalidate destroy streams involving it ",NULL,"Support composed module deletion Provided it is not currently used in any stream V Attempt to destroy a composed module Should not be supported at all Should not be supported if involved in at least one stream EB<span class='highlight-text severity-high'>?, MF! Should be supported and have no other consequences whatsoever see IV EB? Should be supported and invalidate destroy streams involving it </span>","minimal","punctuation","high",False
25101,"Remove legacy application code following Spring bootification See the discussion in There are now various superseded classes and tests which we no longer need.",NULL,"Remove legacy application code following Spring bootification See the discussion in There are now various superseded classes and tests which we no longer need.",NULL,"Add for who this story is","well_formed","no_role","high",False
25101,"Remove legacy application code following Spring bootification See the discussion in There are now various superseded classes and tests which we no longer need.",NULL,"Remove legacy application code following Spring bootification See the discussion in There are now various superseded classes and tests which we no longer need.",NULL,"Remove legacy application code following Spring bootification See the discussion in There are now various superseded classes<span class='highlight-text severity-high'> and </span>tests which we no longer need.","atomic","conjunctions","high",False
25117,"Fix mqtt module properties Use of dot in property name prevents the user from specifying a value in stream definition Also, defaults are repeated at .xml and .properties level",NULL,"Fix mqtt module properties Use of dot in property name prevents the user from specifying a value in stream definition Also, defaults are repeated at .xml and .properties level",NULL,"Add for who this story is","well_formed","no_role","high",False
25115,"Remove unnecessary LESS files from XD UI styles Currently, the bootstrap.less file has all the styles that the bootstrap supports. But we should only add compile the LESS that are needed by XD UI.",NULL,"Remove unnecessary LESS files from XD UI styles Currently, the bootstrap.less file has all the styles that the bootstrap supports. But we should only add compile the LESS that are needed by XD UI.",NULL,"Add for who this story is","well_formed","no_role","high",False
25115,"Remove unnecessary LESS files from XD UI styles Currently, the bootstrap.less file has all the styles that the bootstrap supports. But we should only add compile the LESS that are needed by XD UI.",NULL,"Remove unnecessary LESS files from XD UI styles Currently, the bootstrap.less file has all the styles that the bootstrap supports. But we should only add compile the LESS that are needed by XD UI.",NULL,"Remove unnecessary LESS files from XD UI styles Currently, the bootstrap<span class='highlight-text severity-high'>.less file has all the styles that the bootstrap supports. But we should only add compile the LESS that are needed by XD UI.</span>","minimal","punctuation","high",False
25121,"Multiple SLF4J bindings on the classpath Summary says it all. When starting, we now get SLF4J Class path contains multiple SLF4J bindings. SLF4J See for an explanation. SLF4J Actual binding is of type Most certainly introduced by or ",NULL,"Multiple SLF4J bindings on the classpath Summary says it all. When starting, we now get SLF4J Class path contains multiple SLF4J bindings. SLF4J See for an explanation. SLF4J Actual binding is of type Most certainly introduced by or ",NULL,"Add for who this story is","well_formed","no_role","high",False
25121,"Multiple SLF4J bindings on the classpath Summary says it all. When starting, we now get SLF4J Class path contains multiple SLF4J bindings. SLF4J See for an explanation. SLF4J Actual binding is of type Most certainly introduced by or ",NULL,"Multiple SLF4J bindings on the classpath Summary says it all. When starting, we now get SLF4J Class path contains multiple SLF4J bindings. SLF4J See for an explanation. SLF4J Actual binding is of type Most certainly introduced by or ",NULL,"Multiple SLF4J bindings on the classpath Summary says it all<span class='highlight-text severity-high'>. When starting, we now get SLF4J Class path contains multiple SLF4J bindings. SLF4J See for an explanation. SLF4J Actual binding is of type Most certainly introduced by or </span>","minimal","punctuation","high",False
25118,"Remove existing purpose built json processors and ensure all functionality is still available with jsonPath based SpEL expression based processors ",NULL,"Remove existing purpose built json processors and ensure all functionality is still available with jsonPath based SpEL expression based processors ",NULL,"Add for who this story is","well_formed","no_role","high",False
25118,"Remove existing purpose built json processors and ensure all functionality is still available with jsonPath based SpEL expression based processors ",NULL,"Remove existing purpose built json processors and ensure all functionality is still available with jsonPath based SpEL expression based processors ",NULL,"Remove existing purpose built json processors<span class='highlight-text severity-high'> and </span>ensure all functionality is still available with jsonPath based SpEL expression based processors ","atomic","conjunctions","high",False
25122,"Restore XD Banner Migrating to boot dropped the XD banner and its info. Can be restored using eg a boot Initializer and removing the default boot banner",NULL,"Restore XD Banner Migrating to boot dropped the XD banner and its info. Can be restored using eg a boot Initializer and removing the default boot banner",NULL,"Add for who this story is","well_formed","no_role","high",False
25122,"Restore XD Banner Migrating to boot dropped the XD banner and its info. Can be restored using eg a boot Initializer and removing the default boot banner",NULL,"Restore XD Banner Migrating to boot dropped the XD banner and its info. Can be restored using eg a boot Initializer and removing the default boot banner",NULL,"Restore XD Banner Migrating to boot dropped the XD banner<span class='highlight-text severity-high'> and </span>its info. Can be restored using eg a boot Initializer and removing the default boot banner","atomic","conjunctions","high",False
25122,"Restore XD Banner Migrating to boot dropped the XD banner and its info. Can be restored using eg a boot Initializer and removing the default boot banner",NULL,"Restore XD Banner Migrating to boot dropped the XD banner and its info. Can be restored using eg a boot Initializer and removing the default boot banner",NULL,"Restore XD Banner Migrating to boot dropped the XD banner and its info<span class='highlight-text severity-high'>. Can be restored using eg a boot Initializer and removing the default boot banner</span>","minimal","punctuation","high",False
25123,"Create an FTP tasklet to get remote files and put them in the local file system. This is along the lines of what is in this blog post Note that there have been some new developments in SI to get at the underlying stream for FTP. The way to test this is to create a new batch job in XD that has this as it s tasklet. Going forward the target file system will also be HDFS.",NULL,"Create an FTP tasklet to get remote files and put them in the local file system. This is along the lines of what is in this blog post Note that there have been some new developments in SI to get at the underlying stream for FTP. The way to test this is to create a new batch job in XD that has this as it s tasklet. Going forward the target file system will also be HDFS.",NULL,"Add for who this story is","well_formed","no_role","high",False
25241,"Create TCP source module Based off SI tcp inbound adapter. This will allow for event forwarding that can select among the existing SI options. ",NULL,"Create TCP source module Based off SI tcp inbound adapter. This will allow for event forwarding that can select among the existing SI options. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25123,"Create an FTP tasklet to get remote files and put them in the local file system. This is along the lines of what is in this blog post Note that there have been some new developments in SI to get at the underlying stream for FTP. The way to test this is to create a new batch job in XD that has this as it s tasklet. Going forward the target file system will also be HDFS.",NULL,"Create an FTP tasklet to get remote files and put them in the local file system. This is along the lines of what is in this blog post Note that there have been some new developments in SI to get at the underlying stream for FTP. The way to test this is to create a new batch job in XD that has this as it s tasklet. Going forward the target file system will also be HDFS.",NULL,"Create an FTP tasklet to get remote files<span class='highlight-text severity-high'> and </span>put them in the local file system. This is along the lines of what is in this blog post Note that there have been some new developments in SI to get at the underlying stream for FTP. The way to test this is to create a new batch job in XD that has this as it s tasklet. Going forward the target file system will also be HDFS.","atomic","conjunctions","high",False
25123,"Create an FTP tasklet to get remote files and put them in the local file system. This is along the lines of what is in this blog post Note that there have been some new developments in SI to get at the underlying stream for FTP. The way to test this is to create a new batch job in XD that has this as it s tasklet. Going forward the target file system will also be HDFS.",NULL,"Create an FTP tasklet to get remote files and put them in the local file system. This is along the lines of what is in this blog post Note that there have been some new developments in SI to get at the underlying stream for FTP. The way to test this is to create a new batch job in XD that has this as it s tasklet. Going forward the target file system will also be HDFS.",NULL,"Create an FTP tasklet to get remote files and put them in the local file system<span class='highlight-text severity-high'>. This is along the lines of what is in this blog post Note that there have been some new developments in SI to get at the underlying stream for FTP. The way to test this is to create a new batch job in XD that has this as it s tasklet. Going forward the target file system will also be HDFS.</span>","minimal","punctuation","high",False
25119,"Clean shutdown of redis in xd admin A ctrl c of xd admin results in exception messages about disconnecting from redis. 14 16 07,327 ERROR task scheduler 1 Redis command interrupted; nested exception is Command interrupted ",NULL,"Clean shutdown of redis in xd admin A ctrl c of xd admin results in exception messages about disconnecting from redis. 14 16 07,327 ERROR task scheduler 1 Redis command interrupted; nested exception is Command interrupted ",NULL,"Add for who this story is","well_formed","no_role","high",False
25119,"Clean shutdown of redis in xd admin A ctrl c of xd admin results in exception messages about disconnecting from redis. 14 16 07,327 ERROR task scheduler 1 Redis command interrupted; nested exception is Command interrupted ",NULL,"Clean shutdown of redis in xd admin A ctrl c of xd admin results in exception messages about disconnecting from redis. 14 16 07,327 ERROR task scheduler 1 Redis command interrupted; nested exception is Command interrupted ",NULL,"Clean shutdown of redis in xd admin A ctrl c of xd admin results in exception messages about disconnecting from redis<span class='highlight-text severity-high'>. 14 16 07,327 ERROR task scheduler 1 Redis command interrupted; nested exception is Command interrupted </span>","minimal","punctuation","high",False
25112,"Schedule button shows up but does not perform any task I know that the feature is not ready, but we either should post a message to the user that the feature is not available or hide the button",NULL,"Schedule button shows up but does not perform any task I know that the feature is not ready, but we either should post a message to the user that the feature is not available or hide the button",NULL,"Add for who this story is","well_formed","no_role","high",False
25112,"Schedule button shows up but does not perform any task I know that the feature is not ready, but we either should post a message to the user that the feature is not available or hide the button",NULL,"Schedule button shows up but does not perform any task I know that the feature is not ready, but we either should post a message to the user that the feature is not available or hide the button",NULL,"Schedule button shows up but does not perform any task I know that the feature is not ready, but we either should post a message to the user that the feature is not available<span class='highlight-text severity-high'> or </span>hide the button","atomic","conjunctions","high",False
25116,"Upgrade to 0.7.0 Looks like we need to spend a cycle on Asciidoc as we still have the author tag issue I thought we can simply upgrade the to 0.7.0 currently 0.4.1 but that breaks the docs being generated.",NULL,"Upgrade to 0.7.0 Looks like we need to spend a cycle on Asciidoc as we still have the author tag issue I thought we can simply upgrade the to 0.7.0 currently 0.4.1 but that breaks the docs being generated.",NULL,"Add for who this story is","well_formed","no_role","high",False
25113,"Empty parameter sent to job when launched from UI Job gets a empty key value pair when launching the job from the admin ui.",NULL,"Empty parameter sent to job when launched from UI Job gets a empty key value pair when launching the job from the admin ui.",NULL,"Add for who this story is","well_formed","no_role","high",False
25120,"Change default container port from 9000 to something else Change the default port since it conflicts with the default port for the http source",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25120,"Change default container port from 9000 to something else Change the default port since it conflicts with the default port for the http source",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25114,"Colors on Job Definition tab are different than other tabs The table background color on the Job Definition Tab is green while the others tabs have a white background. They should be consistent.",NULL,"Colors on Job Definition tab are different than other tabs The table background color on the Job Definition Tab is green while the others tabs have a white background. They should be consistent.",NULL,"Add for who this story is","well_formed","no_role","high",False
25114,"Colors on Job Definition tab are different than other tabs The table background color on the Job Definition Tab is green while the others tabs have a white background. They should be consistent.",NULL,"Colors on Job Definition tab are different than other tabs The table background color on the Job Definition Tab is green while the others tabs have a white background. They should be consistent.",NULL,"Colors on Job Definition tab are different than other tabs The table background color on the Job Definition Tab is green while the others tabs have a white background<span class='highlight-text severity-high'>. They should be consistent.</span>","minimal","punctuation","high",False
25152,"Provide using simple approach Following merge of XD 953, provide module options using the simple approach where applicable",NULL,"Provide using simple approach Following merge of XD 953, provide module options using the simple approach where applicable",NULL,"Add for who this story is","well_formed","no_role","high",False
25153,"Switch CAPITAL LETTERS to system.property style in application config ",NULL,"Switch CAPITAL LETTERS to system.property style in application config ",NULL,"Add for who this story is","well_formed","no_role","high",False
25154,"Add support for deploying a batch job with partitioning across multiple XD nodes. This is a very big story, needs some before starting work. Should be able to be implemented as a plugin. ",NULL,"Add support for deploying a batch job with partitioning across multiple XD nodes. This is a very big story, needs some before starting work. Should be able to be implemented as a plugin. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25154,"Add support for deploying a batch job with partitioning across multiple XD nodes. This is a very big story, needs some before starting work. Should be able to be implemented as a plugin. ",NULL,"Add support for deploying a batch job with partitioning across multiple XD nodes. This is a very big story, needs some before starting work. Should be able to be implemented as a plugin. ",NULL,"Add support for deploying a batch job with partitioning across multiple XD nodes<span class='highlight-text severity-high'>. This is a very big story, needs some before starting work. Should be able to be implemented as a plugin. </span>","minimal","punctuation","high",False
25155,"Disable JMX by default and extend to other contexts than modules ",NULL,"Disable JMX by default and extend to other contexts than modules ",NULL,"Add for who this story is","well_formed","no_role","high",False
25155,"Disable JMX by default and extend to other contexts than modules ",NULL,"Disable JMX by default and extend to other contexts than modules ",NULL,"Disable JMX by default<span class='highlight-text severity-high'> and </span>extend to other contexts than modules ","atomic","conjunctions","high",False
25156,"Enable into be present when executing gradlew This could be inside gradlew or a .settings file.",NULL,"Enable into be present when executing gradlew This could be inside gradlew or a .settings file.",NULL,"Add for who this story is","well_formed","no_role","high",False
25158,"Local control channels enabled in when alternate transport is selected. This causes intermittent test failures when testing streams with other transports since ModuleDeployer receives duplicate requests from multiple threads. Fix is to check for local transport before invoking ",NULL,"Local control channels enabled in when alternate transport is selected. This causes intermittent test failures when testing streams with other transports since ModuleDeployer receives duplicate requests from multiple threads. Fix is to check for local transport before invoking ",NULL,"Add for who this story is","well_formed","no_role","high",False
25158,"Local control channels enabled in when alternate transport is selected. This causes intermittent test failures when testing streams with other transports since ModuleDeployer receives duplicate requests from multiple threads. Fix is to check for local transport before invoking ",NULL,"Local control channels enabled in when alternate transport is selected. This causes intermittent test failures when testing streams with other transports since ModuleDeployer receives duplicate requests from multiple threads. Fix is to check for local transport before invoking ",NULL,"Local control channels enabled in when alternate transport is selected<span class='highlight-text severity-high'>. This causes intermittent test failures when testing streams with other transports since ModuleDeployer receives duplicate requests from multiple threads. Fix is to check for local transport before invoking </span>","minimal","punctuation","high",False
25157,"Create test script that reproduces failure in writing to HDFS when undeploying and redeploying a stream See This test should be created so that it reproduces the failure and then turned off, so that when we switch to the new HDFS writing code ",NULL,"Create test script that reproduces failure in writing to HDFS when undeploying and redeploying a stream See This test should be created","so that it reproduces the failure and then turned off, so that when we switch to the new HDFS writing code","Add for who this story is","well_formed","no_role","high",False
25157,"Create test script that reproduces failure in writing to HDFS when undeploying and redeploying a stream See This test should be created so that it reproduces the failure and then turned off, so that when we switch to the new HDFS writing code ",NULL,"Create test script that reproduces failure in writing to HDFS when undeploying and redeploying a stream See This test should be created","so that it reproduces the failure and then turned off, so that when we switch to the new HDFS writing code","Create test script that reproduces failure in writing to HDFS when undeploying<span class='highlight-text severity-high'> and </span>redeploying a stream See This test should be created so that it reproduces the failure and then turned off, so that when we switch to the new HDFS writing code ","atomic","conjunctions","high",False
25157,"Create test script that reproduces failure in writing to HDFS when undeploying and redeploying a stream See This test should be created so that it reproduces the failure and then turned off, so that when we switch to the new HDFS writing code ",NULL,"Create test script that reproduces failure in writing to HDFS when undeploying and redeploying a stream See This test should be created","so that it reproduces the failure and then turned off, so that when we switch to the new HDFS writing code","Create test script that reproduces failure in writing to HDFS when undeploying and redeploying a stream See This test should be created<span class='highlight-text severity-high'> so that </span>it reproduces the failure and then turned off,<span class='highlight-text severity-high'> so that </span>when we switch to the new HDFS writing code ","minimal","indicator_repetition","high",False
25157,"Create test script that reproduces failure in writing to HDFS when undeploying and redeploying a stream See This test should be created so that it reproduces the failure and then turned off, so that when we switch to the new HDFS writing code ",NULL,"Create test script that reproduces failure in writing to HDFS when undeploying and redeploying a stream See This test should be created","so that it reproduces the failure and then turned off, so that when we switch to the new HDFS writing code","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25166,"Allow alternate transports to be used within a stream Need to clarify if this means alternate transports within a stream, e.g source processor sink or specifying that a stream use an alternate transport to the one configured for the container. ",NULL,"Allow alternate transports to be used within a stream Need to clarify if this means alternate transports within a stream, e.g source processor sink or specifying that a stream use an alternate transport to the one configured for the container. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25166,"Allow alternate transports to be used within a stream Need to clarify if this means alternate transports within a stream, e.g source processor sink or specifying that a stream use an alternate transport to the one configured for the container. ",NULL,"Allow alternate transports to be used within a stream Need to clarify if this means alternate transports within a stream, e.g source processor sink or specifying that a stream use an alternate transport to the one configured for the container. ",NULL,"Allow alternate transports to be used within a stream Need to clarify if this means alternate transports within a stream, e.g source processor sink<span class='highlight-text severity-high'> or </span>specifying that a stream use an alternate transport to the one configured for the container. ","atomic","conjunctions","high",False
25159,"Have the REST info about a module advertise enum properties When a ModuleOption is backed by an enum, change the currently String type representation to be the possible values ie java.lang.String String but traffic.Light Red Green Orange",NULL,"Have the REST info about a module advertise enum properties When a ModuleOption is backed by an enum, change the currently String type representation to be the possible values ie java.lang.String String but traffic.Light Red Green Orange",NULL,"Add for who this story is","well_formed","no_role","high",False
25161,"Add TaskLet to Stream from S FTP to HDFS ",NULL,"Add TaskLet to Stream from S FTP to HDFS ",NULL,"Add for who this story is","well_formed","no_role","high",False
25164,"Add date option to the trigger module The class should be able to use an actual Date object, thanks to Spring binding conversion. BUT, the construct will receive a toString version of it. Make sure this works properly",NULL,"Add date option to the trigger module The class should be able to use an actual Date object, thanks to Spring binding conversion. BUT, the construct will receive a toString version of it. Make sure this works properly",NULL,"Add for who this story is","well_formed","no_role","high",False
25164,"Add date option to the trigger module The class should be able to use an actual Date object, thanks to Spring binding conversion. BUT, the construct will receive a toString version of it. Make sure this works properly",NULL,"Add date option to the trigger module The class should be able to use an actual Date object, thanks to Spring binding conversion. BUT, the construct will receive a toString version of it. Make sure this works properly",NULL,"Add date option to the trigger module The class should be able to use an actual Date object, thanks to Spring binding conversion<span class='highlight-text severity-high'>. BUT, the construct will receive a toString version of it. Make sure this works properly</span>","minimal","punctuation","high",False
25165,"With Partitioned Jobs, Wire Partitioner and with the MessageBus ",NULL,"With Partitioned Jobs, Wire Partitioner and with the MessageBus ",NULL,"Add for who this story is","well_formed","no_role","high",False
25167,"Allow local data transport option for the container Currently local is not a supported data transport for the container. It should be an option. Note that local is not valid for control transport for a standalone container. So we need to revisit the current semantics that default the control transport to be the same as the data transport, i.e. , transport local should fail. ",NULL,"Allow local data transport option for the container Currently local is not a supported data transport for the container. It should be an option. Note that local is not valid for control transport for a standalone container.","So we need to revisit the current semantics that default the control transport to be the same as the data transport, i.e. , transport local should fail.","Add for who this story is","well_formed","no_role","high",False
25167,"Allow local data transport option for the container Currently local is not a supported data transport for the container. It should be an option. Note that local is not valid for control transport for a standalone container. So we need to revisit the current semantics that default the control transport to be the same as the data transport, i.e. , transport local should fail. ",NULL,"Allow local data transport option for the container Currently local is not a supported data transport for the container. It should be an option. Note that local is not valid for control transport for a standalone container.","So we need to revisit the current semantics that default the control transport to be the same as the data transport, i.e. , transport local should fail.","Allow local data transport option for the container Currently local is not a supported data transport for the container<span class='highlight-text severity-high'>. It should be an option. Note that local is not valid for control transport for a standalone container. So we need to revisit the current semantics that default the control transport to be the same as the data transport, i.e. , transport local should fail. </span>","minimal","punctuation","high",False
25167,"Allow local data transport option for the container Currently local is not a supported data transport for the container. It should be an option. Note that local is not valid for control transport for a standalone container. So we need to revisit the current semantics that default the control transport to be the same as the data transport, i.e. , transport local should fail. ",NULL,"Allow local data transport option for the container Currently local is not a supported data transport for the container. It should be an option. Note that local is not valid for control transport for a standalone container.","So we need to revisit the current semantics that default the control transport to be the same as the data transport, i.e. , transport local should fail.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25151,"Turn off RestTemplate logging in shell Example xd module delete name sink file 12 31 19,495 WARN Spring Shell DELETE request for resulted in 500 Internal Server Error ; invoking error handler Command failed Cannot delete non composed module sink file The WARN log is redundant with the command result and should be silenced",NULL,"Turn off RestTemplate logging in shell Example xd module delete name sink file 12 31 19,495 WARN Spring Shell DELETE request for resulted in 500 Internal Server Error ; invoking error handler Command failed Cannot delete non composed module sink file The WARN log is redundant with the command result and should be silenced",NULL,"Add for who this story is","well_formed","no_role","high",False
25151,"Turn off RestTemplate logging in shell Example xd module delete name sink file 12 31 19,495 WARN Spring Shell DELETE request for resulted in 500 Internal Server Error ; invoking error handler Command failed Cannot delete non composed module sink file The WARN log is redundant with the command result and should be silenced",NULL,"Turn off RestTemplate logging in shell Example xd module delete name sink file 12 31 19,495 WARN Spring Shell DELETE request for resulted in 500 Internal Server Error ; invoking error handler Command failed Cannot delete non composed module sink file The WARN log is redundant with the command result and should be silenced",NULL,"Turn off RestTemplate logging in shell Example xd module delete name sink file 12 31 19,495 WARN Spring Shell DELETE request for resulted in 500 Internal Server Error ; invoking error handler Command failed Cannot delete non composed module sink file The WARN log is redundant with the command result<span class='highlight-text severity-high'> and </span>should be silenced","atomic","conjunctions","high",False
25151,"Turn off RestTemplate logging in shell Example xd module delete name sink file 12 31 19,495 WARN Spring Shell DELETE request for resulted in 500 Internal Server Error ; invoking error handler Command failed Cannot delete non composed module sink file The WARN log is redundant with the command result and should be silenced",NULL,"Turn off RestTemplate logging in shell Example xd module delete name sink file 12 31 19,495 WARN Spring Shell DELETE request for resulted in 500 Internal Server Error ; invoking error handler Command failed Cannot delete non composed module sink file The WARN log is redundant with the command result and should be silenced",NULL,"Turn off RestTemplate logging in shell Example xd module delete name sink file 12 31 19,495 WARN Spring Shell DELETE request for resulted in 500 Internal Server Error <span class='highlight-text severity-high'>; invoking error handler Command failed Cannot delete non composed module sink file The WARN log is redundant with the command result and should be silenced</span>","minimal","punctuation","high",False
25160,"Review and Optimize the Serialized JSON Nodes for Batch Objects For several Batch Job related JSON endpoints, we serialize too much information.",NULL,"Review and Optimize the Serialized JSON Nodes for Batch Objects For several Batch Job related JSON endpoints, we serialize too much information.",NULL,"Add for who this story is","well_formed","no_role","high",False
25162,"Add S FTP Gateway and Batch Partitioner to List Process Remote Files ",NULL,"Add S FTP Gateway and Batch Partitioner to List Process Remote Files ",NULL,"Add for who this story is","well_formed","no_role","high",False
25162,"Add S FTP Gateway and Batch Partitioner to List Process Remote Files ",NULL,"Add S FTP Gateway and Batch Partitioner to List Process Remote Files ",NULL,"Add S FTP Gateway<span class='highlight-text severity-high'> and </span>Batch Partitioner to List Process Remote Files ","atomic","conjunctions","high",False
25174,"Update docs for gemfire sink to include locator configuration ",NULL,"Update docs for gemfire sink to include locator configuration ",NULL,"Add for who this story is","well_formed","no_role","high",False
25175,"Create integration test script for JMS MQTT Create a script to sanity check JMS and MQTT",NULL,"Create integration test script for JMS MQTT Create a script to sanity check JMS and MQTT",NULL,"Add for who this story is","well_formed","no_role","high",False
25176,"add SpEL filter processor It should provide an expression param for SpEL and have a default value of true accept everything .",NULL,"add SpEL filter processor It should provide an expression param for SpEL and have a default value of true accept everything .",NULL,"Add for who this story is","well_formed","no_role","high",False
25176,"add SpEL filter processor It should provide an expression param for SpEL and have a default value of true accept everything .",NULL,"add SpEL filter processor It should provide an expression param for SpEL and have a default value of true accept everything .",NULL,"add SpEL filter processor It should provide an expression param for SpEL<span class='highlight-text severity-high'> and </span>have a default value of true accept everything .","atomic","conjunctions","high",False
25177,"Standardize naming and unit for options across modules We should standardize on the options between modules idleTimeout timeout rolloverSize rollover Also, need to standardize on unit used for timeout should this be s or ms? ",NULL,"Standardize naming and unit for options across modules We should standardize on the options between modules idleTimeout timeout rolloverSize rollover Also, need to standardize on unit used for timeout should this be s or ms? ",NULL,"Add for who this story is","well_formed","no_role","high",False
25177,"Standardize naming and unit for options across modules We should standardize on the options between modules idleTimeout timeout rolloverSize rollover Also, need to standardize on unit used for timeout should this be s or ms? ",NULL,"Standardize naming and unit for options across modules We should standardize on the options between modules idleTimeout timeout rolloverSize rollover Also, need to standardize on unit used for timeout should this be s or ms? ",NULL,"Standardize naming<span class='highlight-text severity-high'> and </span>unit for options across modules We should standardize on the options between modules idleTimeout timeout rolloverSize rollover Also, need to standardize on unit used for timeout should this be s<span class='highlight-text severity-high'> or </span>ms? ","atomic","conjunctions","high",False
25183,"add to container dependencies This will enable the use of groovy scripts within modules.",NULL,"add to container dependencies This will enable the use of groovy scripts within modules.",NULL,"Add for who this story is","well_formed","no_role","high",False
25185,"Restore previous CmdLine library to populate options Expected benefits are key space value as well as key value on the command line eg XD 1108 nice usage screen ",NULL,"Restore previous CmdLine library to populate options Expected benefits are key space value as well as key value on the command line eg XD 1108 nice usage screen ",NULL,"Add for who this story is","well_formed","no_role","high",False
25184,"Container Launcher id is not unique XD container s id is set to use its application context id which is derived from With the default values , the launcher id is set to application 0 When I have multiple launchers then all the launchers have the same id as application 0 which doesn t seem correct. Do we need to use the Id that is generated at the XDContainer s constructor here? public XDContainer this.id ",NULL,"Container Launcher id is not unique XD container s id is set to use its application context id which is derived from With the default values , the launcher id is set to application 0 When I have multiple launchers then all the launchers have the same id as application 0 which doesn t seem correct. Do we need to use the Id that is generated at the XDContainer s constructor here? public XDContainer this.id ",NULL,"Add for who this story is","well_formed","no_role","high",False
25184,"Container Launcher id is not unique XD container s id is set to use its application context id which is derived from With the default values , the launcher id is set to application 0 When I have multiple launchers then all the launchers have the same id as application 0 which doesn t seem correct. Do we need to use the Id that is generated at the XDContainer s constructor here? public XDContainer this.id ",NULL,"Container Launcher id is not unique XD container s id is set to use its application context id which is derived from With the default values , the launcher id is set to application 0 When I have multiple launchers then all the launchers have the same id as application 0 which doesn t seem correct. Do we need to use the Id that is generated at the XDContainer s constructor here? public XDContainer this.id ",NULL,"Container Launcher id is not unique XD container s id is set to use its application context id which is derived from With the default values , the launcher id is set to application 0 When I have multiple launchers then all the launchers have the same id as application 0 which doesn t seem correct<span class='highlight-text severity-high'>. Do we need to use the Id that is generated at the XDContainer s constructor here? public XDContainer this.id </span>","minimal","punctuation","high",False
25190,"Enabling of JMX support is broken However this is triggered depending on whether is merged yet or not , jmx seems to be broken because of duplicate beans mbeans names",NULL,"Enabling of JMX support is broken However this is triggered depending on whether is merged yet or not , jmx seems to be broken because of duplicate beans mbeans names",NULL,"Add for who this story is","well_formed","no_role","high",False
25190,"Enabling of JMX support is broken However this is triggered depending on whether is merged yet or not , jmx seems to be broken because of duplicate beans mbeans names",NULL,"Enabling of JMX support is broken However this is triggered depending on whether is merged yet or not , jmx seems to be broken because of duplicate beans mbeans names",NULL,"Enabling of JMX support is broken However this is triggered depending on whether is merged yet<span class='highlight-text severity-high'> or </span>not , jmx seems to be broken because of duplicate beans mbeans names","atomic","conjunctions","high",False
25189,"replace testsource with time and testsink with log This should facilitate testing while avoiding any class dependencies. Also, log is a generally useful sink by itself and time is a more interesting source for testing should accept interval for the seconds between time messages .",NULL,"replace testsource with time and testsink with log This should facilitate testing while avoiding any class dependencies. Also, log is a generally useful sink by itself and time is a more interesting source for testing should accept interval for the seconds between time messages .",NULL,"Add for who this story is","well_formed","no_role","high",False
25189,"replace testsource with time and testsink with log This should facilitate testing while avoiding any class dependencies. Also, log is a generally useful sink by itself and time is a more interesting source for testing should accept interval for the seconds between time messages .",NULL,"replace testsource with time and testsink with log This should facilitate testing while avoiding any class dependencies. Also, log is a generally useful sink by itself and time is a more interesting source for testing should accept interval for the seconds between time messages .",NULL,"replace testsource with time<span class='highlight-text severity-high'> and </span>testsink with log This should facilitate testing while avoiding any class dependencies. Also, log is a generally useful sink by itself and time is a more interesting source for testing should accept interval for the seconds between time messages .","atomic","conjunctions","high",False
25189,"replace testsource with time and testsink with log This should facilitate testing while avoiding any class dependencies. Also, log is a generally useful sink by itself and time is a more interesting source for testing should accept interval for the seconds between time messages .",NULL,"replace testsource with time and testsink with log This should facilitate testing while avoiding any class dependencies. Also, log is a generally useful sink by itself and time is a more interesting source for testing should accept interval for the seconds between time messages .",NULL,"replace testsource with time and testsink with log This should facilitate testing while avoiding any class dependencies<span class='highlight-text severity-high'>. Also, log is a generally useful sink by itself and time is a more interesting source for testing should accept interval for the seconds between time messages .</span>","minimal","punctuation","high",False
25187,"Update to spring data hadoop 2.0.0.M4 Update dependencies to spring data hadoop 2.0.0.M4",NULL,"Update to spring data hadoop 2.0.0.M4 Update dependencies to spring data hadoop 2.0.0.M4",NULL,"Add for who this story is","well_formed","no_role","high",False
25188,"Make avro sink options consistent with hdfs and add docs ",NULL,"Make avro sink options consistent with hdfs and add docs ",NULL,"Add for who this story is","well_formed","no_role","high",False
25188,"Make avro sink options consistent with hdfs and add docs ",NULL,"Make avro sink options consistent with hdfs and add docs ",NULL,"Make avro sink options consistent with hdfs<span class='highlight-text severity-high'> and </span>add docs ","atomic","conjunctions","high",False
25193,"xd admin server to transport as an option. NAME?",NULL,"xd admin server to transport as an option. NAME?",NULL,"Add for who this story is","well_formed","no_role","high",False
25193,"xd admin server to transport as an option. NAME?",NULL,"xd admin server to transport as an option. NAME?",NULL,"xd admin server to transport as an option<span class='highlight-text severity-high'>. NAME?</span>","minimal","punctuation","high",False
25191,"Surface the provenance of a default to the user When using Value for providing a default value in a module options POJO, make it so that the REST API and hence the module info command advertises that 1 the expression was 2 to the best extent possible value may come from another property source , tell which config file it came from introspecting the PropertySource annotation ",NULL,"Surface the provenance of a default to the user When using Value for providing a default value in a module options POJO, make it","so that the REST API and hence the module info command advertises that 1 the expression was 2 to the best extent possible value may come from another property source , tell which config file it came from introspecting the PropertySource annotation","Add for who this story is","well_formed","no_role","high",False
25191,"Surface the provenance of a default to the user When using Value for providing a default value in a module options POJO, make it so that the REST API and hence the module info command advertises that 1 the expression was 2 to the best extent possible value may come from another property source , tell which config file it came from introspecting the PropertySource annotation ",NULL,"Surface the provenance of a default to the user When using Value for providing a default value in a module options POJO, make it","so that the REST API and hence the module info command advertises that 1 the expression was 2 to the best extent possible value may come from another property source , tell which config file it came from introspecting the PropertySource annotation","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25192,"Update to spring data hadoop 2.0.0.M5 Update to spring data hadoop 2.0.0.M5 when it is released and remove the temporary in spring xd hadoop We should also review the supported hadoop distros think we should support anything that is current stable hadoop12 hadoop22 phd1 PHD 1.1 hdp13 hdp20 cdh4 ",NULL,"Update to spring data hadoop 2.0.0.M5 Update to spring data hadoop 2.0.0.M5 when it is released and remove the temporary in spring xd hadoop We should also review the supported hadoop distros think we should support anything that is current stable hadoop12 hadoop22 phd1 PHD 1.1 hdp13 hdp20 cdh4 ",NULL,"Add for who this story is","well_formed","no_role","high",False
25192,"Update to spring data hadoop 2.0.0.M5 Update to spring data hadoop 2.0.0.M5 when it is released and remove the temporary in spring xd hadoop We should also review the supported hadoop distros think we should support anything that is current stable hadoop12 hadoop22 phd1 PHD 1.1 hdp13 hdp20 cdh4 ",NULL,"Update to spring data hadoop 2.0.0.M5 Update to spring data hadoop 2.0.0.M5 when it is released and remove the temporary in spring xd hadoop We should also review the supported hadoop distros think we should support anything that is current stable hadoop12 hadoop22 phd1 PHD 1.1 hdp13 hdp20 cdh4 ",NULL,"Update to spring data hadoop 2.0.0.M5 Update to spring data hadoop 2.0.0.M5 when it is released<span class='highlight-text severity-high'> and </span>remove the temporary in spring xd hadoop We should also review the supported hadoop distros think we should support anything that is current stable hadoop12 hadoop22 phd1 PHD 1.1 hdp13 hdp20 cdh4 ","atomic","conjunctions","high",False
25194,"HDFS sink should default to The current default is but most new use 8020",NULL,"HDFS sink should default to The current default is but most new use 8020",NULL,"Add for who this story is","well_formed","no_role","high",False
25178,"Update Spring Framework dependency to 4.0 GA ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25178,"Update Spring Framework dependency to 4.0 GA ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25179,"Update Spring Integration version to 4.0.M2 ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25179,"Update Spring Integration version to 4.0.M2 ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25181,"Create Gemfire Integration Test Scripts ",NULL,"Create Gemfire Integration Test Scripts ",NULL,"Add for who this story is","well_formed","no_role","high",False
25182,"Mail Source ModuleOptions profiles ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25182,"Mail Source ModuleOptions profiles ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25186,"Update HDFS sink documentation to reflect new functionality introduced in XD 990 and XD 991 ",NULL,"Update HDFS sink documentation to reflect new functionality introduced in XD 990 and XD 991 ",NULL,"Add for who this story is","well_formed","no_role","high",False
25204,"Update jdbchdfs properties and defaults to better match hdfs sink We should use fileName, fileExtension properties and default to xd jobname as directory",NULL,"Update jdbchdfs properties and defaults to better match hdfs sink We should use fileName, fileExtension properties and default to xd jobname as directory",NULL,"Add for who this story is","well_formed","no_role","high",False
25212,"Make job names unique across tests that use the same JobRepository The job names used by the tests should be unique across the tests when use the same JobRepository. ",NULL,"Make job names unique across tests that use the same JobRepository The job names used by the tests should be unique across the tests when use the same JobRepository. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25205,"Add test for filejdbc to test scripts The filejdbc jobs isn t included in the test scripts",NULL,"Add test for filejdbc to test scripts The filejdbc jobs isn t included in the test scripts",NULL,"Add for who this story is","well_formed","no_role","high",False
25213,"Distributed JobLocator should return a valid job In distributed batch processing in XD, the JobLocator implementation for getJob String jobName should return a valid Job Since we won t we relying on the MapJobRegistry s joblocator implementation which doesn t work in distributed use case, we need to have an appropriate way to return FlowJob SimpleJob using XD s BatchJobLocator.",NULL,"Distributed JobLocator should return a valid job In distributed batch processing in XD, the JobLocator implementation for getJob String jobName should return a valid Job Since we won t we relying on the MapJobRegistry s joblocator implementation which doesn t work in distributed use case, we need to have an appropriate way to return FlowJob SimpleJob using XD s BatchJobLocator.",NULL,"Add for who this story is","well_formed","no_role","high",False
25207,"Add support for XD CONFIG environment variable in windows shell scripts This was added in bash scripts as part of XD 1186.",NULL,"Add support for XD CONFIG environment variable in windows shell scripts This was added in bash scripts as part of XD 1186.",NULL,"Add for who this story is","well_formed","no_role","high",False
25208,"Add pre compiled redis distributions for the selective OS platforms ",NULL,"Add pre compiled redis distributions for the selective OS platforms ",NULL,"Add for who this story is","well_formed","no_role","high",False
25209,"Update hadoop instructions in the xd samples batchHashtagCount and batchWordCount projects need hadoop fs ls instructions need to be updated. ",NULL,"Update hadoop instructions in the xd samples batchHashtagCount and batchWordCount projects need hadoop fs ls instructions need to be updated. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25210,"Boot updates post 0.5 M7 Some boot classes we compile against have changed or been replaced.",NULL,"Boot updates post 0.5 M7 Some boot classes we compile against have changed or been replaced.",NULL,"Add for who this story is","well_formed","no_role","high",False
25210,"Boot updates post 0.5 M7 Some boot classes we compile against have changed or been replaced.",NULL,"Boot updates post 0.5 M7 Some boot classes we compile against have changed or been replaced.",NULL,"Boot updates post 0.5 M7 Some boot classes we compile against have changed<span class='highlight-text severity-high'> or </span>been replaced.","atomic","conjunctions","high",False
25211,"Allow conditional validation for module options Using JSR303 groups, which should be derived from injected values",NULL,"Allow conditional validation for module options Using JSR303 groups, which should be derived from injected values",NULL,"Add for who this story is","well_formed","no_role","high",False
25215,"XD that has empty MANIFEST file. This build directory also gets copied into the bundle after dist .",NULL,"XD that has empty MANIFEST file. This build directory also gets copied into the bundle after dist .",NULL,"Add for who this story is","well_formed","no_role","high",False
25291,"Add aliases concept to module options and use in composed modules Following merge of allow a module option to be known by several names and elect a short name in composed module options when there is no ambiguity",NULL,"Add aliases concept to module options and use in composed modules Following merge of allow a module option to be known by several names and elect a short name in composed module options when there is no ambiguity",NULL,"Add for who this story is","well_formed","no_role","high",False
25214,"Batch jobs should use application.yml provided connection as default Batch jobs should use application.yml provided connection as default. They now have their own configuration in This config needs to account for any changes made to application.yml settings so the data is written to the batch metadata database by default.",NULL,"Batch jobs should use application.yml provided connection as default Batch jobs should use application.yml provided connection as default. They now have their own configuration in This config needs to account for any changes made to application.yml settings","so the data is written to the batch metadata database by default.","Batch jobs should use application<span class='highlight-text severity-high'>.yml provided connection as default Batch jobs should use application.yml provided connection as default. They now have their own configuration in This config needs to account for any changes made to application.yml settings so the data is written to the batch metadata database by default.</span>","minimal","punctuation","high",False
25214,"Batch jobs should use application.yml provided connection as default Batch jobs should use application.yml provided connection as default. They now have their own configuration in This config needs to account for any changes made to application.yml settings so the data is written to the batch metadata database by default.",NULL,"Batch jobs should use application.yml provided connection as default Batch jobs should use application.yml provided connection as default. They now have their own configuration in This config needs to account for any changes made to application.yml settings","so the data is written to the batch metadata database by default.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25217,"Integrate code coverage reports into the CI process Not sure if this is best done via Sonar our sonar build plan, the nightly one, or the frequent one off master... Open question is if we want to fail a build do to code coverage levels.",NULL,"Integrate code coverage reports into the CI process Not sure if this is best done via Sonar our sonar build plan, the nightly one, or the frequent one off master... Open question is if we want to fail a build do to code coverage levels.",NULL,"Add for who this story is","well_formed","no_role","high",False
25217,"Integrate code coverage reports into the CI process Not sure if this is best done via Sonar our sonar build plan, the nightly one, or the frequent one off master... Open question is if we want to fail a build do to code coverage levels.",NULL,"Integrate code coverage reports into the CI process Not sure if this is best done via Sonar our sonar build plan, the nightly one, or the frequent one off master... Open question is if we want to fail a build do to code coverage levels.",NULL,"Integrate code coverage reports into the CI process Not sure if this is best done via Sonar our sonar build plan, the nightly one,<span class='highlight-text severity-high'> or </span>the frequent one off master... Open question is if we want to fail a build do to code coverage levels.","atomic","conjunctions","high",False
25217,"Integrate code coverage reports into the CI process Not sure if this is best done via Sonar our sonar build plan, the nightly one, or the frequent one off master... Open question is if we want to fail a build do to code coverage levels.",NULL,"Integrate code coverage reports into the CI process Not sure if this is best done via Sonar our sonar build plan, the nightly one, or the frequent one off master... Open question is if we want to fail a build do to code coverage levels.",NULL,"Integrate code coverage reports into the CI process Not sure if this is best done via Sonar our sonar build plan, the nightly one, or the frequent one off master<span class='highlight-text severity-high'>... Open question is if we want to fail a build do to code coverage levels.</span>","minimal","punctuation","high",False
25216,"Add code coverage to gradle build Build should be able to generate code coverage reports. After a quick tour of the intertubes it seems that JaCoCo is a well maintained project and has first class support inside gradle. ",NULL,"Add code coverage to gradle build Build should be able to generate code coverage reports. After a quick tour of the intertubes it seems that JaCoCo is a well maintained project and has first class support inside gradle. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25216,"Add code coverage to gradle build Build should be able to generate code coverage reports. After a quick tour of the intertubes it seems that JaCoCo is a well maintained project and has first class support inside gradle. ",NULL,"Add code coverage to gradle build Build should be able to generate code coverage reports. After a quick tour of the intertubes it seems that JaCoCo is a well maintained project and has first class support inside gradle. ",NULL,"Add code coverage to gradle build Build should be able to generate code coverage reports. After a quick tour of the intertubes it seems that JaCoCo is a well maintained project<span class='highlight-text severity-high'> and </span>has first class support inside gradle. ","atomic","conjunctions","high",False
25216,"Add code coverage to gradle build Build should be able to generate code coverage reports. After a quick tour of the intertubes it seems that JaCoCo is a well maintained project and has first class support inside gradle. ",NULL,"Add code coverage to gradle build Build should be able to generate code coverage reports. After a quick tour of the intertubes it seems that JaCoCo is a well maintained project and has first class support inside gradle. ",NULL,"Add code coverage to gradle build Build should be able to generate code coverage reports<span class='highlight-text severity-high'>. After a quick tour of the intertubes it seems that JaCoCo is a well maintained project and has first class support inside gradle. </span>","minimal","punctuation","high",False
25218,"Review abstract base classes used in test cases to ensure proper resource cleanup. ",NULL,"Review abstract base classes used in test cases to ensure proper resource cleanup. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25219,"Create build infrastructure for Angular based UI Create a project that includes build and test automation for a new Angular based UI. This work is independent of calling the UI build step from gradle. A super minimal UI, just to have some basic code, is all that is required. This should use Grunt Jasmine Karma Bower YUIdoc separate story? UI Components from backbone should be available in the base project. ",NULL,"Create build infrastructure for Angular based UI Create a project that includes build and test automation for a new Angular based UI. This work is independent of calling the UI build step from gradle. A super minimal UI, just to have some basic code, is all that is required. This should use Grunt Jasmine Karma Bower YUIdoc separate story? UI Components from backbone should be available in the base project. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25219,"Create build infrastructure for Angular based UI Create a project that includes build and test automation for a new Angular based UI. This work is independent of calling the UI build step from gradle. A super minimal UI, just to have some basic code, is all that is required. This should use Grunt Jasmine Karma Bower YUIdoc separate story? UI Components from backbone should be available in the base project. ",NULL,"Create build infrastructure for Angular based UI Create a project that includes build and test automation for a new Angular based UI. This work is independent of calling the UI build step from gradle. A super minimal UI, just to have some basic code, is all that is required. This should use Grunt Jasmine Karma Bower YUIdoc separate story? UI Components from backbone should be available in the base project. ",NULL,"Create build infrastructure for Angular based UI Create a project that includes build<span class='highlight-text severity-high'> and </span>test automation for a new Angular based UI. This work is independent of calling the UI build step from gradle. A super minimal UI, just to have some basic code, is all that is required. This should use Grunt Jasmine Karma Bower YUIdoc separate story? UI Components from backbone should be available in the base project. ","atomic","conjunctions","high",False
25219,"Create build infrastructure for Angular based UI Create a project that includes build and test automation for a new Angular based UI. This work is independent of calling the UI build step from gradle. A super minimal UI, just to have some basic code, is all that is required. This should use Grunt Jasmine Karma Bower YUIdoc separate story? UI Components from backbone should be available in the base project. ",NULL,"Create build infrastructure for Angular based UI Create a project that includes build and test automation for a new Angular based UI. This work is independent of calling the UI build step from gradle. A super minimal UI, just to have some basic code, is all that is required. This should use Grunt Jasmine Karma Bower YUIdoc separate story? UI Components from backbone should be available in the base project. ",NULL,"Create build infrastructure for Angular based UI Create a project that includes build and test automation for a new Angular based UI<span class='highlight-text severity-high'>. This work is independent of calling the UI build step from gradle. A super minimal UI, just to have some basic code, is all that is required. This should use Grunt Jasmine Karma Bower YUIdoc separate story? UI Components from backbone should be available in the base project. </span>","minimal","punctuation","high",False
25203,"Update build script to use correct version of spring data hadoop based on distro ",NULL,"Update build script to use correct version of spring data hadoop based on distro ",NULL,"Add for who this story is","well_formed","no_role","high",False
25206,"Create Module options metadata for OOTB jobs Create Module options metadata for OOTB jobs ",NULL,"Create Module options metadata for OOTB jobs Create Module options metadata for OOTB jobs ",NULL,"Add for who this story is","well_formed","no_role","high",False
25234,"Create App for CI to Shutdown XD EC2 Cluster Application will shutdown all servers with a specific name. Application will take a cluster name parameter. Generate artifact to state success or failure ",NULL,"Create App for CI to Shutdown XD EC2 Cluster Application will shutdown all servers with a specific name. Application will take a cluster name parameter. Generate artifact to state success or failure ",NULL,"Add for who this story is","well_formed","no_role","high",False
25234,"Create App for CI to Shutdown XD EC2 Cluster Application will shutdown all servers with a specific name. Application will take a cluster name parameter. Generate artifact to state success or failure ",NULL,"Create App for CI to Shutdown XD EC2 Cluster Application will shutdown all servers with a specific name. Application will take a cluster name parameter. Generate artifact to state success or failure ",NULL,"Create App for CI to Shutdown XD EC2 Cluster Application will shutdown all servers with a specific name<span class='highlight-text severity-high'>. Application will take a cluster name parameter. Generate artifact to state success or failure </span>","minimal","punctuation","high",False
25233,"Optimize deployment of xd admin and multiple nodes in spring xd ec2 to occur in parallel. The deployment of nodes is sequential, we can reduce the time to deploy a cluster greatly by having these tasks execute in parallel.",NULL,"Optimize deployment of xd admin and multiple nodes in spring xd ec2 to occur in parallel. The deployment of nodes is sequential, we can reduce the time to deploy a cluster greatly by having these tasks execute in parallel.",NULL,"Add for who this story is","well_formed","no_role","high",False
25233,"Optimize deployment of xd admin and multiple nodes in spring xd ec2 to occur in parallel. The deployment of nodes is sequential, we can reduce the time to deploy a cluster greatly by having these tasks execute in parallel.",NULL,"Optimize deployment of xd admin and multiple nodes in spring xd ec2 to occur in parallel. The deployment of nodes is sequential, we can reduce the time to deploy a cluster greatly by having these tasks execute in parallel.",NULL,"Optimize deployment of xd admin<span class='highlight-text severity-high'> and </span>multiple nodes in spring xd ec2 to occur in parallel. The deployment of nodes is sequential, we can reduce the time to deploy a cluster greatly by having these tasks execute in parallel.","atomic","conjunctions","high",False
25233,"Optimize deployment of xd admin and multiple nodes in spring xd ec2 to occur in parallel. The deployment of nodes is sequential, we can reduce the time to deploy a cluster greatly by having these tasks execute in parallel.",NULL,"Optimize deployment of xd admin and multiple nodes in spring xd ec2 to occur in parallel. The deployment of nodes is sequential, we can reduce the time to deploy a cluster greatly by having these tasks execute in parallel.",NULL,"Optimize deployment of xd admin and multiple nodes in spring xd ec2 to occur in parallel<span class='highlight-text severity-high'>. The deployment of nodes is sequential, we can reduce the time to deploy a cluster greatly by having these tasks execute in parallel.</span>","minimal","punctuation","high",False
25236,"header should not be hard coded See also XD 451 as reference.",NULL,"header should not be hard coded See also XD 451 as reference.",NULL,"Add for who this story is","well_formed","no_role","high",False
25235,"Create CI Plan for XD EC2 deployment Use the cleanup app from XD 1243 to stop previous CI runs of XD on EC2. Build XD EC2 deployer from github. Use XD EC2 Deployer to deploy the CI XD Instance Should produce artifact that contains the URL admin server of the XD cluster. container servers of the XD cluster",NULL,"Create CI Plan for XD EC2 deployment Use the cleanup app from XD 1243 to stop previous CI runs of XD on EC2. Build XD EC2 deployer from github. Use XD EC2 Deployer to deploy the CI XD Instance Should produce artifact that contains the URL admin server of the XD cluster. container servers of the XD cluster",NULL,"Add for who this story is","well_formed","no_role","high",False
25235,"Create CI Plan for XD EC2 deployment Use the cleanup app from XD 1243 to stop previous CI runs of XD on EC2. Build XD EC2 deployer from github. Use XD EC2 Deployer to deploy the CI XD Instance Should produce artifact that contains the URL admin server of the XD cluster. container servers of the XD cluster",NULL,"Create CI Plan for XD EC2 deployment Use the cleanup app from XD 1243 to stop previous CI runs of XD on EC2. Build XD EC2 deployer from github. Use XD EC2 Deployer to deploy the CI XD Instance Should produce artifact that contains the URL admin server of the XD cluster. container servers of the XD cluster",NULL,"Create CI Plan for XD EC2 deployment Use the cleanup app from XD 1243 to stop previous CI runs of XD on EC2<span class='highlight-text severity-high'>. Build XD EC2 deployer from github. Use XD EC2 Deployer to deploy the CI XD Instance Should produce artifact that contains the URL admin server of the XD cluster. container servers of the XD cluster</span>","minimal","punctuation","high",False
25237,"Allow processor script variables to be passed as module parameters Currently, if we want to bind values to script variables we need to put them in a properties file like so xd stream create name definition http port 9006 script log Ideally it should be xd stream create name definition http port 9006 script foo bar baz boo log ",NULL,"Allow proces","sor script variables to be passed as module parameters Currently, if we want to bind values to script variables we need to put them in a properties file like so xd stream create name definition http port 9006 script log Ideally it should be xd stream create name definition http port 9006 script foo bar baz boo log","Add for who this story is","well_formed","no_role","high",False
25237,"Allow processor script variables to be passed as module parameters Currently, if we want to bind values to script variables we need to put them in a properties file like so xd stream create name definition http port 9006 script log Ideally it should be xd stream create name definition http port 9006 script foo bar baz boo log ",NULL,"Allow proces","sor script variables to be passed as module parameters Currently, if we want to bind values to script variables we need to put them in a properties file like so xd stream create name definition http port 9006 script log Ideally it should be xd stream create name definition http port 9006 script foo bar baz boo log","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25238,"Support default values for options derived out of placeholders The logic can be found in but caused problems in the initial PR. Revisit if needed",NULL,"Support default values for options derived out of placeholders The logic can be found in but caused problems in the initial PR. Revisit if needed",NULL,"Add for who this story is","well_formed","no_role","high",False
25238,"Support default values for options derived out of placeholders The logic can be found in but caused problems in the initial PR. Revisit if needed",NULL,"Support default values for options derived out of placeholders The logic can be found in but caused problems in the initial PR. Revisit if needed",NULL,"Support default values for options derived out of placeholders The logic can be found in but caused problems in the initial PR<span class='highlight-text severity-high'>. Revisit if needed</span>","minimal","punctuation","high",False
25239,"Copy latest build to S3 after a XD Build ",NULL,"Copy latest build to S3 after a XD Build ",NULL,"Add for who this story is","well_formed","no_role","high",False
25240,"Remove unused code related to accepted media type in MessageBus ",NULL,"Remove unused code related to accepted media type in MessageBus ",NULL,"Add for who this story is","well_formed","no_role","high",False
25245,"Rename avro sink to hdfs dataset and add support for parquet format The kite SDK is used to write Avro records in a Kite specific format and also it support the parquet format for which we will eventually support.",NULL,"Rename avro sink to hdfs dataset and add support for parquet format The kite SDK is used to write Avro records in a Kite specific format and also it support the parquet format for which we will eventually support.",NULL,"Add for who this story is","well_formed","no_role","high",False
25245,"Rename avro sink to hdfs dataset and add support for parquet format The kite SDK is used to write Avro records in a Kite specific format and also it support the parquet format for which we will eventually support.",NULL,"Rename avro sink to hdfs dataset and add support for parquet format The kite SDK is used to write Avro records in a Kite specific format and also it support the parquet format for which we will eventually support.",NULL,"Rename avro sink to hdfs dataset<span class='highlight-text severity-high'> and </span>add support for parquet format The kite SDK is used to write Avro records in a Kite specific format and also it support the parquet format for which we will eventually support.","atomic","conjunctions","high",False
25242,"Remove job options that are handled at module level from shell Since makeUnique, dateFormat and numberFormat now have their own module options now, they are nicely advertised as options to a job and will benefit from code completion soon , so they can be removed from the shell where they currently allow for a misconfiguration if set at both the job and shell level ",NULL,"Remove job options that are handled at module level from shell Since makeUnique, dateFormat and numberFormat now have their own module options now, they are nicely advertised as options to a job and will benefit from code completion","soon , so they can be removed from the shell where they currently allow for a misconfiguration if set at both the job and shell level","Add for who this story is","well_formed","no_role","high",False
25242,"Remove job options that are handled at module level from shell Since makeUnique, dateFormat and numberFormat now have their own module options now, they are nicely advertised as options to a job and will benefit from code completion soon , so they can be removed from the shell where they currently allow for a misconfiguration if set at both the job and shell level ",NULL,"Remove job options that are handled at module level from shell Since makeUnique, dateFormat and numberFormat now have their own module options now, they are nicely advertised as options to a job and will benefit from code completion","soon , so they can be removed from the shell where they currently allow for a misconfiguration if set at both the job and shell level","Remove job options that are handled at module level from shell Since makeUnique, dateFormat<span class='highlight-text severity-high'> and </span>numberFormat now have their own module options now, they are nicely advertised as options to a job and will benefit from code completion soon , so they can be removed from the shell where they currently allow for a misconfiguration if set at both the job and shell level ","atomic","conjunctions","high",False
25242,"Remove job options that are handled at module level from shell Since makeUnique, dateFormat and numberFormat now have their own module options now, they are nicely advertised as options to a job and will benefit from code completion soon , so they can be removed from the shell where they currently allow for a misconfiguration if set at both the job and shell level ",NULL,"Remove job options that are handled at module level from shell Since makeUnique, dateFormat and numberFormat now have their own module options now, they are nicely advertised as options to a job and will benefit from code completion","soon , so they can be removed from the shell where they currently allow for a misconfiguration if set at both the job and shell level","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25243,"and reactor Imports the SI 3.0 Instead of SI 4.0 Schema ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25243,"and reactor Imports the SI 3.0 Instead of SI 4.0 Schema ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25248,"Create Better UI instead of Boot s default Whitelabel Error Page Create a better UI instead of Boot s default Whitelabel Error Page ",NULL,"Create Better UI instead of Boot s default Whitelabel Error Page Create a better UI instead of Boot s default Whitelabel Error Page ",NULL,"Add for who this story is","well_formed","no_role","high",False
25241,"Create TCP source module Based off SI tcp inbound adapter. This will allow for event forwarding that can select among the existing SI options. ",NULL,"Create TCP source module Based off SI tcp inbound adapter. This will allow for event forwarding that can select among the existing SI options. ",NULL,"Create TCP source module Based off SI tcp inbound adapter<span class='highlight-text severity-high'>. This will allow for event forwarding that can select among the existing SI options. </span>","minimal","punctuation","high",False
25231,"Add to Acceptance Test EC2 CI build plan a stage that uses XD distributed mode with rabbit See Stages are comprised of one or more Jobs, which run in parallel we would like the tests across the rabbit and redis transport to occur in parallel. ",NULL,"Add to Acceptance Test EC2 CI build plan a stage that uses XD distributed mode with rabbit See Stages are comprised of one or more Jobs, which run in parallel we would like the tests across the rabbit and redis transport to occur in parallel. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25231,"Add to Acceptance Test EC2 CI build plan a stage that uses XD distributed mode with rabbit See Stages are comprised of one or more Jobs, which run in parallel we would like the tests across the rabbit and redis transport to occur in parallel. ",NULL,"Add to Acceptance Test EC2 CI build plan a stage that uses XD distributed mode with rabbit See Stages are comprised of one or more Jobs, which run in parallel we would like the tests across the rabbit and redis transport to occur in parallel. ",NULL,"Add to Acceptance Test EC2 CI build plan a stage that uses XD distributed mode with rabbit See Stages are comprised of one<span class='highlight-text severity-high'> or </span>more Jobs, which run in parallel we would like the tests across the rabbit<span class='highlight-text severity-high'> and </span>redis transport to occur in parallel. ","atomic","conjunctions","high",False
25246,"The HDFS Sink should roll over based on the number of events. ",NULL,"The HDFS Sink should roll over based on the number of events. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25247,"Create TCP sink module Based off SI tcp inbound adapter. This will allow for event fowarding.",NULL,"Create TCP sink module Based off SI tcp inbound adapter. This will allow for event fowarding.",NULL,"Add for who this story is","well_formed","no_role","high",False
25247,"Create TCP sink module Based off SI tcp inbound adapter. This will allow for event fowarding.",NULL,"Create TCP sink module Based off SI tcp inbound adapter. This will allow for event fowarding.",NULL,"Create TCP sink module Based off SI tcp inbound adapter<span class='highlight-text severity-high'>. This will allow for event fowarding.</span>","minimal","punctuation","high",False
25253,"Use dedicated modules for code completion fingerprinting see discussion at ",NULL,"Use dedicated modules for code completion fingerprinting see discussion at ",NULL,"Add for who this story is","well_formed","no_role","high",False
25252,"Support shell completions for module names see Ideally, would require a change in the parser so that it knows which kind of module was expected when it failed.",NULL,"Support shell completions for module names see Ideally, would require a change in the parser","so that it knows which kind of module was expected when it failed.","Add for who this story is","well_formed","no_role","high",False
25252,"Support shell completions for module names see Ideally, would require a change in the parser so that it knows which kind of module was expected when it failed.",NULL,"Support shell completions for module names see Ideally, would require a change in the parser","so that it knows which kind of module was expected when it failed.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25255,"Documenation for building starting redis servers ",NULL,"Documenation for building starting redis servers ",NULL,"Add for who this story is","well_formed","no_role","high",False
25254,"Remove references to XD 1050 in documentation ",NULL,"Remove references to XD 1050 in documentation ",NULL,"Add for who this story is","well_formed","no_role","high",False
25259,"Fix module type guessing heuristics Commit strengthened module type inference, but some corner cases remain marked as TODOs and commented out assertions in tests . To be effective, we need to look at the whole deployed stream or composed module . Modify ParsinContext accordingly.",NULL,"Fix module type guessing heuristics Commit strengthened module type inference, but some corner cases remain marked as TODOs and commented out assertions in tests . To be effective, we need to look at the whole deployed stream or composed module . Modify ParsinContext accordingly.",NULL,"Add for who this story is","well_formed","no_role","high",False
25259,"Fix module type guessing heuristics Commit strengthened module type inference, but some corner cases remain marked as TODOs and commented out assertions in tests . To be effective, we need to look at the whole deployed stream or composed module . Modify ParsinContext accordingly.",NULL,"Fix module type guessing heuristics Commit strengthened module type inference, but some corner cases remain marked as TODOs and commented out assertions in tests . To be effective, we need to look at the whole deployed stream or composed module . Modify ParsinContext accordingly.",NULL,"Fix module type guessing heuristics Commit strengthened module type inference, but some corner cases remain marked as TODOs<span class='highlight-text severity-high'> and </span>commented out assertions in tests . To be effective, we need to look at the whole deployed stream<span class='highlight-text severity-high'> or </span>composed module . Modify ParsinContext accordingly.","atomic","conjunctions","high",False
25259,"Fix module type guessing heuristics Commit strengthened module type inference, but some corner cases remain marked as TODOs and commented out assertions in tests . To be effective, we need to look at the whole deployed stream or composed module . Modify ParsinContext accordingly.",NULL,"Fix module type guessing heuristics Commit strengthened module type inference, but some corner cases remain marked as TODOs and commented out assertions in tests . To be effective, we need to look at the whole deployed stream or composed module . Modify ParsinContext accordingly.",NULL,"Fix module type guessing heuristics Commit strengthened module type inference, but some corner cases remain marked as TODOs and commented out assertions in tests <span class='highlight-text severity-high'>. To be effective, we need to look at the whole deployed stream or composed module . Modify ParsinContext accordingly.</span>","minimal","punctuation","high",False
25256,"Module context should have allowNulls true The current configuration prevents modules to have default values that evaluate to null. The workaround is to either have the module have its own PPC which allows nulls rid the placeholders with ",NULL,"Module context should have allowNulls true The current configuration prevents modules to have default values that evaluate to null. The workaround is to either have the module have its own PPC which allows nulls rid the placeholders with ",NULL,"Add for who this story is","well_formed","no_role","high",False
25256,"Module context should have allowNulls true The current configuration prevents modules to have default values that evaluate to null. The workaround is to either have the module have its own PPC which allows nulls rid the placeholders with ",NULL,"Module context should have allowNulls true The current configuration prevents modules to have default values that evaluate to null. The workaround is to either have the module have its own PPC which allows nulls rid the placeholders with ",NULL,"Module context should have allowNulls true The current configuration prevents modules to have default values that evaluate to null<span class='highlight-text severity-high'>. The workaround is to either have the module have its own PPC which allows nulls rid the placeholders with </span>","minimal","punctuation","high",False
25258,"Remove the constraint on job module batch job id to be job Currently, the job module s batch job s bean id should be job . This also causes the job name to be actual job name .job and the batch job controllers require to search for job with suffix .job . Removing this constraint would help us avoiding these.",NULL,"Remove the constraint on job module batch job id to be job Currently, the job module s batch job s bean id should be job . This also causes the job name to be actual job name .job and the batch job controllers require to search for job with suffix .job . Removing this constraint would help us avoiding these.",NULL,"Add for who this story is","well_formed","no_role","high",False
25258,"Remove the constraint on job module batch job id to be job Currently, the job module s batch job s bean id should be job . This also causes the job name to be actual job name .job and the batch job controllers require to search for job with suffix .job . Removing this constraint would help us avoiding these.",NULL,"Remove the constraint on job module batch job id to be job Currently, the job module s batch job s bean id should be job . This also causes the job name to be actual job name .job and the batch job controllers require to search for job with suffix .job . Removing this constraint would help us avoiding these.",NULL,"Remove the constraint on job module batch job id to be job Currently, the job module s batch job s bean id should be job . This also causes the job name to be actual job name .job<span class='highlight-text severity-high'> and </span>the batch job controllers require to search for job with suffix .job . Removing this constraint would help us avoiding these.","atomic","conjunctions","high",False
25258,"Remove the constraint on job module batch job id to be job Currently, the job module s batch job s bean id should be job . This also causes the job name to be actual job name .job and the batch job controllers require to search for job with suffix .job . Removing this constraint would help us avoiding these.",NULL,"Remove the constraint on job module batch job id to be job Currently, the job module s batch job s bean id should be job . This also causes the job name to be actual job name .job and the batch job controllers require to search for job with suffix .job . Removing this constraint would help us avoiding these.",NULL,"Remove the constraint on job module batch job id to be job Currently, the job module s batch job s bean id should be job <span class='highlight-text severity-high'>. This also causes the job name to be actual job name .job and the batch job controllers require to search for job with suffix .job . Removing this constraint would help us avoiding these.</span>","minimal","punctuation","high",False
25267,"Use HATEOAS Link templates HATEOAS 0.9 introduced some support for templated links. This should be leveraged to properly handle eg streams instead of using string concatenation",NULL,"Use HATEOAS Link templates HATEOAS 0.9 introduced some support for templated links. This should be leveraged to properly handle eg streams instead of using string concatenation",NULL,"Add for who this story is","well_formed","no_role","high",False
25267,"Use HATEOAS Link templates HATEOAS 0.9 introduced some support for templated links. This should be leveraged to properly handle eg streams instead of using string concatenation",NULL,"Use HATEOAS Link templates HATEOAS 0.9 introduced some support for templated links. This should be leveraged to properly handle eg streams instead of using string concatenation",NULL,"Use HATEOAS Link templates HATEOAS 0<span class='highlight-text severity-high'>.9 introduced some support for templated links. This should be leveraged to properly handle eg streams instead of using string concatenation</span>","minimal","punctuation","high",False
25260,"Tail file channel adapters ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25260,"Tail file channel adapters ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25266,"Move ftp support from .x package to spring xd dirt batch package Commit introduced support for FTP and added a bunch of .x classes. These should not belong to DIRT proper though, and should be added to an extension style project. The job s module would then depend on them",NULL,"Move ftp support from .x package to spring xd dirt batch package Commit introduced support for FTP and added a bunch of .x classes. These should not belong to DIRT proper though, and should be added to an extension style project. The job s module would then depend on them",NULL,"Add for who this story is","well_formed","no_role","high",False
25266,"Move ftp support from .x package to spring xd dirt batch package Commit introduced support for FTP and added a bunch of .x classes. These should not belong to DIRT proper though, and should be added to an extension style project. The job s module would then depend on them",NULL,"Move ftp support from .x package to spring xd dirt batch package Commit introduced support for FTP and added a bunch of .x classes. These should not belong to DIRT proper though, and should be added to an extension style project. The job s module would then depend on them",NULL,"Move ftp support from .x package to spring xd dirt batch package Commit introduced support for FTP<span class='highlight-text severity-high'> and </span>added a bunch of .x classes. These should not belong to DIRT proper though, and should be added to an extension style project. The job s module would then depend on them","atomic","conjunctions","high",False
25266,"Move ftp support from .x package to spring xd dirt batch package Commit introduced support for FTP and added a bunch of .x classes. These should not belong to DIRT proper though, and should be added to an extension style project. The job s module would then depend on them",NULL,"Move ftp support from .x package to spring xd dirt batch package Commit introduced support for FTP and added a bunch of .x classes. These should not belong to DIRT proper though, and should be added to an extension style project. The job s module would then depend on them",NULL,"Move ftp support from <span class='highlight-text severity-high'>.x package to spring xd dirt batch package Commit introduced support for FTP and added a bunch of .x classes. These should not belong to DIRT proper though, and should be added to an extension style project. The job s module would then depend on them</span>","minimal","punctuation","high",False
25264,"Create shell command for getting information on a given job instance ",NULL,"Create shell command for getting information on a given job instance ",NULL,"Add for who this story is","well_formed","no_role","high",False
25265,"File Sink should support Replace as an option currently the file sink only supports append. User should support an overwrite feature.",NULL,"File Sink should support Replace as an option currently the file sink only supports append. User should support an overwrite feature.",NULL,"Add for who this story is","well_formed","no_role","high",False
25265,"File Sink should support Replace as an option currently the file sink only supports append. User should support an overwrite feature.",NULL,"File Sink should support Replace as an option currently the file sink only supports append. User should support an overwrite feature.",NULL,"File Sink should support Replace as an option currently the file sink only supports append<span class='highlight-text severity-high'>. User should support an overwrite feature.</span>","minimal","punctuation","high",False
25268,"Weird behavior of the transform module When trying some of the examples of XD 159, came up with weird behavior of the transform module. This boils down to stream create foo definition http transform expression new transform log http post data 42 Integer OK http post data WTH WTH ! Seems that when the expression can not be evaluated, the incoming payload is transmitted as is",NULL,"Weird behavior of the transform module When trying some of the examples of XD 159, came up with weird behavior of the transform module. This boils down to stream create foo definition http transform expression new transform log http post data 42 Integer OK http post data WTH WTH ! Seems that when the expression can not be evaluated, the incoming payload is transmitted as is",NULL,"Add for who this story is","well_formed","no_role","high",False
25268,"Weird behavior of the transform module When trying some of the examples of XD 159, came up with weird behavior of the transform module. This boils down to stream create foo definition http transform expression new transform log http post data 42 Integer OK http post data WTH WTH ! Seems that when the expression can not be evaluated, the incoming payload is transmitted as is",NULL,"Weird behavior of the transform module When trying some of the examples of XD 159, came up with weird behavior of the transform module. This boils down to stream create foo definition http transform expression new transform log http post data 42 Integer OK http post data WTH WTH ! Seems that when the expression can not be evaluated, the incoming payload is transmitted as is",NULL,"Weird behavior of the transform module When trying some of the examples of XD 159, came up with weird behavior of the transform module<span class='highlight-text severity-high'>. This boils down to stream create foo definition http transform expression new transform log http post data 42 Integer OK http post data WTH WTH ! Seems that when the expression can not be evaluated, the incoming payload is transmitted as is</span>","minimal","punctuation","high",False
25269,"JSR303 validation of options interferes with dsl completion When using a JSR303 annotated class for module options, the binding failures should be bypassed, as they interfere with completion proposals. ",NULL,"JSR303 validation of options interferes with dsl completion When using a JSR303 annotated class for module options, the binding failures should be bypassed, as they interfere with completion proposals. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25270,"Upgrade Lettuce to 2.3.2 ",NULL,"Upgrade Lettuce to 2.3.2 ",NULL,"Add for who this story is","well_formed","no_role","high",False
25261,"Remove container entry in Redis when the application context event to shutdown the container is fired ",NULL,"Remove container entry in Redis when the application context event to shutdown the container is fired ",NULL,"Add for who this story is","well_formed","no_role","high",False
25251,"Support shell completions for closed set of values in stream definitions When doing dsl completion in a stream definition and a module option accepts a value that has a closed set of possible values eg booleans, enums , we can provide completions for those. ",NULL,"Support shell completions for closed set of values in stream definitions When doing dsl completion in a stream definition and a module option accepts a value that has a closed set of possible values eg booleans, enums , we can provide completions for those. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25251,"Support shell completions for closed set of values in stream definitions When doing dsl completion in a stream definition and a module option accepts a value that has a closed set of possible values eg booleans, enums , we can provide completions for those. ",NULL,"Support shell completions for closed set of values in stream definitions When doing dsl completion in a stream definition and a module option accepts a value that has a closed set of possible values eg booleans, enums , we can provide completions for those. ",NULL,"Support shell completions for closed set of values in stream definitions When doing dsl completion in a stream definition<span class='highlight-text severity-high'> and </span>a module option accepts a value that has a closed set of possible values eg booleans, enums , we can provide completions for those. ","atomic","conjunctions","high",False
25263,"Create REST API for getting information on a given job instance ",NULL,"Create REST API for getting information on a given job instance ",NULL,"Add for who this story is","well_formed","no_role","high",False
25274,"Create XD .zip distribution for YARN Create XD .zip distribution for YARN that adds an additional sub project to the spring xd repo for building the xd YARN.zip Link into main build file Produce a new artifact as part of the nightly CI process will now have 2 artifacts, main xd.zip distribution and xd yarn.zip Does not include any Hadoop distribution libraries s for Apache22 unflavored ",NULL,"Create XD .zip distribution for YARN Create XD .zip distribution for YARN that adds an additional sub project to the spring xd repo for building the xd YARN.zip Link into main build file Produce a new artifact as part of the nightly CI process will now have 2 artifacts, main xd.zip distribution and xd yarn.zip Does not include any Hadoop distribution libraries s for Apache22 unflavored ",NULL,"Add for who this story is","well_formed","no_role","high",False
25274,"Create XD .zip distribution for YARN Create XD .zip distribution for YARN that adds an additional sub project to the spring xd repo for building the xd YARN.zip Link into main build file Produce a new artifact as part of the nightly CI process will now have 2 artifacts, main xd.zip distribution and xd yarn.zip Does not include any Hadoop distribution libraries s for Apache22 unflavored ",NULL,"Create XD .zip distribution for YARN Create XD .zip distribution for YARN that adds an additional sub project to the spring xd repo for building the xd YARN.zip Link into main build file Produce a new artifact as part of the nightly CI process will now have 2 artifacts, main xd.zip distribution and xd yarn.zip Does not include any Hadoop distribution libraries s for Apache22 unflavored ",NULL,"Create XD .zip distribution for YARN Create XD .zip distribution for YARN that adds an additional sub project to the spring xd repo for building the xd YARN.zip Link into main build file Produce a new artifact as part of the nightly CI process will now have 2 artifacts, main xd.zip distribution<span class='highlight-text severity-high'> and </span>xd yarn.zip Does not include any Hadoop distribution libraries s for Apache22 unflavored ","atomic","conjunctions","high",False
25275,"Create POJO based FileSink module metadata This is so that we can have an ENUM that can show the possible values and autocomplete. Using just the XML the user has a greater chance to enter an invalid mode. ",NULL,"Create POJO based FileSink module metadata This is","so that we can have an ENUM that can show the possible values and autocomplete. Using just the XML the user has a greater chance to enter an invalid mode.","Add for who this story is","well_formed","no_role","high",False
25275,"Create POJO based FileSink module metadata This is so that we can have an ENUM that can show the possible values and autocomplete. Using just the XML the user has a greater chance to enter an invalid mode. ",NULL,"Create POJO based FileSink module metadata This is","so that we can have an ENUM that can show the possible values and autocomplete. Using just the XML the user has a greater chance to enter an invalid mode.","Create POJO based FileSink module metadata This is so that we can have an ENUM that can show the possible values and autocomplete<span class='highlight-text severity-high'>. Using just the XML the user has a greater chance to enter an invalid mode. </span>","minimal","punctuation","high",False
25275,"Create POJO based FileSink module metadata This is so that we can have an ENUM that can show the possible values and autocomplete. Using just the XML the user has a greater chance to enter an invalid mode. ",NULL,"Create POJO based FileSink module metadata This is","so that we can have an ENUM that can show the possible values and autocomplete. Using just the XML the user has a greater chance to enter an invalid mode.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25276,"Profile support for modules To allow for groups of beans to be defined or not in the container that runs a module. When deploying a stream e.g. via the REST API , it should be possible to also provide profile names. Then those would apply to any modules within that particular stream deployment.",NULL,"Profile support for modules To allow for groups of beans to be defined or not in the container that runs a module. When deploying a stream e.g. via the REST API , it should be possible to also provide profile names. Then those would apply to any modules within that particular stream deployment.",NULL,"Add for who this story is","well_formed","no_role","high",False
25276,"Profile support for modules To allow for groups of beans to be defined or not in the container that runs a module. When deploying a stream e.g. via the REST API , it should be possible to also provide profile names. Then those would apply to any modules within that particular stream deployment.",NULL,"Profile support for modules To allow for groups of beans to be defined or not in the container that runs a module. When deploying a stream e.g. via the REST API , it should be possible to also provide profile names. Then those would apply to any modules within that particular stream deployment.",NULL,"Profile support for modules To allow for groups of beans to be defined<span class='highlight-text severity-high'> or </span>not in the container that runs a module. When deploying a stream e.g. via the REST API , it should be possible to also provide profile names. Then those would apply to any modules within that particular stream deployment.","atomic","conjunctions","high",False
25276,"Profile support for modules To allow for groups of beans to be defined or not in the container that runs a module. When deploying a stream e.g. via the REST API , it should be possible to also provide profile names. Then those would apply to any modules within that particular stream deployment.",NULL,"Profile support for modules To allow for groups of beans to be defined or not in the container that runs a module. When deploying a stream e.g. via the REST API , it should be possible to also provide profile names. Then those would apply to any modules within that particular stream deployment.",NULL,"Profile support for modules To allow for groups of beans to be defined or not in the container that runs a module<span class='highlight-text severity-high'>. When deploying a stream e.g. via the REST API , it should be possible to also provide profile names. Then those would apply to any modules within that particular stream deployment.</span>","minimal","punctuation","high",False
25279,"Create shell script to retrieve list of xd components running on YARN ",NULL,"Create shell script to retrieve list of xd components running on YARN ",NULL,"Add for who this story is","well_formed","no_role","high",False
25277,"Make Batch Job Restarts Work with Distributed Nodes Job restart fails with NPE. See PR for XD 1090 ",NULL,"Make Batch Job Restarts Work with Distributed Nodes Job restart fails with NPE. See PR for XD 1090 ",NULL,"Add for who this story is","well_formed","no_role","high",False
25277,"Make Batch Job Restarts Work with Distributed Nodes Job restart fails with NPE. See PR for XD 1090 ",NULL,"Make Batch Job Restarts Work with Distributed Nodes Job restart fails with NPE. See PR for XD 1090 ",NULL,"Make Batch Job Restarts Work with Distributed Nodes Job restart fails with NPE<span class='highlight-text severity-high'>. See PR for XD 1090 </span>","minimal","punctuation","high",False
25278,"Add XD deployment for YARN Add YARN specific code based on Janne s prototyping Add YARN Client and AppMaster implementations and startup config files This includes shell scripts to deploy XD to YARN Test working on Apache 2.2 distribution We can modify config files, everything should be possible to override by providing command line args or env variables. . xd yarn deploy zipFile config ",NULL,"Add XD deployment for YARN Add YARN specific code based on Janne s prototyping Add YARN Client and AppMaster implementations and startup config files This includes shell scripts to deploy XD to YARN Test working on Apache 2.2 distribution We can modify config files, everything should be possible to override by providing command line args or env variables. . xd yarn deploy zipFile config ",NULL,"Add for who this story is","well_formed","no_role","high",False
25278,"Add XD deployment for YARN Add YARN specific code based on Janne s prototyping Add YARN Client and AppMaster implementations and startup config files This includes shell scripts to deploy XD to YARN Test working on Apache 2.2 distribution We can modify config files, everything should be possible to override by providing command line args or env variables. . xd yarn deploy zipFile config ",NULL,"Add XD deployment for YARN Add YARN specific code based on Janne s prototyping Add YARN Client and AppMaster implementations and startup config files This includes shell scripts to deploy XD to YARN Test working on Apache 2.2 distribution We can modify config files, everything should be possible to override by providing command line args or env variables. . xd yarn deploy zipFile config ",NULL,"Add XD deployment for YARN Add YARN specific code based on Janne s prototyping Add YARN Client<span class='highlight-text severity-high'> and </span>AppMaster implementations and startup config files This includes shell scripts to deploy XD to YARN Test working on Apache 2.2 distribution We can modify config files, everything should be possible to override by providing command line args<span class='highlight-text severity-high'> or </span>env variables. . xd yarn deploy zipFile config ","atomic","conjunctions","high",False
25278,"Add XD deployment for YARN Add YARN specific code based on Janne s prototyping Add YARN Client and AppMaster implementations and startup config files This includes shell scripts to deploy XD to YARN Test working on Apache 2.2 distribution We can modify config files, everything should be possible to override by providing command line args or env variables. . xd yarn deploy zipFile config ",NULL,"Add XD deployment for YARN Add YARN specific code based on Janne s prototyping Add YARN Client and AppMaster implementations and startup config files This includes shell scripts to deploy XD to YARN Test working on Apache 2.2 distribution We can modify config files, everything should be possible to override by providing command line args or env variables. . xd yarn deploy zipFile config ",NULL,"Add XD deployment for YARN Add YARN specific code based on Janne s prototyping Add YARN Client and AppMaster implementations and startup config files This includes shell scripts to deploy XD to YARN Test working on Apache 2<span class='highlight-text severity-high'>.2 distribution We can modify config files, everything should be possible to override by providing command line args or env variables. . xd yarn deploy zipFile config </span>","minimal","punctuation","high",False
25280,"Make Hadoop22 the default for the build ",NULL,"Make Hadoop22 the default for the build ",NULL,"Add for who this story is","well_formed","no_role","high",False
25993,"Create gradle task to check that all projects have descriptions This keeps coming up as an issue that prevents us from publishing to maven central.",NULL,"Create gradle task to check that all projects have descriptions This keeps coming up as an issue that prevents us from publishing to maven central.",NULL,"Add for who this story is","well_formed","no_role","high",False
25286,"XD Integration pauses should be configurable While the current setting work while running from your laptop to local deployments. Or running from your laptop to ec2, they are not long enough for CI to Ec2. This should have good defaults and have CI set them to what it needs.",NULL,"XD Integration pauses should be configurable While the current setting work while running from your laptop to local deployments. Or running from your laptop to ec2, they are not long enough for CI to Ec2. This should have good defaults and have CI set them to what it needs.",NULL,"Add for who this story is","well_formed","no_role","high",False
25286,"XD Integration pauses should be configurable While the current setting work while running from your laptop to local deployments. Or running from your laptop to ec2, they are not long enough for CI to Ec2. This should have good defaults and have CI set them to what it needs.",NULL,"XD Integration pauses should be configurable While the current setting work while running from your laptop to local deployments. Or running from your laptop to ec2, they are not long enough for CI to Ec2. This should have good defaults and have CI set them to what it needs.",NULL,"XD Integration pauses should be configurable While the current setting work while running from your laptop to local deployments.<span class='highlight-text severity-high'> or </span>running from your laptop to ec2, they are not long enough for CI to Ec2. This should have good defaults<span class='highlight-text severity-high'> and </span>have CI set them to what it needs.","atomic","conjunctions","high",False
25286,"XD Integration pauses should be configurable While the current setting work while running from your laptop to local deployments. Or running from your laptop to ec2, they are not long enough for CI to Ec2. This should have good defaults and have CI set them to what it needs.",NULL,"XD Integration pauses should be configurable While the current setting work while running from your laptop to local deployments. Or running from your laptop to ec2, they are not long enough for CI to Ec2. This should have good defaults and have CI set them to what it needs.",NULL,"XD Integration pauses should be configurable While the current setting work while running from your laptop to local deployments<span class='highlight-text severity-high'>. Or running from your laptop to ec2, they are not long enough for CI to Ec2. This should have good defaults and have CI set them to what it needs.</span>","minimal","punctuation","high",False
25282,"Provide xd shell integration for deploying XD on YARN Command such as yarn app list yarn deploy xd zipFile tmp myapp.zip config tmp myconfig.yml ",NULL,"Provide xd shell integration for deploying XD on YARN Command such as yarn app list yarn deploy xd zipFile tmp myapp.zip config tmp myconfig.yml ",NULL,"Add for who this story is","well_formed","no_role","high",False
25283,"Modularize XD UI From we understand the importance of modularizing client side javascript code. This story tracks modularization of XD UI.",NULL,"Modularize XD UI From we understand the importance of modularizing client side javascript code. This story tracks modularization of XD UI.",NULL,"Add for who this story is","well_formed","no_role","high",False
25283,"Modularize XD UI From we understand the importance of modularizing client side javascript code. This story tracks modularization of XD UI.",NULL,"Modularize XD UI From we understand the importance of modularizing client side javascript code. This story tracks modularization of XD UI.",NULL,"Modularize XD UI From we understand the importance of modularizing client side javascript code<span class='highlight-text severity-high'>. This story tracks modularization of XD UI.</span>","minimal","punctuation","high",False
25284,"Fail Sonar CI build if there are any package tangles violated. Similar to what would show up on structure101 reports.",NULL,"Fail Sonar CI build if there are any package tangles violated. Similar to what would show up on structure101 reports.",NULL,"Add for who this story is","well_formed","no_role","high",False
25284,"Fail Sonar CI build if there are any package tangles violated. Similar to what would show up on structure101 reports.",NULL,"Fail Sonar CI build if there are any package tangles violated. Similar to what would show up on structure101 reports.",NULL,"Fail Sonar CI build if there are any package tangles violated<span class='highlight-text severity-high'>. Similar to what would show up on structure101 reports.</span>","minimal","punctuation","high",False
25285,"Make Batch Job Restarts Work using Single Node See also XD 1320.",NULL,"Make Batch Job Restarts Work using Single Node See also XD 1320.",NULL,"Add for who this story is","well_formed","no_role","high",False
25273,"Commands that start a job should return a representation of the JobExecution See discussion at ",NULL,"Commands that start a job should return a representation of the JobExecution See discussion at ",NULL,"Add for who this story is","well_formed","no_role","high",False
25271,"Job execution list should mention jobs that have been deleted Create a job, execute it a couple of times, destroy it and then invoke job execution list. The job name column should mention that a job is defunct even though a job with the same name could have been re created in the interim ",NULL,"Job execution list should mention jobs that have been deleted Create a job, execute it a couple of times, destroy it and then invoke job execution list. The job name column should mention that a job is defunct even though a job with the same name could have been re created in the interim ",NULL,"Add for who this story is","well_formed","no_role","high",False
25271,"Job execution list should mention jobs that have been deleted Create a job, execute it a couple of times, destroy it and then invoke job execution list. The job name column should mention that a job is defunct even though a job with the same name could have been re created in the interim ",NULL,"Job execution list should mention jobs that have been deleted Create a job, execute it a couple of times, destroy it and then invoke job execution list. The job name column should mention that a job is defunct even though a job with the same name could have been re created in the interim ",NULL,"Job execution list should mention jobs that have been deleted Create a job, execute it a couple of times, destroy it<span class='highlight-text severity-high'> and </span>then invoke job execution list. The job name column should mention that a job is defunct even though a job with the same name could have been re created in the interim ","atomic","conjunctions","high",False
25271,"Job execution list should mention jobs that have been deleted Create a job, execute it a couple of times, destroy it and then invoke job execution list. The job name column should mention that a job is defunct even though a job with the same name could have been re created in the interim ",NULL,"Job execution list should mention jobs that have been deleted Create a job, execute it a couple of times, destroy it and then invoke job execution list. The job name column should mention that a job is defunct even though a job with the same name could have been re created in the interim ",NULL,"Job execution list should mention jobs that have been deleted Create a job, execute it a couple of times, destroy it and then invoke job execution list<span class='highlight-text severity-high'>. The job name column should mention that a job is defunct even though a job with the same name could have been re created in the interim </span>","minimal","punctuation","high",False
25281,"Deploy XD on YARN for a distribution other than Apache Hadoop 2.2 Suggest trying with Hortonworks 2.0",NULL,"Deploy XD on YARN for a distribution other than Apache Hadoop 2.2 Suggest trying with Hortonworks 2.0",NULL,"Add for who this story is","well_formed","no_role","high",False
25288,"Investigate link checking tool for user guide Asciidoc doctor might have one as part of it toolchain",NULL,"Investigate link checking tool for user guide Asciidoc doctor might have one as part of it toolchain",NULL,"Add for who this story is","well_formed","no_role","high",False
25289,"Support oracle jdbc configuration for XD batch job repository Currently, hsqldb, postgres and mysql job repositories are supported. We need to add configurable oracle jdbc settings.",NULL,"Support oracle jdbc configuration for XD batch job repository Currently, hsqldb, postgres and mysql job repositories are supported. We need to add configurable oracle jdbc settings.",NULL,"Add for who this story is","well_formed","no_role","high",False
25289,"Support oracle jdbc configuration for XD batch job repository Currently, hsqldb, postgres and mysql job repositories are supported. We need to add configurable oracle jdbc settings.",NULL,"Support oracle jdbc configuration for XD batch job repository Currently, hsqldb, postgres and mysql job repositories are supported. We need to add configurable oracle jdbc settings.",NULL,"Support oracle jdbc configuration for XD batch job repository Currently, hsqldb, postgres and mysql job repositories are supported<span class='highlight-text severity-high'>. We need to add configurable oracle jdbc settings.</span>","minimal","punctuation","high",False
25290,"Use dot as the composed module option separator Following merge of use dot as the separator for a composed module option. Need change to the parser to accept dots",NULL,"Use dot as the composed module option separator Following merge of use dot as the separator for a composed module option. Need change to the parser to accept dots",NULL,"Add for who this story is","well_formed","no_role","high",False
25290,"Use dot as the composed module option separator Following merge of use dot as the separator for a composed module option. Need change to the parser to accept dots",NULL,"Use dot as the composed module option separator Following merge of use dot as the separator for a composed module option. Need change to the parser to accept dots",NULL,"Use dot as the composed module option separator Following merge of use dot as the separator for a composed module option<span class='highlight-text severity-high'>. Need change to the parser to accept dots</span>","minimal","punctuation","high",False
25291,"Add aliases concept to module options and use in composed modules Following merge of allow a module option to be known by several names and elect a short name in composed module options when there is no ambiguity",NULL,"Add aliases concept to module options and use in composed modules Following merge of allow a module option to be known by several names and elect a short name in composed module options when there is no ambiguity",NULL,"Add aliases concept to module options<span class='highlight-text severity-high'> and </span>use in composed modules Following merge of allow a module option to be known by several names and elect a short name in composed module options when there is no ambiguity","atomic","conjunctions","high",False
25292,"Expose a getter for a module unique id inside a stream definition Following merge of expose a unique id under which a module is known inside a stream. That id which defaults to the module name is what should be used as the qualifier for an option name inside a composed module, ie module compose foo definition f1 filter filter f1.expression and filter.expression are available ",NULL,"Expose a getter for a module unique id inside a stream definition Following merge of expose a unique id under which a module is known inside a stream. That id which defaults to the module name is what should be used as the qualifier for an option name inside a composed module, ie module compose foo definition f1 filter filter f1.expression and filter.expression are available ",NULL,"Add for who this story is","well_formed","no_role","high",False
25292,"Expose a getter for a module unique id inside a stream definition Following merge of expose a unique id under which a module is known inside a stream. That id which defaults to the module name is what should be used as the qualifier for an option name inside a composed module, ie module compose foo definition f1 filter filter f1.expression and filter.expression are available ",NULL,"Expose a getter for a module unique id inside a stream definition Following merge of expose a unique id under which a module is known inside a stream. That id which defaults to the module name is what should be used as the qualifier for an option name inside a composed module, ie module compose foo definition f1 filter filter f1.expression and filter.expression are available ",NULL,"Expose a getter for a module unique id inside a stream definition Following merge of expose a unique id under which a module is known inside a stream. That id which defaults to the module name is what should be used as the qualifier for an option name inside a composed module, ie module compose foo definition f1 filter filter f1.expression<span class='highlight-text severity-high'> and </span>filter.expression are available ","atomic","conjunctions","high",False
25292,"Expose a getter for a module unique id inside a stream definition Following merge of expose a unique id under which a module is known inside a stream. That id which defaults to the module name is what should be used as the qualifier for an option name inside a composed module, ie module compose foo definition f1 filter filter f1.expression and filter.expression are available ",NULL,"Expose a getter for a module unique id inside a stream definition Following merge of expose a unique id under which a module is known inside a stream. That id which defaults to the module name is what should be used as the qualifier for an option name inside a composed module, ie module compose foo definition f1 filter filter f1.expression and filter.expression are available ",NULL,"Expose a getter for a module unique id inside a stream definition Following merge of expose a unique id under which a module is known inside a stream<span class='highlight-text severity-high'>. That id which defaults to the module name is what should be used as the qualifier for an option name inside a composed module, ie module compose foo definition f1 filter filter f1.expression and filter.expression are available </span>","minimal","punctuation","high",False
25296,"Remove enum for transport options The enum unnecessarily restricts the ability to add new transport MessageBus implementations whereas the config location path is open for extensions since it uses wildcards in message bus.xml import bus.xml ",NULL,"Remove enum for transport options The enum unnecessarily restricts the ability to add new transport MessageBus implementations whereas the config location path is open for extensions since it uses wildcards in message bus.xml import bus.xml ",NULL,"Add for who this story is","well_formed","no_role","high",False
25805,"Implement a Spark Streaming Receiver that binds to the MessageBus ",NULL,"Implement a Spark Streaming Receiver that binds to the MessageBus ",NULL,"Add for who this story is","well_formed","no_role","high",False
25298,"Switch to use Jedis driver for Redis The Spring Data team recommends using the Jedis driver since the Lettuce driver hasn t had any update activity for several months. Jedis is actively maintained. We might also want to investigate Redisson which is a fork of Lettuce ",NULL,"Switch to use Jedis driver for Redis The Spring Data team recommends using the Jedis driver since the Lettuce driver hasn t had any update activity for several months. Jedis is actively maintained. We might also want to investigate Redisson which is a fork of Lettuce ",NULL,"Add for who this story is","well_formed","no_role","high",False
25298,"Switch to use Jedis driver for Redis The Spring Data team recommends using the Jedis driver since the Lettuce driver hasn t had any update activity for several months. Jedis is actively maintained. We might also want to investigate Redisson which is a fork of Lettuce ",NULL,"Switch to use Jedis driver for Redis The Spring Data team recommends using the Jedis driver since the Lettuce driver hasn t had any update activity for several months. Jedis is actively maintained. We might also want to investigate Redisson which is a fork of Lettuce ",NULL,"Switch to use Jedis driver for Redis The Spring Data team recommends using the Jedis driver since the Lettuce driver hasn t had any update activity for several months<span class='highlight-text severity-high'>. Jedis is actively maintained. We might also want to investigate Redisson which is a fork of Lettuce </span>","minimal","punctuation","high",False
25299,"Remove XDContainer and rename Post boot refactoring. XDContainer lifecycle methods are not being used. Refactor by merging relevant functionality into Rename to consistent with ",NULL,"Remove XDContainer and rename Post boot refactoring. XDContainer lifecycle methods are not being used. Refactor by merging relevant functionality into Rename to consistent with ",NULL,"Add for who this story is","well_formed","no_role","high",False
25299,"Remove XDContainer and rename Post boot refactoring. XDContainer lifecycle methods are not being used. Refactor by merging relevant functionality into Rename to consistent with ",NULL,"Remove XDContainer and rename Post boot refactoring. XDContainer lifecycle methods are not being used. Refactor by merging relevant functionality into Rename to consistent with ",NULL,"Remove XDContainer<span class='highlight-text severity-high'> and </span>rename Post boot refactoring. XDContainer lifecycle methods are not being used. Refactor by merging relevant functionality into Rename to consistent with ","atomic","conjunctions","high",False
25299,"Remove XDContainer and rename Post boot refactoring. XDContainer lifecycle methods are not being used. Refactor by merging relevant functionality into Rename to consistent with ",NULL,"Remove XDContainer and rename Post boot refactoring. XDContainer lifecycle methods are not being used. Refactor by merging relevant functionality into Rename to consistent with ",NULL,"Remove XDContainer and rename Post boot refactoring<span class='highlight-text severity-high'>. XDContainer lifecycle methods are not being used. Refactor by merging relevant functionality into Rename to consistent with </span>","minimal","punctuation","high",False
25322,"Container and Single Node do not update their associated log After the is up and running, the application does not update the singlenode.log or containernode.log. create a stream time log . you will see the timestamp in your console, but it will not be in the log.",NULL,"Container and Single Node do not update their associated log After the is up and running, the application does not update the singlenode.log or containernode.log. create a stream time log . you will see the timestamp in your console, but it will not be in the log.",NULL,"Add for who this story is","well_formed","no_role","high",False
25322,"Container and Single Node do not update their associated log After the is up and running, the application does not update the singlenode.log or containernode.log. create a stream time log . you will see the timestamp in your console, but it will not be in the log.",NULL,"Container and Single Node do not update their associated log After the is up and running, the application does not update the singlenode.log or containernode.log. create a stream time log . you will see the timestamp in your console, but it will not be in the log.",NULL,"Container<span class='highlight-text severity-high'> and </span>Single Node do not update their associated log After the is up and running, the application does not update the singlenode.log<span class='highlight-text severity-high'> or </span>containernode.log. create a stream time log . you will see the timestamp in your console, but it will not be in the log.","atomic","conjunctions","high",False
25322,"Container and Single Node do not update their associated log After the is up and running, the application does not update the singlenode.log or containernode.log. create a stream time log . you will see the timestamp in your console, but it will not be in the log.",NULL,"Container and Single Node do not update their associated log After the is up and running, the application does not update the singlenode.log or containernode.log. create a stream time log . you will see the timestamp in your console, but it will not be in the log.",NULL,"Container and Single Node do not update their associated log After the is up and running, the application does not update the singlenode<span class='highlight-text severity-high'>.log or containernode.log. create a stream time log . you will see the timestamp in your console, but it will not be in the log.</span>","minimal","punctuation","high",False
25294,"Make hdfs configurable via application.yml We currently pull all hdfs config properties from hdfs.properties change that to use application.yml",NULL,"Make hdfs configurable via application.yml We currently pull all hdfs config properties from hdfs.properties change that to use application.yml",NULL,"Add for who this story is","well_formed","no_role","high",False
25295,"Documentation on XD Architecture Documentation on XD Architecture Show overall flow of data in a stream, the server components admin and container . How modules are deployed. Show overall flow of data in a stream, the server components admin and container . How modules are deployed.",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25295,"Documentation on XD Architecture Documentation on XD Architecture Show overall flow of data in a stream, the server components admin and container . How modules are deployed. Show overall flow of data in a stream, the server components admin and container . How modules are deployed.",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25295,"Documentation on XD Architecture Documentation on XD Architecture Show overall flow of data in a stream, the server components admin and container . How modules are deployed. Show overall flow of data in a stream, the server components admin and container . How modules are deployed.",NULL,NULL,NULL,"Documentation on XD Architecture Documentation on XD Architecture Show overall flow of data in a stream, the server components admin and container <span class='highlight-text severity-high'>. How modules are deployed. Show overall flow of data in a stream, the server components admin and container . How modules are deployed.</span>","minimal","punctuation","high",False
25297,"Replace with Ordered Plugins This will allow us to control the order of plugins and use plugin s to manage the common module context, replacing ",NULL,"Replace with Ordered Plugins This will allow us to control the order of plugins and use plugin s to manage the common module context, replacing ",NULL,"Add for who this story is","well_formed","no_role","high",False
25297,"Replace with Ordered Plugins This will allow us to control the order of plugins and use plugin s to manage the common module context, replacing ",NULL,"Replace with Ordered Plugins This will allow us to control the order of plugins and use plugin s to manage the common module context, replacing ",NULL,"Replace with Ordered Plugins This will allow us to control the order of plugins<span class='highlight-text severity-high'> and </span>use plugin s to manage the common module context, replacing ","atomic","conjunctions","high",False
25300,"Publish when the container shutsdown When the container shuts down, should be published so that appropriate listeners would act on. Please refer to this discussion here ",NULL,"Publish when the container shutsdown When the container shuts down, should be published","so that appropriate listeners would act on. Please refer to this discussion here","Add for who this story is","well_formed","no_role","high",False
25300,"Publish when the container shutsdown When the container shuts down, should be published so that appropriate listeners would act on. Please refer to this discussion here ",NULL,"Publish when the container shutsdown When the container shuts down, should be published","so that appropriate listeners would act on. Please refer to this discussion here","Publish when the container shutsdown When the container shuts down, should be published so that appropriate listeners would act on<span class='highlight-text severity-high'>. Please refer to this discussion here </span>","minimal","punctuation","high",False
25300,"Publish when the container shutsdown When the container shuts down, should be published so that appropriate listeners would act on. Please refer to this discussion here ",NULL,"Publish when the container shutsdown When the container shuts down, should be published","so that appropriate listeners would act on. Please refer to this discussion here","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25887,"Support GET streams Support GET streams Pagination support, maybe querying by name as well Pagination support, maybe querying by name as well",NULL,"Support GET streams Support GET streams Pagination support, maybe querying by name as well Pagination support, maybe querying by name as well",NULL,"Add for who this story is","well_formed","no_role","high",False
25303,"Make Job notification channels subscribable Currently, the job notification channels are direct channels. We need to make these pub sub channels. With XD 885 allowing automatic job listeners registration , this would allow us to create named channel syntax like log log ",NULL,"Make Job notification channels subscribable Currently, the job notification channels are direct channels. We need to make these pub sub channels. With XD 885 allowing automatic job listeners registration , this would allow us to create named channel syntax like log log ",NULL,"Add for who this story is","well_formed","no_role","high",False
25303,"Make Job notification channels subscribable Currently, the job notification channels are direct channels. We need to make these pub sub channels. With XD 885 allowing automatic job listeners registration , this would allow us to create named channel syntax like log log ",NULL,"Make Job notification channels subscribable Currently, the job notification channels are direct channels. We need to make these pub sub channels. With XD 885 allowing automatic job listeners registration , this would allow us to create named channel syntax like log log ",NULL,"Make Job notification channels subscribable Currently, the job notification channels are direct channels<span class='highlight-text severity-high'>. We need to make these pub sub channels. With XD 885 allowing automatic job listeners registration , this would allow us to create named channel syntax like log log </span>","minimal","punctuation","high",False
25306,"Refactor container to remove shared module context as a separate context The main container context becomes the shared context for modules.",NULL,"Refactor container to remove shared module context as a separate context The main container context becomes the shared context for modules.",NULL,"Add for who this story is","well_formed","no_role","high",False
25304,"Upgrade to SHDP 2.0 M6 The YARN support in M6 changes most of the config properties, need to update XD to use new ones.",NULL,"Upgrade to SHDP 2.0 M6 The YARN support in M6 changes most of the config properties, need to update XD to use new ones.",NULL,"Add for who this story is","well_formed","no_role","high",False
25307,"Release Spring XD 1.0 M1 Release Spring XD 1.0 M1 ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25307,"Release Spring XD 1.0 M1 Release Spring XD 1.0 M1 ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25310,"Create spike of web app that maps UI design docs to MVC components in Angluar ",NULL,"Create spike of web app that maps UI design docs to MVC components in Angluar ",NULL,"Add for who this story is","well_formed","no_role","high",False
25308,"Update Reactor integration to align 1.1 changes Need to update the support to reflect the changes to Reactor refactorings introduced in v1.1.",NULL,"Update Reactor integration to align 1.1 changes Need to update the support to reflect the changes to Reactor refactorings introduced in v1.1.",NULL,"Add for who this story is","well_formed","no_role","high",False
25312,"Rename node references to container This applies to a few places when addressing the issue, a search should be done to uncover any others , e.g. public static final String NODE PROFILE node ; Options classes The transport to use for data messages from node to node The transport to use for control messages between admin and nodes ",NULL,"Rename node references to container This applies to a few places when addressing the issue, a search should be done to uncover any others , e.g. public static final String NODE PROFILE node ; Options classes The transport to use for data messages from node to node The transport to use for control messages between admin and nodes ",NULL,"Add for who this story is","well_formed","no_role","high",False
25312,"Rename node references to container This applies to a few places when addressing the issue, a search should be done to uncover any others , e.g. public static final String NODE PROFILE node ; Options classes The transport to use for data messages from node to node The transport to use for control messages between admin and nodes ",NULL,"Rename node references to container This applies to a few places when addressing the issue, a search should be done to uncover any others , e.g. public static final String NODE PROFILE node ; Options classes The transport to use for data messages from node to node The transport to use for control messages between admin and nodes ",NULL,"Rename node references to container This applies to a few places when addressing the issue, a search should be done to uncover any others , e<span class='highlight-text severity-high'>.g. public static final String NODE PROFILE node ; Options classes The transport to use for data messages from node to node The transport to use for control messages between admin and nodes </span>","minimal","punctuation","high",False
25311,"XD Shell crashes when the stream DSL has ! The XD shell crashes when the following command issued stream create test definition http filter log It looks like the JLine ConsoleReader s expandEvents is set to true by default and this causes the issue Exception in thread Spring Shell log event not found at at at at at at at at at ",NULL,"XD Shell crashes when the stream DSL has ! The XD shell crashes when the following command issued stream create test definition http filter log It looks like the JLine ConsoleReader s expandEvents is set to true by default and this causes the issue Exception in thread Spring Shell log event not found at at at at at at at at at ",NULL,"Add for who this story is","well_formed","no_role","high",False
25311,"XD Shell crashes when the stream DSL has ! The XD shell crashes when the following command issued stream create test definition http filter log It looks like the JLine ConsoleReader s expandEvents is set to true by default and this causes the issue Exception in thread Spring Shell log event not found at at at at at at at at at ",NULL,"XD Shell crashes when the stream DSL has ! The XD shell crashes when the following command issued stream create test definition http filter log It looks like the JLine ConsoleReader s expandEvents is set to true by default and this causes the issue Exception in thread Spring Shell log event not found at at at at at at at at at ",NULL,"XD Shell crashes when the stream DSL has ! The XD shell crashes when the following command issued stream create test definition http filter log It looks like the JLine ConsoleReader s expandEvents is set to true by default<span class='highlight-text severity-high'> and </span>this causes the issue Exception in thread Spring Shell log event not found at at at at at at at at at ","atomic","conjunctions","high",False
25313,"Prepare blog post for M1 Prepare blog post for M1 ",NULL,"Prepare blog post for M1 Prepare blog post for M1 ",NULL,"Add for who this story is","well_formed","no_role","high",False
25319,"Upgrade to Spring Batch 3.0.0 M3 ",NULL,"Upgrade to Spring Batch 3.0.0 M3 ",NULL,"Add for who this story is","well_formed","no_role","high",False
25315,"Add acceptance tests for stream with sources of TCP, HTTP, and Time and sinks of File and Log Need to be able to test the following sources TCP, HTTP, Time,",NULL,"Add acceptance tests for stream with sources of TCP, HTTP, and Time and sinks of File and Log Need to be able to test the following sources TCP, HTTP, Time,",NULL,"Add for who this story is","well_formed","no_role","high",False
25315,"Add acceptance tests for stream with sources of TCP, HTTP, and Time and sinks of File and Log Need to be able to test the following sources TCP, HTTP, Time,",NULL,"Add acceptance tests for stream with sources of TCP, HTTP, and Time and sinks of File and Log Need to be able to test the following sources TCP, HTTP, Time,",NULL,"Add acceptance tests for stream with sources of TCP, HTTP,<span class='highlight-text severity-high'> and </span>Time and sinks of File and Log Need to be able to test the following sources TCP, HTTP, Time,","atomic","conjunctions","high",False
25316,"Add JDBC Sink to acceptance tests ",NULL,"Add JDBC Sink to acceptance tests ",NULL,"Add for who this story is","well_formed","no_role","high",False
25318,"Add documentation on how to deploy XD to YARN ",NULL,"Add documentation on how to deploy XD to YARN ",NULL,"Add for who this story is","well_formed","no_role","high",False
25320,"Update README.txt to include instructions on how to build Building XD should not be part of the out first out of the box experience, but we should include some instructions on what targets are available, such as distXD.",NULL,"Update README.txt to include instructions on how to build Building XD should not be part of the out first out of the box experience, but we should include some instructions on what targets are available, such as distXD.",NULL,"Add for who this story is","well_formed","no_role","high",False
25321,"Upgrade to Spring 4.0.2.RELEASE ",NULL,"Upgrade to Spring 4.0.2.RELEASE ",NULL,"Add for who this story is","well_formed","no_role","high",False
25403,"Allow the value of xd.module.number to be used as property placeholder value This will allow us to use multiple instances of hdfs file sinks and not have any filename path collisions.",NULL,"Allow the value of xd.module.number to be used as property placeholder value This will allow us to use multiple instances of hdfs file sinks and not have any filename path collisions.",NULL,"Add for who this story is","well_formed","no_role","high",False
25403,"Allow the value of xd.module.number to be used as property placeholder value This will allow us to use multiple instances of hdfs file sinks and not have any filename path collisions.",NULL,"Allow the value of xd.module.number to be used as property placeholder value This will allow us to use multiple instances of hdfs file sinks and not have any filename path collisions.",NULL,"Allow the value of xd.module.number to be used as property placeholder value This will allow us to use multiple instances of hdfs file sinks<span class='highlight-text severity-high'> and </span>not have any filename path collisions.","atomic","conjunctions","high",False
25314,"tcp source requires a r n to suffix all inbound data When sending data to the TCP Source if the data is not terminated with a r n when the socket is closed by the client, XD throws an exception. ",NULL,"tcp source requires a r n to suffix all inbound data When sending data to the TCP Source if the data is not terminated with a r n when the socket is closed by the client, XD throws an exception. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25302,"Documentation that points on how to install hadoop Pointers to other documentation on how to install hadoop. ",NULL,"Documentation that points on how to install hadoop Pointers to other documentation on how to install hadoop. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25305,"Exclude s in the modules or extensions ",NULL,"Exclude s in the modules or extensions ",NULL,"Add for who this story is","well_formed","no_role","high",False
25309,"Update to use spring data hadoop 2.0 M6 ",NULL,"Update to use spring data hadoop 2.0 M6 ",NULL,"Add for who this story is","well_formed","no_role","high",False
25324,"Admin leader should watch Container nodes in ZooKeeper This will require a in based on singlenode vs. distributed via profiles, see for an example . Then a PathChildrenCache should be established for the xd containers node.",NULL,"Admin leader should watch Container nodes in ZooKeeper This will require a in based on singlenode vs. distributed via profiles, see for an example . Then a PathChildrenCache should be established for the xd containers node.",NULL,"Add for who this story is","well_formed","no_role","high",False
25324,"Admin leader should watch Container nodes in ZooKeeper This will require a in based on singlenode vs. distributed via profiles, see for an example . Then a PathChildrenCache should be established for the xd containers node.",NULL,"Admin leader should watch Container nodes in ZooKeeper This will require a in based on singlenode vs. distributed via profiles, see for an example . Then a PathChildrenCache should be established for the xd containers node.",NULL,"Admin leader should watch Container nodes in ZooKeeper This will require a in based on singlenode vs<span class='highlight-text severity-high'>. distributed via profiles, see for an example . Then a PathChildrenCache should be established for the xd containers node.</span>","minimal","punctuation","high",False
25329,"Create a module for benchmarking A module that could be used in a stream definition such as reactor bind do stuff throughput sampler where throughput sampler could start measurements once a key START is found in a Message and stop when the key STOP is found in a Message, listing the number of msgs sec etc.",NULL,"Create a module for benchmarking A module that could be used in a stream definition such as reactor bind do stuff throughput sampler where throughput sampler could start measurements once a key START is found in a Message and stop when the key STOP is found in a Message, listing the number of msgs sec etc.",NULL,"Add for who this story is","well_formed","no_role","high",False
25329,"Create a module for benchmarking A module that could be used in a stream definition such as reactor bind do stuff throughput sampler where throughput sampler could start measurements once a key START is found in a Message and stop when the key STOP is found in a Message, listing the number of msgs sec etc.",NULL,"Create a module for benchmarking A module that could be used in a stream definition such as reactor bind do stuff throughput sampler where throughput sampler could start measurements once a key START is found in a Message and stop when the key STOP is found in a Message, listing the number of msgs sec etc.",NULL,"Create a module for benchmarking A module that could be used in a stream definition such as reactor bind do stuff throughput sampler where throughput sampler could start measurements once a key START is found in a Message<span class='highlight-text severity-high'> and </span>stop when the key STOP is found in a Message, listing the number of msgs sec etc.","atomic","conjunctions","high",False
25328,"Add new reactor tcp module A reactor based TCP module that would support some basic CODECS. Should evaluate if this new TCP module would subsume the current reactor syslog module functionality or if the reactor syslog module should be enhanced upgradted.",NULL,"Add new reactor tcp module A reactor based TCP module that would support some basic CODECS. Should evaluate if this new TCP module would subsume the current reactor syslog module functionality or if the reactor syslog module should be enhanced upgradted.",NULL,"Add for who this story is","well_formed","no_role","high",False
25328,"Add new reactor tcp module A reactor based TCP module that would support some basic CODECS. Should evaluate if this new TCP module would subsume the current reactor syslog module functionality or if the reactor syslog module should be enhanced upgradted.",NULL,"Add new reactor tcp module A reactor based TCP module that would support some basic CODECS. Should evaluate if this new TCP module would subsume the current reactor syslog module functionality or if the reactor syslog module should be enhanced upgradted.",NULL,"Add new reactor tcp module A reactor based TCP module that would support some basic CODECS. Should evaluate if this new TCP module would subsume the current reactor syslog module functionality<span class='highlight-text severity-high'> or </span>if the reactor syslog module should be enhanced upgradted.","atomic","conjunctions","high",False
25328,"Add new reactor tcp module A reactor based TCP module that would support some basic CODECS. Should evaluate if this new TCP module would subsume the current reactor syslog module functionality or if the reactor syslog module should be enhanced upgradted.",NULL,"Add new reactor tcp module A reactor based TCP module that would support some basic CODECS. Should evaluate if this new TCP module would subsume the current reactor syslog module functionality or if the reactor syslog module should be enhanced upgradted.",NULL,"Add new reactor tcp module A reactor based TCP module that would support some basic CODECS<span class='highlight-text severity-high'>. Should evaluate if this new TCP module would subsume the current reactor syslog module functionality or if the reactor syslog module should be enhanced upgradted.</span>","minimal","punctuation","high",False
25330,"Create benchmarking application to demonstrate high performance message processing The application should live in in spring xd samples repository. The stream created in should be documented how to run a benchmark and made easy to execute. Can use ruby bash awk sed to generate traffic via sendfile in order to saturate the stream. ",NULL,"Create benchmarking application to demonstrate high performance message processing The application should live in in spring xd samples repository. The stream created in should be documented how to run a benchmark and made easy to execute. Can use ruby bash awk sed to generate traffic via sendfile","in order to saturate the stream.","Add for who this story is","well_formed","no_role","high",False
25330,"Create benchmarking application to demonstrate high performance message processing The application should live in in spring xd samples repository. The stream created in should be documented how to run a benchmark and made easy to execute. Can use ruby bash awk sed to generate traffic via sendfile in order to saturate the stream. ",NULL,"Create benchmarking application to demonstrate high performance message processing The application should live in in spring xd samples repository. The stream created in should be documented how to run a benchmark and made easy to execute. Can use ruby bash awk sed to generate traffic via sendfile","in order to saturate the stream.","Create benchmarking application to demonstrate high performance message processing The application should live in in spring xd samples repository. The stream created in should be documented how to run a benchmark<span class='highlight-text severity-high'> and </span>made easy to execute. Can use ruby bash awk sed to generate traffic via sendfile in order to saturate the stream. ","atomic","conjunctions","high",False
25330,"Create benchmarking application to demonstrate high performance message processing The application should live in in spring xd samples repository. The stream created in should be documented how to run a benchmark and made easy to execute. Can use ruby bash awk sed to generate traffic via sendfile in order to saturate the stream. ",NULL,"Create benchmarking application to demonstrate high performance message processing The application should live in in spring xd samples repository. The stream created in should be documented how to run a benchmark and made easy to execute. Can use ruby bash awk sed to generate traffic via sendfile","in order to saturate the stream.","Create benchmarking application to demonstrate high performance message processing The application should live in in spring xd samples repository<span class='highlight-text severity-high'>. The stream created in should be documented how to run a benchmark and made easy to execute. Can use ruby bash awk sed to generate traffic via sendfile in order to saturate the stream. </span>","minimal","punctuation","high",False
25330,"Create benchmarking application to demonstrate high performance message processing The application should live in in spring xd samples repository. The stream created in should be documented how to run a benchmark and made easy to execute. Can use ruby bash awk sed to generate traffic via sendfile in order to saturate the stream. ",NULL,"Create benchmarking application to demonstrate high performance message processing The application should live in in spring xd samples repository. The stream created in should be documented how to run a benchmark and made easy to execute. Can use ruby bash awk sed to generate traffic via sendfile","in order to saturate the stream.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25332,"Upgrade groovy version to 2.2.2 Currently, XD hast testCompile dependency to use The uses 2.2.2 and it is what spring IO platform uses as well. To keep it all same, we can change this testCompile dependency to use 2.2.2 ",NULL,"Upgrade groovy version to 2.2.2 Currently, XD hast testCompile dependency to use The uses 2.2.2 and it is what spring IO platform uses as well. To keep it all same, we can change this testCompile dependency to use 2.2.2 ",NULL,"Add for who this story is","well_formed","no_role","high",False
25332,"Upgrade groovy version to 2.2.2 Currently, XD hast testCompile dependency to use The uses 2.2.2 and it is what spring IO platform uses as well. To keep it all same, we can change this testCompile dependency to use 2.2.2 ",NULL,"Upgrade groovy version to 2.2.2 Currently, XD hast testCompile dependency to use The uses 2.2.2 and it is what spring IO platform uses as well. To keep it all same, we can change this testCompile dependency to use 2.2.2 ",NULL,"Upgrade groovy version to 2.2.2 Currently, XD hast testCompile dependency to use The uses 2.2.2<span class='highlight-text severity-high'> and </span>it is what spring IO platform uses as well. To keep it all same, we can change this testCompile dependency to use 2.2.2 ","atomic","conjunctions","high",False
25332,"Upgrade groovy version to 2.2.2 Currently, XD hast testCompile dependency to use The uses 2.2.2 and it is what spring IO platform uses as well. To keep it all same, we can change this testCompile dependency to use 2.2.2 ",NULL,"Upgrade groovy version to 2.2.2 Currently, XD hast testCompile dependency to use The uses 2.2.2 and it is what spring IO platform uses as well. To keep it all same, we can change this testCompile dependency to use 2.2.2 ",NULL,"Upgrade groovy version to 2<span class='highlight-text severity-high'>.2.2 Currently, XD hast testCompile dependency to use The uses 2.2.2 and it is what spring IO platform uses as well. To keep it all same, we can change this testCompile dependency to use 2.2.2 </span>","minimal","punctuation","high",False
25378,"Do not eagerly use repositories in completion s Strategy ",NULL,"Do not eagerly use repositories in completion s Strategy ",NULL,"Add for who this story is","well_formed","no_role","high",False
25331,"Test against Spring Boot Snapshot build ",NULL,"Test against Spring Boot Snapshot build ",NULL,"Add for who this story is","well_formed","no_role","high",False
25333,"Create a throughput sink The throughput module would expect a payload of the type Message byte and look for the byte to be START or STOP strings to trigger a throughput measurement. would be the place for the module to live.",NULL,"Create a throughput sink The throughput module would expect a payload of the type Message byte and look for the byte to be START or STOP strings to trigger a throughput measurement. would be the place for the module to live.",NULL,"Add for who this story is","well_formed","no_role","high",False
25333,"Create a throughput sink The throughput module would expect a payload of the type Message byte and look for the byte to be START or STOP strings to trigger a throughput measurement. would be the place for the module to live.",NULL,"Create a throughput sink The throughput module would expect a payload of the type Message byte and look for the byte to be START or STOP strings to trigger a throughput measurement. would be the place for the module to live.",NULL,"Create a throughput sink The throughput module would expect a payload of the type Message byte<span class='highlight-text severity-high'> and </span>look for the byte to be START<span class='highlight-text severity-high'> or </span>STOP strings to trigger a throughput measurement. would be the place for the module to live.","atomic","conjunctions","high",False
25333,"Create a throughput sink The throughput module would expect a payload of the type Message byte and look for the byte to be START or STOP strings to trigger a throughput measurement. would be the place for the module to live.",NULL,"Create a throughput sink The throughput module would expect a payload of the type Message byte and look for the byte to be START or STOP strings to trigger a throughput measurement. would be the place for the module to live.",NULL,"Create a throughput sink The throughput module would expect a payload of the type Message byte and look for the byte to be START or STOP strings to trigger a throughput measurement<span class='highlight-text severity-high'>. would be the place for the module to live.</span>","minimal","punctuation","high",False
25334,"GemFire sink properties missmatch The documentation lists the gemfire server sink module s attributes to be gemfireHost and gemfirePort . In the module code they are host and port . The other attributes are correct. ",NULL,"GemFire sink properties missmatch The documentation lists the gemfire server sink module s attributes to be gemfireHost and gemfirePort . In the module code they are host and port . The other attributes are correct. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25334,"GemFire sink properties missmatch The documentation lists the gemfire server sink module s attributes to be gemfireHost and gemfirePort . In the module code they are host and port . The other attributes are correct. ",NULL,"GemFire sink properties missmatch The documentation lists the gemfire server sink module s attributes to be gemfireHost and gemfirePort . In the module code they are host and port . The other attributes are correct. ",NULL,"GemFire sink properties missmatch The documentation lists the gemfire server sink module s attributes to be gemfireHost and gemfirePort <span class='highlight-text severity-high'>. In the module code they are host and port . The other attributes are correct. </span>","minimal","punctuation","high",False
25335,"install redis script should not use relative path to determine redis source dist Currently, the install redis script uses relative path to determine redis source dist file. Since this is error prone, we need to fix it.",NULL,"install redis script should not use relative path to determine redis source dist Currently, the install redis script uses relative path to determine redis source dist file. Since this is error prone, we need to fix it.",NULL,"Add for who this story is","well_formed","no_role","high",False
25335,"install redis script should not use relative path to determine redis source dist Currently, the install redis script uses relative path to determine redis source dist file. Since this is error prone, we need to fix it.",NULL,"install redis script should not use relative path to determine redis source dist Currently, the install redis script uses relative path to determine redis source dist file. Since this is error prone, we need to fix it.",NULL,"install redis script should not use relative path to determine redis source dist Currently, the install redis script uses relative path to determine redis source dist file<span class='highlight-text severity-high'>. Since this is error prone, we need to fix it.</span>","minimal","punctuation","high",False
25336,"XD EC2 needs to bootstrap ZOOKEEPER at installation time. Startup zookeeper on EC2 cluster instances.",NULL,"XD EC2 needs to bootstrap ZOOKEEPER at installation time. Startup zookeeper on EC2 cluster instances.",NULL,"Add for who this story is","well_formed","no_role","high",False
25336,"XD EC2 needs to bootstrap ZOOKEEPER at installation time. Startup zookeeper on EC2 cluster instances.",NULL,"XD EC2 needs to bootstrap ZOOKEEPER at installation time. Startup zookeeper on EC2 cluster instances.",NULL,"XD EC2 needs to bootstrap ZOOKEEPER at installation time<span class='highlight-text severity-high'>. Startup zookeeper on EC2 cluster instances.</span>","minimal","punctuation","high",False
25337,"Create xd yarn script Create an xd yarn script that is more Cloud Foundry like xd yarn push p xd yarn start admin xd yarn start container ",NULL,"Create xd yarn script Create an xd yarn script that is more Cloud Foundry like xd yarn push p xd yarn start admin xd yarn start container ",NULL,"Add for who this story is","well_formed","no_role","high",False
25338,"Create one xd yarn shell script that encompases the functionality of seperate shell scripts ",NULL,"Create one xd yarn shell script that encompases the functionality of seperate shell scripts ",NULL,"Add for who this story is","well_formed","no_role","high",False
25326,"Design for deploying XD on EC2 create enough of a design to develop additional stories.",NULL,"Design for deploying XD on EC2 create enough of a design to develop additional stories.",NULL,"Add for who this story is","well_formed","no_role","high",False
25377,"Update XdEc2Validation to reference root management endpoint Update XdEc2Validation to reference root management endpoint change to etc. change to etc.",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25377,"Update XdEc2Validation to reference root management endpoint Update XdEc2Validation to reference root management endpoint change to etc. change to etc.",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25377,"Update XdEc2Validation to reference root management endpoint Update XdEc2Validation to reference root management endpoint change to etc. change to etc.",NULL,NULL,NULL,"Update XdEc2Validation to reference root management endpoint Update XdEc2Validation to reference root management endpoint change to etc<span class='highlight-text severity-high'>. change to etc.</span>","minimal","punctuation","high",False
25327,"Parameterize syslog Source; Add Support for TCP The syslog source currently is hard coded to use udp on port 11111. Need to parameterize the port and provide an option to use TCP.",NULL,"Parameterize syslog Source; Add Support for TCP The syslog source currently is hard coded to use udp on port 11111. Need to parameterize the port and provide an option to use TCP.",NULL,"Add for who this story is","well_formed","no_role","high",False
25327,"Parameterize syslog Source; Add Support for TCP The syslog source currently is hard coded to use udp on port 11111. Need to parameterize the port and provide an option to use TCP.",NULL,"Parameterize syslog Source; Add Support for TCP The syslog source currently is hard coded to use udp on port 11111. Need to parameterize the port and provide an option to use TCP.",NULL,"Parameterize syslog Source; Add Support for TCP The syslog source currently is hard coded to use udp on port 11111. Need to parameterize the port<span class='highlight-text severity-high'> and </span>provide an option to use TCP.","atomic","conjunctions","high",False
25327,"Parameterize syslog Source; Add Support for TCP The syslog source currently is hard coded to use udp on port 11111. Need to parameterize the port and provide an option to use TCP.",NULL,"Parameterize syslog Source; Add Support for TCP The syslog source currently is hard coded to use udp on port 11111. Need to parameterize the port and provide an option to use TCP.",NULL,"Parameterize syslog Source<span class='highlight-text severity-high'>; Add Support for TCP The syslog source currently is hard coded to use udp on port 11111. Need to parameterize the port and provide an option to use TCP.</span>","minimal","punctuation","high",False
25342,"Create documentation for the core analytical model abstractions and use of jpmml processor Create documentation for the core analytical model abstractions and use of jpmml processor ",NULL,"Create documentation for the core analytical model abstractions and use of jpmml processor Create documentation for the core analytical model abstractions and use of jpmml processor ",NULL,"Add for who this story is","well_formed","no_role","high",False
25342,"Create documentation for the core analytical model abstractions and use of jpmml processor Create documentation for the core analytical model abstractions and use of jpmml processor ",NULL,"Create documentation for the core analytical model abstractions and use of jpmml processor Create documentation for the core analytical model abstractions and use of jpmml processor ",NULL,"Create documentation for the core analytical model abstractions<span class='highlight-text severity-high'> and </span>use of jpmml processor Create documentation for the core analytical model abstractions and use of jpmml processor ","atomic","conjunctions","high",False
25341,"StreamServer Context Lifecycle Issues The is pre instantiated to determine the type of object it will serve up.",NULL,"StreamServer Context Lifecycle Issues The is pre instantiated to determine the type of object it will serve up.",NULL,"Add for who this story is","well_formed","no_role","high",False
25344,"Fix existing Karma unit tests Migrate E2E tests to Protractor Fix existing Karma unit tests Migrate E2E tests to Protractor The grunt build for karma unit tests is currently broken with requireJS support on the XD admin app. The grunt build for karma unit tests is currently broken with requireJS support on the XD admin app. ",NULL,"Fix existing Karma unit tests Migrate E2E tests to Protractor Fix existing Karma unit tests Migrate E2E tests to Protractor The grunt build for karma unit tests is currently broken with requireJS support on the XD admin app. The grunt build for karma unit tests is currently broken with requireJS support on the XD admin app. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25344,"Fix existing Karma unit tests Migrate E2E tests to Protractor Fix existing Karma unit tests Migrate E2E tests to Protractor The grunt build for karma unit tests is currently broken with requireJS support on the XD admin app. The grunt build for karma unit tests is currently broken with requireJS support on the XD admin app. ",NULL,"Fix existing Karma unit tests Migrate E2E tests to Protractor Fix existing Karma unit tests Migrate E2E tests to Protractor The grunt build for karma unit tests is currently broken with requireJS support on the XD admin app. The grunt build for karma unit tests is currently broken with requireJS support on the XD admin app. ",NULL,"Fix existing Karma unit tests Migrate E2E tests to Protractor Fix existing Karma unit tests Migrate E2E tests to Protractor The grunt build for karma unit tests is currently broken with requireJS support on the XD admin app<span class='highlight-text severity-high'>. The grunt build for karma unit tests is currently broken with requireJS support on the XD admin app. </span>","minimal","punctuation","high",False
25343,"Create documentation for how module properties are resolved. The ordering of the lookup should be described, in particular detail on how environment variables can overrride properties. Some details will necessarily change based on outcome of current discussion, but the overall ordering is going to remain.",NULL,"Create documentation for how module properties are resolved. The ordering of the lookup should be described, in particular detail on how environment variables can overrride properties. Some details will necessarily change based on outcome of current discussion, but the overall ordering is going to remain.",NULL,"Add for who this story is","well_formed","no_role","high",False
25343,"Create documentation for how module properties are resolved. The ordering of the lookup should be described, in particular detail on how environment variables can overrride properties. Some details will necessarily change based on outcome of current discussion, but the overall ordering is going to remain.",NULL,"Create documentation for how module properties are resolved. The ordering of the lookup should be described, in particular detail on how environment variables can overrride properties. Some details will necessarily change based on outcome of current discussion, but the overall ordering is going to remain.",NULL,"Create documentation for how module properties are resolved<span class='highlight-text severity-high'>. The ordering of the lookup should be described, in particular detail on how environment variables can overrride properties. Some details will necessarily change based on outcome of current discussion, but the overall ordering is going to remain.</span>","minimal","punctuation","high",False
25346,"Create externalized property file to support connectivity to redis Create externalized property file to support connectivity to redis We need to have an externalized property file under for the xd container admin scripts to use as options. We need to have an externalized property file under for the xd container admin scripts to use as options. ",NULL,"Create externalized property file to support connectivity to redis Create externalized property file to support connectivity to redis We need to have an externalized property file under for the xd container admin scripts to use as options. We need to have an externalized property file under for the xd container admin scripts to use as options. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25346,"Create externalized property file to support connectivity to redis Create externalized property file to support connectivity to redis We need to have an externalized property file under for the xd container admin scripts to use as options. We need to have an externalized property file under for the xd container admin scripts to use as options. ",NULL,"Create externalized property file to support connectivity to redis Create externalized property file to support connectivity to redis We need to have an externalized property file under for the xd container admin scripts to use as options. We need to have an externalized property file under for the xd container admin scripts to use as options. ",NULL,"Create externalized property file to support connectivity to redis Create externalized property file to support connectivity to redis We need to have an externalized property file under for the xd container admin scripts to use as options<span class='highlight-text severity-high'>. We need to have an externalized property file under for the xd container admin scripts to use as options. </span>","minimal","punctuation","high",False
25345,"Upgrade to ZooKeeper 3.4.6 3.4.6 was released on 2014.03.10 Especially relevant for us, they updated Netty from 3.2.2 to 3.6.6 ",NULL,"Upgrade to ZooKeeper 3.4.6 3.4.6 was released on 2014.03.10 Especially relevant for us, they updated Netty from 3.2.2 to 3.6.6 ",NULL,"Add for who this story is","well_formed","no_role","high",False
25348,"Support multiple admin servers on a same host By default, XD admin server uses hsqldb as data source for batch job repository and uses the default port 9101, specific database location and dbname. This makes the existence of multiple admin server on a same host not possible. ",NULL,"Support multiple admin servers on a same host By default, XD admin server uses hsqldb as data source for batch job repository and uses the default port 9101, specific database location and dbname. This makes the existence of multiple admin server on a same host not possible. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25348,"Support multiple admin servers on a same host By default, XD admin server uses hsqldb as data source for batch job repository and uses the default port 9101, specific database location and dbname. This makes the existence of multiple admin server on a same host not possible. ",NULL,"Support multiple admin servers on a same host By default, XD admin server uses hsqldb as data source for batch job repository and uses the default port 9101, specific database location and dbname. This makes the existence of multiple admin server on a same host not possible. ",NULL,"Support multiple admin servers on a same host By default, XD admin server uses hsqldb as data source for batch job repository<span class='highlight-text severity-high'> and </span>uses the default port 9101, specific database location and dbname. This makes the existence of multiple admin server on a same host not possible. ","atomic","conjunctions","high",False
25348,"Support multiple admin servers on a same host By default, XD admin server uses hsqldb as data source for batch job repository and uses the default port 9101, specific database location and dbname. This makes the existence of multiple admin server on a same host not possible. ",NULL,"Support multiple admin servers on a same host By default, XD admin server uses hsqldb as data source for batch job repository and uses the default port 9101, specific database location and dbname. This makes the existence of multiple admin server on a same host not possible. ",NULL,"Support multiple admin servers on a same host By default, XD admin server uses hsqldb as data source for batch job repository and uses the default port 9101, specific database location and dbname<span class='highlight-text severity-high'>. This makes the existence of multiple admin server on a same host not possible. </span>","minimal","punctuation","high",False
25347,"Add JMS Acceptance Tests Add JMS Acceptance Tests ",NULL,"Add JMS Acceptance Tests Add JMS Acceptance Tests ",NULL,"Add for who this story is","well_formed","no_role","high",False
25352,"Improvements to Executions Tab 1. Add quick filter 2. The table should have columns for name instance execution id Getting the name might require a bit of extra work given some limitations with JSON serialization and cycles in the current object returned from spring batch. 3. The restart action should appear only if the job is restartable and the status was failed. ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25352,"Improvements to Executions Tab 1. Add quick filter 2. The table should have columns for name instance execution id Getting the name might require a bit of extra work given some limitations with JSON serialization and cycles in the current object returned from spring batch. 3. The restart action should appear only if the job is restartable and the status was failed. ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25352,"Improvements to Executions Tab 1. Add quick filter 2. The table should have columns for name instance execution id Getting the name might require a bit of extra work given some limitations with JSON serialization and cycles in the current object returned from spring batch. 3. The restart action should appear only if the job is restartable and the status was failed. ",NULL,NULL,NULL,"Improvements to Executions Tab 1<span class='highlight-text severity-high'>. Add quick filter 2. The table should have columns for name instance execution id Getting the name might require a bit of extra work given some limitations with JSON serialization and cycles in the current object returned from spring batch. 3. The restart action should appear only if the job is restartable and the status was failed. </span>","minimal","punctuation","high",False
25349,"Configure servers to use The standard that boot performs a database test that fails in xd container since it does not require the use of a database. ",NULL,"Configure servers to use The standard that boot performs a database test that fails in xd container since it does not require the use of a database. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25354,"Investigate module classloader leakage See report at This should not happen as the module holds the classes that hold the classloader, but who knows. An integration test that verifies this would be nice, albeit tricky.",NULL,"Investigate module classloader leakage See report at This should not happen as the module holds the classes that hold the classloader, but who knows. An integration test that verifies this would be nice, albeit tricky.",NULL,"Add for who this story is","well_formed","no_role","high",False
25354,"Investigate module classloader leakage See report at This should not happen as the module holds the classes that hold the classloader, but who knows. An integration test that verifies this would be nice, albeit tricky.",NULL,"Investigate module classloader leakage See report at This should not happen as the module holds the classes that hold the classloader, but who knows. An integration test that verifies this would be nice, albeit tricky.",NULL,"Investigate module classloader leakage See report at This should not happen as the module holds the classes that hold the classloader, but who knows<span class='highlight-text severity-high'>. An integration test that verifies this would be nice, albeit tricky.</span>","minimal","punctuation","high",False
25355,"Remove Log4j Properties XMLs from Projects If, say, xd dirt is ahead of a local config on the classpath, it s log4j.properties is found first.",NULL,"Remove Log4j Properties XMLs from Projects If, say, xd dirt is ahead of a local config on the classpath, it s log4j.properties is found first.",NULL,"Add for who this story is","well_formed","no_role","high",False
25350,"Update to Spring Boot RC5 ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25350,"Update to Spring Boot RC5 ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25340,"Create subproject Using the jppml evaluator, provide an implementation of the core abstractions in the The initial code for this has been developed in a separate github repo and is located here ",NULL,"Create subproject Using the jppml evaluator, provide an implementation of the core abstractions in the The initial code for this has been developed in a separate github repo and is located here ",NULL,"Add for who this story is","well_formed","no_role","high",False
25340,"Create subproject Using the jppml evaluator, provide an implementation of the core abstractions in the The initial code for this has been developed in a separate github repo and is located here ",NULL,"Create subproject Using the jppml evaluator, provide an implementation of the core abstractions in the The initial code for this has been developed in a separate github repo and is located here ",NULL,"Create subproject Using the jppml evaluator, provide an implementation of the core abstractions in the The initial code for this has been developed in a separate github repo<span class='highlight-text severity-high'> and </span>is located here ","atomic","conjunctions","high",False
25351,"Improvements to Modules Tab 1. Get listing of job modules 2. Remove version and action column 3. Text to say creating definitions from available modules in the UI is forthcoming, link to for how to do this in the command line. 4. Hardcode an association between spring xd out of the box module names and a description. 5. Add button to display the XML file that defines the job module ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25351,"Improvements to Modules Tab 1. Get listing of job modules 2. Remove version and action column 3. Text to say creating definitions from available modules in the UI is forthcoming, link to for how to do this in the command line. 4. Hardcode an association between spring xd out of the box module names and a description. 5. Add button to display the XML file that defines the job module ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25351,"Improvements to Modules Tab 1. Get listing of job modules 2. Remove version and action column 3. Text to say creating definitions from available modules in the UI is forthcoming, link to for how to do this in the command line. 4. Hardcode an association between spring xd out of the box module names and a description. 5. Add button to display the XML file that defines the job module ",NULL,NULL,NULL,"Improvements to Modules Tab 1<span class='highlight-text severity-high'>. Get listing of job modules 2. Remove version and action column 3. Text to say creating definitions from available modules in the UI is forthcoming, link to for how to do this in the command line. 4. Hardcode an association between spring xd out of the box module names and a description. 5. Add button to display the XML file that defines the job module </span>","minimal","punctuation","high",False
25379,"Update to Reactor 1.1.0 M3 ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25379,"Update to Reactor 1.1.0 M3 ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25353,"Exclude slf4j Transitive Dependencies ",NULL,"Exclude slf4j Transitive Dependencies ",NULL,"Add for who this story is","well_formed","no_role","high",False
25364,"Support CI build in Travis Get minimal compilation going in Travis. Redis Rabbit services can be done in a separate story.",NULL,"Support CI build in Travis Get minimal compilation going in Travis. Redis Rabbit services can be done in a separate story.",NULL,"Add for who this story is","well_formed","no_role","high",False
25364,"Support CI build in Travis Get minimal compilation going in Travis. Redis Rabbit services can be done in a separate story.",NULL,"Support CI build in Travis Get minimal compilation going in Travis. Redis Rabbit services can be done in a separate story.",NULL,"Support CI build in Travis Get minimal compilation going in Travis<span class='highlight-text severity-high'>. Redis Rabbit services can be done in a separate story.</span>","minimal","punctuation","high",False
25358,"Remove Hadoop distro Enum options Please see the discussion here ",NULL,"Remove Hadoop distro Enum options Please see the discussion here ",NULL,"Add for who this story is","well_formed","no_role","high",False
25363,"Add Support for Binary Payloads in The TCP source supports inbound binary data. We currently have to go through unnecessary conversion.",NULL,"Add Support for Binary Payloads in The TCP source supports inbound binary data. We currently have to go through unnecessary conversion.",NULL,"Add for who this story is","well_formed","no_role","high",False
25363,"Add Support for Binary Payloads in The TCP source supports inbound binary data. We currently have to go through unnecessary conversion.",NULL,"Add Support for Binary Payloads in The TCP source supports inbound binary data. We currently have to go through unnecessary conversion.",NULL,"Add Support for Binary Payloads in The TCP source supports inbound binary data<span class='highlight-text severity-high'>. We currently have to go through unnecessary conversion.</span>","minimal","punctuation","high",False
25367,"Environment checkers in acceptance tests should use Asserts Replace tests and throws in the XdEc2Validation with asserts in the following methods verifyTestContent verifyLogContent verifySendCounts VerifySendCounts should check for the exact number of Jmx events instead of 0.",NULL,"Environment checkers in acceptance tests should use Asserts Replace tests and throws in the XdEc2Validation with asserts in the following methods verifyTestContent verifyLogContent verifySendCounts VerifySendCounts should check for the exact number of Jmx events instead of 0.",NULL,"Add for who this story is","well_formed","no_role","high",False
25367,"Environment checkers in acceptance tests should use Asserts Replace tests and throws in the XdEc2Validation with asserts in the following methods verifyTestContent verifyLogContent verifySendCounts VerifySendCounts should check for the exact number of Jmx events instead of 0.",NULL,"Environment checkers in acceptance tests should use Asserts Replace tests and throws in the XdEc2Validation with asserts in the following methods verifyTestContent verifyLogContent verifySendCounts VerifySendCounts should check for the exact number of Jmx events instead of 0.",NULL,"Environment checkers in acceptance tests should use Asserts Replace tests<span class='highlight-text severity-high'> and </span>throws in the XdEc2Validation with asserts in the following methods verifyTestContent verifyLogContent verifySendCounts VerifySendCounts should check for the exact number of Jmx events instead of 0.","atomic","conjunctions","high",False
25365,"Update Spring AMQP to 1.3.1.RELEASE ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25365,"Update Spring AMQP to 1.3.1.RELEASE ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25366,"User should not be required to specify a control channel With the addition of zookeeper, a user does not have to specify rabbit or redis for the control channel. This story should allow a user to specify redis, rabbit or no control channel.",NULL,"User should not be required to specify a control channel With the addition of zookeeper, a user does not have to specify rabbit or redis for the control channel. This story should allow a user to specify redis, rabbit or no control channel.",NULL,"Add for who this story is","well_formed","no_role","high",False
25366,"User should not be required to specify a control channel With the addition of zookeeper, a user does not have to specify rabbit or redis for the control channel. This story should allow a user to specify redis, rabbit or no control channel.",NULL,"User should not be required to specify a control channel With the addition of zookeeper, a user does not have to specify rabbit or redis for the control channel. This story should allow a user to specify redis, rabbit or no control channel.",NULL,"User should not be required to specify a control channel With the addition of zookeeper, a user does not have to specify rabbit or redis for the control channel<span class='highlight-text severity-high'>. This story should allow a user to specify redis, rabbit or no control channel.</span>","minimal","punctuation","high",False
25371,"Remove jmxEnabled as a cmdLine option and enable JMX by default After some discussion and voting, we decided to remove jmxEnabled as a command line option and have JMX enabled by default. This can be disabled from xd config.yml externally.",NULL,"Remove jmxEnabled as a cmdLine option and enable JMX by default After some discussion and voting, we decided to remove jmxEnabled as a command line option and have JMX enabled by default. This can be disabled from xd config.yml externally.",NULL,"Add for who this story is","well_formed","no_role","high",False
25371,"Remove jmxEnabled as a cmdLine option and enable JMX by default After some discussion and voting, we decided to remove jmxEnabled as a command line option and have JMX enabled by default. This can be disabled from xd config.yml externally.",NULL,"Remove jmxEnabled as a cmdLine option and enable JMX by default After some discussion and voting, we decided to remove jmxEnabled as a command line option and have JMX enabled by default. This can be disabled from xd config.yml externally.",NULL,"Remove jmxEnabled as a cmdLine option<span class='highlight-text severity-high'> and </span>enable JMX by default After some discussion and voting, we decided to remove jmxEnabled as a command line option and have JMX enabled by default. This can be disabled from xd config.yml externally.","atomic","conjunctions","high",False
25371,"Remove jmxEnabled as a cmdLine option and enable JMX by default After some discussion and voting, we decided to remove jmxEnabled as a command line option and have JMX enabled by default. This can be disabled from xd config.yml externally.",NULL,"Remove jmxEnabled as a cmdLine option and enable JMX by default After some discussion and voting, we decided to remove jmxEnabled as a command line option and have JMX enabled by default. This can be disabled from xd config.yml externally.",NULL,"Remove jmxEnabled as a cmdLine option and enable JMX by default After some discussion and voting, we decided to remove jmxEnabled as a command line option and have JMX enabled by default<span class='highlight-text severity-high'>. This can be disabled from xd config.yml externally.</span>","minimal","punctuation","high",False
25368,"Allow user to configure tests with DI With the addition of sinks and sources that require connections with external entities hadoop, JMS, JDBC, ... the environment setup is getting unwieldy. Integrate into acceptance tests. Retrieve environment variables via Dependency injection from Utilize profiles for local single node local cluster ec2 single node ec2 cluster",NULL,"Allow user to configure tests with DI With the addition of sinks and sources that require connections with external entities hadoop, JMS, JDBC, ... the environment setup is getting unwieldy. Integrate into acceptance tests. Retrieve environment variables via Dependency injection from Utilize profiles for local single node local cluster ec2 single node ec2 cluster",NULL,"Add for who this story is","well_formed","no_role","high",False
25368,"Allow user to configure tests with DI With the addition of sinks and sources that require connections with external entities hadoop, JMS, JDBC, ... the environment setup is getting unwieldy. Integrate into acceptance tests. Retrieve environment variables via Dependency injection from Utilize profiles for local single node local cluster ec2 single node ec2 cluster",NULL,"Allow user to configure tests with DI With the addition of sinks and sources that require connections with external entities hadoop, JMS, JDBC, ... the environment setup is getting unwieldy. Integrate into acceptance tests. Retrieve environment variables via Dependency injection from Utilize profiles for local single node local cluster ec2 single node ec2 cluster",NULL,"Allow user to configure tests with DI With the addition of sinks<span class='highlight-text severity-high'> and </span>sources that require connections with external entities hadoop, JMS, JDBC, ... the environment setup is getting unwieldy. Integrate into acceptance tests. Retrieve environment variables via Dependency injection from Utilize profiles for local single node local cluster ec2 single node ec2 cluster","atomic","conjunctions","high",False
25368,"Allow user to configure tests with DI With the addition of sinks and sources that require connections with external entities hadoop, JMS, JDBC, ... the environment setup is getting unwieldy. Integrate into acceptance tests. Retrieve environment variables via Dependency injection from Utilize profiles for local single node local cluster ec2 single node ec2 cluster",NULL,"Allow user to configure tests with DI With the addition of sinks and sources that require connections with external entities hadoop, JMS, JDBC, ... the environment setup is getting unwieldy. Integrate into acceptance tests. Retrieve environment variables via Dependency injection from Utilize profiles for local single node local cluster ec2 single node ec2 cluster",NULL,"Allow user to configure tests with DI With the addition of sinks and sources that require connections with external entities hadoop, JMS, JDBC, <span class='highlight-text severity-high'>... the environment setup is getting unwieldy. Integrate into acceptance tests. Retrieve environment variables via Dependency injection from Utilize profiles for local single node local cluster ec2 single node ec2 cluster</span>","minimal","punctuation","high",False
25370,"Upgrade to Spring Hadoop 2.0 RC2 ",NULL,"Upgrade to Spring Hadoop 2.0 RC2 ",NULL,"Add for who this story is","well_formed","no_role","high",False
25369,"Remove the S3 XD Jar Cache Originally it was placed in the code to prevent overtasking our servers with downloads when people want to install XD. And to allow for faster downloads. However XD Jars are already placed on S3, so this feature is no longer needed.",NULL,"Remove the S3 XD Jar Cache Originally it was placed in the code to prevent overtasking our servers with downloads when people want to install XD. And to allow for faster downloads. However XD Jars are already placed on S3,","so this feature is no longer needed.","Add for who this story is","well_formed","no_role","high",False
25369,"Remove the S3 XD Jar Cache Originally it was placed in the code to prevent overtasking our servers with downloads when people want to install XD. And to allow for faster downloads. However XD Jars are already placed on S3, so this feature is no longer needed.",NULL,"Remove the S3 XD Jar Cache Originally it was placed in the code to prevent overtasking our servers with downloads when people want to install XD. And to allow for faster downloads. However XD Jars are already placed on S3,","so this feature is no longer needed.","Remove the S3 XD Jar Cache Originally it was placed in the code to prevent overtasking our servers with downloads when people want to install XD.<span class='highlight-text severity-high'> and </span>to allow for faster downloads. However XD Jars are already placed on S3, so this feature is no longer needed.","atomic","conjunctions","high",False
25369,"Remove the S3 XD Jar Cache Originally it was placed in the code to prevent overtasking our servers with downloads when people want to install XD. And to allow for faster downloads. However XD Jars are already placed on S3, so this feature is no longer needed.",NULL,"Remove the S3 XD Jar Cache Originally it was placed in the code to prevent overtasking our servers with downloads when people want to install XD. And to allow for faster downloads. However XD Jars are already placed on S3,","so this feature is no longer needed.","Remove the S3 XD Jar Cache Originally it was placed in the code to prevent overtasking our servers with downloads when people want to install XD<span class='highlight-text severity-high'>. And to allow for faster downloads. However XD Jars are already placed on S3, so this feature is no longer needed.</span>","minimal","punctuation","high",False
25369,"Remove the S3 XD Jar Cache Originally it was placed in the code to prevent overtasking our servers with downloads when people want to install XD. And to allow for faster downloads. However XD Jars are already placed on S3, so this feature is no longer needed.",NULL,"Remove the S3 XD Jar Cache Originally it was placed in the code to prevent overtasking our servers with downloads when people want to install XD. And to allow for faster downloads. However XD Jars are already placed on S3,","so this feature is no longer needed.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25373,"Validate time field processing with AggregateCounter AggregateCounter needs a test case along the lines of of that will demonstrate the base functionality of the module as well as use of the timeField and dateFormat options.",NULL,"Validate time field processing with AggregateCounter AggregateCounter needs a test case along the lines of of that will demonstrate the base functionality of the module as well as use of the timeField and dateFormat options.",NULL,"Add for who this story is","well_formed","no_role","high",False
25372,"Use Hadoop mini cluster test support in XD tests The tests that use HDFS currently require an external Hadoop installation and is hard to set up update version in all the environments where we want to run tests, e.g. bamboo, travis. See if the mini cluster described in can be used in the test cases instead.",NULL,"Use Hadoop mini cluster test support in XD tests The tests that use HDFS currently require an external Hadoop installation and is hard to set up update version in all the environments where we want to run tests, e.g. bamboo, travis. See if the mini cluster described in can be used in the test cases instead.",NULL,"Add for who this story is","well_formed","no_role","high",False
25372,"Use Hadoop mini cluster test support in XD tests The tests that use HDFS currently require an external Hadoop installation and is hard to set up update version in all the environments where we want to run tests, e.g. bamboo, travis. See if the mini cluster described in can be used in the test cases instead.",NULL,"Use Hadoop mini cluster test support in XD tests The tests that use HDFS currently require an external Hadoop installation and is hard to set up update version in all the environments where we want to run tests, e.g. bamboo, travis. See if the mini cluster described in can be used in the test cases instead.",NULL,"Use Hadoop mini cluster test support in XD tests The tests that use HDFS currently require an external Hadoop installation<span class='highlight-text severity-high'> and </span>is hard to set up update version in all the environments where we want to run tests, e.g. bamboo, travis. See if the mini cluster described in can be used in the test cases instead.","atomic","conjunctions","high",False
25372,"Use Hadoop mini cluster test support in XD tests The tests that use HDFS currently require an external Hadoop installation and is hard to set up update version in all the environments where we want to run tests, e.g. bamboo, travis. See if the mini cluster described in can be used in the test cases instead.",NULL,"Use Hadoop mini cluster test support in XD tests The tests that use HDFS currently require an external Hadoop installation and is hard to set up update version in all the environments where we want to run tests, e.g. bamboo, travis. See if the mini cluster described in can be used in the test cases instead.",NULL,"Use Hadoop mini cluster test support in XD tests The tests that use HDFS currently require an external Hadoop installation and is hard to set up update version in all the environments where we want to run tests, e<span class='highlight-text severity-high'>.g. bamboo, travis. See if the mini cluster described in can be used in the test cases instead.</span>","minimal","punctuation","high",False
25375,"Upgrade to Spring Integration 4.0.0.M4 Currently on snapshots, which is oddly pulling in groovy 2.1.0",NULL,"Upgrade to Spring Integration 4.0.0.M4 Currently on snapshots, which is oddly pulling in groovy 2.1.0",NULL,"Add for who this story is","well_formed","no_role","high",False
25374,"Delete post module and CF profile This would get rid of the CF specific post module, keeping the general abstraction of http source across CF and non CF environments.",NULL,"Delete post module and CF profile This would get rid of the CF specific post module, keeping the general abstraction of http source across CF and non CF environments.",NULL,"Add for who this story is","well_formed","no_role","high",False
25374,"Delete post module and CF profile This would get rid of the CF specific post module, keeping the general abstraction of http source across CF and non CF environments.",NULL,"Delete post module and CF profile This would get rid of the CF specific post module, keeping the general abstraction of http source across CF and non CF environments.",NULL,"Delete post module<span class='highlight-text severity-high'> and </span>CF profile This would get rid of the CF specific post module, keeping the general abstraction of http source across CF and non CF environments.","atomic","conjunctions","high",False
25376,"Update management context path to root management ",NULL,"Update management context path to root management ",NULL,"Add for who this story is","well_formed","no_role","high",False
25359,"Update Spring Framework dependency to 4.0.3 GA ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25359,"Update Spring Framework dependency to 4.0.3 GA ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25357,"Implement NAME Implement NAME The description in the google doc describes the usage of and The description in the google doc describes the usage of and ",NULL,"Implement NAME Implement NAME The description in the google doc describes the usage of and The description in the google doc describes the usage of and ",NULL,"Add for who this story is","well_formed","no_role","high",False
25357,"Implement NAME Implement NAME The description in the google doc describes the usage of and The description in the google doc describes the usage of and ",NULL,"Implement NAME Implement NAME The description in the google doc describes the usage of and The description in the google doc describes the usage of and ",NULL,"Implement NAME Implement NAME The description in the google doc describes the usage of<span class='highlight-text severity-high'> and </span>The description in the google doc describes the usage of and ","atomic","conjunctions","high",False
25360,"Update to Spring Boot 1.0 GA ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25360,"Update to Spring Boot 1.0 GA ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25361,"Don t swallow unexpected exceptions in ",NULL,"Don t swallow unexpected exceptions in ",NULL,"Add for who this story is","well_formed","no_role","high",False
25362,"Update to Spring Shell 1.1 RC1 ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25362,"Update to Spring Shell 1.1 RC1 ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25387,"Create a test case for insulating environment variables in module property lookup For PR see if one can have a test case such that a test module would have a PATH property that overlaps with the environment variable. It should never resolve to the real unix windows path.",NULL,"Create a test case for insulating environment variables in module property lookup For PR see if one can have a test case such that a test module would have a PATH property that overlaps with the environment variable. It should never resolve to the real unix windows path.",NULL,"Add for who this story is","well_formed","no_role","high",False
25387,"Create a test case for insulating environment variables in module property lookup For PR see if one can have a test case such that a test module would have a PATH property that overlaps with the environment variable. It should never resolve to the real unix windows path.",NULL,"Create a test case for insulating environment variables in module property lookup For PR see if one can have a test case such that a test module would have a PATH property that overlaps with the environment variable. It should never resolve to the real unix windows path.",NULL,"Create a test case for insulating environment variables in module property lookup For PR see if one can have a test case such that a test module would have a PATH property that overlaps with the environment variable<span class='highlight-text severity-high'>. It should never resolve to the real unix windows path.</span>","minimal","punctuation","high",False
25386,"Test scripts on windows that use ",NULL,"Test scripts on windows that use ",NULL,"Add for who this story is","well_formed","no_role","high",False
25389,"Allow users to set attribute values on a container Allow users to configure arbitrary key value pairs for a container instance that may be referenced in deployment descriptors to target specific container instances. ",NULL,"Allow users to set attribute values on a container Allow users to configure arbitrary key value pairs for a container instance that may be referenced in deployment descriptors to target specific container instances. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25388,"Add documentation for new module property configuration support the algorithm and approach in needs to be added to the section on application configuration",NULL,"Add documentation for new module property configuration support the algorithm and approach in needs to be added to the section on application configuration",NULL,"Add for who this story is","well_formed","no_role","high",False
25388,"Add documentation for new module property configuration support the algorithm and approach in needs to be added to the section on application configuration",NULL,"Add documentation for new module property configuration support the algorithm and approach in needs to be added to the section on application configuration",NULL,"Add documentation for new module property configuration support the algorithm<span class='highlight-text severity-high'> and </span>approach in needs to be added to the section on application configuration","atomic","conjunctions","high",False
25391,"Move JMX Endpoints from jolokia to management jolokia Update code to use the management jolokia endpoint.",NULL,"Move JMX Endpoints from jolokia to management jolokia Update code to use the management jolokia endpoint.",NULL,"Add for who this story is","well_formed","no_role","high",False
25390,"Support groups container attribute A container instance may be designated as belonging to a group. The end user may define this attribute using yaml config as delimited string or an environment variable or groups command line argument. ",NULL,"Support groups container attribute A container instance may be designated as belonging to a group. The end user may define this attribute using yaml config as delimited string or an environment variable or groups command line argument. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25390,"Support groups container attribute A container instance may be designated as belonging to a group. The end user may define this attribute using yaml config as delimited string or an environment variable or groups command line argument. ",NULL,"Support groups container attribute A container instance may be designated as belonging to a group. The end user may define this attribute using yaml config as delimited string or an environment variable or groups command line argument. ",NULL,"Support groups container attribute A container instance may be designated as belonging to a group. The end user may define this attribute using yaml config as delimited string<span class='highlight-text severity-high'> or </span>an environment variable or groups command line argument. ","atomic","conjunctions","high",False
25390,"Support groups container attribute A container instance may be designated as belonging to a group. The end user may define this attribute using yaml config as delimited string or an environment variable or groups command line argument. ",NULL,"Support groups container attribute A container instance may be designated as belonging to a group. The end user may define this attribute using yaml config as delimited string or an environment variable or groups command line argument. ",NULL,"Support groups container attribute A container instance may be designated as belonging to a group<span class='highlight-text severity-high'>. The end user may define this attribute using yaml config as delimited string or an environment variable or groups command line argument. </span>","minimal","punctuation","high",False
25395,"Avoid duplication when loading streams for deployment Avoid duplication when loading streams for deployment See and Both require the stream definition as well as stream deployment manifest. See and Both require the stream definition as well as stream deployment manifest.",NULL,"Avoid duplication when loading streams for deployment Avoid duplication when loading streams for deployment See and Both require the stream definition as well as stream deployment manifest. See and Both require the stream definition as well as stream deployment manifest.",NULL,"Add for who this story is","well_formed","no_role","high",False
25395,"Avoid duplication when loading streams for deployment Avoid duplication when loading streams for deployment See and Both require the stream definition as well as stream deployment manifest. See and Both require the stream definition as well as stream deployment manifest.",NULL,"Avoid duplication when loading streams for deployment Avoid duplication when loading streams for deployment See and Both require the stream definition as well as stream deployment manifest. See and Both require the stream definition as well as stream deployment manifest.",NULL,"Avoid duplication when loading streams for deployment Avoid duplication when loading streams for deployment See<span class='highlight-text severity-high'> and </span>Both require the stream definition as well as stream deployment manifest. See and Both require the stream definition as well as stream deployment manifest.","atomic","conjunctions","high",False
25395,"Avoid duplication when loading streams for deployment Avoid duplication when loading streams for deployment See and Both require the stream definition as well as stream deployment manifest. See and Both require the stream definition as well as stream deployment manifest.",NULL,"Avoid duplication when loading streams for deployment Avoid duplication when loading streams for deployment See and Both require the stream definition as well as stream deployment manifest. See and Both require the stream definition as well as stream deployment manifest.",NULL,"Avoid duplication when loading streams for deployment Avoid duplication when loading streams for deployment See and Both require the stream definition as well as stream deployment manifest<span class='highlight-text severity-high'>. See and Both require the stream definition as well as stream deployment manifest.</span>","minimal","punctuation","high",False
25392,"Create documentation for module property configuration Describe the algorithm as defined in ",NULL,"Create documentation for module property configuration Describe the algorithm as defined in ",NULL,"Add for who this story is","well_formed","no_role","high",False
25394,"Publish Spring XD final distribution zip as part of Bamboo artifactory plugin Currently, Bamboo s gradle artifactory plugin has the artifacts configured to projects target build directory archives . We need to have a way to set the final distribution archive as one of the gradle configurations in our build.gradle and refer it inside bamboo artifacts.",NULL,"Publish Spring XD final distribution zip as part of Bamboo artifactory plugin Currently, Bamboo s gradle artifactory plugin has the artifacts configured to projects target build directory archives . We need to have a way to set the final distribution archive as one of the gradle configurations in our build.gradle and refer it inside bamboo artifacts.",NULL,"Add for who this story is","well_formed","no_role","high",False
25394,"Publish Spring XD final distribution zip as part of Bamboo artifactory plugin Currently, Bamboo s gradle artifactory plugin has the artifacts configured to projects target build directory archives . We need to have a way to set the final distribution archive as one of the gradle configurations in our build.gradle and refer it inside bamboo artifacts.",NULL,"Publish Spring XD final distribution zip as part of Bamboo artifactory plugin Currently, Bamboo s gradle artifactory plugin has the artifacts configured to projects target build directory archives . We need to have a way to set the final distribution archive as one of the gradle configurations in our build.gradle and refer it inside bamboo artifacts.",NULL,"Publish Spring XD final distribution zip as part of Bamboo artifactory plugin Currently, Bamboo s gradle artifactory plugin has the artifacts configured to projects target build directory archives . We need to have a way to set the final distribution archive as one of the gradle configurations in our build.gradle<span class='highlight-text severity-high'> and </span>refer it inside bamboo artifacts.","atomic","conjunctions","high",False
25394,"Publish Spring XD final distribution zip as part of Bamboo artifactory plugin Currently, Bamboo s gradle artifactory plugin has the artifacts configured to projects target build directory archives . We need to have a way to set the final distribution archive as one of the gradle configurations in our build.gradle and refer it inside bamboo artifacts.",NULL,"Publish Spring XD final distribution zip as part of Bamboo artifactory plugin Currently, Bamboo s gradle artifactory plugin has the artifacts configured to projects target build directory archives . We need to have a way to set the final distribution archive as one of the gradle configurations in our build.gradle and refer it inside bamboo artifacts.",NULL,"Publish Spring XD final distribution zip as part of Bamboo artifactory plugin Currently, Bamboo s gradle artifactory plugin has the artifacts configured to projects target build directory archives <span class='highlight-text severity-high'>. We need to have a way to set the final distribution archive as one of the gradle configurations in our build.gradle and refer it inside bamboo artifacts.</span>","minimal","punctuation","high",False
25397,"Clean up publishing to maven repositories of empty module projects See the various module.xyz directories here ",NULL,"Clean up publishing to maven repositories of empty module projects See the various module.xyz directories here ",NULL,"Add for who this story is","well_formed","no_role","high",False
25396,"Add admin ui to YARN zip packaging ",NULL,"Add admin ui to YARN zip packaging ",NULL,"Add for who this story is","well_formed","no_role","high",False
25399,"Create documentation for ZK runtime ",NULL,"Create documentation for ZK runtime ",NULL,"Add for who this story is","well_formed","no_role","high",False
25398,"Add Redis binaries for Windows Presently, Spring XD does not ship Windows binaries for Redis. However, Microsoft is actively working on supporting Redis on Windows. You can download Windows Redis binaries from ",NULL,"Add Redis binaries for Windows Presently, Spring XD does not ship Windows binaries for Redis. However, Microsoft is actively working on supporting Redis on Windows. You can download Windows Redis binaries from ",NULL,"Add for who this story is","well_formed","no_role","high",False
25398,"Add Redis binaries for Windows Presently, Spring XD does not ship Windows binaries for Redis. However, Microsoft is actively working on supporting Redis on Windows. You can download Windows Redis binaries from ",NULL,"Add Redis binaries for Windows Presently, Spring XD does not ship Windows binaries for Redis. However, Microsoft is actively working on supporting Redis on Windows. You can download Windows Redis binaries from ",NULL,"Add Redis binaries for Windows Presently, Spring XD does not ship Windows binaries for Redis<span class='highlight-text severity-high'>. However, Microsoft is actively working on supporting Redis on Windows. You can download Windows Redis binaries from </span>","minimal","punctuation","high",False
25401,"Change the default deploy option to false for stream job deploy commands With the introduction of the deployment manifest setting this to false makes it easier to use the deployment manifest, which is the main use case scenario. ",NULL,"Change the default deploy option to false for stream job deploy commands With the introduction of the deployment manifest setting this to false makes it easier to use the deployment manifest, which is the main use case scenario. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25400,"Create documentation for how to extend the XD containers Create documentation for how to extend the XD containers and related issues. and related issues.",NULL,"Create documentation for how to extend the XD containers Create documentation for how to extend the XD containers and related issues. and related issues.",NULL,"Add for who this story is","well_formed","no_role","high",False
25400,"Create documentation for how to extend the XD containers Create documentation for how to extend the XD containers and related issues. and related issues.",NULL,"Create documentation for how to extend the XD containers Create documentation for how to extend the XD containers and related issues. and related issues.",NULL,"Create documentation for how to extend the XD containers Create documentation for how to extend the XD containers and related issues<span class='highlight-text severity-high'>. and related issues.</span>","minimal","punctuation","high",False
26622,"Create shell integration tests for job lifeycle creating job defs, deploying jobs, undeploying jobs, deleting job defs",NULL,"Create shell integration tests for job lifeycle creating job defs, deploying jobs, undeploying jobs, deleting job defs",NULL,"Add for who this story is","well_formed","no_role","high",False
25402,"Create documentation for the deployment manifest ",NULL,"Create documentation for the deployment manifest ",NULL,"Add for who this story is","well_formed","no_role","high",False
25393,"change xd config.yml and to servers.yml and modules.yml ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25393,"change xd config.yml and to servers.yml and modules.yml ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25385,"The Container s DeploymentListener should watch Currently it watches but due to the reuse of that top level node for XD 1483 and XD 1484, we should instead use ",NULL,"The Container s DeploymentListener should watch Currently it watches but due to the reuse of that top level node for XD 1483 and XD 1484, we should instead use ",NULL,"Add for who this story is","well_formed","no_role","high",False
25385,"The Container s DeploymentListener should watch Currently it watches but due to the reuse of that top level node for XD 1483 and XD 1484, we should instead use ",NULL,"The Container s DeploymentListener should watch Currently it watches but due to the reuse of that top level node for XD 1483 and XD 1484, we should instead use ",NULL,"The Container s DeploymentListener should watch Currently it watches but due to the reuse of that top level node for XD 1483<span class='highlight-text severity-high'> and </span>XD 1484, we should instead use ","atomic","conjunctions","high",False
25405,"Add test cases for ",NULL,"Add test cases for ",NULL,"Add for who this story is","well_formed","no_role","high",False
25406,"Provide job repository creation schema for additonal databases oracle, gemfire xd derby should be the dialect , and sybase",NULL,"Provide job repository creation schema for additonal databases oracle, gemfire xd derby should be the dialect , and sybase",NULL,"Add for who this story is","well_formed","no_role","high",False
25407,"Create rich gauge module Spring config for rich gauge plus message handler to coerce a numeric or string payload to a double.",NULL,"Create rich gauge module Spring config for rich gauge plus message handler to coerce a numeric or string payload to a double.",NULL,"Add for who this story is","well_formed","no_role","high",False
25410,"stream list should show undeployed rather than blank if a stream is not deployed ",NULL,"stream list should show undeployed rather than blank if a stream is not deployed ",NULL,"Add for who this story is","well_formed","no_role","high",False
25412,"Support external datasource for single node application Currently, single node application assumes to use hsqldb server by default and starts the hsqldb as it starts. We need a way to provide external datasource and not to start hsqldb by default when the single node starts up.",NULL,"Support external datasource for single node application Currently, single node application assumes to use hsqldb server by default and starts the hsqldb as it starts. We need a way to provide external datasource and not to start hsqldb by default when the single node starts up.",NULL,"Add for who this story is","well_formed","no_role","high",False
25412,"Support external datasource for single node application Currently, single node application assumes to use hsqldb server by default and starts the hsqldb as it starts. We need a way to provide external datasource and not to start hsqldb by default when the single node starts up.",NULL,"Support external datasource for single node application Currently, single node application assumes to use hsqldb server by default and starts the hsqldb as it starts. We need a way to provide external datasource and not to start hsqldb by default when the single node starts up.",NULL,"Support external datasource for single node application Currently, single node application assumes to use hsqldb server by default<span class='highlight-text severity-high'> and </span>starts the hsqldb as it starts. We need a way to provide external datasource and not to start hsqldb by default when the single node starts up.","atomic","conjunctions","high",False
25412,"Support external datasource for single node application Currently, single node application assumes to use hsqldb server by default and starts the hsqldb as it starts. We need a way to provide external datasource and not to start hsqldb by default when the single node starts up.",NULL,"Support external datasource for single node application Currently, single node application assumes to use hsqldb server by default and starts the hsqldb as it starts. We need a way to provide external datasource and not to start hsqldb by default when the single node starts up.",NULL,"Support external datasource for single node application Currently, single node application assumes to use hsqldb server by default and starts the hsqldb as it starts<span class='highlight-text severity-high'>. We need a way to provide external datasource and not to start hsqldb by default when the single node starts up.</span>","minimal","punctuation","high",False
25411,"Create small documentation section on jmx monitoring functionalty Should mention jolokia, how to turn on off boot jolokia http metric monitoring and jmx. Mention the naming strategy to identify modules running in a stream.",NULL,"Create small documentation section on jmx monitoring functionalty Should mention jolokia, how to turn on off boot jolokia http metric monitoring and jmx. Mention the naming strategy to identify modules running in a stream.",NULL,"Add for who this story is","well_formed","no_role","high",False
25545,"Add single threaded executor service to This will eliminate any race conditions between deployments and containers joining leaving the cluster.",NULL,"Add single threaded executor service to This will eliminate any race conditions between deployments and containers joining leaving the cluster.",NULL,"Add single threaded executor service to This will eliminate any race conditions between deployments<span class='highlight-text severity-high'> and </span>containers joining leaving the cluster.","atomic","conjunctions","high",False
25411,"Create small documentation section on jmx monitoring functionalty Should mention jolokia, how to turn on off boot jolokia http metric monitoring and jmx. Mention the naming strategy to identify modules running in a stream.",NULL,"Create small documentation section on jmx monitoring functionalty Should mention jolokia, how to turn on off boot jolokia http metric monitoring and jmx. Mention the naming strategy to identify modules running in a stream.",NULL,"Create small documentation section on jmx monitoring functionalty Should mention jolokia, how to turn on off boot jolokia http metric monitoring and jmx<span class='highlight-text severity-high'>. Mention the naming strategy to identify modules running in a stream.</span>","minimal","punctuation","high",False
25413,"create a gauge module Spring config for simple gauge plus message handler to process message. There is some code common to RichGaugeHandler to coerce the payload to a double that should be refactored for reuse.",NULL,"create a gauge module Spring config for simple gauge plus message handler to process message. There is some code common to RichGaugeHandler to coerce the payload to a double that should be refactored for reuse.",NULL,"Add for who this story is","well_formed","no_role","high",False
25413,"create a gauge module Spring config for simple gauge plus message handler to process message. There is some code common to RichGaugeHandler to coerce the payload to a double that should be refactored for reuse.",NULL,"create a gauge module Spring config for simple gauge plus message handler to process message. There is some code common to RichGaugeHandler to coerce the payload to a double that should be refactored for reuse.",NULL,"create a gauge module Spring config for simple gauge plus message handler to process message<span class='highlight-text severity-high'>. There is some code common to RichGaugeHandler to coerce the payload to a double that should be refactored for reuse.</span>","minimal","punctuation","high",False
25414,"Rename xd config.yml to servers.yml and add to spring xd yarn Rename xd config.yml to servers.yml and add to spring xd yarn Make changes to XD on YARN config that correspond to XD 1499 changes Make changes to XD on YARN config that correspond to XD 1499 changes",NULL,"Rename xd config.yml to servers.yml and add to spring xd yarn Rename xd config.yml to servers.yml and add to spring xd yarn Make changes to XD on YARN config that correspond to XD 1499 changes Make changes to XD on YARN config that correspond to XD 1499 changes",NULL,"Add for who this story is","well_formed","no_role","high",False
25414,"Rename xd config.yml to servers.yml and add to spring xd yarn Rename xd config.yml to servers.yml and add to spring xd yarn Make changes to XD on YARN config that correspond to XD 1499 changes Make changes to XD on YARN config that correspond to XD 1499 changes",NULL,"Rename xd config.yml to servers.yml and add to spring xd yarn Rename xd config.yml to servers.yml and add to spring xd yarn Make changes to XD on YARN config that correspond to XD 1499 changes Make changes to XD on YARN config that correspond to XD 1499 changes",NULL,"Rename xd config.yml to servers.yml<span class='highlight-text severity-high'> and </span>add to spring xd yarn Rename xd config.yml to servers.yml and add to spring xd yarn Make changes to XD on YARN config that correspond to XD 1499 changes Make changes to XD on YARN config that correspond to XD 1499 changes","atomic","conjunctions","high",False
25415,"Create documentation for Job listeners support ",NULL,"Create documentation for Job listeners support ",NULL,"Add for who this story is","well_formed","no_role","high",False
25418,"Support deploying to multiple containers in EC2 acceptance tests need the ability to support the group option.",NULL,"Support deploying to multiple containers in EC2 acceptance tests need the ability to support the group option.",NULL,"Add for who this story is","well_formed","no_role","high",False
25419,"transform processor with script option is broken Creating the following stream throws exception stream create s1 definition http transform log Command failed Error with option s for module transform of type processor valid the script and expression options are mutually exclusive The assertions to check if script and expression options are mutually exclusive always fails.",NULL,"transform processor with script option is broken Creating the following stream throws exception stream create s1 definition http transform log Command failed Error with option s for module transform of type processor valid the script and expression options are mutually exclusive The assertions to check if script and expression options are mutually exclusive always fails.",NULL,"Add for who this story is","well_formed","no_role","high",False
25419,"transform processor with script option is broken Creating the following stream throws exception stream create s1 definition http transform log Command failed Error with option s for module transform of type processor valid the script and expression options are mutually exclusive The assertions to check if script and expression options are mutually exclusive always fails.",NULL,"transform processor with script option is broken Creating the following stream throws exception stream create s1 definition http transform log Command failed Error with option s for module transform of type processor valid the script and expression options are mutually exclusive The assertions to check if script and expression options are mutually exclusive always fails.",NULL,"transform processor with script option is broken Creating the following stream throws exception stream create s1 definition http transform log Command failed Error with option s for module transform of type processor valid the script<span class='highlight-text severity-high'> and </span>expression options are mutually exclusive The assertions to check if script and expression options are mutually exclusive always fails.","atomic","conjunctions","high",False
25417,"Update instructions to how to setup admin to use RDBMS. Need to update instructions to discuss the setup of the relational database requirement for the xd admin.",NULL,"Update instructions to how to setup admin to use RDBMS. Need to update instructions to discuss the setup of the relational database requirement for the xd admin.",NULL,"Add for who this story is","well_formed","no_role","high",False
25417,"Update instructions to how to setup admin to use RDBMS. Need to update instructions to discuss the setup of the relational database requirement for the xd admin.",NULL,"Update instructions to how to setup admin to use RDBMS. Need to update instructions to discuss the setup of the relational database requirement for the xd admin.",NULL,"Update instructions to how to setup admin to use RDBMS<span class='highlight-text severity-high'>. Need to update instructions to discuss the setup of the relational database requirement for the xd admin.</span>","minimal","punctuation","high",False
25420,"shell cp command fails from the wordcount sample xd ! cp You cannot specify option more than once in a single command ",NULL,"shell cp command fails from the wordcount sample xd ! cp You cannot specify option more than once in a single command ",NULL,"Add for who this story is","well_formed","no_role","high",False
25421,"Payload Conversion will need to migrated to M6 as soon as M6 is available Currently uses m5 dependency. ",NULL,"Payload Conversion will need to migrated to M6 as soon as M6 is available Currently uses m5 dependency. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25422,"Create config support for Redis We would like to have Redis driven from a config property file under XD HOME.",NULL,"Create config support for Redis We would like to have Redis driven from a config property file under XD HOME.",NULL,"Add for who this story is","well_formed","no_role","high",False
26642,"Switch to use Lettuce driver for Redis Replace the use of Jedis with Lettuce as it has higher performance",NULL,"Switch to use Lettuce driver for Redis Replace the use of Jedis with Lettuce as it has higher performance",NULL,"Add for who this story is","well_formed","no_role","high",False
25409,"parser should only allow one label instance per module ",NULL,"parser should only allow one label instance per module ",NULL,"Add for who this story is","well_formed","no_role","high",False
25404,"Change request mapping for removing a stream deployment in XDController Currently deployments with an understore in XDController should be something else. Need to segment up the url space better for stream jobs to avoid a clash.",NULL,"Change request mapping for removing a stream deployment in XDController Currently deployments with an understore in XDController should be something else. Need to segment up the url space better for stream jobs to avoid a clash.",NULL,"Add for who this story is","well_formed","no_role","high",False
25404,"Change request mapping for removing a stream deployment in XDController Currently deployments with an understore in XDController should be something else. Need to segment up the url space better for stream jobs to avoid a clash.",NULL,"Change request mapping for removing a stream deployment in XDController Currently deployments with an understore in XDController should be something else. Need to segment up the url space better for stream jobs to avoid a clash.",NULL,"Change request mapping for removing a stream deployment in XDController Currently deployments with an understore in XDController should be something else<span class='highlight-text severity-high'>. Need to segment up the url space better for stream jobs to avoid a clash.</span>","minimal","punctuation","high",False
25416,"Update docs and samples now that deploy is false on job stream creation ",NULL,"Update docs and samples now that deploy is false on job stream creation ",NULL,"Add for who this story is","well_formed","no_role","high",False
25426,"Rename reactor tcp module to reactor ip since it also supports udp the transport option allows udp as well as tcp ",NULL,"Rename reactor tcp module to reactor ip since it also supports udp the transport option allows udp as well as tcp ",NULL,"Add for who this story is","well_formed","no_role","high",False
25425,"Update documentation related to transport and controlTransport e.g. Need to update this section maybe others Remove all mentions of Control Bus, and replace any mentions of the transport cmd line arg with the xd.transport property in yml. ",NULL,"Update documentation related to transport and controlTransport e.g. Need to update this section maybe others Remove all mentions of Control Bus, and replace any mentions of the transport cmd line arg with the xd.transport property in yml. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25425,"Update documentation related to transport and controlTransport e.g. Need to update this section maybe others Remove all mentions of Control Bus, and replace any mentions of the transport cmd line arg with the xd.transport property in yml. ",NULL,"Update documentation related to transport and controlTransport e.g. Need to update this section maybe others Remove all mentions of Control Bus, and replace any mentions of the transport cmd line arg with the xd.transport property in yml. ",NULL,"Update documentation related to transport<span class='highlight-text severity-high'> and </span>controlTransport e.g. Need to update this section maybe others Remove all mentions of Control Bus, and replace any mentions of the transport cmd line arg with the xd.transport property in yml. ","atomic","conjunctions","high",False
25425,"Update documentation related to transport and controlTransport e.g. Need to update this section maybe others Remove all mentions of Control Bus, and replace any mentions of the transport cmd line arg with the xd.transport property in yml. ",NULL,"Update documentation related to transport and controlTransport e.g. Need to update this section maybe others Remove all mentions of Control Bus, and replace any mentions of the transport cmd line arg with the xd.transport property in yml. ",NULL,"Update documentation related to transport and controlTransport e<span class='highlight-text severity-high'>.g. Need to update this section maybe others Remove all mentions of Control Bus, and replace any mentions of the transport cmd line arg with the xd.transport property in yml. </span>","minimal","punctuation","high",False
25428,"Unable to delete composed module After creating a composed module, I am unable to delete it. xd module compose doo definition filter file Successfully created module doo with type sink xd module module compose module delete module display module info module list xd module delete name doo type sink Failed to convert doo to type for option name, String index out of range 1 xd ",NULL,"Unable to delete composed module After creating a composed module, I am unable to delete it. xd module compose doo definition filter file Successfully created module doo with type sink xd module module compose module delete module display module info module list xd module delete name doo type sink Failed to convert doo to type for option name, String index out of range 1 xd ",NULL,"Add for who this story is","well_formed","no_role","high",False
25428,"Unable to delete composed module After creating a composed module, I am unable to delete it. xd module compose doo definition filter file Successfully created module doo with type sink xd module module compose module delete module display module info module list xd module delete name doo type sink Failed to convert doo to type for option name, String index out of range 1 xd ",NULL,"Unable to delete composed module After creating a composed module, I am unable to delete it. xd module compose doo definition filter file Successfully created module doo with type sink xd module module compose module delete module display module info module list xd module delete name doo type sink Failed to convert doo to type for option name, String index out of range 1 xd ",NULL,"Unable to delete composed module After creating a composed module, I am unable to delete it<span class='highlight-text severity-high'>. xd module compose doo definition filter file Successfully created module doo with type sink xd module module compose module delete module display module info module list xd module delete name doo type sink Failed to convert doo to type for option name, String index out of range 1 xd </span>","minimal","punctuation","high",False
25427,"Verify use of JMX managed bean to shutdown cleanly the xd admin and xd container servers In both cases there are multiple application contexts that can be running in the process. The JMX Managed bean should call close on those application contexts. The more detailed lifecycle of cleanly shutting down components within those application contexts is another story.",NULL,"Verify use of JMX managed bean to shutdown cleanly the xd admin and xd container servers In both cases there are multiple application contexts that can be running in the process. The JMX Managed bean should call close on those application contexts. The more detailed lifecycle of cleanly shutting down components within those application contexts is another story.",NULL,"Add for who this story is","well_formed","no_role","high",False
25427,"Verify use of JMX managed bean to shutdown cleanly the xd admin and xd container servers In both cases there are multiple application contexts that can be running in the process. The JMX Managed bean should call close on those application contexts. The more detailed lifecycle of cleanly shutting down components within those application contexts is another story.",NULL,"Verify use of JMX managed bean to shutdown cleanly the xd admin and xd container servers In both cases there are multiple application contexts that can be running in the process. The JMX Managed bean should call close on those application contexts. The more detailed lifecycle of cleanly shutting down components within those application contexts is another story.",NULL,"Verify use of JMX managed bean to shutdown cleanly the xd admin<span class='highlight-text severity-high'> and </span>xd container servers In both cases there are multiple application contexts that can be running in the process. The JMX Managed bean should call close on those application contexts. The more detailed lifecycle of cleanly shutting down components within those application contexts is another story.","atomic","conjunctions","high",False
25427,"Verify use of JMX managed bean to shutdown cleanly the xd admin and xd container servers In both cases there are multiple application contexts that can be running in the process. The JMX Managed bean should call close on those application contexts. The more detailed lifecycle of cleanly shutting down components within those application contexts is another story.",NULL,"Verify use of JMX managed bean to shutdown cleanly the xd admin and xd container servers In both cases there are multiple application contexts that can be running in the process. The JMX Managed bean should call close on those application contexts. The more detailed lifecycle of cleanly shutting down components within those application contexts is another story.",NULL,"Verify use of JMX managed bean to shutdown cleanly the xd admin and xd container servers In both cases there are multiple application contexts that can be running in the process<span class='highlight-text severity-high'>. The JMX Managed bean should call close on those application contexts. The more detailed lifecycle of cleanly shutting down components within those application contexts is another story.</span>","minimal","punctuation","high",False
25430,"JDBC Acceptance tests must jdbc props vs. configProps setting. In this case we will use environment variables to set the JDBC sink settings. Thus we will just remove code.",NULL,"JDBC Acceptance tests must jdbc props vs. configProps setting. In this case we will use environment variables to set the JDBC sink settings. Thus we will just remove code.",NULL,"Add for who this story is","well_formed","no_role","high",False
25430,"JDBC Acceptance tests must jdbc props vs. configProps setting. In this case we will use environment variables to set the JDBC sink settings. Thus we will just remove code.",NULL,"JDBC Acceptance tests must jdbc props vs. configProps setting. In this case we will use environment variables to set the JDBC sink settings. Thus we will just remove code.",NULL,"JDBC Acceptance tests must jdbc props vs<span class='highlight-text severity-high'>. configProps setting. In this case we will use environment variables to set the JDBC sink settings. Thus we will just remove code.</span>","minimal","punctuation","high",False
25429,"Update diagrams that show control transport The first 2 images in the documentation section linked below should no longer show redis, rabbit, or local for the communication between Admins and Containers. Rather we need to show ZooKeeper. ",NULL,"Update diagrams that show control transport The first 2 images in the documentation section linked below should no longer show redis, rabbit, or local for the communication between Admins and Containers. Rather we need to show ZooKeeper. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25429,"Update diagrams that show control transport The first 2 images in the documentation section linked below should no longer show redis, rabbit, or local for the communication between Admins and Containers. Rather we need to show ZooKeeper. ",NULL,"Update diagrams that show control transport The first 2 images in the documentation section linked below should no longer show redis, rabbit, or local for the communication between Admins and Containers. Rather we need to show ZooKeeper. ",NULL,"Update diagrams that show control transport The first 2 images in the documentation section linked below should no longer show redis, rabbit,<span class='highlight-text severity-high'> or </span>local for the communication between Admins<span class='highlight-text severity-high'> and </span>Containers. Rather we need to show ZooKeeper. ","atomic","conjunctions","high",False
25429,"Update diagrams that show control transport The first 2 images in the documentation section linked below should no longer show redis, rabbit, or local for the communication between Admins and Containers. Rather we need to show ZooKeeper. ",NULL,"Update diagrams that show control transport The first 2 images in the documentation section linked below should no longer show redis, rabbit, or local for the communication between Admins and Containers. Rather we need to show ZooKeeper. ",NULL,"Update diagrams that show control transport The first 2 images in the documentation section linked below should no longer show redis, rabbit, or local for the communication between Admins and Containers<span class='highlight-text severity-high'>. Rather we need to show ZooKeeper. </span>","minimal","punctuation","high",False
25432,"Remove unused .properties files in config and update docs There are some properties files in the config directory that no longer are needed. We should clean that up and also remove update any documentation references to these files",NULL,"Remove unused .properties files in config and update docs There are some properties files in the config directory that no longer are needed. We should clean that up and also remove update any documentation references to these files",NULL,"Add for who this story is","well_formed","no_role","high",False
25544,"Fix JMS Property Names The JMS Source Sink has a pluggable provider default implies activeMQ the property name should be generic found while testing XD 1149 .",NULL,"Fix JMS Property Names The JMS Source Sink has a pluggable provider default implies activeMQ the property name should be generic found while testing XD 1149 .",NULL,"Add for who this story is","well_formed","no_role","high",False
25547,"Add unregistration support to the channel registry ",NULL,"Add unregistration support to the channel registry ",NULL,"Add for who this story is","well_formed","no_role","high",False
25432,"Remove unused .properties files in config and update docs There are some properties files in the config directory that no longer are needed. We should clean that up and also remove update any documentation references to these files",NULL,"Remove unused .properties files in config and update docs There are some properties files in the config directory that no longer are needed. We should clean that up and also remove update any documentation references to these files",NULL,"Remove unused .properties files in config<span class='highlight-text severity-high'> and </span>update docs There are some properties files in the config directory that no longer are needed. We should clean that up and also remove update any documentation references to these files","atomic","conjunctions","high",False
25432,"Remove unused .properties files in config and update docs There are some properties files in the config directory that no longer are needed. We should clean that up and also remove update any documentation references to these files",NULL,"Remove unused .properties files in config and update docs There are some properties files in the config directory that no longer are needed. We should clean that up and also remove update any documentation references to these files",NULL,"Remove unused <span class='highlight-text severity-high'>.properties files in config and update docs There are some properties files in the config directory that no longer are needed. We should clean that up and also remove update any documentation references to these files</span>","minimal","punctuation","high",False
25431,"Add UDP support to reactor syslog source module Currently the reactor syslog source module only supports TCP. Once we add UDP support, we can probably remove the existing syslog tcp and syslog udp modules.",NULL,"Add UDP support to reactor syslog source module Currently the reactor syslog source module only supports TCP. Once we add UDP support, we can probably remove the existing syslog tcp and syslog udp modules.",NULL,"Add for who this story is","well_formed","no_role","high",False
25431,"Add UDP support to reactor syslog source module Currently the reactor syslog source module only supports TCP. Once we add UDP support, we can probably remove the existing syslog tcp and syslog udp modules.",NULL,"Add UDP support to reactor syslog source module Currently the reactor syslog source module only supports TCP. Once we add UDP support, we can probably remove the existing syslog tcp and syslog udp modules.",NULL,"Add UDP support to reactor syslog source module Currently the reactor syslog source module only supports TCP<span class='highlight-text severity-high'>. Once we add UDP support, we can probably remove the existing syslog tcp and syslog udp modules.</span>","minimal","punctuation","high",False
25434,"Move resusable analytics repository classes to a new project. The analytics project has been used as a host for common repository classes because it was easily visible by both dirt and other stuff can t remember which This should be cleaned and a dedicated project for core , utility , re usable , whatever classes should be created ",NULL,"Move resusable analytics repository classes to a new project. The analytics project has been used as a host for common repository classes because it was easily visible by both dirt and other stuff can t remember which This should be cleaned and a dedicated project for core , utility , re usable , whatever classes should be created ",NULL,"Add for who this story is","well_formed","no_role","high",False
25434,"Move resusable analytics repository classes to a new project. The analytics project has been used as a host for common repository classes because it was easily visible by both dirt and other stuff can t remember which This should be cleaned and a dedicated project for core , utility , re usable , whatever classes should be created ",NULL,"Move resusable analytics repository classes to a new project. The analytics project has been used as a host for common repository classes because it was easily visible by both dirt and other stuff can t remember which This should be cleaned and a dedicated project for core , utility , re usable , whatever classes should be created ",NULL,"Move resusable analytics repository classes to a new project. The analytics project has been used as a host for common repository classes because it was easily visible by both dirt<span class='highlight-text severity-high'> and </span>other stuff can t remember which This should be cleaned and a dedicated project for core , utility , re usable , whatever classes should be created ","atomic","conjunctions","high",False
25434,"Move resusable analytics repository classes to a new project. The analytics project has been used as a host for common repository classes because it was easily visible by both dirt and other stuff can t remember which This should be cleaned and a dedicated project for core , utility , re usable , whatever classes should be created ",NULL,"Move resusable analytics repository classes to a new project. The analytics project has been used as a host for common repository classes because it was easily visible by both dirt and other stuff can t remember which This should be cleaned and a dedicated project for core , utility , re usable , whatever classes should be created ",NULL,"Move resusable analytics repository classes to a new project<span class='highlight-text severity-high'>. The analytics project has been used as a host for common repository classes because it was easily visible by both dirt and other stuff can t remember which This should be cleaned and a dedicated project for core , utility , re usable , whatever classes should be created </span>","minimal","punctuation","high",False
25433,"Support Groovy bean definitions as XD extensions Modify the to consume .groovy bean definitions as well as XML. ",NULL,"Support Groovy bean definitions as XD extensions Modify the to consume .groovy bean definitions as well as XML. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25455,"Refactor Exception Handling and update JavaDocs for acceptance test StreamUtils HttpTest MqttTest JmsSource StreamUtils stream method should throw instead of a checked exception. XDEc2Validation assertReceived, assertValid should throw instead of a checked exception ",NULL,"Refactor Exception Handling and update JavaDocs for acceptance test StreamUtils HttpTest MqttTest JmsSource StreamUtils stream method should throw instead of a checked exception. XDEc2Validation assertReceived, assertValid should throw instead of a checked exception ",NULL,"Add for who this story is","well_formed","no_role","high",False
25455,"Refactor Exception Handling and update JavaDocs for acceptance test StreamUtils HttpTest MqttTest JmsSource StreamUtils stream method should throw instead of a checked exception. XDEc2Validation assertReceived, assertValid should throw instead of a checked exception ",NULL,"Refactor Exception Handling and update JavaDocs for acceptance test StreamUtils HttpTest MqttTest JmsSource StreamUtils stream method should throw instead of a checked exception. XDEc2Validation assertReceived, assertValid should throw instead of a checked exception ",NULL,"Refactor Exception Handling and update JavaDocs for acceptance test StreamUtils HttpTest MqttTest JmsSource StreamUtils stream method should throw instead of a checked exception<span class='highlight-text severity-high'>. XDEc2Validation assertReceived, assertValid should throw instead of a checked exception </span>","minimal","punctuation","high",False
25435,"Rabbit Source Should Expose More Container Options Rabbit Source Should Expose More Container Options acknowlege more, tx size, prefetch count, concurrency etc. acknowlege more, tx size, prefetch count, concurrency etc.",NULL,"Rabbit Source Should Expose More Container Options Rabbit Source Should Expose More Container Options acknowlege more, tx size, prefetch count, concurrency etc. acknowlege more, tx size, prefetch count, concurrency etc.",NULL,"Add for who this story is","well_formed","no_role","high",False
25435,"Rabbit Source Should Expose More Container Options Rabbit Source Should Expose More Container Options acknowlege more, tx size, prefetch count, concurrency etc. acknowlege more, tx size, prefetch count, concurrency etc.",NULL,"Rabbit Source Should Expose More Container Options Rabbit Source Should Expose More Container Options acknowlege more, tx size, prefetch count, concurrency etc. acknowlege more, tx size, prefetch count, concurrency etc.",NULL,"Rabbit Source Should Expose More Container Options Rabbit Source Should Expose More Container Options acknowlege more, tx size, prefetch count, concurrency etc<span class='highlight-text severity-high'>. acknowlege more, tx size, prefetch count, concurrency etc.</span>","minimal","punctuation","high",False
25424,"Update XD Ec2 deployer to use XD TRANSPORT XD EC2 must use environment variable XD TRANSPORT instead of transport to declare data transport for XD.",NULL,"Update XD Ec2 deployer to use XD TRANSPORT XD EC2 must use environment variable XD TRANSPORT instead of transport to declare data transport for XD.",NULL,"Add for who this story is","well_formed","no_role","high",False
25437,"Change SpringSource references in pom.xml to Spring spring.io This is currently in the M6 pom organization url organization ",NULL,"Change SpringSource references in pom.xml to Spring spring.io This is currently in the M6 pom organization url organization ",NULL,"Add for who this story is","well_formed","no_role","high",False
25438,"Publish golo themed docs documentation to as part of nightly build The wiki repo contains a script, gen docs.sh, that we are planning to use to generate a pretty HTML version of the Getting Started guide. We should consider using maven or gradle, but there is currently an issue documented in build.gradle to generate this and other reference docs and publish them automatically as part of a nightly build.",NULL,"Publish golo themed docs documentation to as part of nightly build The wiki repo contains a script, gen docs.sh, that we are planning to use to generate a pretty HTML version of the Getting Started guide. We should consider using maven or gradle, but there is currently an issue documented in build.gradle to generate this and other reference docs and publish them automatically as part of a nightly build.",NULL,"Add for who this story is","well_formed","no_role","high",False
25438,"Publish golo themed docs documentation to as part of nightly build The wiki repo contains a script, gen docs.sh, that we are planning to use to generate a pretty HTML version of the Getting Started guide. We should consider using maven or gradle, but there is currently an issue documented in build.gradle to generate this and other reference docs and publish them automatically as part of a nightly build.",NULL,"Publish golo themed docs documentation to as part of nightly build The wiki repo contains a script, gen docs.sh, that we are planning to use to generate a pretty HTML version of the Getting Started guide. We should consider using maven or gradle, but there is currently an issue documented in build.gradle to generate this and other reference docs and publish them automatically as part of a nightly build.",NULL,"Publish golo themed docs documentation to as part of nightly build The wiki repo contains a script, gen docs.sh, that we are planning to use to generate a pretty HTML version of the Getting Started guide. We should consider using maven<span class='highlight-text severity-high'> or </span>gradle, but there is currently an issue documented in build.gradle to generate this<span class='highlight-text severity-high'> and </span>other reference docs and publish them automatically as part of a nightly build.","atomic","conjunctions","high",False
25438,"Publish golo themed docs documentation to as part of nightly build The wiki repo contains a script, gen docs.sh, that we are planning to use to generate a pretty HTML version of the Getting Started guide. We should consider using maven or gradle, but there is currently an issue documented in build.gradle to generate this and other reference docs and publish them automatically as part of a nightly build.",NULL,"Publish golo themed docs documentation to as part of nightly build The wiki repo contains a script, gen docs.sh, that we are planning to use to generate a pretty HTML version of the Getting Started guide. We should consider using maven or gradle, but there is currently an issue documented in build.gradle to generate this and other reference docs and publish them automatically as part of a nightly build.",NULL,"Publish golo themed docs documentation to as part of nightly build The wiki repo contains a script, gen docs<span class='highlight-text severity-high'>.sh, that we are planning to use to generate a pretty HTML version of the Getting Started guide. We should consider using maven or gradle, but there is currently an issue documented in build.gradle to generate this and other reference docs and publish them automatically as part of a nightly build.</span>","minimal","punctuation","high",False
25439,"Add HTTP Delete Stream Operation Add HTTP Delete Stream Operation ",NULL,"Add HTTP Delete Stream Operation Add HTTP Delete Stream Operation ",NULL,"Add for who this story is","well_formed","no_role","high",False
25440,"UI The user can create a new job definition by selecting a job template and providing additional configuration properties ",NULL,"UI The user can create a new job definition by selecting a job template and providing additional configuration properties ",NULL,"Add for who this story is","well_formed","no_role","high",False
25440,"UI The user can create a new job definition by selecting a job template and providing additional configuration properties ",NULL,"UI The user can create a new job definition by selecting a job template and providing additional configuration properties ",NULL,"UI The user can create a new job definition by selecting a job template<span class='highlight-text severity-high'> and </span>providing additional configuration properties ","atomic","conjunctions","high",False
25441,"UI The user should provide username password to gain access to the UI Secure Admin UI to challenge users to enter username and password to gain access.",NULL,"UI The user should provide username password to gain access to the UI Secure Admin UI to challenge users to enter username and password to gain access.",NULL,"Add for who this story is","well_formed","no_role","high",False
25441,"UI The user should provide username password to gain access to the UI Secure Admin UI to challenge users to enter username and password to gain access.",NULL,"UI The user should provide username password to gain access to the UI Secure Admin UI to challenge users to enter username and password to gain access.",NULL,"UI The user should provide username password to gain access to the UI Secure Admin UI to challenge users to enter username<span class='highlight-text severity-high'> and </span>password to gain access.","atomic","conjunctions","high",False
25442,"UI The user can view progress information about a given step ",NULL,"UI The user can view progress information about a given step ",NULL,"Add for who this story is","well_formed","no_role","high",False
25443,"UI The user can stop a specific job execution ",NULL,"UI The user can stop a specific job execution ",NULL,"Add for who this story is","well_formed","no_role","high",False
25444,"Fix JobCommandTests verification of shell result table rows using specific index Some of the tests in JobCommandTests use the verification of shell command results table row on a specific row mostly first row like this String id It is possible that the list of table rows may have the intended row in different order. This poses inconsistent test failures. ",NULL,"Fix JobCommandTests verification of shell result table rows using specific index Some of the tests in JobCommandTests use the verification of shell command results table row on a specific row mostly first row like this String id It is possible that the list of table rows may have the intended row in different order. This poses inconsistent test failures. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25444,"Fix JobCommandTests verification of shell result table rows using specific index Some of the tests in JobCommandTests use the verification of shell command results table row on a specific row mostly first row like this String id It is possible that the list of table rows may have the intended row in different order. This poses inconsistent test failures. ",NULL,"Fix JobCommandTests verification of shell result table rows using specific index Some of the tests in JobCommandTests use the verification of shell command results table row on a specific row mostly first row like this String id It is possible that the list of table rows may have the intended row in different order. This poses inconsistent test failures. ",NULL,"Fix JobCommandTests verification of shell result table rows using specific index Some of the tests in JobCommandTests use the verification of shell command results table row on a specific row mostly first row like this String id It is possible that the list of table rows may have the intended row in different order<span class='highlight-text severity-high'>. This poses inconsistent test failures. </span>","minimal","punctuation","high",False
25445,"Add support for typed Batch Steps This may require additional support Jiras for Spring Batch",NULL,"Add support for typed Batch Steps This may require additional support Jiras for Spring Batch",NULL,"Add for who this story is","well_formed","no_role","high",False
25446,"UI For Hadoop Steps provide a link to the MapReduce Job details in Hadoop. ",NULL,"UI For Hadoop Steps provide a link to the MapReduce Job details in Hadoop. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25447,"UI The user should be able to view metrics about an executed job. ",NULL,"UI The user should be able to view metrics about an executed job. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25448,"UI The user can view the job properties that were specified when the job definition was created as well as job parameters when it was launched executed ",NULL,"UI The user can view the job properties that were specified when the job definition was created as well as job parameters when it was launched executed ",NULL,"Add for who this story is","well_formed","no_role","high",False
25450,"Packaging s from being packaged that are not used.",NULL,"Packaging s from being packaged that are not used.",NULL,"Add for who this story is","well_formed","no_role","high",False
25449,"RabbitMessageBus should prefix all created queues with a prefix in order to support HA To configure Rabbit HA a naming convention should be used to identify the queue that need to be mirrored. ",NULL,"RabbitMessageBus should prefix all created queues with a prefix","in order to support HA To configure Rabbit HA a naming convention should be used to identify the queue that need to be mirrored.","Add for who this story is","well_formed","no_role","high",False
25449,"RabbitMessageBus should prefix all created queues with a prefix in order to support HA To configure Rabbit HA a naming convention should be used to identify the queue that need to be mirrored. ",NULL,"RabbitMessageBus should prefix all created queues with a prefix","in order to support HA To configure Rabbit HA a naming convention should be used to identify the queue that need to be mirrored.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25456,"CLI needs to be setup to use the updated acceptance test structure This change has to be facilitated because of the XD 1456 and XD 1455 stories.",NULL,"CLI needs to be setup to use the updated acceptance test structure This change has to be facilitated because of the XD 1456 and XD 1455 stories.",NULL,"Add for who this story is","well_formed","no_role","high",False
25451,"Update hdfs sink docs Options that are not covered codec idleTimeout inUsePrefix inUseSuffix inputType overwrite Options Renamed filename is now fileName",NULL,"Update hdfs sink docs Options that are not covered codec idleTimeout inUsePrefix inUseSuffix inputType overwrite Options Renamed filename is now fileName",NULL,"Add for who this story is","well_formed","no_role","high",False
25454,"Fail fast admin server if admin s embedded tomcat couldn t start During admin server startup, if it fails due to embedded tomcat failure, then the admin server instance still up and running. Since its tomcat isn t running it can not handle any REST client requests. In this scenario, we need fail fast the admin server process itself with better error message.",NULL,"Fail fast admin server if admin s embedded tomcat couldn t start During admin server startup, if it fails due to embedded tomcat failure, then the admin server instance still up and running. Since its tomcat isn t running it can not handle any REST client requests. In this scenario, we need fail fast the admin server process itself with better error message.",NULL,"Add for who this story is","well_formed","no_role","high",False
25454,"Fail fast admin server if admin s embedded tomcat couldn t start During admin server startup, if it fails due to embedded tomcat failure, then the admin server instance still up and running. Since its tomcat isn t running it can not handle any REST client requests. In this scenario, we need fail fast the admin server process itself with better error message.",NULL,"Fail fast admin server if admin s embedded tomcat couldn t start During admin server startup, if it fails due to embedded tomcat failure, then the admin server instance still up and running. Since its tomcat isn t running it can not handle any REST client requests. In this scenario, we need fail fast the admin server process itself with better error message.",NULL,"Fail fast admin server if admin s embedded tomcat couldn t start During admin server startup, if it fails due to embedded tomcat failure, then the admin server instance still up<span class='highlight-text severity-high'> and </span>running. Since its tomcat isn t running it can not handle any REST client requests. In this scenario, we need fail fast the admin server process itself with better error message.","atomic","conjunctions","high",False
25454,"Fail fast admin server if admin s embedded tomcat couldn t start During admin server startup, if it fails due to embedded tomcat failure, then the admin server instance still up and running. Since its tomcat isn t running it can not handle any REST client requests. In this scenario, we need fail fast the admin server process itself with better error message.",NULL,"Fail fast admin server if admin s embedded tomcat couldn t start During admin server startup, if it fails due to embedded tomcat failure, then the admin server instance still up and running. Since its tomcat isn t running it can not handle any REST client requests. In this scenario, we need fail fast the admin server process itself with better error message.",NULL,"Fail fast admin server if admin s embedded tomcat couldn t start During admin server startup, if it fails due to embedded tomcat failure, then the admin server instance still up and running<span class='highlight-text severity-high'>. Since its tomcat isn t running it can not handle any REST client requests. In this scenario, we need fail fast the admin server process itself with better error message.</span>","minimal","punctuation","high",False
25452,"Update Spring Integration Version to 4.0.0.RELEASE ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25452,"Update Spring Integration Version to 4.0.0.RELEASE ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25453,"Validate processing modules declare the required channels Validate that modules have required channels declared according to their type. Currently the stream deployer accepts processors with no input, but the stream doesn t complete. We should fail earlier and more loudly.",NULL,"Validate processing modules declare the required channels Validate that modules have required channels declared according to their type. Currently the stream deployer accepts processors with no input, but the stream doesn t complete. We should fail earlier and more loudly.",NULL,"Add for who this story is","well_formed","no_role","high",False
25453,"Validate processing modules declare the required channels Validate that modules have required channels declared according to their type. Currently the stream deployer accepts processors with no input, but the stream doesn t complete. We should fail earlier and more loudly.",NULL,"Validate processing modules declare the required channels Validate that modules have required channels declared according to their type. Currently the stream deployer accepts processors with no input, but the stream doesn t complete. We should fail earlier and more loudly.",NULL,"Validate processing modules declare the required channels Validate that modules have required channels declared according to their type<span class='highlight-text severity-high'>. Currently the stream deployer accepts processors with no input, but the stream doesn t complete. We should fail earlier and more loudly.</span>","minimal","punctuation","high",False
25458,"Add Zookeeper distribution in the download zip This will reduce one extra step for getting started using XD in distributed mode out of the box ",NULL,"Add Zookeeper distribution in the download zip This will reduce one extra step for getting started using XD in distributed mode out of the box ",NULL,"Add for who this story is","well_formed","no_role","high",False
25459,"Fix package tangles Sonar build is currently failing.",NULL,"Fix package tangles Sonar build is currently failing.",NULL,"Add for who this story is","well_formed","no_role","high",False
25460,"Tests are failing due to change in JMX endpoint data Need to update the Jackson parser.",NULL,"Tests are failing due to change in JMX endpoint data Need to update the Jackson parser.",NULL,"Add for who this story is","well_formed","no_role","high",False
25461,"Add Steams page to show job triggers The streams page needs to be added to the UI at least to show the job triggers that are created while scheduling XD jobs.",NULL,"Add Steams page to show job triggers The streams page needs to be added to the UI at least to show the job triggers that are created while scheduling XD jobs.",NULL,"Add for who this story is","well_formed","no_role","high",False
25462,"Modularize angular app modules based on the functionality When adding streams page to the UI from XD 1667 , it is necessary to modularize the angular app modules based on the job, stream, auth etc., . As we expand into more components and use cases in the UI, this definitely makes it easier to concentrate on specific modules based on the functionality.",NULL,"Modularize angular app modules based on the functionality When adding streams page to the UI from XD 1667 , it is necessary to modularize the angular app modules based on the job, stream, auth etc., . As we expand into more components and use cases in the UI, this definitely makes it easier to concentrate on specific modules based on the functionality.",NULL,"Add for who this story is","well_formed","no_role","high",False
25462,"Modularize angular app modules based on the functionality When adding streams page to the UI from XD 1667 , it is necessary to modularize the angular app modules based on the job, stream, auth etc., . As we expand into more components and use cases in the UI, this definitely makes it easier to concentrate on specific modules based on the functionality.",NULL,"Modularize angular app modules based on the functionality When adding streams page to the UI from XD 1667 , it is necessary to modularize the angular app modules based on the job, stream, auth etc., . As we expand into more components and use cases in the UI, this definitely makes it easier to concentrate on specific modules based on the functionality.",NULL,"Modularize angular app modules based on the functionality When adding streams page to the UI from XD 1667 , it is necessary to modularize the angular app modules based on the job, stream, auth etc., . As we expand into more components<span class='highlight-text severity-high'> and </span>use cases in the UI, this definitely makes it easier to concentrate on specific modules based on the functionality.","atomic","conjunctions","high",False
25462,"Modularize angular app modules based on the functionality When adding streams page to the UI from XD 1667 , it is necessary to modularize the angular app modules based on the job, stream, auth etc., . As we expand into more components and use cases in the UI, this definitely makes it easier to concentrate on specific modules based on the functionality.",NULL,"Modularize angular app modules based on the functionality When adding streams page to the UI from XD 1667 , it is necessary to modularize the angular app modules based on the job, stream, auth etc., . As we expand into more components and use cases in the UI, this definitely makes it easier to concentrate on specific modules based on the functionality.",NULL,"Modularize angular app modules based on the functionality When adding streams page to the UI from XD 1667 , it is necessary to modularize the angular app modules based on the job, stream, auth etc<span class='highlight-text severity-high'>., . As we expand into more components and use cases in the UI, this definitely makes it easier to concentrate on specific modules based on the functionality.</span>","minimal","punctuation","high",False
25463,"Update Spring Batch Admin dependency to release version XD 1623 introduced the dependency to a SNAPSHOT version",NULL,"Update Spring Batch Admin dependency to release version XD 1623 introduced the dependency to a SNAPSHOT version",NULL,"Add for who this story is","well_formed","no_role","high",False
25464,"Script to generate reference documentation from wiki and include in .zip distribution ",NULL,"Script to generate reference documentation from wiki and include in .zip distribution ",NULL,"Add for who this story is","well_formed","no_role","high",False
25464,"Script to generate reference documentation from wiki and include in .zip distribution ",NULL,"Script to generate reference documentation from wiki and include in .zip distribution ",NULL,"Script to generate reference documentation from wiki<span class='highlight-text severity-high'> and </span>include in .zip distribution ","atomic","conjunctions","high",False
25465,"Add filepollhdfs Acceptance Tests ",NULL,"Add filepollhdfs Acceptance Tests ",NULL,"Add for who this story is","well_formed","no_role","high",False
25466,"Add log full message Property to the Log Sink Allows looking at message headers without turning on debugging.",NULL,"Add log full message Property to the Log Sink Allows looking at message headers without turning on debugging.",NULL,"Add for who this story is","well_formed","no_role","high",False
25467,"Remove L from Log4j PatternLayout The xd dirt log4j.properties includes the calling line number which is not recommended for production. ",NULL,"Remove L from Log4j PatternLayout The xd dirt log4j.properties includes the calling line number which is not recommended for production. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25468,"Decide on location to host http reference documentation and automate upload in build scripts ",NULL,"Decide on location to host http reference documentation and automate upload in build scripts ",NULL,"Add for who this story is","well_formed","no_role","high",False
25468,"Decide on location to host http reference documentation and automate upload in build scripts ",NULL,"Decide on location to host http reference documentation and automate upload in build scripts ",NULL,"Decide on location to host http reference documentation<span class='highlight-text severity-high'> and </span>automate upload in build scripts ","atomic","conjunctions","high",False
25469,"Test integration with jboss queue message I am new to Spring XD, I want to read the jboss queue message and then want to write it into text file by using stream create comment i.e stream create name TEST LOG definition jms file deploy . I am trying to configure the to invoke the jboss queue and read the queue message. Can you help me to do the configuration and resolve my objective?",NULL,"Test integration with jboss queue message I am new to Spring XD, I want to read the jboss queue message and then want to write it into text file by using stream create comment i.e stream create name TEST LOG definition jms file deploy . I am trying to configure the to invoke the jboss queue and read the queue message. Can you help me to do the configuration and resolve my objective?",NULL,"Add for who this story is","well_formed","no_role","high",False
25469,"Test integration with jboss queue message I am new to Spring XD, I want to read the jboss queue message and then want to write it into text file by using stream create comment i.e stream create name TEST LOG definition jms file deploy . I am trying to configure the to invoke the jboss queue and read the queue message. Can you help me to do the configuration and resolve my objective?",NULL,"Test integration with jboss queue message I am new to Spring XD, I want to read the jboss queue message and then want to write it into text file by using stream create comment i.e stream create name TEST LOG definition jms file deploy . I am trying to configure the to invoke the jboss queue and read the queue message. Can you help me to do the configuration and resolve my objective?",NULL,"Test integration with jboss queue message I am new to Spring XD, I want to read the jboss queue message<span class='highlight-text severity-high'> and </span>then want to write it into text file by using stream create comment i.e stream create name TEST LOG definition jms file deploy . I am trying to configure the to invoke the jboss queue and read the queue message. Can you help me to do the configuration and resolve my objective?","atomic","conjunctions","high",False
25469,"Test integration with jboss queue message I am new to Spring XD, I want to read the jboss queue message and then want to write it into text file by using stream create comment i.e stream create name TEST LOG definition jms file deploy . I am trying to configure the to invoke the jboss queue and read the queue message. Can you help me to do the configuration and resolve my objective?",NULL,"Test integration with jboss queue message I am new to Spring XD, I want to read the jboss queue message and then want to write it into text file by using stream create comment i.e stream create name TEST LOG definition jms file deploy . I am trying to configure the to invoke the jboss queue and read the queue message. Can you help me to do the configuration and resolve my objective?",NULL,"Test integration with jboss queue message I am new to Spring XD, I want to read the jboss queue message and then want to write it into text file by using stream create comment i<span class='highlight-text severity-high'>.e stream create name TEST LOG definition jms file deploy . I am trying to configure the to invoke the jboss queue and read the queue message. Can you help me to do the configuration and resolve my objective?</span>","minimal","punctuation","high",False
25469,"Test integration with jboss queue message I am new to Spring XD, I want to read the jboss queue message and then want to write it into text file by using stream create comment i.e stream create name TEST LOG definition jms file deploy . I am trying to configure the to invoke the jboss queue and read the queue message. Can you help me to do the configuration and resolve my objective?",NULL,"Test integration with jboss queue message I am new to Spring XD, I want to read the jboss queue message and then want to write it into text file by using stream create comment i.e stream create name TEST LOG definition jms file deploy . I am trying to configure the to invoke the jboss queue and read the queue message. Can you help me to do the configuration and resolve my objective?",NULL,"Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25474,"Rabbit Sink Acceptance Tests ",NULL,"Rabbit Sink Acceptance Tests ",NULL,"Add for who this story is","well_formed","no_role","high",False
25473,"Enable Job deployment properties for job deploy Support the ability to provide deployment properties for job deploy .",NULL,"Enable Job deployment properties for job deploy Support the ability to provide deployment properties for job deploy .",NULL,"Add for who this story is","well_formed","no_role","high",False
25477,"Disable auto formatting of JavaDoc ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25477,"Disable auto formatting of JavaDoc ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26663,"Create a abstract base class for rest controllers ",NULL,"Create a abstract base class for rest controllers ",NULL,"Add for who this story is","well_formed","no_role","high",False
25475,"Reactor based websocket ingestion ",NULL,"Reactor based websocket ingestion ",NULL,"Add for who this story is","well_formed","no_role","high",False
25478,"Remove Hadoop from admin classpath Not sure why the Hadoop classes are on the admin servers classpath. There is no way to select the distro, and the Hadoop classes shouldn t be needed except for module info for hdfs sink see XD 1701 ",NULL,"Remove Hadoop from admin classpath Not sure why the Hadoop classes are on the admin servers classpath. There is no way to select the distro, and the Hadoop classes shouldn t be needed except for module info for hdfs sink see XD 1701 ",NULL,"Add for who this story is","well_formed","no_role","high",False
25478,"Remove Hadoop from admin classpath Not sure why the Hadoop classes are on the admin servers classpath. There is no way to select the distro, and the Hadoop classes shouldn t be needed except for module info for hdfs sink see XD 1701 ",NULL,"Remove Hadoop from admin classpath Not sure why the Hadoop classes are on the admin servers classpath. There is no way to select the distro, and the Hadoop classes shouldn t be needed except for module info for hdfs sink see XD 1701 ",NULL,"Remove Hadoop from admin classpath Not sure why the Hadoop classes are on the admin servers classpath. There is no way to select the distro,<span class='highlight-text severity-high'> and </span>the Hadoop classes shouldn t be needed except for module info for hdfs sink see XD 1701 ","atomic","conjunctions","high",False
25478,"Remove Hadoop from admin classpath Not sure why the Hadoop classes are on the admin servers classpath. There is no way to select the distro, and the Hadoop classes shouldn t be needed except for module info for hdfs sink see XD 1701 ",NULL,"Remove Hadoop from admin classpath Not sure why the Hadoop classes are on the admin servers classpath. There is no way to select the distro, and the Hadoop classes shouldn t be needed except for module info for hdfs sink see XD 1701 ",NULL,"Remove Hadoop from admin classpath Not sure why the Hadoop classes are on the admin servers classpath<span class='highlight-text severity-high'>. There is no way to select the distro, and the Hadoop classes shouldn t be needed except for module info for hdfs sink see XD 1701 </span>","minimal","punctuation","high",False
26662,"Document queue channel capacity configurable when using local transport ",NULL,"Document queue channel capacity configurable when using local transport ",NULL,"Add for who this story is","well_formed","no_role","high",False
25471,"Add UI screen shots to docs for new features in Alpha JobScheduler Stream page Job definition XD1615 ",NULL,"Add UI screen shots to docs for new features in Alpha JobScheduler Stream page Job definition XD1615 ",NULL,"Add for who this story is","well_formed","no_role","high",False
25472,"XD to the classpath to resolve this.",NULL,"XD to the classpath to resolve this.",NULL,"Add for who this story is","well_formed","no_role","high",False
25476,"Home wiki page improvements Add more structure, more easily find the reference guide. The style that is here is nice. ",NULL,"Home wiki page improvements Add more structure, more easily find the reference guide. The style that is here is nice. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25476,"Home wiki page improvements Add more structure, more easily find the reference guide. The style that is here is nice. ",NULL,"Home wiki page improvements Add more structure, more easily find the reference guide. The style that is here is nice. ",NULL,"Home wiki page improvements Add more structure, more easily find the reference guide<span class='highlight-text severity-high'>. The style that is here is nice. </span>","minimal","punctuation","high",False
25481,"Add entry for phd20, cdh5 and hdp21 Each Hadoop distro uses different settings for and we should provide some starting points for the distros we support running XD on YARN for. We should add a commented out stub entry for phd20, cdh5 and hdp21 to replace the one for hadoop22 when someone deploys on these distros. ",NULL,"Add entry for phd20, cdh5 and hdp21 Each Hadoop distro uses different settings for and we should provide some starting points for the distros we support running XD on YARN for. We should add a commented out stub entry for phd20, cdh5 and hdp21 to replace the one for hadoop22 when someone deploys on these distros. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25481,"Add entry for phd20, cdh5 and hdp21 Each Hadoop distro uses different settings for and we should provide some starting points for the distros we support running XD on YARN for. We should add a commented out stub entry for phd20, cdh5 and hdp21 to replace the one for hadoop22 when someone deploys on these distros. ",NULL,"Add entry for phd20, cdh5 and hdp21 Each Hadoop distro uses different settings for and we should provide some starting points for the distros we support running XD on YARN for. We should add a commented out stub entry for phd20, cdh5 and hdp21 to replace the one for hadoop22 when someone deploys on these distros. ",NULL,"Add entry for phd20, cdh5<span class='highlight-text severity-high'> and </span>hdp21 Each Hadoop distro uses different settings for and we should provide some starting points for the distros we support running XD on YARN for. We should add a commented out stub entry for phd20, cdh5 and hdp21 to replace the one for hadoop22 when someone deploys on these distros. ","atomic","conjunctions","high",False
25546,"Job execution display to show job status With XD 1311, the job execution list shows the status of the associated job. We need to show the same information for a given job execution.",NULL,"Job execution display to show job status With XD 1311, the job execution list shows the status of the associated job. We need to show the same information for a given job execution.",NULL,"Add for who this story is","well_formed","no_role","high",False
25604,"Anchor the footer at the bottom of page ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25481,"Add entry for phd20, cdh5 and hdp21 Each Hadoop distro uses different settings for and we should provide some starting points for the distros we support running XD on YARN for. We should add a commented out stub entry for phd20, cdh5 and hdp21 to replace the one for hadoop22 when someone deploys on these distros. ",NULL,"Add entry for phd20, cdh5 and hdp21 Each Hadoop distro uses different settings for and we should provide some starting points for the distros we support running XD on YARN for. We should add a commented out stub entry for phd20, cdh5 and hdp21 to replace the one for hadoop22 when someone deploys on these distros. ",NULL,"Add entry for phd20, cdh5 and hdp21 Each Hadoop distro uses different settings for and we should provide some starting points for the distros we support running XD on YARN for<span class='highlight-text severity-high'>. We should add a commented out stub entry for phd20, cdh5 and hdp21 to replace the one for hadoop22 when someone deploys on these distros. </span>","minimal","punctuation","high",False
25480,"Create doc section about quotes handling Document the different onion layers that come in play with regard to quoting and escaping shell, xd parser, SpEL expressions in some cases and provide practical examples to common scenarios ",NULL,"Create doc section about quotes handling Document the different onion layers that come in play with regard to quoting and escaping shell, xd parser, SpEL expressions in some cases and provide practical examples to common scenarios ",NULL,"Add for who this story is","well_formed","no_role","high",False
25480,"Create doc section about quotes handling Document the different onion layers that come in play with regard to quoting and escaping shell, xd parser, SpEL expressions in some cases and provide practical examples to common scenarios ",NULL,"Create doc section about quotes handling Document the different onion layers that come in play with regard to quoting and escaping shell, xd parser, SpEL expressions in some cases and provide practical examples to common scenarios ",NULL,"Create doc section about quotes handling Document the different onion layers that come in play with regard to quoting<span class='highlight-text severity-high'> and </span>escaping shell, xd parser, SpEL expressions in some cases and provide practical examples to common scenarios ","atomic","conjunctions","high",False
25483,"needs to use http as its test source Also check the JMX output to see that the filter rejected the entry.",NULL,"needs to use http as its test source Also check the JMX output to see that the filter rejected the entry.",NULL,"Add for who this story is","well_formed","no_role","high",False
25482,"Create project home page for SpringXD on A minimal project page of a top level project page that has basic information of docs and links to the github wiki page. No need to list maven coordinates.",NULL,"Create project home page for SpringXD on A minimal project page of a top level project page that has basic information of docs and links to the github wiki page. No need to list maven coordinates.",NULL,"Add for who this story is","well_formed","no_role","high",False
25482,"Create project home page for SpringXD on A minimal project page of a top level project page that has basic information of docs and links to the github wiki page. No need to list maven coordinates.",NULL,"Create project home page for SpringXD on A minimal project page of a top level project page that has basic information of docs and links to the github wiki page. No need to list maven coordinates.",NULL,"Create project home page for SpringXD on A minimal project page of a top level project page that has basic information of docs and links to the github wiki page<span class='highlight-text severity-high'>. No need to list maven coordinates.</span>","minimal","punctuation","high",False
25486,"Twitter Search test uses case sensitive search when it should be case insensitive. The TwitterSearch does a case insensitive search. Tests need to do a insensitive check for the keywords in the search result.",NULL,"Twitter Search test uses case sensitive search when it should be case insensitive. The TwitterSearch does a case insensitive search. Tests need to do a insensitive check for the keywords in the search result.",NULL,"Add for who this story is","well_formed","no_role","high",False
25486,"Twitter Search test uses case sensitive search when it should be case insensitive. The TwitterSearch does a case insensitive search. Tests need to do a insensitive check for the keywords in the search result.",NULL,"Twitter Search test uses case sensitive search when it should be case insensitive. The TwitterSearch does a case insensitive search. Tests need to do a insensitive check for the keywords in the search result.",NULL,"Twitter Search test uses case sensitive search when it should be case insensitive<span class='highlight-text severity-high'>. The TwitterSearch does a case insensitive search. Tests need to do a insensitive check for the keywords in the search result.</span>","minimal","punctuation","high",False
25484,"StreamUtil Cleanup Update StreamUtils based on Code Review comments.",NULL,"StreamUtil Cleanup Update StreamUtils based on Code Review comments.",NULL,"Add for who this story is","well_formed","no_role","high",False
25488,"Document OOTB available that are available to users come to mind, there may be others",NULL,"Document OOTB available that are available to users come to mind, there may be others",NULL,"Add for who this story is","well_formed","no_role","high",False
25487,"Create links to SpringXD on other pages of springsource.org site bottom home page list of projects data integration category landing pages related projects. ",NULL,"Create links to SpringXD on other pages of springsource.org site bottom home page list of projects data integration category landing pages related projects. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25490,"Add Stream Job destroy option at the UI Add an option to destroy the stream job definitions. Also add confirm action that asks for user to confirm to proceed with destroy.",NULL,"Add Stream Job destroy option at the UI Add an option to destroy the stream job definitions. Also add confirm action that asks for user to confirm to proceed with destroy.",NULL,"Add for who this story is","well_formed","no_role","high",False
25490,"Add Stream Job destroy option at the UI Add an option to destroy the stream job definitions. Also add confirm action that asks for user to confirm to proceed with destroy.",NULL,"Add Stream Job destroy option at the UI Add an option to destroy the stream job definitions. Also add confirm action that asks for user to confirm to proceed with destroy.",NULL,"Add Stream Job destroy option at the UI Add an option to destroy the stream job definitions<span class='highlight-text severity-high'>. Also add confirm action that asks for user to confirm to proceed with destroy.</span>","minimal","punctuation","high",False
25489,"Add a test for inside the DSL definition of a stream ",NULL,"Add a test for inside the DSL definition of a stream ",NULL,"Add for who this story is","well_formed","no_role","high",False
25494,"Support for UUID suffix for hdfs file names in acceptance tests ",NULL,"Support for UUID suffix for hdfs file names in acceptance tests ",NULL,"Add for who this story is","well_formed","no_role","high",False
25491,"Add Support for Bold Strong Fonts Hitting this issue in Chrome Looks like Chrome has some issues with making text bold if the font does not explicitly support it. ",NULL,"Add Support for Bold Strong Fonts Hitting this issue in Chrome Looks like Chrome has some issues with making text bold if the font does not explicitly support it. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25493,"Document how to create a custom input output module for existing SI channel adapters Document how to take an existing input output channel adapters in spring integration and add them as a XD source sink module. Should be as end user focused, step by step guide as possible. Consider including a getting started gradle pom.xml ",NULL,"Document how to create a custom input output module for existing SI channel adapters Document how to take an existing input output channel adapters in spring integration and add them as a XD source sink module. Should be as end user focused, step by step guide as possible. Consider including a getting started gradle pom.xml ",NULL,"Add for who this story is","well_formed","no_role","high",False
25493,"Document how to create a custom input output module for existing SI channel adapters Document how to take an existing input output channel adapters in spring integration and add them as a XD source sink module. Should be as end user focused, step by step guide as possible. Consider including a getting started gradle pom.xml ",NULL,"Document how to create a custom input output module for existing SI channel adapters Document how to take an existing input output channel adapters in spring integration and add them as a XD source sink module. Should be as end user focused, step by step guide as possible. Consider including a getting started gradle pom.xml ",NULL,"Document how to create a custom input output module for existing SI channel adapters Document how to take an existing input output channel adapters in spring integration<span class='highlight-text severity-high'> and </span>add them as a XD source sink module. Should be as end user focused, step by step guide as possible. Consider including a getting started gradle pom.xml ","atomic","conjunctions","high",False
25493,"Document how to create a custom input output module for existing SI channel adapters Document how to take an existing input output channel adapters in spring integration and add them as a XD source sink module. Should be as end user focused, step by step guide as possible. Consider including a getting started gradle pom.xml ",NULL,"Document how to create a custom input output module for existing SI channel adapters Document how to take an existing input output channel adapters in spring integration and add them as a XD source sink module. Should be as end user focused, step by step guide as possible. Consider including a getting started gradle pom.xml ",NULL,"Document how to create a custom input output module for existing SI channel adapters Document how to take an existing input output channel adapters in spring integration and add them as a XD source sink module<span class='highlight-text severity-high'>. Should be as end user focused, step by step guide as possible. Consider including a getting started gradle pom.xml </span>","minimal","punctuation","high",False
25497,"Document how to create a custom processor module. The use case is to write custom code that does processing on a specific domain class perhaps from twitter adapter or a tuple. Need to package up this code so that it can be used inside XD. ",NULL,"Document how to create a custom processor module. The use case is to write custom code that does processing on a specific domain class perhaps from twitter adapter or a tuple. Need to package up this code","so that it can be used inside XD.","Add for who this story is","well_formed","no_role","high",False
25497,"Document how to create a custom processor module. The use case is to write custom code that does processing on a specific domain class perhaps from twitter adapter or a tuple. Need to package up this code so that it can be used inside XD. ",NULL,"Document how to create a custom processor module. The use case is to write custom code that does processing on a specific domain class perhaps from twitter adapter or a tuple. Need to package up this code","so that it can be used inside XD.","Document how to create a custom processor module<span class='highlight-text severity-high'>. The use case is to write custom code that does processing on a specific domain class perhaps from twitter adapter or a tuple. Need to package up this code so that it can be used inside XD. </span>","minimal","punctuation","high",False
25497,"Document how to create a custom processor module. The use case is to write custom code that does processing on a specific domain class perhaps from twitter adapter or a tuple. Need to package up this code so that it can be used inside XD. ",NULL,"Document how to create a custom processor module. The use case is to write custom code that does processing on a specific domain class perhaps from twitter adapter or a tuple. Need to package up this code","so that it can be used inside XD.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25499,"Update CI server to run tests that depend on rabbit redis and hadoop ",NULL,"Update CI server to run tests that depend on rabbit redis and hadoop ",NULL,"Add for who this story is","well_formed","no_role","high",False
25498,"ZooKeeper Admin server node data to have admin server host address It would be useful to store admin server ip address in ZooKeeper leadership group node to identify admin server and it s admin port. ",NULL,"ZooKeeper Admin server node data to have admin server host address It would be useful to store admin server ip address in ZooKeeper leadership group node to identify admin server and it s admin port. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25498,"ZooKeeper Admin server node data to have admin server host address It would be useful to store admin server ip address in ZooKeeper leadership group node to identify admin server and it s admin port. ",NULL,"ZooKeeper Admin server node data to have admin server host address It would be useful to store admin server ip address in ZooKeeper leadership group node to identify admin server and it s admin port. ",NULL,"ZooKeeper Admin server node data to have admin server host address It would be useful to store admin server ip address in ZooKeeper leadership group node to identify admin server<span class='highlight-text severity-high'> and </span>it s admin port. ","atomic","conjunctions","high",False
25485,"Show visual representation of stream in admin UI ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25485,"Show visual representation of stream in admin UI ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25492,"Update dependencies in Spring XD Sample Repository ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25492,"Update dependencies in Spring XD Sample Repository ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25496,"Improve JMX checks for processors taking into account error channels ",NULL,"Improve JMX checks for processors taking into account error channels ",NULL,"Add for who this story is","well_formed","no_role","high",False
25495,"Remove dependency on Sprint Boot in xd dirt tests ",NULL,"Remove dependency on Sprint Boot in xd dirt tests ",NULL,"Add for who this story is","well_formed","no_role","high",False
25506,"Update spring data hadoop version to 2.0.0.RC4 Update spring data hadoop version to 2.0.0.RC4 and make necessary changes to the YARN configuration.",NULL,"Update spring data hadoop version to 2.0.0.RC4 Update spring data hadoop version to 2.0.0.RC4 and make necessary changes to the YARN configuration.",NULL,"Add for who this story is","well_formed","no_role","high",False
25506,"Update spring data hadoop version to 2.0.0.RC4 Update spring data hadoop version to 2.0.0.RC4 and make necessary changes to the YARN configuration.",NULL,"Update spring data hadoop version to 2.0.0.RC4 Update spring data hadoop version to 2.0.0.RC4 and make necessary changes to the YARN configuration.",NULL,"Update spring data hadoop version to 2.0.0.RC4 Update spring data hadoop version to 2.0.0.RC4<span class='highlight-text severity-high'> and </span>make necessary changes to the YARN configuration.","atomic","conjunctions","high",False
25510,"Documentation for enhanced HDFS sink with paths based off content ",NULL,"Documentation for enhanced HDFS sink with paths based off content ",NULL,"Add for who this story is","well_formed","no_role","high",False
25507,"Support exponential moving average in RichGauge This could easily be supported in the existing gauge by adding a setAlpha method to RichGaugeService and adding the extra parameter alpha to the gauge data If not set it would default to the current behaviour simple mean , otherwise it would calculate the exponential moving average in place of the mean.",NULL,"Support exponential moving average in RichGauge This could easily be supported in the existing gauge by adding a setAlpha method to RichGaugeService and adding the extra parameter alpha to the gauge data If not set it would default to the current behaviour simple mean , otherwise it would calculate the exponential moving average in place of the mean.",NULL,"Add for who this story is","well_formed","no_role","high",False
25507,"Support exponential moving average in RichGauge This could easily be supported in the existing gauge by adding a setAlpha method to RichGaugeService and adding the extra parameter alpha to the gauge data If not set it would default to the current behaviour simple mean , otherwise it would calculate the exponential moving average in place of the mean.",NULL,"Support exponential moving average in RichGauge This could easily be supported in the existing gauge by adding a setAlpha method to RichGaugeService and adding the extra parameter alpha to the gauge data If not set it would default to the current behaviour simple mean , otherwise it would calculate the exponential moving average in place of the mean.",NULL,"Support exponential moving average in RichGauge This could easily be supported in the existing gauge by adding a setAlpha method to RichGaugeService<span class='highlight-text severity-high'> and </span>adding the extra parameter alpha to the gauge data If not set it would default to the current behaviour simple mean , otherwise it would calculate the exponential moving average in place of the mean.","atomic","conjunctions","high",False
25508,"Documentation for data partitioning, and all Rabbit Bus properties ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25508,"Documentation for data partitioning, and all Rabbit Bus properties ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25509,"Update to Spring Batch 3.0 RELEASE ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25509,"Update to Spring Batch 3.0 RELEASE ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25512,"JobExecution restart action should depend on job deployment status At the JobExecution page, if the job execution is failed and restartable, then we should enable the restart action only if the job is deployed. Please see for the discussion related to this.",NULL,"JobExecution restart action should depend on job deployment status At the JobExecution page, if the job execution is failed and restartable, then we should enable the restart action only if the job is deployed. Please see for the discussion related to this.",NULL,"Add for who this story is","well_formed","no_role","high",False
25512,"JobExecution restart action should depend on job deployment status At the JobExecution page, if the job execution is failed and restartable, then we should enable the restart action only if the job is deployed. Please see for the discussion related to this.",NULL,"JobExecution restart action should depend on job deployment status At the JobExecution page, if the job execution is failed and restartable, then we should enable the restart action only if the job is deployed. Please see for the discussion related to this.",NULL,"JobExecution restart action should depend on job deployment status At the JobExecution page, if the job execution is failed<span class='highlight-text severity-high'> and </span>restartable, then we should enable the restart action only if the job is deployed. Please see for the discussion related to this.","atomic","conjunctions","high",False
25567,"Integration test for and aggregate counter use and aggregate counter. Should do a simplified version of this so that we can assert values of the and aggregate counter.",NULL,NULL,"so that we can assert values of the and aggregate counter.","Add for who this story is","well_formed","no_role","high",False
25512,"JobExecution restart action should depend on job deployment status At the JobExecution page, if the job execution is failed and restartable, then we should enable the restart action only if the job is deployed. Please see for the discussion related to this.",NULL,"JobExecution restart action should depend on job deployment status At the JobExecution page, if the job execution is failed and restartable, then we should enable the restart action only if the job is deployed. Please see for the discussion related to this.",NULL,"JobExecution restart action should depend on job deployment status At the JobExecution page, if the job execution is failed and restartable, then we should enable the restart action only if the job is deployed<span class='highlight-text severity-high'>. Please see for the discussion related to this.</span>","minimal","punctuation","high",False
25513,"User should be able to specify deploy properties for Jobs When clicking deploy from the job definitions page, user should be able to specify the deployment manifest module count, module criteria etc., ",NULL,"User should be able to specify deploy properties for Jobs When clicking deploy from the job definitions page, user should be able to specify the deployment manifest module count, module criteria etc., ",NULL,"Add for who this story is","well_formed","no_role","high",False
25515,"Update twitterSearchTest to handle the latest release of twitterSearch The changes to twitterSearch means that it will send multiple messages during the duration of the test. To support these changes 1 Remove assertReceived. Since the number of messages is indeterminate 2 Change file sink that captures the results to append mode. Because each message will overwrite the previous messages result.",NULL,"Update twitterSearchTest to handle the latest release of twitterSearch The changes to twitterSearch means that it will send multiple messages during the duration of the test. To support these changes 1 Remove assertReceived. Since the number of messages is indeterminate 2 Change file sink that captures the results to append mode. Because each message will overwrite the previous messages result.",NULL,"Add for who this story is","well_formed","no_role","high",False
25515,"Update twitterSearchTest to handle the latest release of twitterSearch The changes to twitterSearch means that it will send multiple messages during the duration of the test. To support these changes 1 Remove assertReceived. Since the number of messages is indeterminate 2 Change file sink that captures the results to append mode. Because each message will overwrite the previous messages result.",NULL,"Update twitterSearchTest to handle the latest release of twitterSearch The changes to twitterSearch means that it will send multiple messages during the duration of the test. To support these changes 1 Remove assertReceived. Since the number of messages is indeterminate 2 Change file sink that captures the results to append mode. Because each message will overwrite the previous messages result.",NULL,"Update twitterSearchTest to handle the latest release of twitterSearch The changes to twitterSearch means that it will send multiple messages during the duration of the test<span class='highlight-text severity-high'>. To support these changes 1 Remove assertReceived. Since the number of messages is indeterminate 2 Change file sink that captures the results to append mode. Because each message will overwrite the previous messages result.</span>","minimal","punctuation","high",False
25518,"Check job restartable flag for JobExecution restart action job create bogus definition jdbchdfs sql select from bogus job deploy bogus job launch bogus click Restart Job Execution on the failed job execution get message Job was relaunched container log has 12 36 27,231 ERROR task scheduler 10 JobInstance already exists and is not restartable",NULL,"Check job restartable flag for JobExecution restart action job create bogus definition jdbchdfs sql select from bogus job deploy bogus job launch bogus click Restart Job Execution on the failed job execution get message Job was relaunched container log has 12 36 27,231 ERROR task scheduler 10 JobInstance already exists and is not restartable",NULL,"Add for who this story is","well_formed","no_role","high",False
25518,"Check job restartable flag for JobExecution restart action job create bogus definition jdbchdfs sql select from bogus job deploy bogus job launch bogus click Restart Job Execution on the failed job execution get message Job was relaunched container log has 12 36 27,231 ERROR task scheduler 10 JobInstance already exists and is not restartable",NULL,"Check job restartable flag for JobExecution restart action job create bogus definition jdbchdfs sql select from bogus job deploy bogus job launch bogus click Restart Job Execution on the failed job execution get message Job was relaunched container log has 12 36 27,231 ERROR task scheduler 10 JobInstance already exists and is not restartable",NULL,"Check job restartable flag for JobExecution restart action job create bogus definition jdbchdfs sql select from bogus job deploy bogus job launch bogus click Restart Job Execution on the failed job execution get message Job was relaunched container log has 12 36 27,231 ERROR task scheduler 10 JobInstance already exists<span class='highlight-text severity-high'> and </span>is not restartable","atomic","conjunctions","high",False
25516,"Upgrade Curator to 2.5.0 ",NULL,"Upgrade Curator to 2.5.0 ",NULL,"Add for who this story is","well_formed","no_role","high",False
25504,"Change default date formats to be yyyy MM dd We have some places where we us a default data format specified as In Spring for Apache Hadoop we use yyyy MM dd for partitioning path expressions. This seems more in line with ISO standard date format. For consistency we should have both SHDP and XD use the same default format.",NULL,"Change default date formats to be yyyy MM dd We have some places where we us a default data format specified as In Spring for Apache Hadoop we use yyyy MM dd for partitioning path expressions. This seems more in line with ISO standard date format. For consistency we should have both SHDP and XD use the same default format.",NULL,"Add for who this story is","well_formed","no_role","high",False
25504,"Change default date formats to be yyyy MM dd We have some places where we us a default data format specified as In Spring for Apache Hadoop we use yyyy MM dd for partitioning path expressions. This seems more in line with ISO standard date format. For consistency we should have both SHDP and XD use the same default format.",NULL,"Change default date formats to be yyyy MM dd We have some places where we us a default data format specified as In Spring for Apache Hadoop we use yyyy MM dd for partitioning path expressions. This seems more in line with ISO standard date format. For consistency we should have both SHDP and XD use the same default format.",NULL,"Change default date formats to be yyyy MM dd We have some places where we us a default data format specified as In Spring for Apache Hadoop we use yyyy MM dd for partitioning path expressions. This seems more in line with ISO standard date format. For consistency we should have both SHDP<span class='highlight-text severity-high'> and </span>XD use the same default format.","atomic","conjunctions","high",False
25504,"Change default date formats to be yyyy MM dd We have some places where we us a default data format specified as In Spring for Apache Hadoop we use yyyy MM dd for partitioning path expressions. This seems more in line with ISO standard date format. For consistency we should have both SHDP and XD use the same default format.",NULL,"Change default date formats to be yyyy MM dd We have some places where we us a default data format specified as In Spring for Apache Hadoop we use yyyy MM dd for partitioning path expressions. This seems more in line with ISO standard date format. For consistency we should have both SHDP and XD use the same default format.",NULL,"Change default date formats to be yyyy MM dd We have some places where we us a default data format specified as In Spring for Apache Hadoop we use yyyy MM dd for partitioning path expressions<span class='highlight-text severity-high'>. This seems more in line with ISO standard date format. For consistency we should have both SHDP and XD use the same default format.</span>","minimal","punctuation","high",False
25502,"Create and document a syslog aggregation example 2 3 containers separate processes that the stream syslog tcp 1 container separate process that aggregates the data sent from those conainers, tcp severityFilter hdfs ",NULL,"Create and document a syslog aggregation example 2 3 containers separate processes that the stream syslog tcp 1 container separate process that aggregates the data sent from those conainers, tcp severityFilter hdfs ",NULL,"Add for who this story is","well_formed","no_role","high",False
25502,"Create and document a syslog aggregation example 2 3 containers separate processes that the stream syslog tcp 1 container separate process that aggregates the data sent from those conainers, tcp severityFilter hdfs ",NULL,"Create and document a syslog aggregation example 2 3 containers separate processes that the stream syslog tcp 1 container separate process that aggregates the data sent from those conainers, tcp severityFilter hdfs ",NULL,"Create<span class='highlight-text severity-high'> and </span>document a syslog aggregation example 2 3 containers separate processes that the stream syslog tcp 1 container separate process that aggregates the data sent from those conainers, tcp severityFilter hdfs ","atomic","conjunctions","high",False
25505,"gemfire source does not offer host nor port options ",NULL,"gemfire source does not offer host nor port options ",NULL,"Add for who this story is","well_formed","no_role","high",False
25514,"User should be able to provide job deployment properties At the job definitions page, user should be able to provide the job deployment manifest module count, criteria etc., ",NULL,"User should be able to provide job deployment properties At the job definitions page, user should be able to provide the job deployment manifest module count, criteria etc., ",NULL,"Add for who this story is","well_formed","no_role","high",False
25511,"Update documentation to list supported Hadoop distributions After spring hadoop 2.0 RC4 update.",NULL,"Update documentation to list supported Hadoop distributions After spring hadoop 2.0 RC4 update.",NULL,"Add for who this story is","well_formed","no_role","high",False
25517,"UI Automatically close notification messages Automatically close notification messages Polish UI",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25517,"UI Automatically close notification messages Automatically close notification messages Polish UI",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25530,"Paging support for repositories Add paging support for the appropriate accessor methods in repositories",NULL,"Paging support for repositories Add paging support for the appropriate accessor methods in repositories",NULL,"Add for who this story is","well_formed","no_role","high",False
25529,"Add Eclipse target to EC2 build.gradle. So that the code format matches that of the XD Project.",NULL,"Add Eclipse target to EC2 build.gradle.","So that the code format matches that of the XD Project.","Add for who this story is","well_formed","no_role","high",False
25529,"Add Eclipse target to EC2 build.gradle. So that the code format matches that of the XD Project.",NULL,"Add Eclipse target to EC2 build.gradle.","So that the code format matches that of the XD Project.","Add Eclipse target to EC2 build<span class='highlight-text severity-high'>.gradle. So that the code format matches that of the XD Project.</span>","minimal","punctuation","high",False
25529,"Add Eclipse target to EC2 build.gradle. So that the code format matches that of the XD Project.",NULL,"Add Eclipse target to EC2 build.gradle.","So that the code format matches that of the XD Project.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25533,"Add with custom modules location If someone wants to have a dedicated location module registry for the custom modules and can be accessed from any Spring supported resource URL location, then we need to support. Currently, we use Delegating ModuleRegistry which uses implementations that look for location xd.module.home and Maybe we can add an additional with and use it for custom modules.",NULL,"Add with custom modules location If someone wants to have a dedicated location module registry for the custom modules and can be accessed from any Spring supported resource URL location, then we need to support. Currently, we use Delegating ModuleRegistry which uses implementations that look for location xd.module.home and Maybe we can add an additional with and use it for custom modules.",NULL,"Add for who this story is","well_formed","no_role","high",False
25533,"Add with custom modules location If someone wants to have a dedicated location module registry for the custom modules and can be accessed from any Spring supported resource URL location, then we need to support. Currently, we use Delegating ModuleRegistry which uses implementations that look for location xd.module.home and Maybe we can add an additional with and use it for custom modules.",NULL,"Add with custom modules location If someone wants to have a dedicated location module registry for the custom modules and can be accessed from any Spring supported resource URL location, then we need to support. Currently, we use Delegating ModuleRegistry which uses implementations that look for location xd.module.home and Maybe we can add an additional with and use it for custom modules.",NULL,"Add with custom modules location If someone wants to have a dedicated location module registry for the custom modules<span class='highlight-text severity-high'> and </span>can be accessed from any Spring supported resource URL location, then we need to support. Currently, we use Delegating ModuleRegistry which uses implementations that look for location xd.module.home and Maybe we can add an additional with and use it for custom modules.","atomic","conjunctions","high",False
25533,"Add with custom modules location If someone wants to have a dedicated location module registry for the custom modules and can be accessed from any Spring supported resource URL location, then we need to support. Currently, we use Delegating ModuleRegistry which uses implementations that look for location xd.module.home and Maybe we can add an additional with and use it for custom modules.",NULL,"Add with custom modules location If someone wants to have a dedicated location module registry for the custom modules and can be accessed from any Spring supported resource URL location, then we need to support. Currently, we use Delegating ModuleRegistry which uses implementations that look for location xd.module.home and Maybe we can add an additional with and use it for custom modules.",NULL,"Add with custom modules location If someone wants to have a dedicated location module registry for the custom modules and can be accessed from any Spring supported resource URL location, then we need to support<span class='highlight-text severity-high'>. Currently, we use Delegating ModuleRegistry which uses implementations that look for location xd.module.home and Maybe we can add an additional with and use it for custom modules.</span>","minimal","punctuation","high",False
25532,"Improve E2E Test Coverage ",NULL,"Improve E2E Test Coverage ",NULL,"Add for who this story is","well_formed","no_role","high",False
25534,"Support Bus Producer Properties for Dynamic Producers Pass module properties from stream plugin to . Disallow partitioning properties.",NULL,"Support Bus Producer Properties for Dynamic Producers Pass module properties from stream plugin to . Disallow partitioning properties.",NULL,"Add for who this story is","well_formed","no_role","high",False
25534,"Support Bus Producer Properties for Dynamic Producers Pass module properties from stream plugin to . Disallow partitioning properties.",NULL,"Support Bus Producer Properties for Dynamic Producers Pass module properties from stream plugin to . Disallow partitioning properties.",NULL,"Support Bus Producer Properties for Dynamic Producers Pass module properties from stream plugin to <span class='highlight-text severity-high'>. Disallow partitioning properties.</span>","minimal","punctuation","high",False
25535,"Upgrade to Spring Boot 1.1 SNAPSHOT ",NULL,"Upgrade to Spring Boot 1.1 SNAPSHOT ",NULL,"Add for who this story is","well_formed","no_role","high",False
25538,"Provide DSL completion after a some channel prefix ",NULL,"Provide DSL completion after a some channel prefix ",NULL,"Add for who this story is","well_formed","no_role","high",False
25536,"Acceptance Tests for Labels and taps ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25536,"Acceptance Tests for Labels and taps ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25537,"Generate asciidoc doc from module options Generate asciidoc fragments for each module s options, this way it is always up to date.",NULL,"Generate asciidoc doc from module options Generate asciidoc fragments for each module s options, this way it is always up to date.",NULL,"Add for who this story is","well_formed","no_role","high",False
25540,"Create redisProtocol.xml that will load all the Redis specific implementations to suppor the XD container runtime and administration The redis specific beans that are defined in the current launcher.xml should move into this configuration file. ",NULL,"Create redisProtocol.xml that will load all the Redis specific implementations to suppor the XD container runtime and administration The redis specific beans that are defined in the current launcher.xml should move into this configuration file. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25540,"Create redisProtocol.xml that will load all the Redis specific implementations to suppor the XD container runtime and administration The redis specific beans that are defined in the current launcher.xml should move into this configuration file. ",NULL,"Create redisProtocol.xml that will load all the Redis specific implementations to suppor the XD container runtime and administration The redis specific beans that are defined in the current launcher.xml should move into this configuration file. ",NULL,"Create redisProtocol.xml that will load all the Redis specific implementations to suppor the XD container runtime<span class='highlight-text severity-high'> and </span>administration The redis specific beans that are defined in the current launcher.xml should move into this configuration file. ","atomic","conjunctions","high",False
25539,"Investigate increased size of XD distribution. ",NULL,"Investigate increased size of XD distribution. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25543,"Create that will load all the SI specific implementations to suppor the XD container runtime and administration ",NULL,"Create that will load all the SI specific implementations to suppor the XD container runtime and administration ",NULL,"Add for who this story is","well_formed","no_role","high",False
25541,"Combine Distributed job locator related schema changes into one table Currently, there are and tables and we can possibly combine them into one table and have a better schema for this.",NULL,"Combine Distributed job locator related schema changes into one table Currently, there are and tables and we can possibly combine them into one table and have a better schema for this.",NULL,"Add for who this story is","well_formed","no_role","high",False
25541,"Combine Distributed job locator related schema changes into one table Currently, there are and tables and we can possibly combine them into one table and have a better schema for this.",NULL,"Combine Distributed job locator related schema changes into one table Currently, there are and tables and we can possibly combine them into one table and have a better schema for this.",NULL,"Combine Distributed job locator related schema changes into one table Currently, there are<span class='highlight-text severity-high'> and </span>tables and we can possibly combine them into one table and have a better schema for this.","atomic","conjunctions","high",False
25545,"Add single threaded executor service to This will eliminate any race conditions between deployments and containers joining leaving the cluster.",NULL,"Add single threaded executor service to This will eliminate any race conditions between deployments and containers joining leaving the cluster.",NULL,"Add for who this story is","well_formed","no_role","high",False
25603,"The no longer works. Change the object.",NULL,NULL,NULL,"The no longer works<span class='highlight-text severity-high'>. Change the object.</span>","minimal","punctuation","high",False
25546,"Job execution display to show job status With XD 1311, the job execution list shows the status of the associated job. We need to show the same information for a given job execution.",NULL,"Job execution display to show job status With XD 1311, the job execution list shows the status of the associated job. We need to show the same information for a given job execution.",NULL,"Job execution display to show job status With XD 1311, the job execution list shows the status of the associated job<span class='highlight-text severity-high'>. We need to show the same information for a given job execution.</span>","minimal","punctuation","high",False
25548,"Method for obtaining stream job state See the design document for more details. This class or perhaps a method on a repository? will need to query ZooKeeper to obtain the state of a stream job in order to pass it along to the REST controller.",NULL,"Method for obtaining stream job state See the design document for more details. This class or perhaps a method on a repository? will need to query ZooKeeper to obtain the state of a stream job","in order to pass it along to the REST controller.","Add for who this story is","well_formed","no_role","high",False
25548,"Method for obtaining stream job state See the design document for more details. This class or perhaps a method on a repository? will need to query ZooKeeper to obtain the state of a stream job in order to pass it along to the REST controller.",NULL,"Method for obtaining stream job state See the design document for more details. This class or perhaps a method on a repository? will need to query ZooKeeper to obtain the state of a stream job","in order to pass it along to the REST controller.","Method for obtaining stream job state See the design document for more details<span class='highlight-text severity-high'>. This class or perhaps a method on a repository? will need to query ZooKeeper to obtain the state of a stream job in order to pass it along to the REST controller.</span>","minimal","punctuation","high",False
25548,"Method for obtaining stream job state See the design document for more details. This class or perhaps a method on a repository? will need to query ZooKeeper to obtain the state of a stream job in order to pass it along to the REST controller.",NULL,"Method for obtaining stream job state See the design document for more details. This class or perhaps a method on a repository? will need to query ZooKeeper to obtain the state of a stream job","in order to pass it along to the REST controller.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25542,"Add Support for addresses Property on RabbitMQ Source Support receiving messages from an HA cluster.",NULL,"Add Support for addresses Property on RabbitMQ Source Support receiving messages from an HA cluster.",NULL,"Add for who this story is","well_formed","no_role","high",False
25528,"Support the ability to create module definitions in Groovy XML is currently required for module definitions. XD should also support Java Config and Groovy bean definitions and potentially, SI DSLs. ",NULL,"Support the ability to create module definitions in Groovy XML is currently required for module definitions. XD should also support Java Config and Groovy bean definitions and potentially, SI DSLs. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25528,"Support the ability to create module definitions in Groovy XML is currently required for module definitions. XD should also support Java Config and Groovy bean definitions and potentially, SI DSLs. ",NULL,"Support the ability to create module definitions in Groovy XML is currently required for module definitions. XD should also support Java Config and Groovy bean definitions and potentially, SI DSLs. ",NULL,"Support the ability to create module definitions in Groovy XML is currently required for module definitions<span class='highlight-text severity-high'>. XD should also support Java Config and Groovy bean definitions and potentially, SI DSLs. </span>","minimal","punctuation","high",False
25549,"Modify REST controller to obtain stream job state See the design document for more details. The REST controller needs to be modified to obtain stream job state once it is available in ZooKeeper. This depends on XD 1847.",NULL,"Modify REST controller to obtain stream job state See the design document for more details. The REST controller needs to be modified to obtain stream job state once it is available in ZooKeeper. This depends on XD 1847.",NULL,"Add for who this story is","well_formed","no_role","high",False
25549,"Modify REST controller to obtain stream job state See the design document for more details. The REST controller needs to be modified to obtain stream job state once it is available in ZooKeeper. This depends on XD 1847.",NULL,"Modify REST controller to obtain stream job state See the design document for more details. The REST controller needs to be modified to obtain stream job state once it is available in ZooKeeper. This depends on XD 1847.",NULL,"Modify REST controller to obtain stream job state See the design document for more details<span class='highlight-text severity-high'>. The REST controller needs to be modified to obtain stream job state once it is available in ZooKeeper. This depends on XD 1847.</span>","minimal","punctuation","high",False
25557,"Create a pipe protocol independent StreamDeployer Create StreamDeployer that does not depend on an adapter implementation",NULL,"Create a pipe protocol independent StreamDeployer Create StreamDeployer that does not depend on an adapter implementation",NULL,"Add for who this story is","well_formed","no_role","high",False
25558,"Create way to deploy custom modules for XD on YARN Need a way for end user to package and add custom modules scripts when deploying XD on YARN. Currently we have a zip file containing all code including modules. It s not convenient to un zip re zip this archive to add custom modules scripts. See ",NULL,"Create way to deploy custom modules for XD on YARN Need a way for end user to package and add custom modules scripts when deploying XD on YARN. Currently we have a zip file containing all code including modules. It s not convenient to un zip re zip this archive to add custom modules scripts. See ",NULL,"Add for who this story is","well_formed","no_role","high",False
25558,"Create way to deploy custom modules for XD on YARN Need a way for end user to package and add custom modules scripts when deploying XD on YARN. Currently we have a zip file containing all code including modules. It s not convenient to un zip re zip this archive to add custom modules scripts. See ",NULL,"Create way to deploy custom modules for XD on YARN Need a way for end user to package and add custom modules scripts when deploying XD on YARN. Currently we have a zip file containing all code including modules. It s not convenient to un zip re zip this archive to add custom modules scripts. See ",NULL,"Create way to deploy custom modules for XD on YARN Need a way for end user to package<span class='highlight-text severity-high'> and </span>add custom modules scripts when deploying XD on YARN. Currently we have a zip file containing all code including modules. It s not convenient to un zip re zip this archive to add custom modules scripts. See ","atomic","conjunctions","high",False
25558,"Create way to deploy custom modules for XD on YARN Need a way for end user to package and add custom modules scripts when deploying XD on YARN. Currently we have a zip file containing all code including modules. It s not convenient to un zip re zip this archive to add custom modules scripts. See ",NULL,"Create way to deploy custom modules for XD on YARN Need a way for end user to package and add custom modules scripts when deploying XD on YARN. Currently we have a zip file containing all code including modules. It s not convenient to un zip re zip this archive to add custom modules scripts. See ",NULL,"Create way to deploy custom modules for XD on YARN Need a way for end user to package and add custom modules scripts when deploying XD on YARN<span class='highlight-text severity-high'>. Currently we have a zip file containing all code including modules. It s not convenient to un zip re zip this archive to add custom modules scripts. See </span>","minimal","punctuation","high",False
25559,"Create XD script for xd single node This script will launch XD admin along with the module container. As part of this implementation, we will also remove the embedded options for XD admin container scripts.",NULL,"Create XD script for xd single node This script will launch XD admin along with the module container. As part of this implementation, we will also remove the embedded options for XD admin container scripts.",NULL,"Add for who this story is","well_formed","no_role","high",False
25559,"Create XD script for xd single node This script will launch XD admin along with the module container. As part of this implementation, we will also remove the embedded options for XD admin container scripts.",NULL,"Create XD script for xd single node This script will launch XD admin along with the module container. As part of this implementation, we will also remove the embedded options for XD admin container scripts.",NULL,"Create XD script for xd single node This script will launch XD admin along with the module container<span class='highlight-text severity-high'>. As part of this implementation, we will also remove the embedded options for XD admin container scripts.</span>","minimal","punctuation","high",False
25560,"Create documentation for Batch DB migration Update documentation related to database migration with the changes from XD 1822",NULL,"Create documentation for Batch DB migration Update documentation related to database migration with the changes from XD 1822",NULL,"Add for who this story is","well_formed","no_role","high",False
25561,"Document json to tuple, object to json and http client Note that the documentation for the module options in particular for http client should be autogenerated using the following syntax see others ",NULL,"Document json to tuple, object to json and http client Note that the documentation for the module options in particular for http client should be autogenerated using the following syntax see others ",NULL,"Add for who this story is","well_formed","no_role","high",False
25562,"Create test that uses jsonPath with the filter module The script tests does the following. Filter for good and bad create stream httpfilter http good filter aftergood filter expression true bad filter goodandbad splitter file dir TEST DIR true ",NULL,"Create test that uses jsonPath with the filter module The script tests does the following. Filter for good and bad create stream httpfilter http good filter aftergood filter expression true bad filter goodandbad splitter file dir TEST DIR true ",NULL,"Add for who this story is","well_formed","no_role","high",False
25562,"Create test that uses jsonPath with the filter module The script tests does the following. Filter for good and bad create stream httpfilter http good filter aftergood filter expression true bad filter goodandbad splitter file dir TEST DIR true ",NULL,"Create test that uses jsonPath with the filter module The script tests does the following. Filter for good and bad create stream httpfilter http good filter aftergood filter expression true bad filter goodandbad splitter file dir TEST DIR true ",NULL,"Create test that uses jsonPath with the filter module The script tests does the following. Filter for good<span class='highlight-text severity-high'> and </span>bad create stream httpfilter http good filter aftergood filter expression true bad filter goodandbad splitter file dir TEST DIR true ","atomic","conjunctions","high",False
25562,"Create test that uses jsonPath with the filter module The script tests does the following. Filter for good and bad create stream httpfilter http good filter aftergood filter expression true bad filter goodandbad splitter file dir TEST DIR true ",NULL,"Create test that uses jsonPath with the filter module The script tests does the following. Filter for good and bad create stream httpfilter http good filter aftergood filter expression true bad filter goodandbad splitter file dir TEST DIR true ",NULL,"Create test that uses jsonPath with the filter module The script tests does the following<span class='highlight-text severity-high'>. Filter for good and bad create stream httpfilter http good filter aftergood filter expression true bad filter goodandbad splitter file dir TEST DIR true </span>","minimal","punctuation","high",False
25563,"Create gemfire test Port Need to consider how to start the server, maybe use the jvm fork utilities? Look into as well.",NULL,"Create gemfire test Port Need to consider how to start the server, maybe use the jvm fork utilities? Look into as well.",NULL,"Add for who this story is","well_formed","no_role","high",False
25563,"Create gemfire test Port Need to consider how to start the server, maybe use the jvm fork utilities? Look into as well.",NULL,"Create gemfire test Port Need to consider how to start the server, maybe use the jvm fork utilities? Look into as well.",NULL,"Create gemfire test Port Need to consider how to start the server, maybe use the jvm fork utilities<span class='highlight-text severity-high'>? Look into as well.</span>","minimal","punctuation","high",False
25570,"Provide ability to disable tab completion for specific module options Not all module options are born equal. Some are more important useful than others, and having the more expert ones show up e.g. in TAB completion is very noisy esp. given how JLine2 currently presents the whole stream definition typed so far when doing completion, as opposed to just the last bit ",NULL,"Provide ability to disable tab completion for specific module options Not all module options are born equal.","Some are more important useful than others, and having the more expert ones show up e.g. in TAB completion is very noisy esp. given how JLine2 currently presents the whole stream definition typed so far when doing completion, as opposed to just the last bit","Add for who this story is","well_formed","no_role","high",False
25570,"Provide ability to disable tab completion for specific module options Not all module options are born equal. Some are more important useful than others, and having the more expert ones show up e.g. in TAB completion is very noisy esp. given how JLine2 currently presents the whole stream definition typed so far when doing completion, as opposed to just the last bit ",NULL,"Provide ability to disable tab completion for specific module options Not all module options are born equal.","Some are more important useful than others, and having the more expert ones show up e.g. in TAB completion is very noisy esp. given how JLine2 currently presents the whole stream definition typed so far when doing completion, as opposed to just the last bit","Provide ability to disable tab completion for specific module options Not all module options are born equal<span class='highlight-text severity-high'>. Some are more important useful than others, and having the more expert ones show up e.g. in TAB completion is very noisy esp. given how JLine2 currently presents the whole stream definition typed so far when doing completion, as opposed to just the last bit </span>","minimal","punctuation","high",False
25570,"Provide ability to disable tab completion for specific module options Not all module options are born equal. Some are more important useful than others, and having the more expert ones show up e.g. in TAB completion is very noisy esp. given how JLine2 currently presents the whole stream definition typed so far when doing completion, as opposed to just the last bit ",NULL,"Provide ability to disable tab completion for specific module options Not all module options are born equal.","Some are more important useful than others, and having the more expert ones show up e.g. in TAB completion is very noisy esp. given how JLine2 currently presents the whole stream definition typed so far when doing completion, as opposed to just the last bit","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25564,"Create low volume http stress test The test is very simple, it doesn t even check the results. A small change to so that number of messages to post is specified would be part of this work.",NULL,"Create low volume http stress test The test is very simple, it doesn t even check the results. A small change to","so that number of messages to post is specified would be part of this work.","Add for who this story is","well_formed","no_role","high",False
25564,"Create low volume http stress test The test is very simple, it doesn t even check the results. A small change to so that number of messages to post is specified would be part of this work.",NULL,"Create low volume http stress test The test is very simple, it doesn t even check the results. A small change to","so that number of messages to post is specified would be part of this work.","Create low volume http stress test The test is very simple, it doesn t even check the results<span class='highlight-text severity-high'>. A small change to so that number of messages to post is specified would be part of this work.</span>","minimal","punctuation","high",False
25564,"Create low volume http stress test The test is very simple, it doesn t even check the results. A small change to so that number of messages to post is specified would be part of this work.",NULL,"Create low volume http stress test The test is very simple, it doesn t even check the results. A small change to","so that number of messages to post is specified would be part of this work.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25565,"Create test with jdbc sink and initializeDb false See and The second assert has initializeDb false and so there are double the number of rows running the job a second time.",NULL,"Create test with jdbc sink and initializeDb false See and The second assert has initializeDb false and","so there are double the number of rows running the job a second time.","Add for who this story is","well_formed","no_role","high",False
25565,"Create test with jdbc sink and initializeDb false See and The second assert has initializeDb false and so there are double the number of rows running the job a second time.",NULL,"Create test with jdbc sink and initializeDb false See and The second assert has initializeDb false and","so there are double the number of rows running the job a second time.","Create test with jdbc sink<span class='highlight-text severity-high'> and </span>initializeDb false See and The second assert has initializeDb false and so there are double the number of rows running the job a second time.","atomic","conjunctions","high",False
25565,"Create test with jdbc sink and initializeDb false See and The second assert has initializeDb false and so there are double the number of rows running the job a second time.",NULL,"Create test with jdbc sink and initializeDb false See and The second assert has initializeDb false and","so there are double the number of rows running the job a second time.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25568,"fails when XD HOME ends with a Also, the approach may not work as expected on windows.",NULL,"fails when XD HOME ends with a Also, the approach may not work as expected on windows.",NULL,"Add for who this story is","well_formed","no_role","high",False
25571,"Update Netty to 4 Spring IO Compatibility",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25571,"Update Netty to 4 Spring IO Compatibility",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25573,"Create multi container, single host, testing framework Use external JVM launch support provided by the Oracle Tools framework ",NULL,"Create multi container, single host, testing framework Use external JVM launch support provided by the Oracle Tools framework ",NULL,"Add for who this story is","well_formed","no_role","high",False
25569,"Module option validation not happening anymore It seems that no option validation being Spring or jsr 303 is happening anymore at stream creation time. eg stream create foo definition http port bar log ",NULL,"Module option validation not happening anymore It seems that no option validation being Spring or jsr 303 is happening anymore at stream creation time. eg stream create foo definition http port bar log ",NULL,"Add for who this story is","well_formed","no_role","high",False
25569,"Module option validation not happening anymore It seems that no option validation being Spring or jsr 303 is happening anymore at stream creation time. eg stream create foo definition http port bar log ",NULL,"Module option validation not happening anymore It seems that no option validation being Spring or jsr 303 is happening anymore at stream creation time. eg stream create foo definition http port bar log ",NULL,"Module option validation not happening anymore It seems that no option validation being Spring<span class='highlight-text severity-high'> or </span>jsr 303 is happening anymore at stream creation time. eg stream create foo definition http port bar log ","atomic","conjunctions","high",False
25569,"Module option validation not happening anymore It seems that no option validation being Spring or jsr 303 is happening anymore at stream creation time. eg stream create foo definition http port bar log ",NULL,"Module option validation not happening anymore It seems that no option validation being Spring or jsr 303 is happening anymore at stream creation time. eg stream create foo definition http port bar log ",NULL,"Module option validation not happening anymore It seems that no option validation being Spring or jsr 303 is happening anymore at stream creation time<span class='highlight-text severity-high'>. eg stream create foo definition http port bar log </span>","minimal","punctuation","high",False
25567,"Integration test for and aggregate counter use and aggregate counter. Should do a simplified version of this so that we can assert values of the and aggregate counter.",NULL,NULL,"so that we can assert values of the and aggregate counter.","Add what you want to achieve","well_formed","no_means","high",False
25567,"Integration test for and aggregate counter use and aggregate counter. Should do a simplified version of this so that we can assert values of the and aggregate counter.",NULL,NULL,"so that we can assert values of the and aggregate counter.","Integration test for and aggregate counter use and aggregate counter<span class='highlight-text severity-high'>. Should do a simplified version of this so that we can assert values of the and aggregate counter.</span>","minimal","punctuation","high",False
25567,"Integration test for and aggregate counter use and aggregate counter. Should do a simplified version of this so that we can assert values of the and aggregate counter.",NULL,NULL,"so that we can assert values of the and aggregate counter.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25572,"Investigate running XD on Cloud Foundry ",NULL,"Investigate running XD on Cloud Foundry ",NULL,"Add for who this story is","well_formed","no_role","high",False
25585,"Improve getting started docs for installation ",NULL,"Improve getting started docs for installation ",NULL,"Add for who this story is","well_formed","no_role","high",False
25583,"Update to Spring Shell 1.0 RC4 ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25583,"Update to Spring Shell 1.0 RC4 ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25584,"Move Redis connection metadata logging into the code closest to establishing that connection XD 106 included detailed logging about the Redis metadata within the but it seems as though that info could be logged somewhere closer to the establishment of a Redis connection for the XD runtime and could be logged even if this listener, whose main role is to capture Container related events, is not enabled .",NULL,"Move Redis connection metadata logging into the code closest to establishing that connection XD 106 included detailed logging about the Redis metadata within the but it seems as though that info could be logged somewhere closer to the establishment of a Redis connection for the XD runtime and could be logged even if this listener, whose main role is to capture Container related events, is not enabled .",NULL,"Add for who this story is","well_formed","no_role","high",False
25584,"Move Redis connection metadata logging into the code closest to establishing that connection XD 106 included detailed logging about the Redis metadata within the but it seems as though that info could be logged somewhere closer to the establishment of a Redis connection for the XD runtime and could be logged even if this listener, whose main role is to capture Container related events, is not enabled .",NULL,"Move Redis connection metadata logging into the code closest to establishing that connection XD 106 included detailed logging about the Redis metadata within the but it seems as though that info could be logged somewhere closer to the establishment of a Redis connection for the XD runtime and could be logged even if this listener, whose main role is to capture Container related events, is not enabled .",NULL,"Move Redis connection metadata logging into the code closest to establishing that connection XD 106 included detailed logging about the Redis metadata within the but it seems as though that info could be logged somewhere closer to the establishment of a Redis connection for the XD runtime<span class='highlight-text severity-high'> and </span>could be logged even if this listener, whose main role is to capture Container related events, is not enabled .","atomic","conjunctions","high",False
25587,"Update getting started documentation to use xd singlenode start script. With the new option of starting without requiring redis, the getting started documentation should reflect this easier way to start processing data.",NULL,"Update getting started documentation to use xd singlenode start script. With the new option of starting without requiring redis, the getting started documentation should reflect this easier way to start processing data.",NULL,"Add for who this story is","well_formed","no_role","high",False
25587,"Update getting started documentation to use xd singlenode start script. With the new option of starting without requiring redis, the getting started documentation should reflect this easier way to start processing data.",NULL,"Update getting started documentation to use xd singlenode start script. With the new option of starting without requiring redis, the getting started documentation should reflect this easier way to start processing data.",NULL,"Update getting started documentation to use xd singlenode start script<span class='highlight-text severity-high'>. With the new option of starting without requiring redis, the getting started documentation should reflect this easier way to start processing data.</span>","minimal","punctuation","high",False
25586,"Add Hadoop 2.4.x as an option Hadoop 2.4.1 is now a stable release and we should add support for running against it",NULL,"Add Hadoop 2.4.x as an option Hadoop 2.4.1 is now a stable release and we should add support for running against it",NULL,"Add for who this story is","well_formed","no_role","high",False
25586,"Add Hadoop 2.4.x as an option Hadoop 2.4.1 is now a stable release and we should add support for running against it",NULL,"Add Hadoop 2.4.x as an option Hadoop 2.4.1 is now a stable release and we should add support for running against it",NULL,"Add Hadoop 2.4.x as an option Hadoop 2.4.1 is now a stable release<span class='highlight-text severity-high'> and </span>we should add support for running against it","atomic","conjunctions","high",False
25588,"Update for new Release ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25588,"Update for new Release ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25589,"Find logging configuration relative to environment Previously, the scripts all looked for the logging configuration in XD HOME config or XD HOME config . This caused issues because it meant that if you moved all of the configuration and overrode or the logging configuration changes would not be found in the new location. This change updates the scripts to look for logging configuration in or ",NULL,"Find logging configuration relative to environment Previously, the scripts all looked for the logging configuration in XD HOME config or XD HOME config . This caused issues because it meant that if you moved all of the configuration and overrode or the logging configuration changes would not be found in the new location. This change updates the scripts to look for logging configuration in or ",NULL,"Add for who this story is","well_formed","no_role","high",False
25589,"Find logging configuration relative to environment Previously, the scripts all looked for the logging configuration in XD HOME config or XD HOME config . This caused issues because it meant that if you moved all of the configuration and overrode or the logging configuration changes would not be found in the new location. This change updates the scripts to look for logging configuration in or ",NULL,"Find logging configuration relative to environment Previously, the scripts all looked for the logging configuration in XD HOME config or XD HOME config . This caused issues because it meant that if you moved all of the configuration and overrode or the logging configuration changes would not be found in the new location. This change updates the scripts to look for logging configuration in or ",NULL,"Find logging configuration relative to environment Previously, the scripts all looked for the logging configuration in XD HOME config<span class='highlight-text severity-high'> or </span>XD HOME config . This caused issues because it meant that if you moved all of the configuration<span class='highlight-text severity-high'> and </span>overrode or the logging configuration changes would not be found in the new location. This change updates the scripts to look for logging configuration in or ","atomic","conjunctions","high",False
25589,"Find logging configuration relative to environment Previously, the scripts all looked for the logging configuration in XD HOME config or XD HOME config . This caused issues because it meant that if you moved all of the configuration and overrode or the logging configuration changes would not be found in the new location. This change updates the scripts to look for logging configuration in or ",NULL,"Find logging configuration relative to environment Previously, the scripts all looked for the logging configuration in XD HOME config or XD HOME config . This caused issues because it meant that if you moved all of the configuration and overrode or the logging configuration changes would not be found in the new location. This change updates the scripts to look for logging configuration in or ",NULL,"Find logging configuration relative to environment Previously, the scripts all looked for the logging configuration in XD HOME config or XD HOME config <span class='highlight-text severity-high'>. This caused issues because it meant that if you moved all of the configuration and overrode or the logging configuration changes would not be found in the new location. This change updates the scripts to look for logging configuration in or </span>","minimal","punctuation","high",False
25590,"Jolokia endpoints returning 404 for singlenode in M7 returned a value..... on master it returns 404 error... ",NULL,"Jolokia endpoints returning 404 for singlenode in M7 returned a value..... on master it returns 404 error... ",NULL,"Add for who this story is","well_formed","no_role","high",False
25590,"Jolokia endpoints returning 404 for singlenode in M7 returned a value..... on master it returns 404 error... ",NULL,"Jolokia endpoints returning 404 for singlenode in M7 returned a value..... on master it returns 404 error... ",NULL,"Jolokia endpoints returning 404 for singlenode in M7 returned a value<span class='highlight-text severity-high'>..... on master it returns 404 error... </span>","minimal","punctuation","high",False
25591,"Need more unique resource locations for XD internal configuration Currently internal config files are in META INF spring with fairly generic names. To avoid potential collisions if users add their own configuration in the classpath, we should have a more unique location, e.g. ",NULL,"Need more unique resource locations for XD internal configuration Currently internal config files are in META INF spring with fairly generic names. To avoid potential collisions if users add their own configuration in the classpath, we should have a more unique location, e.g. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25591,"Need more unique resource locations for XD internal configuration Currently internal config files are in META INF spring with fairly generic names. To avoid potential collisions if users add their own configuration in the classpath, we should have a more unique location, e.g. ",NULL,"Need more unique resource locations for XD internal configuration Currently internal config files are in META INF spring with fairly generic names. To avoid potential collisions if users add their own configuration in the classpath, we should have a more unique location, e.g. ",NULL,"Need more unique resource locations for XD internal configuration Currently internal config files are in META INF spring with fairly generic names<span class='highlight-text severity-high'>. To avoid potential collisions if users add their own configuration in the classpath, we should have a more unique location, e.g. </span>","minimal","punctuation","high",False
25592,"Verify platform compatibility versions with the XD dependencies We need to make sure there is no dependency with build.gradle using spring IO platform dependencies. is one such scenario where jolokia dependency went missing.",NULL,"Verify platform compatibility versions with the XD dependencies We need to make sure there is no dependency with build.gradle using spring IO platform dependencies. is one such scenario where jolokia dependency went missing.",NULL,"Add for who this story is","well_formed","no_role","high",False
25592,"Verify platform compatibility versions with the XD dependencies We need to make sure there is no dependency with build.gradle using spring IO platform dependencies. is one such scenario where jolokia dependency went missing.",NULL,"Verify platform compatibility versions with the XD dependencies We need to make sure there is no dependency with build.gradle using spring IO platform dependencies. is one such scenario where jolokia dependency went missing.",NULL,"Verify platform compatibility versions with the XD dependencies We need to make sure there is no dependency with build<span class='highlight-text severity-high'>.gradle using spring IO platform dependencies. is one such scenario where jolokia dependency went missing.</span>","minimal","punctuation","high",False
25593,"Remove jars from .zip packaging whose license prevents distribution The work here is doing the research.... should be removed as it is GPL GPL postgresql is BSD so that is ok another issue will handle license file inclusion.",NULL,"Remove jars from .zip packaging whose license prevents distribution The work here is doing the research.... should be removed as it is GPL GPL postgresql is BSD","so that is ok another issue will handle license file inclusion.","Add for who this story is","well_formed","no_role","high",False
25593,"Remove jars from .zip packaging whose license prevents distribution The work here is doing the research.... should be removed as it is GPL GPL postgresql is BSD so that is ok another issue will handle license file inclusion.",NULL,"Remove jars from .zip packaging whose license prevents distribution The work here is doing the research.... should be removed as it is GPL GPL postgresql is BSD","so that is ok another issue will handle license file inclusion.","Remove jars from <span class='highlight-text severity-high'>.zip packaging whose license prevents distribution The work here is doing the research.... should be removed as it is GPL GPL postgresql is BSD so that is ok another issue will handle license file inclusion.</span>","minimal","punctuation","high",False
25593,"Remove jars from .zip packaging whose license prevents distribution The work here is doing the research.... should be removed as it is GPL GPL postgresql is BSD so that is ok another issue will handle license file inclusion.",NULL,"Remove jars from .zip packaging whose license prevents distribution The work here is doing the research.... should be removed as it is GPL GPL postgresql is BSD","so that is ok another issue will handle license file inclusion.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25594,"Add licence files in distribution for 3rd party dependencies. postgresql is BSD ",NULL,"Add licence files in distribution for 3rd party dependencies. postgresql is BSD ",NULL,"Add for who this story is","well_formed","no_role","high",False
25594,"Add licence files in distribution for 3rd party dependencies. postgresql is BSD ",NULL,"Add licence files in distribution for 3rd party dependencies. postgresql is BSD ",NULL,"Add licence files in distribution for 3rd party dependencies<span class='highlight-text severity-high'>. postgresql is BSD </span>","minimal","punctuation","high",False
25598,"Use guava 15.0 for jclouds is not compatible with versions of guava higher than 15.",NULL,"Use guava 15.0 for jclouds is not compatible with versions of guava higher than 15.",NULL,"Add for who this story is","well_formed","no_role","high",False
25599,"Add stream state tests Test to verify stream state is correct after starting stopping containers.",NULL,"Add stream state tests Test to verify stream state is correct after starting stopping containers.",NULL,"Add for who this story is","well_formed","no_role","high",False
25600,"Fix support for See PR ",NULL,"Fix support for See PR ",NULL,"Add for who this story is","well_formed","no_role","high",False
25602,"Ensure DSM matrix is diagonal ",NULL,"Ensure DSM matrix is diagonal ",NULL,"Add for who this story is","well_formed","no_role","high",False
25601,"Build should use Spring Boot plugin version 1.1.4 The platform uses Boot version 1.1.4 so the plugin version used in build.gradle should match that.",NULL,"Build should use Spring Boot plugin version 1.1.4 The platform uses Boot version 1.1.4","so the plugin version used in build.gradle should match that.","Add for who this story is","well_formed","no_role","high",False
25601,"Build should use Spring Boot plugin version 1.1.4 The platform uses Boot version 1.1.4 so the plugin version used in build.gradle should match that.",NULL,"Build should use Spring Boot plugin version 1.1.4 The platform uses Boot version 1.1.4","so the plugin version used in build.gradle should match that.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25582,"Remove Retry from TCP Sink Now that the bus supports retry it is no longer necessary to have the retry advice in the TCP Sink.",NULL,"Remove Retry from TCP Sink Now that the bus supports retry it is no longer necessary to have the retry advice in the TCP Sink.",NULL,"Add for who this story is","well_formed","no_role","high",False
25597,"Clean s from the lib directory in spring xd yarn zip distribution",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25597,"Clean s from the lib directory in spring xd yarn zip distribution",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25595,"Update to Spring Batch Admin 1.3.0.RC1 ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25595,"Update to Spring Batch Admin 1.3.0.RC1 ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25596,"Users . and xml files in the modules dir, though that brings up the issue of classpath isolation.",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25596,"Users . and xml files in the modules dir, though that brings up the issue of classpath isolation.",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25596,"Users . and xml files in the modules dir, though that brings up the issue of classpath isolation.",NULL,NULL,NULL,"Users <span class='highlight-text severity-high'>. and xml files in the modules dir, though that brings up the issue of classpath isolation.</span>","minimal","punctuation","high",False
25603,"The no longer works. Change the object.",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25603,"The no longer works. Change the object.",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25604,"Anchor the footer at the bottom of page ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25606,"Remove copyright licence info in UI screens ",NULL,"Remove copyright licence info in UI screens ",NULL,"Add for who this story is","well_formed","no_role","high",False
25607,"replace the hacky parser with a good one Replace the existing DSL parser that uses string indexing with a more robust one based on a derivative of SpEL. This will provide a stable base on which to quickly iterate on syntax. ",NULL,"replace the hacky parser with a good one Replace the existing DSL parser that uses string indexing with a more robust one based on a derivative of SpEL. This will provide a stable base on which to quickly iterate on syntax. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25607,"replace the hacky parser with a good one Replace the existing DSL parser that uses string indexing with a more robust one based on a derivative of SpEL. This will provide a stable base on which to quickly iterate on syntax. ",NULL,"replace the hacky parser with a good one Replace the existing DSL parser that uses string indexing with a more robust one based on a derivative of SpEL. This will provide a stable base on which to quickly iterate on syntax. ",NULL,"replace the hacky parser with a good one Replace the existing DSL parser that uses string indexing with a more robust one based on a derivative of SpEL<span class='highlight-text severity-high'>. This will provide a stable base on which to quickly iterate on syntax. </span>","minimal","punctuation","high",False
25610,"StepExecutionInfo is missing from admin classpath in distributed mode. Following exception is thrown SEVERE Servlet.service for servlet in context with path threw exception Handler processing failed; nested exception is with root cause at at at Method at at at at at at at at Method at at at at ",NULL,"StepExecutionInfo is missing from admin classpath in distributed mode. Following exception is thrown SEVERE Servlet.service for servlet in context with path threw exception Handler processing failed; nested exception is with root cause at at at Method at at at at at at at at Method at at at at ",NULL,"Add for who this story is","well_formed","no_role","high",False
25610,"StepExecutionInfo is missing from admin classpath in distributed mode. Following exception is thrown SEVERE Servlet.service for servlet in context with path threw exception Handler processing failed; nested exception is with root cause at at at Method at at at at at at at at Method at at at at ",NULL,"StepExecutionInfo is missing from admin classpath in distributed mode. Following exception is thrown SEVERE Servlet.service for servlet in context with path threw exception Handler processing failed; nested exception is with root cause at at at Method at at at at at at at at Method at at at at ",NULL,"StepExecutionInfo is missing from admin classpath in distributed mode<span class='highlight-text severity-high'>. Following exception is thrown SEVERE Servlet.service for servlet in context with path threw exception Handler processing failed; nested exception is with root cause at at at Method at at at at at at at at Method at at at at </span>","minimal","punctuation","high",False
25613,"Name the TaskExecutors in the RabbitMessageBus The Rabbit by default. This makes it difficult to debug when multiple modules are in the same container because all threads are named .",NULL,"Name the TaskExecutors in the RabbitMessageBus The Rabbit by default. This makes it difficult to debug when multiple modules are in the same container because all threads are named .",NULL,"Add for who this story is","well_formed","no_role","high",False
25613,"Name the TaskExecutors in the RabbitMessageBus The Rabbit by default. This makes it difficult to debug when multiple modules are in the same container because all threads are named .",NULL,"Name the TaskExecutors in the RabbitMessageBus The Rabbit by default. This makes it difficult to debug when multiple modules are in the same container because all threads are named .",NULL,"Name the TaskExecutors in the RabbitMessageBus The Rabbit by default<span class='highlight-text severity-high'>. This makes it difficult to debug when multiple modules are in the same container because all threads are named .</span>","minimal","punctuation","high",False
25611,"Dependendcies s i the lib directory. That is no longer working and all distros seem to contain mostly the same version hadoop 2.2.0 dependencies This is the list for phd1 now ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25611,"Dependendcies s i the lib directory. That is no longer working and all distros seem to contain mostly the same version hadoop 2.2.0 dependencies This is the list for phd1 now ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25611,"Dependendcies s i the lib directory. That is no longer working and all distros seem to contain mostly the same version hadoop 2.2.0 dependencies This is the list for phd1 now ",NULL,NULL,NULL,"Dependendcies s i the lib directory<span class='highlight-text severity-high'>. That is no longer working and all distros seem to contain mostly the same version hadoop 2.2.0 dependencies This is the list for phd1 now </span>","minimal","punctuation","high",False
25615,"SSL Support For RabbitMQ Bus and Modules ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25615,"SSL Support For RabbitMQ Bus and Modules ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25616,"Automatically align version for tomcat components from platform introduces which is not covered by platform. Yet, we should lookup the version to use from other tomcat artifacts, using some gradle magic",NULL,"Automatically align version for tomcat components from platform introduces which is not covered by platform. Yet, we should lookup the version to use from other tomcat artifacts, using some gradle magic",NULL,"Add for who this story is","well_formed","no_role","high",False
25616,"Automatically align version for tomcat components from platform introduces which is not covered by platform. Yet, we should lookup the version to use from other tomcat artifacts, using some gradle magic",NULL,"Automatically align version for tomcat components from platform introduces which is not covered by platform. Yet, we should lookup the version to use from other tomcat artifacts, using some gradle magic",NULL,"Automatically align version for tomcat components from platform introduces which is not covered by platform<span class='highlight-text severity-high'>. Yet, we should lookup the version to use from other tomcat artifacts, using some gradle magic</span>","minimal","punctuation","high",False
25618,"Avoid all modules deploying to the first container instance upon system restart A possible approach is to set a configurable wait period when the first container arrives. If another container arrives during the wait period, reset the clock. When the wait period expires, start deploying modules. ",NULL,"Avoid all modules deploying to the first container instance upon system restart A possible approach is to set a configurable wait period when the first container arrives. If another container arrives during the wait period, reset the clock. When the wait period expires, start deploying modules. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25618,"Avoid all modules deploying to the first container instance upon system restart A possible approach is to set a configurable wait period when the first container arrives. If another container arrives during the wait period, reset the clock. When the wait period expires, start deploying modules. ",NULL,"Avoid all modules deploying to the first container instance upon system restart A possible approach is to set a configurable wait period when the first container arrives. If another container arrives during the wait period, reset the clock. When the wait period expires, start deploying modules. ",NULL,"Avoid all modules deploying to the first container instance upon system restart A possible approach is to set a configurable wait period when the first container arrives<span class='highlight-text severity-high'>. If another container arrives during the wait period, reset the clock. When the wait period expires, start deploying modules. </span>","minimal","punctuation","high",False
25620,"Error message about memory leak when ctrl c xd container and xd admin e.g., ^C09 42 00,882 ERROR The web application appears to have started a thread named but has failed to stop it. This is very likely to create a memory leak. The thread name may be different...",NULL,"Error message about memory leak when ctrl c xd container and xd admin e.g., ^C09 42 00,882 ERROR The web application appears to have started a thread named but has failed to stop it. This is very likely to create a memory leak. The thread name may be different...",NULL,"Add for who this story is","well_formed","no_role","high",False
25620,"Error message about memory leak when ctrl c xd container and xd admin e.g., ^C09 42 00,882 ERROR The web application appears to have started a thread named but has failed to stop it. This is very likely to create a memory leak. The thread name may be different...",NULL,"Error message about memory leak when ctrl c xd container and xd admin e.g., ^C09 42 00,882 ERROR The web application appears to have started a thread named but has failed to stop it. This is very likely to create a memory leak. The thread name may be different...",NULL,"Error message about memory leak when ctrl c xd container<span class='highlight-text severity-high'> and </span>xd admin e.g., ^C09 42 00,882 ERROR The web application appears to have started a thread named but has failed to stop it. This is very likely to create a memory leak. The thread name may be different...","atomic","conjunctions","high",False
25620,"Error message about memory leak when ctrl c xd container and xd admin e.g., ^C09 42 00,882 ERROR The web application appears to have started a thread named but has failed to stop it. This is very likely to create a memory leak. The thread name may be different...",NULL,"Error message about memory leak when ctrl c xd container and xd admin e.g., ^C09 42 00,882 ERROR The web application appears to have started a thread named but has failed to stop it. This is very likely to create a memory leak. The thread name may be different...",NULL,"Error message about memory leak when ctrl c xd container and xd admin e<span class='highlight-text severity-high'>.g., ^C09 42 00,882 ERROR The web application appears to have started a thread named but has failed to stop it. This is very likely to create a memory leak. The thread name may be different...</span>","minimal","punctuation","high",False
25619,"Add Docs or Reference For Standard Shell Commands e.g. script It is documented here But maybe it should also be at the top of the appendix? ",NULL,"Add Docs or Reference For Standard Shell Commands e.g. script It is documented here But maybe it should also be at the top of the appendix? ",NULL,"Add for who this story is","well_formed","no_role","high",False
25619,"Add Docs or Reference For Standard Shell Commands e.g. script It is documented here But maybe it should also be at the top of the appendix? ",NULL,"Add Docs or Reference For Standard Shell Commands e.g. script It is documented here But maybe it should also be at the top of the appendix? ",NULL,"Add Docs<span class='highlight-text severity-high'> or </span>Reference For Standard Shell Commands e.g. script It is documented here But maybe it should also be at the top of the appendix? ","atomic","conjunctions","high",False
25619,"Add Docs or Reference For Standard Shell Commands e.g. script It is documented here But maybe it should also be at the top of the appendix? ",NULL,"Add Docs or Reference For Standard Shell Commands e.g. script It is documented here But maybe it should also be at the top of the appendix? ",NULL,"Add Docs or Reference For Standard Shell Commands e<span class='highlight-text severity-high'>.g. script It is documented here But maybe it should also be at the top of the appendix? </span>","minimal","punctuation","high",False
25609,"Servers not finding logging file 12 30 43,930 WARN main Logging environment value cannot be opened and will be ignored There are extra slashes in there.... probably due to some recent changes related to xd config location in the scripts.",NULL,"Servers not finding logging file 12 30 43,930 WARN main Logging environment value cannot be opened and will be ignored There are extra slashes in there.... probably due to some recent changes related to xd config location in the scripts.",NULL,"Add for who this story is","well_formed","no_role","high",False
25609,"Servers not finding logging file 12 30 43,930 WARN main Logging environment value cannot be opened and will be ignored There are extra slashes in there.... probably due to some recent changes related to xd config location in the scripts.",NULL,"Servers not finding logging file 12 30 43,930 WARN main Logging environment value cannot be opened and will be ignored There are extra slashes in there.... probably due to some recent changes related to xd config location in the scripts.",NULL,"Servers not finding logging file 12 30 43,930 WARN main Logging environment value cannot be opened<span class='highlight-text severity-high'> and </span>will be ignored There are extra slashes in there.... probably due to some recent changes related to xd config location in the scripts.","atomic","conjunctions","high",False
25609,"Servers not finding logging file 12 30 43,930 WARN main Logging environment value cannot be opened and will be ignored There are extra slashes in there.... probably due to some recent changes related to xd config location in the scripts.",NULL,"Servers not finding logging file 12 30 43,930 WARN main Logging environment value cannot be opened and will be ignored There are extra slashes in there.... probably due to some recent changes related to xd config location in the scripts.",NULL,"Servers not finding logging file 12 30 43,930 WARN main Logging environment value cannot be opened and will be ignored There are extra slashes in there<span class='highlight-text severity-high'>.... probably due to some recent changes related to xd config location in the scripts.</span>","minimal","punctuation","high",False
25605,"Automate execution of gradle pushGeneratedDocs Should be part of the daily build. One easy way to do it would be to use the hardcoded authentication scheme as described here bamboo should mask a property whose name contains password We may want to create a dedicated github user though",NULL,"Automate execution of gradle pushGeneratedDocs Should be part of the daily build. One easy way to do it would be to use the hardcoded authentication scheme as described here bamboo should mask a property whose name contains password We may want to create a dedicated github user though",NULL,"Add for who this story is","well_formed","no_role","high",False
25605,"Automate execution of gradle pushGeneratedDocs Should be part of the daily build. One easy way to do it would be to use the hardcoded authentication scheme as described here bamboo should mask a property whose name contains password We may want to create a dedicated github user though",NULL,"Automate execution of gradle pushGeneratedDocs Should be part of the daily build. One easy way to do it would be to use the hardcoded authentication scheme as described here bamboo should mask a property whose name contains password We may want to create a dedicated github user though",NULL,"Automate execution of gradle pushGeneratedDocs Should be part of the daily build<span class='highlight-text severity-high'>. One easy way to do it would be to use the hardcoded authentication scheme as described here bamboo should mask a property whose name contains password We may want to create a dedicated github user though</span>","minimal","punctuation","high",False
25612,"Create a scriptProcessor module that allows the execution of a groovy potentially jruby,jython based SI Service Activator This will enable arbitrary processing logic to be used in a processing step. See ... script script lang groovy would be the essence of the module. Probably lang gets detected from the file extension.",NULL,"Create a scriptProcessor module that allows the execution of a groovy potentially jruby,jython based SI Service Activator This will enable arbitrary processing logic to be used in a processing step. See ... script script lang groovy would be the essence of the module. Probably lang gets detected from the file extension.",NULL,"Add for who this story is","well_formed","no_role","high",False
25612,"Create a scriptProcessor module that allows the execution of a groovy potentially jruby,jython based SI Service Activator This will enable arbitrary processing logic to be used in a processing step. See ... script script lang groovy would be the essence of the module. Probably lang gets detected from the file extension.",NULL,"Create a scriptProcessor module that allows the execution of a groovy potentially jruby,jython based SI Service Activator This will enable arbitrary processing logic to be used in a processing step. See ... script script lang groovy would be the essence of the module. Probably lang gets detected from the file extension.",NULL,"Create a scriptProcessor module that allows the execution of a groovy potentially jruby,jython based SI Service Activator This will enable arbitrary processing logic to be used in a processing step<span class='highlight-text severity-high'>. See ... script script lang groovy would be the essence of the module. Probably lang gets detected from the file extension.</span>","minimal","punctuation","high",False
25614,"Move button to top right The button is at lower left of the page which requires scrolling all the way to the bottom could we move it to top right? Would make clicking back and forth for job executions much easier.",NULL,"Move button to top right The button is at lower left of the page which requires scrolling all the way to the bottom could we move it to top right? Would make clicking back and forth for job executions much easier.",NULL,"Add for who this story is","well_formed","no_role","high",False
25614,"Move button to top right The button is at lower left of the page which requires scrolling all the way to the bottom could we move it to top right? Would make clicking back and forth for job executions much easier.",NULL,"Move button to top right The button is at lower left of the page which requires scrolling all the way to the bottom could we move it to top right? Would make clicking back and forth for job executions much easier.",NULL,"Move button to top right The button is at lower left of the page which requires scrolling all the way to the bottom could we move it to top right<span class='highlight-text severity-high'>? Would make clicking back and forth for job executions much easier.</span>","minimal","punctuation","high",False
25617,"Add Https Support to the HTTP Source ",NULL,"Add Https Support to the HTTP Source ",NULL,"Add for who this story is","well_formed","no_role","high",False
25623,"Remove unused post module references ",NULL,"Remove unused post module references ",NULL,"Add for who this story is","well_formed","no_role","high",False
25624,"HDFS Core writing helper classes Simple file writer that has existed in the spring hadoop samples.",NULL,"HDFS Core writing helper classes Simple file writer that has existed in the spring hadoop samples.",NULL,"Add for who this story is","well_formed","no_role","high",False
25625,"DIRT Runtime that deploys an application context across multiple nodes using redis. ",NULL,"DIRT Runtime that deploys an application context across multiple nodes using redis. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25626,"Rename packages that is applicable for both stream job Determine a better package name for the following packages once we have a common model that applies to both stream job ",NULL,"Rename packages that is applicable for both stream job Determine a better package name for the following packages once we have a common model that applies to both stream job ",NULL,"Add for who this story is","well_formed","no_role","high",False
25629,"Verify we meet all requirements to publish to maven central has a list of requirements. This also means that is critical to fix.",NULL,"Verify we meet all requirements to publish to maven central has a list of requirements. This also means that is critical to fix.",NULL,"Add for who this story is","well_formed","no_role","high",False
25679,"Add Cassandra sink As a user, I'd like to have the option of Cassandra sink, so I can leverage the NoSQL database to write high volumes of variable data segments in high velocity.",NULL,"Add Cassandra sink As a user, I'd like to have the option of Cassandra sink,","so I can leverage the NoSQL database to write high volumes of variable data segments in high velocity.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25629,"Verify we meet all requirements to publish to maven central has a list of requirements. This also means that is critical to fix.",NULL,"Verify we meet all requirements to publish to maven central has a list of requirements. This also means that is critical to fix.",NULL,"Verify we meet all requirements to publish to maven central has a list of requirements<span class='highlight-text severity-high'>. This also means that is critical to fix.</span>","minimal","punctuation","high",False
25627,"In from a http site and place it in lib xd. from the distribution, the CI tests could not start the XD instances on EC2 without it. It was suggested that we use the postgresql instead, but decided to continue the use of mysql for acceptance tests.",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25627,"In from a http site and place it in lib xd. from the distribution, the CI tests could not start the XD instances on EC2 without it. It was suggested that we use the postgresql instead, but decided to continue the use of mysql for acceptance tests.",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25627,"In from a http site and place it in lib xd. from the distribution, the CI tests could not start the XD instances on EC2 without it. It was suggested that we use the postgresql instead, but decided to continue the use of mysql for acceptance tests.",NULL,NULL,NULL,"In from a http site and place it in lib xd<span class='highlight-text severity-high'>. from the distribution, the CI tests could not start the XD instances on EC2 without it. It was suggested that we use the postgresql instead, but decided to continue the use of mysql for acceptance tests.</span>","minimal","punctuation","high",False
25628,"Acceptance test must be able to handle log names with PID suffix Introduced by XD 2006, admin and container logs will have a pid suffix appended to their filename. The acceptance tests will have to identify the PID for the admin server and the container servers deployed in the cluster and then append the pid value to the filename contained in the ",NULL,"Acceptance test must be able to handle log names with PID suffix Introduced by XD 2006, admin and container logs will have a pid suffix appended to their filename. The acceptance tests will have to identify the PID for the admin server and the container servers deployed in the cluster and then append the pid value to the filename contained in the ",NULL,"Add for who this story is","well_formed","no_role","high",False
25628,"Acceptance test must be able to handle log names with PID suffix Introduced by XD 2006, admin and container logs will have a pid suffix appended to their filename. The acceptance tests will have to identify the PID for the admin server and the container servers deployed in the cluster and then append the pid value to the filename contained in the ",NULL,"Acceptance test must be able to handle log names with PID suffix Introduced by XD 2006, admin and container logs will have a pid suffix appended to their filename. The acceptance tests will have to identify the PID for the admin server and the container servers deployed in the cluster and then append the pid value to the filename contained in the ",NULL,"Acceptance test must be able to handle log names with PID suffix Introduced by XD 2006, admin<span class='highlight-text severity-high'> and </span>container logs will have a pid suffix appended to their filename. The acceptance tests will have to identify the PID for the admin server and the container servers deployed in the cluster and then append the pid value to the filename contained in the ","atomic","conjunctions","high",False
25628,"Acceptance test must be able to handle log names with PID suffix Introduced by XD 2006, admin and container logs will have a pid suffix appended to their filename. The acceptance tests will have to identify the PID for the admin server and the container servers deployed in the cluster and then append the pid value to the filename contained in the ",NULL,"Acceptance test must be able to handle log names with PID suffix Introduced by XD 2006, admin and container logs will have a pid suffix appended to their filename. The acceptance tests will have to identify the PID for the admin server and the container servers deployed in the cluster and then append the pid value to the filename contained in the ",NULL,"Acceptance test must be able to handle log names with PID suffix Introduced by XD 2006, admin and container logs will have a pid suffix appended to their filename<span class='highlight-text severity-high'>. The acceptance tests will have to identify the PID for the admin server and the container servers deployed in the cluster and then append the pid value to the filename contained in the </span>","minimal","punctuation","high",False
25631,"Fix package info.java warnings ",NULL,"Fix package info.java warnings ",NULL,"Add for who this story is","well_formed","no_role","high",False
25630,"Cleanup Module Deployer Container s module deployer has some unused code and has listeners.xml which is no longer used. Also, all the extension code is moved to ",NULL,"Cleanup Module Deployer Container s module deployer has some unused code and has listeners.xml which is no longer used. Also, all the extension code is moved to ",NULL,"Add for who this story is","well_formed","no_role","high",False
25630,"Cleanup Module Deployer Container s module deployer has some unused code and has listeners.xml which is no longer used. Also, all the extension code is moved to ",NULL,"Cleanup Module Deployer Container s module deployer has some unused code and has listeners.xml which is no longer used. Also, all the extension code is moved to ",NULL,"Cleanup Module Deployer Container s module deployer has some unused code<span class='highlight-text severity-high'> and </span>has listeners.xml which is no longer used. Also, all the extension code is moved to ","atomic","conjunctions","high",False
25630,"Cleanup Module Deployer Container s module deployer has some unused code and has listeners.xml which is no longer used. Also, all the extension code is moved to ",NULL,"Cleanup Module Deployer Container s module deployer has some unused code and has listeners.xml which is no longer used. Also, all the extension code is moved to ",NULL,"Cleanup Module Deployer Container s module deployer has some unused code and has listeners<span class='highlight-text severity-high'>.xml which is no longer used. Also, all the extension code is moved to </span>","minimal","punctuation","high",False
25632,"Replace xd MongoItemWriter in hdfsmongodb with spring batch MongoItemWriter When hdfsmongodb was written Spring Batch did not have a MongoItemWriter available, so Mark wrote one for XD. The hdfsmongodb module now needs to be use Spring Batches MongoItemWriter.",NULL,"Replace xd MongoItemWriter in hdfsmongodb with spring batch MongoItemWriter When hdfsmongodb was written Spring Batch did not have a MongoItemWriter available,","so Mark wrote one for XD. The hdfsmongodb module now needs to be use Spring Batches MongoItemWriter.","Add for who this story is","well_formed","no_role","high",False
25632,"Replace xd MongoItemWriter in hdfsmongodb with spring batch MongoItemWriter When hdfsmongodb was written Spring Batch did not have a MongoItemWriter available, so Mark wrote one for XD. The hdfsmongodb module now needs to be use Spring Batches MongoItemWriter.",NULL,"Replace xd MongoItemWriter in hdfsmongodb with spring batch MongoItemWriter When hdfsmongodb was written Spring Batch did not have a MongoItemWriter available,","so Mark wrote one for XD. The hdfsmongodb module now needs to be use Spring Batches MongoItemWriter.","Replace xd MongoItemWriter in hdfsmongodb with spring batch MongoItemWriter When hdfsmongodb was written Spring Batch did not have a MongoItemWriter available, so Mark wrote one for XD<span class='highlight-text severity-high'>. The hdfsmongodb module now needs to be use Spring Batches MongoItemWriter.</span>","minimal","punctuation","high",False
25632,"Replace xd MongoItemWriter in hdfsmongodb with spring batch MongoItemWriter When hdfsmongodb was written Spring Batch did not have a MongoItemWriter available, so Mark wrote one for XD. The hdfsmongodb module now needs to be use Spring Batches MongoItemWriter.",NULL,"Replace xd MongoItemWriter in hdfsmongodb with spring batch MongoItemWriter When hdfsmongodb was written Spring Batch did not have a MongoItemWriter available,","so Mark wrote one for XD. The hdfsmongodb module now needs to be use Spring Batches MongoItemWriter.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25633,"Upgrade to Spring Shell 1.1 GA ",NULL,"Upgrade to Spring Shell 1.1 GA ",NULL,"Add for who this story is","well_formed","no_role","high",False
25634,"Update twittersearch module for Twitter 1.0 API retirement ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25634,"Update twittersearch module for Twitter 1.0 API retirement ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25636,"Handle random available http port for admin server If the XD admin server lets tomcat chooses random http port by setting PORT or server.port to 0 , the XD config logging and admin server context id still points to port zero as these are set before tomcat assigns the available random port. We also need to persist the admin servers ports into ZK so that this repo can be accessed by the client.",NULL,"Handle random available http port for admin server If the XD admin server lets tomcat chooses random http port by setting PORT or server.port to 0 , the XD config logging and admin server context id still points to port zero as these are set before tomcat assigns the available random port. We also need to persist the admin servers ports into ZK","so that this repo can be accessed by the client.","Add for who this story is","well_formed","no_role","high",False
25636,"Handle random available http port for admin server If the XD admin server lets tomcat chooses random http port by setting PORT or server.port to 0 , the XD config logging and admin server context id still points to port zero as these are set before tomcat assigns the available random port. We also need to persist the admin servers ports into ZK so that this repo can be accessed by the client.",NULL,"Handle random available http port for admin server If the XD admin server lets tomcat chooses random http port by setting PORT or server.port to 0 , the XD config logging and admin server context id still points to port zero as these are set before tomcat assigns the available random port. We also need to persist the admin servers ports into ZK","so that this repo can be accessed by the client.","Handle random available http port for admin server If the XD admin server lets tomcat chooses random http port by setting PORT<span class='highlight-text severity-high'> or </span>server.port to 0 , the XD config logging<span class='highlight-text severity-high'> and </span>admin server context id still points to port zero as these are set before tomcat assigns the available random port. We also need to persist the admin servers ports into ZK so that this repo can be accessed by the client.","atomic","conjunctions","high",False
25636,"Handle random available http port for admin server If the XD admin server lets tomcat chooses random http port by setting PORT or server.port to 0 , the XD config logging and admin server context id still points to port zero as these are set before tomcat assigns the available random port. We also need to persist the admin servers ports into ZK so that this repo can be accessed by the client.",NULL,"Handle random available http port for admin server If the XD admin server lets tomcat chooses random http port by setting PORT or server.port to 0 , the XD config logging and admin server context id still points to port zero as these are set before tomcat assigns the available random port. We also need to persist the admin servers ports into ZK","so that this repo can be accessed by the client.","Handle random available http port for admin server If the XD admin server lets tomcat chooses random http port by setting PORT or server<span class='highlight-text severity-high'>.port to 0 , the XD config logging and admin server context id still points to port zero as these are set before tomcat assigns the available random port. We also need to persist the admin servers ports into ZK so that this repo can be accessed by the client.</span>","minimal","punctuation","high",False
25636,"Handle random available http port for admin server If the XD admin server lets tomcat chooses random http port by setting PORT or server.port to 0 , the XD config logging and admin server context id still points to port zero as these are set before tomcat assigns the available random port. We also need to persist the admin servers ports into ZK so that this repo can be accessed by the client.",NULL,"Handle random available http port for admin server If the XD admin server lets tomcat chooses random http port by setting PORT or server.port to 0 , the XD config logging and admin server context id still points to port zero as these are set before tomcat assigns the available random port. We also need to persist the admin servers ports into ZK","so that this repo can be accessed by the client.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25637,"Add docs for Creating a job Item Processor should be very brief introduction to this topic, before linking to relevant spring batch documentation.",NULL,"Add docs for Creating a job Item Processor should be very brief introduction to this topic, before linking to relevant spring batch documentation.",NULL,"Add for who this story is","well_formed","no_role","high",False
25639,"Provided modules should be integration tested I don t see that we have automated tests for the modules we provide out of the box. We could make the modules folder an Eclipse project which would also help solve XD 198 and add some integration tests similar to those documented here ",NULL,"Provided modules should be integration tested I don t see that we have automated tests for the modules we provide out of the box. We could make the modules folder an Eclipse project which would also help solve XD 198 and add some integration tests similar to those documented here ",NULL,"Add for who this story is","well_formed","no_role","high",False
25639,"Provided modules should be integration tested I don t see that we have automated tests for the modules we provide out of the box. We could make the modules folder an Eclipse project which would also help solve XD 198 and add some integration tests similar to those documented here ",NULL,"Provided modules should be integration tested I don t see that we have automated tests for the modules we provide out of the box. We could make the modules folder an Eclipse project which would also help solve XD 198 and add some integration tests similar to those documented here ",NULL,"Provided modules should be integration tested I don t see that we have automated tests for the modules we provide out of the box. We could make the modules folder an Eclipse project which would also help solve XD 198<span class='highlight-text severity-high'> and </span>add some integration tests similar to those documented here ","atomic","conjunctions","high",False
25639,"Provided modules should be integration tested I don t see that we have automated tests for the modules we provide out of the box. We could make the modules folder an Eclipse project which would also help solve XD 198 and add some integration tests similar to those documented here ",NULL,"Provided modules should be integration tested I don t see that we have automated tests for the modules we provide out of the box. We could make the modules folder an Eclipse project which would also help solve XD 198 and add some integration tests similar to those documented here ",NULL,"Provided modules should be integration tested I don t see that we have automated tests for the modules we provide out of the box<span class='highlight-text severity-high'>. We could make the modules folder an Eclipse project which would also help solve XD 198 and add some integration tests similar to those documented here </span>","minimal","punctuation","high",False
25640,"Create JDK6 CI build Maybe only have it run after the publish build instead of triggering builds directly from jdk6 7 8.",NULL,"Create JDK6 CI build Maybe only have it run after the publish build instead of triggering builds directly from jdk6 7 8.",NULL,"Add for who this story is","well_formed","no_role","high",False
25641,"Document processor modules Fill in ",NULL,"Document processor modules Fill in ",NULL,"Add for who this story is","well_formed","no_role","high",False
25622,"Remove s are incorrectly classified as compile time deps in hadoop vs. testCompile. ",NULL,"Remove s are incorrectly classified as compile time deps in hadoop vs. testCompile. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25622,"Remove s are incorrectly classified as compile time deps in hadoop vs. testCompile. ",NULL,"Remove s are incorrectly classified as compile time deps in hadoop vs. testCompile. ",NULL,"Remove s are incorrectly classified as compile time deps in hadoop vs<span class='highlight-text severity-high'>. testCompile. </span>","minimal","punctuation","high",False
25638,"Use instead of 3rd party library Spring 4.0 provides a UUID generator used by default in SI that should be used instead of the com.eaoi.uuid library in the xd tuple library",NULL,"Use instead of 3rd party library Spring 4.0 provides a UUID generator used by default in SI that should be used instead of the com.eaoi.uuid library in the xd tuple library",NULL,"Add for who this story is","well_formed","no_role","high",False
25635,"0xData investigate embedding 0xData is a rich JVM based machine learning and scoring engine.",NULL,"0xData investigate embedding 0xData is a rich JVM based machine learning and scoring engine.",NULL,"Add for who this story is","well_formed","no_role","high",False
25635,"0xData investigate embedding 0xData is a rich JVM based machine learning and scoring engine.",NULL,"0xData investigate embedding 0xData is a rich JVM based machine learning and scoring engine.",NULL,"0xData investigate embedding 0xData is a rich JVM based machine learning<span class='highlight-text severity-high'> and </span>scoring engine.","atomic","conjunctions","high",False
25646,"Add Redis sink As an user, I'd like to have the ability to ingest data into Redis sink.",NULL,"Add Redis sink As an user, I'd like to have the ability to ingest data into Redis sink.",NULL,"Add for who this story is","well_formed","no_role","high",False
25643,"Add SFTP source As a user, I'd like to have the option to use the SFTP source module so that I can access, transfer, and mange files over any reliable data streams. Reference Spring Integration SFTP Adapter Need to consider the infrastructure for testing.",NULL,"Add SFTP source As a user, I'd like to have the option to use the SFTP source module","so that I can access, transfer, and mange files over any reliable data streams. Reference Spring Integration SFTP Adapter Need to consider the infrastructure for testing.","Add for who this story is","well_formed","no_role","high",False
25643,"Add SFTP source As a user, I'd like to have the option to use the SFTP source module so that I can access, transfer, and mange files over any reliable data streams. Reference Spring Integration SFTP Adapter Need to consider the infrastructure for testing.",NULL,"Add SFTP source As a user, I'd like to have the option to use the SFTP source module","so that I can access, transfer, and mange files over any reliable data streams. Reference Spring Integration SFTP Adapter Need to consider the infrastructure for testing.","Add SFTP source As a user, I'd like to have the option to use the SFTP source module so that I can access, transfer, and mange files over any reliable data streams<span class='highlight-text severity-high'>. Reference Spring Integration SFTP Adapter Need to consider the infrastructure for testing.</span>","minimal","punctuation","high",False
25643,"Add SFTP source As a user, I'd like to have the option to use the SFTP source module so that I can access, transfer, and mange files over any reliable data streams. Reference Spring Integration SFTP Adapter Need to consider the infrastructure for testing.",NULL,"Add SFTP source As a user, I'd like to have the option to use the SFTP source module","so that I can access, transfer, and mange files over any reliable data streams. Reference Spring Integration SFTP Adapter Need to consider the infrastructure for testing.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25645,"Add JDBC source As an user, I'd like to have a native JDBC source module to ingest data directly from various databases. ",NULL,"Add JDBC source As an user, I'd like to have a native JDBC source module to ingest data directly from various databases. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25647,"Investigate setting up performance test environment on cloud providers Use a baseline DIRT infrastructure to measure throughput, HA and scalability for various payload sizes. Depends on testing infrastructure setup, configuration and availability.",NULL,"Investigate setting up performance test environment on cloud providers Use a baseline DIRT infrastructure to measure throughput, HA and scalability for various payload sizes. Depends on testing infrastructure setup, configuration and availability.",NULL,"Add for who this story is","well_formed","no_role","high",False
25647,"Investigate setting up performance test environment on cloud providers Use a baseline DIRT infrastructure to measure throughput, HA and scalability for various payload sizes. Depends on testing infrastructure setup, configuration and availability.",NULL,"Investigate setting up performance test environment on cloud providers Use a baseline DIRT infrastructure to measure throughput, HA and scalability for various payload sizes. Depends on testing infrastructure setup, configuration and availability.",NULL,"Investigate setting up performance test environment on cloud providers Use a baseline DIRT infrastructure to measure throughput, HA and scalability for various payload sizes<span class='highlight-text severity-high'>. Depends on testing infrastructure setup, configuration and availability.</span>","minimal","punctuation","high",False
25648,"Tests sporadically fail when checking send counts with rabbit as transport Tests that use verifySendCounts to validate whether data was sent to all the modules in a stream occasionally fail. This is because, sometimes it takes 2 or more sends to get the data transmitted between modules. With the current test structure this is considered a failure. Is this the correct behavior?",NULL,"Tests sporadically fail when checking send counts with rabbit as transport Tests that use verifySendCounts to validate whether data was sent to all the modules in a stream occasionally fail. This is because, sometimes it takes 2 or more sends to get the data transmitted between modules. With the current test structure this is considered a failure. Is this the correct behavior?",NULL,"Add for who this story is","well_formed","no_role","high",False
25648,"Tests sporadically fail when checking send counts with rabbit as transport Tests that use verifySendCounts to validate whether data was sent to all the modules in a stream occasionally fail. This is because, sometimes it takes 2 or more sends to get the data transmitted between modules. With the current test structure this is considered a failure. Is this the correct behavior?",NULL,"Tests sporadically fail when checking send counts with rabbit as transport Tests that use verifySendCounts to validate whether data was sent to all the modules in a stream occasionally fail. This is because, sometimes it takes 2 or more sends to get the data transmitted between modules. With the current test structure this is considered a failure. Is this the correct behavior?",NULL,"Tests sporadically fail when checking send counts with rabbit as transport Tests that use verifySendCounts to validate whether data was sent to all the modules in a stream occasionally fail. This is because, sometimes it takes 2<span class='highlight-text severity-high'> or </span>more sends to get the data transmitted between modules. With the current test structure this is considered a failure. Is this the correct behavior?","atomic","conjunctions","high",False
25648,"Tests sporadically fail when checking send counts with rabbit as transport Tests that use verifySendCounts to validate whether data was sent to all the modules in a stream occasionally fail. This is because, sometimes it takes 2 or more sends to get the data transmitted between modules. With the current test structure this is considered a failure. Is this the correct behavior?",NULL,"Tests sporadically fail when checking send counts with rabbit as transport Tests that use verifySendCounts to validate whether data was sent to all the modules in a stream occasionally fail. This is because, sometimes it takes 2 or more sends to get the data transmitted between modules. With the current test structure this is considered a failure. Is this the correct behavior?",NULL,"Tests sporadically fail when checking send counts with rabbit as transport Tests that use verifySendCounts to validate whether data was sent to all the modules in a stream occasionally fail<span class='highlight-text severity-high'>. This is because, sometimes it takes 2 or more sends to get the data transmitted between modules. With the current test structure this is considered a failure. Is this the correct behavior?</span>","minimal","punctuation","high",False
25649,"Provide a way to debug the http source The http source does not provide debug logging to see information such as http headers and requests, in particular if a non OK response is returned. I updated the log4j config for org.jboss.netty but it had no effect. I suspect this is due to the need to configure the netty logging system via ",NULL,"Provide a way to debug the http source The http source does not provide debug logging to see information such as http headers and requests, in particular if a non OK response is returned. I updated the log4j config for org.jboss.netty but it had no effect. I suspect this is due to the need to configure the netty logging system via ",NULL,"Add for who this story is","well_formed","no_role","high",False
25649,"Provide a way to debug the http source The http source does not provide debug logging to see information such as http headers and requests, in particular if a non OK response is returned. I updated the log4j config for org.jboss.netty but it had no effect. I suspect this is due to the need to configure the netty logging system via ",NULL,"Provide a way to debug the http source The http source does not provide debug logging to see information such as http headers and requests, in particular if a non OK response is returned. I updated the log4j config for org.jboss.netty but it had no effect. I suspect this is due to the need to configure the netty logging system via ",NULL,"Provide a way to debug the http source The http source does not provide debug logging to see information such as http headers<span class='highlight-text severity-high'> and </span>requests, in particular if a non OK response is returned. I updated the log4j config for org.jboss.netty but it had no effect. I suspect this is due to the need to configure the netty logging system via ","atomic","conjunctions","high",False
25649,"Provide a way to debug the http source The http source does not provide debug logging to see information such as http headers and requests, in particular if a non OK response is returned. I updated the log4j config for org.jboss.netty but it had no effect. I suspect this is due to the need to configure the netty logging system via ",NULL,"Provide a way to debug the http source The http source does not provide debug logging to see information such as http headers and requests, in particular if a non OK response is returned. I updated the log4j config for org.jboss.netty but it had no effect. I suspect this is due to the need to configure the netty logging system via ",NULL,"Provide a way to debug the http source The http source does not provide debug logging to see information such as http headers and requests, in particular if a non OK response is returned<span class='highlight-text severity-high'>. I updated the log4j config for org.jboss.netty but it had no effect. I suspect this is due to the need to configure the netty logging system via </span>","minimal","punctuation","high",False
25650,"Provide configurable properties for hdfs sink. The config file has a hardcoded value to locate the namenode. hdp configuration the fs.default.name proprety should be configurable and we should also support loading an external configuration file using hdp configuration ",NULL,"Provide configurable properties for hdfs sink. The config file has a hardcoded value to locate the namenode. hdp configuration the fs.default.name proprety should be configurable and we should also support loading an external configuration file using hdp configuration ",NULL,"Add for who this story is","well_formed","no_role","high",False
25650,"Provide configurable properties for hdfs sink. The config file has a hardcoded value to locate the namenode. hdp configuration the fs.default.name proprety should be configurable and we should also support loading an external configuration file using hdp configuration ",NULL,"Provide configurable properties for hdfs sink. The config file has a hardcoded value to locate the namenode. hdp configuration the fs.default.name proprety should be configurable and we should also support loading an external configuration file using hdp configuration ",NULL,"Provide configurable properties for hdfs sink. The config file has a hardcoded value to locate the namenode. hdp configuration the fs.default.name proprety should be configurable<span class='highlight-text severity-high'> and </span>we should also support loading an external configuration file using hdp configuration ","atomic","conjunctions","high",False
25650,"Provide configurable properties for hdfs sink. The config file has a hardcoded value to locate the namenode. hdp configuration the fs.default.name proprety should be configurable and we should also support loading an external configuration file using hdp configuration ",NULL,"Provide configurable properties for hdfs sink. The config file has a hardcoded value to locate the namenode. hdp configuration the fs.default.name proprety should be configurable and we should also support loading an external configuration file using hdp configuration ",NULL,"Provide configurable properties for hdfs sink<span class='highlight-text severity-high'>. The config file has a hardcoded value to locate the namenode. hdp configuration the fs.default.name proprety should be configurable and we should also support loading an external configuration file using hdp configuration </span>","minimal","punctuation","high",False
25652,"Add a Retry Dead Letter Interceptor to the RabbitMQ Source Provide for retry and or dead lettering for the rabbit source similar to the rabbit message bus .",NULL,"Add a Retry Dead Letter Interceptor to the RabbitMQ Source Provide for retry and or dead lettering for the rabbit source similar to the rabbit message bus .",NULL,"Add for who this story is","well_formed","no_role","high",False
25652,"Add a Retry Dead Letter Interceptor to the RabbitMQ Source Provide for retry and or dead lettering for the rabbit source similar to the rabbit message bus .",NULL,"Add a Retry Dead Letter Interceptor to the RabbitMQ Source Provide for retry and or dead lettering for the rabbit source similar to the rabbit message bus .",NULL,"Add a Retry Dead Letter Interceptor to the RabbitMQ Source Provide for retry<span class='highlight-text severity-high'> and </span>span class='highlight-text severity-high'> or </span>dead lettering for the rabbit source similar to the rabbit message bus .","atomic","conjunctions","high",False
25654,"Spring XD EC2 needs to setup cluster that uses static resources. h1. Summary User wants the ability to deploy an ec2 cluster where the admin containers use a pre existing ZK ensemble, Rabbit and redis instance that are deployed on different machines. ",NULL,"Spring XD EC2 needs to setup cluster that uses static resources. h1. Summary User wants the ability to deploy an ec2 cluster where the admin containers use a pre existing ZK ensemble, Rabbit and redis instance that are deployed on different machines. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25654,"Spring XD EC2 needs to setup cluster that uses static resources. h1. Summary User wants the ability to deploy an ec2 cluster where the admin containers use a pre existing ZK ensemble, Rabbit and redis instance that are deployed on different machines. ",NULL,"Spring XD EC2 needs to setup cluster that uses static resources. h1. Summary User wants the ability to deploy an ec2 cluster where the admin containers use a pre existing ZK ensemble, Rabbit and redis instance that are deployed on different machines. ",NULL,"Spring XD EC2 needs to setup cluster that uses static resources. h1. Summary User wants the ability to deploy an ec2 cluster where the admin containers use a pre existing ZK ensemble, Rabbit<span class='highlight-text severity-high'> and </span>redis instance that are deployed on different machines. ","atomic","conjunctions","high",False
25654,"Spring XD EC2 needs to setup cluster that uses static resources. h1. Summary User wants the ability to deploy an ec2 cluster where the admin containers use a pre existing ZK ensemble, Rabbit and redis instance that are deployed on different machines. ",NULL,"Spring XD EC2 needs to setup cluster that uses static resources. h1. Summary User wants the ability to deploy an ec2 cluster where the admin containers use a pre existing ZK ensemble, Rabbit and redis instance that are deployed on different machines. ",NULL,"Spring XD EC2 needs to setup cluster that uses static resources<span class='highlight-text severity-high'>. h1. Summary User wants the ability to deploy an ec2 cluster where the admin containers use a pre existing ZK ensemble, Rabbit and redis instance that are deployed on different machines. </span>","minimal","punctuation","high",False
25653,"Document the file sink ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25653,"Document the file sink ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25656,"Create or document existing project template for custom module creation The wiki docs on creating custom modules have entire build.gradle files in them. Would be good to explore existing STS templates, maven archetypes, etc or create new ones for authoring custom modules.",NULL,"Create or document existing project template for custom module creation The wiki docs on creating custom modules have entire build.gradle files in them. Would be good to explore existing STS templates, maven archetypes, etc or create new ones for authoring custom modules.",NULL,"Add for who this story is","well_formed","no_role","high",False
25656,"Create or document existing project template for custom module creation The wiki docs on creating custom modules have entire build.gradle files in them. Would be good to explore existing STS templates, maven archetypes, etc or create new ones for authoring custom modules.",NULL,"Create or document existing project template for custom module creation The wiki docs on creating custom modules have entire build.gradle files in them. Would be good to explore existing STS templates, maven archetypes, etc or create new ones for authoring custom modules.",NULL,"Create<span class='highlight-text severity-high'> or </span>document existing project template for custom module creation The wiki docs on creating custom modules have entire build.gradle files in them. Would be good to explore existing STS templates, maven archetypes, etc or create new ones for authoring custom modules.","atomic","conjunctions","high",False
25656,"Create or document existing project template for custom module creation The wiki docs on creating custom modules have entire build.gradle files in them. Would be good to explore existing STS templates, maven archetypes, etc or create new ones for authoring custom modules.",NULL,"Create or document existing project template for custom module creation The wiki docs on creating custom modules have entire build.gradle files in them. Would be good to explore existing STS templates, maven archetypes, etc or create new ones for authoring custom modules.",NULL,"Create or document existing project template for custom module creation The wiki docs on creating custom modules have entire build<span class='highlight-text severity-high'>.gradle files in them. Would be good to explore existing STS templates, maven archetypes, etc or create new ones for authoring custom modules.</span>","minimal","punctuation","high",False
25655,"Test Recommended XD Cluster Strategy on slow bad network h1. Run Acceptance tests on the following deployments. ",NULL,"Test Recommended XD Cluster Strategy on slow bad network h1. Run Acceptance tests on the following deployments. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25655,"Test Recommended XD Cluster Strategy on slow bad network h1. Run Acceptance tests on the following deployments. ",NULL,"Test Recommended XD Cluster Strategy on slow bad network h1. Run Acceptance tests on the following deployments. ",NULL,"Test Recommended XD Cluster Strategy on slow bad network h1<span class='highlight-text severity-high'>. Run Acceptance tests on the following deployments. </span>","minimal","punctuation","high",False
25651,"Create a Sink and Source for Riak ",NULL,"Create a Sink and Source for Riak ",NULL,"Add for who this story is","well_formed","no_role","high",False
25657,"Custom module packaging strategy As a user, I'd like to have guidance to create custom modules so that I can align the development practices with recommended approach. 11 20 Update Scope of this task is to create an example to demonstrate and document the capability.",NULL,"Custom module packaging strategy As a user, I'd like to have guidance to create custom modules","so that I can align the development practices with recommended approach. 11 20 Update Scope of this task is to create an example to demonstrate and document the capability.","Add for who this story is","well_formed","no_role","high",False
25657,"Custom module packaging strategy As a user, I'd like to have guidance to create custom modules so that I can align the development practices with recommended approach. 11 20 Update Scope of this task is to create an example to demonstrate and document the capability.",NULL,"Custom module packaging strategy As a user, I'd like to have guidance to create custom modules","so that I can align the development practices with recommended approach. 11 20 Update Scope of this task is to create an example to demonstrate and document the capability.","Custom module packaging strategy As a user, I'd like to have guidance to create custom modules so that I can align the development practices with recommended approach<span class='highlight-text severity-high'>. 11 20 Update Scope of this task is to create an example to demonstrate and document the capability.</span>","minimal","punctuation","high",False
25657,"Custom module packaging strategy As a user, I'd like to have guidance to create custom modules so that I can align the development practices with recommended approach. 11 20 Update Scope of this task is to create an example to demonstrate and document the capability.",NULL,"Custom module packaging strategy As a user, I'd like to have guidance to create custom modules","so that I can align the development practices with recommended approach. 11 20 Update Scope of this task is to create an example to demonstrate and document the capability.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25642,"Update XD EC2 Acceptance Test Configs to use 1.0.1 repo Update XD EC2 configs to Pull from 1.0.1 Repo Update XD EC2 Configs to use dir Update test configs XD HOME to instead of ",NULL,"Update XD EC2 Acceptance Test Configs to use 1.0.1 repo Update XD EC2 configs to Pull from 1.0.1 Repo Update XD EC2 Configs to use dir Update test configs XD HOME to instead of ",NULL,"Add for who this story is","well_formed","no_role","high",False
25661,"UI Ability to deploy stream with deployment properties Admin UI currently allows job to be deployed with deployment properties, we need similar way to deploy stream with the deployment properties module count, container matching criteria .",NULL,"UI Ability to deploy stream with deployment properties Admin UI currently allows job to be deployed with deployment properties, we need similar way to deploy stream with the deployment properties module count, container matching criteria .",NULL,"Add for who this story is","well_formed","no_role","high",False
25663,"Enable shutdown containers from admin server When the container starts up, it has a random http port for management configurations. If the container has management port enabled, then we can store it as container attribute. If the admin can reach out to the container on that port, then we can provide an option to shutdown container from the admin server.",NULL,"Enable shutdown containers from admin server When the container starts up, it has a random http port for management configurations. If the container has management port enabled, then we can store it as container attribute. If the admin can reach out to the container on that port, then we can provide an option to shutdown container from the admin server.",NULL,"Add for who this story is","well_formed","no_role","high",False
25663,"Enable shutdown containers from admin server When the container starts up, it has a random http port for management configurations. If the container has management port enabled, then we can store it as container attribute. If the admin can reach out to the container on that port, then we can provide an option to shutdown container from the admin server.",NULL,"Enable shutdown containers from admin server When the container starts up, it has a random http port for management configurations. If the container has management port enabled, then we can store it as container attribute. If the admin can reach out to the container on that port, then we can provide an option to shutdown container from the admin server.",NULL,"Enable shutdown containers from admin server When the container starts up, it has a random http port for management configurations<span class='highlight-text severity-high'>. If the container has management port enabled, then we can store it as container attribute. If the admin can reach out to the container on that port, then we can provide an option to shutdown container from the admin server.</span>","minimal","punctuation","high",False
25662,"UI Visual representation of Stream Job with deployed modules For a given stream job, we need a visual representation of the stream job with any deployed modules.",NULL,"UI Visual representation of Stream Job with deployed modules For a given stream job, we need a visual representation of the stream job with any deployed modules.",NULL,"Add for who this story is","well_formed","no_role","high",False
25664,"Implement KafkaMessageBus Kafka lends itself well as a message bus, and kafka partitioning maps to MB partitioning. Implement KafkaMessageBus and supporting classes and UT IT.",NULL,"Implement KafkaMessageBus Kafka lends itself well as a message bus, and kafka partitioning maps to MB partitioning. Implement KafkaMessageBus and supporting classes and UT IT.",NULL,"Add for who this story is","well_formed","no_role","high",False
25664,"Implement KafkaMessageBus Kafka lends itself well as a message bus, and kafka partitioning maps to MB partitioning. Implement KafkaMessageBus and supporting classes and UT IT.",NULL,"Implement KafkaMessageBus Kafka lends itself well as a message bus, and kafka partitioning maps to MB partitioning. Implement KafkaMessageBus and supporting classes and UT IT.",NULL,"Implement KafkaMessageBus Kafka lends itself well as a message bus,<span class='highlight-text severity-high'> and </span>kafka partitioning maps to MB partitioning. Implement KafkaMessageBus and supporting classes and UT IT.","atomic","conjunctions","high",False
25664,"Implement KafkaMessageBus Kafka lends itself well as a message bus, and kafka partitioning maps to MB partitioning. Implement KafkaMessageBus and supporting classes and UT IT.",NULL,"Implement KafkaMessageBus Kafka lends itself well as a message bus, and kafka partitioning maps to MB partitioning. Implement KafkaMessageBus and supporting classes and UT IT.",NULL,"Implement KafkaMessageBus Kafka lends itself well as a message bus, and kafka partitioning maps to MB partitioning<span class='highlight-text severity-high'>. Implement KafkaMessageBus and supporting classes and UT IT.</span>","minimal","punctuation","high",False
25666,"Add Kafka sink As a user, I'd like to have the option to write into Kafka sink so that I can publish mass data into Kafka broker.",NULL,"Add Kafka sink As a user, I'd like to have the option to write into Kafka sink","so that I can publish mass data into Kafka broker.","Add for who this story is","well_formed","no_role","high",False
25666,"Add Kafka sink As a user, I'd like to have the option to write into Kafka sink so that I can publish mass data into Kafka broker.",NULL,"Add Kafka sink As a user, I'd like to have the option to write into Kafka sink","so that I can publish mass data into Kafka broker.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25669,"Document the log sink ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25669,"Document the log sink ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25668,"Allow aggregate counter to increment by some value of the message Currently, the aggregate counter only adds 1 to the individual values, even though support is there to add any increment. This ticket is about surfacing a SpEL expression on the message to choose the increment",NULL,"Allow aggregate counter to increment by some value of the message Currently, the aggregate counter only adds 1 to the individual values, even though support is there to add any increment. This ticket is about surfacing a SpEL expression on the message to choose the increment",NULL,"Add for who this story is","well_formed","no_role","high",False
25668,"Allow aggregate counter to increment by some value of the message Currently, the aggregate counter only adds 1 to the individual values, even though support is there to add any increment. This ticket is about surfacing a SpEL expression on the message to choose the increment",NULL,"Allow aggregate counter to increment by some value of the message Currently, the aggregate counter only adds 1 to the individual values, even though support is there to add any increment. This ticket is about surfacing a SpEL expression on the message to choose the increment",NULL,"Allow aggregate counter to increment by some value of the message Currently, the aggregate counter only adds 1 to the individual values, even though support is there to add any increment<span class='highlight-text severity-high'>. This ticket is about surfacing a SpEL expression on the message to choose the increment</span>","minimal","punctuation","high",False
25670,"XD EC2 needs to provide ability to use a preinstalled zip vs downloading from s3 Currently XD EC2 downloads an XD zip file from the location specified by the xd dist url after verifying that the file is accessible.. ",NULL,"XD EC2 needs to provide ability to use a preinstalled zip vs downloading from s3 Currently XD EC2 downloads an XD zip file from the location specified by the xd dist url after verifying that the file is accessible.. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25667,"MessageBus should see custom SpEL property accessors Currently, custom SI property accessors are registered by a plugin and are not visible by the bus. I believe they should be. This may just be a matter of moving them around.",NULL,"MessageBus should see custom SpEL property accessors Currently, custom SI property accessors are registered by a plugin and are not visible by the bus. I believe they should be. This may just be a matter of moving them around.",NULL,"Add for who this story is","well_formed","no_role","high",False
25667,"MessageBus should see custom SpEL property accessors Currently, custom SI property accessors are registered by a plugin and are not visible by the bus. I believe they should be. This may just be a matter of moving them around.",NULL,"MessageBus should see custom SpEL property accessors Currently, custom SI property accessors are registered by a plugin and are not visible by the bus. I believe they should be. This may just be a matter of moving them around.",NULL,"MessageBus should see custom SpEL property accessors Currently, custom SI property accessors are registered by a plugin<span class='highlight-text severity-high'> and </span>are not visible by the bus. I believe they should be. This may just be a matter of moving them around.","atomic","conjunctions","high",False
25667,"MessageBus should see custom SpEL property accessors Currently, custom SI property accessors are registered by a plugin and are not visible by the bus. I believe they should be. This may just be a matter of moving them around.",NULL,"MessageBus should see custom SpEL property accessors Currently, custom SI property accessors are registered by a plugin and are not visible by the bus. I believe they should be. This may just be a matter of moving them around.",NULL,"MessageBus should see custom SpEL property accessors Currently, custom SI property accessors are registered by a plugin and are not visible by the bus<span class='highlight-text severity-high'>. I believe they should be. This may just be a matter of moving them around.</span>","minimal","punctuation","high",False
25673,"Provide file based storage for users, groups and roles As a user, I'd like to have the option to provide file based security configurations so that I can access the endpoints in a secured manner. Ideally, all the listed endpoints needs to be encapsulated within file based security layer. Reference Securing Web App ",NULL,"Provide file based storage for users, groups and roles As a user, I'd like to have the option to provide file based security configurations","so that I can access the endpoints in a secured manner. Ideally, all the listed endpoints needs to be encapsulated within file based security layer. Reference Securing Web App","Add for who this story is","well_formed","no_role","high",False
25673,"Provide file based storage for users, groups and roles As a user, I'd like to have the option to provide file based security configurations so that I can access the endpoints in a secured manner. Ideally, all the listed endpoints needs to be encapsulated within file based security layer. Reference Securing Web App ",NULL,"Provide file based storage for users, groups and roles As a user, I'd like to have the option to provide file based security configurations","so that I can access the endpoints in a secured manner. Ideally, all the listed endpoints needs to be encapsulated within file based security layer. Reference Securing Web App","Provide file based storage for users, groups<span class='highlight-text severity-high'> and </span>roles As a user, I'd like to have the option to provide file based security configurations so that I can access the endpoints in a secured manner. Ideally, all the listed endpoints needs to be encapsulated within file based security layer. Reference Securing Web App ","atomic","conjunctions","high",False
25673,"Provide file based storage for users, groups and roles As a user, I'd like to have the option to provide file based security configurations so that I can access the endpoints in a secured manner. Ideally, all the listed endpoints needs to be encapsulated within file based security layer. Reference Securing Web App ",NULL,"Provide file based storage for users, groups and roles As a user, I'd like to have the option to provide file based security configurations","so that I can access the endpoints in a secured manner. Ideally, all the listed endpoints needs to be encapsulated within file based security layer. Reference Securing Web App","Provide file based storage for users, groups and roles As a user, I'd like to have the option to provide file based security configurations so that I can access the endpoints in a secured manner<span class='highlight-text severity-high'>. Ideally, all the listed endpoints needs to be encapsulated within file based security layer. Reference Securing Web App </span>","minimal","punctuation","high",False
25673,"Provide file based storage for users, groups and roles As a user, I'd like to have the option to provide file based security configurations so that I can access the endpoints in a secured manner. Ideally, all the listed endpoints needs to be encapsulated within file based security layer. Reference Securing Web App ",NULL,"Provide file based storage for users, groups and roles As a user, I'd like to have the option to provide file based security configurations","so that I can access the endpoints in a secured manner. Ideally, all the listed endpoints needs to be encapsulated within file based security layer. Reference Securing Web App","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25672,"Create a shell command processor and sink Create processor and sink modules that can execute a shell command using stdin and stdout to stream data.",NULL,"Create a shell command processor and sink Create processor and sink modules that can execute a shell command using stdin and stdout to stream data.",NULL,"Add for who this story is","well_formed","no_role","high",False
25672,"Create a shell command processor and sink Create processor and sink modules that can execute a shell command using stdin and stdout to stream data.",NULL,"Create a shell command processor and sink Create processor and sink modules that can execute a shell command using stdin and stdout to stream data.",NULL,"Create a shell command processor<span class='highlight-text severity-high'> and </span>sink Create processor and sink modules that can execute a shell command using stdin and stdout to stream data.","atomic","conjunctions","high",False
25660,"UI Cluster view of a container We need a visual representation of the XD cluster with runtime container and deployed modules.",NULL,"UI Cluster view of a container We need a visual representation of the XD cluster with runtime container and deployed modules.",NULL,"Add for who this story is","well_formed","no_role","high",False
25660,"UI Cluster view of a container We need a visual representation of the XD cluster with runtime container and deployed modules.",NULL,"UI Cluster view of a container We need a visual representation of the XD cluster with runtime container and deployed modules.",NULL,"UI Cluster view of a container We need a visual representation of the XD cluster with runtime container<span class='highlight-text severity-high'> and </span>deployed modules.","atomic","conjunctions","high",False
25658,"Research approach to bootstrap custom modules Design Spike Investigate various approaches to bootstrap custom modules. Can Spring Boot be leveraged? Starter POM?",NULL,"Research approach to bootstrap custom modules Design Spike Investigate various approaches to bootstrap custom modules. Can Spring Boot be leveraged? Starter POM?",NULL,"Add for who this story is","well_formed","no_role","high",False
25658,"Research approach to bootstrap custom modules Design Spike Investigate various approaches to bootstrap custom modules. Can Spring Boot be leveraged? Starter POM?",NULL,"Research approach to bootstrap custom modules Design Spike Investigate various approaches to bootstrap custom modules. Can Spring Boot be leveraged? Starter POM?",NULL,"Research approach to bootstrap custom modules Design Spike Investigate various approaches to bootstrap custom modules<span class='highlight-text severity-high'>. Can Spring Boot be leveraged? Starter POM?</span>","minimal","punctuation","high",False
25665,"If output directory does not exist for a file sink, by default allow it to be created There shouldn t be a need to do a mkdir p before sending data to a file sink.",NULL,"If output directory does not exist for a file sink, by default allow it to be created There shouldn t be a need to do a mkdir p before sending data to a file sink.",NULL,"Add for who this story is","well_formed","no_role","high",False
25671,"User wants to select the ec2 zone when deploying XD Currently the application allows AWS select which zone in the region to create an instance.",NULL,"User wants to select the ec2 zone when deploying XD Currently the application allows AWS select which zone in the region to create an instance.",NULL,"Add for who this story is","well_formed","no_role","high",False
25676,"Provide kerberos support for HDFS sink As a user, I'd like to have the option of kerberized HDFS sink so that I can leverage Kerberos open source distributed authentication system for secured data writes into Hadoop.",NULL,"Provide kerberos support for HDFS sink As a user, I'd like to have the option of kerberized HDFS sink","so that I can leverage Kerberos open source distributed authentication system for secured data writes into Hadoop.","Add for who this story is","well_formed","no_role","high",False
25676,"Provide kerberos support for HDFS sink As a user, I'd like to have the option of kerberized HDFS sink so that I can leverage Kerberos open source distributed authentication system for secured data writes into Hadoop.",NULL,"Provide kerberos support for HDFS sink As a user, I'd like to have the option of kerberized HDFS sink","so that I can leverage Kerberos open source distributed authentication system for secured data writes into Hadoop.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25674,"Secure all endpoints using LDAP based security configurations As a user, I'd like to have the option to provide LDAP based security configurations so that I can access the endpoints in a secured manner. Ideally, all the listed endpoints needs to be encapsulated within LDAP based security layer. Reference Authentication using LDAP ",NULL,"Secure all endpoints using LDAP based security configurations As a user, I'd like to have the option to provide LDAP based security configurations","so that I can access the endpoints in a secured manner. Ideally, all the listed endpoints needs to be encapsulated within LDAP based security layer. Reference Authentication using LDAP","Add for who this story is","well_formed","no_role","high",False
25674,"Secure all endpoints using LDAP based security configurations As a user, I'd like to have the option to provide LDAP based security configurations so that I can access the endpoints in a secured manner. Ideally, all the listed endpoints needs to be encapsulated within LDAP based security layer. Reference Authentication using LDAP ",NULL,"Secure all endpoints using LDAP based security configurations As a user, I'd like to have the option to provide LDAP based security configurations","so that I can access the endpoints in a secured manner. Ideally, all the listed endpoints needs to be encapsulated within LDAP based security layer. Reference Authentication using LDAP","Secure all endpoints using LDAP based security configurations As a user, I'd like to have the option to provide LDAP based security configurations so that I can access the endpoints in a secured manner<span class='highlight-text severity-high'>. Ideally, all the listed endpoints needs to be encapsulated within LDAP based security layer. Reference Authentication using LDAP </span>","minimal","punctuation","high",False
25674,"Secure all endpoints using LDAP based security configurations As a user, I'd like to have the option to provide LDAP based security configurations so that I can access the endpoints in a secured manner. Ideally, all the listed endpoints needs to be encapsulated within LDAP based security layer. Reference Authentication using LDAP ",NULL,"Secure all endpoints using LDAP based security configurations As a user, I'd like to have the option to provide LDAP based security configurations","so that I can access the endpoints in a secured manner. Ideally, all the listed endpoints needs to be encapsulated within LDAP based security layer. Reference Authentication using LDAP","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25678,"Temporarily add toString Logic in Local Mode Inter Module Comms ",NULL,"Temporarily add toString Logic in Local Mode Inter Module Comms ",NULL,"Add for who this story is","well_formed","no_role","high",False
25686,"Add authentication information to twittersearch source doc Since the changes for XD 202, twittersearch requires authentication. Need to update the docs to reflect this.",NULL,"Add authentication information to twittersearch source doc Since the changes for XD 202, twittersearch requires authentication. Need to update the docs to reflect this.",NULL,"Add for who this story is","well_formed","no_role","high",False
25686,"Add authentication information to twittersearch source doc Since the changes for XD 202, twittersearch requires authentication. Need to update the docs to reflect this.",NULL,"Add authentication information to twittersearch source doc Since the changes for XD 202, twittersearch requires authentication. Need to update the docs to reflect this.",NULL,"Add authentication information to twittersearch source doc Since the changes for XD 202, twittersearch requires authentication<span class='highlight-text severity-high'>. Need to update the docs to reflect this.</span>","minimal","punctuation","high",False
25677,"Research integration options for Sqoop tasklet As a user, I'd like to have the ability to mass ingest data from various database systems so that I m not restricted with the current approach jdbchdfs that is dependent on JDBC drivers. Spike Scope Identify integration options Collaborate to determine the design Document outcome design specs ",NULL,"Research integration options for Sqoop tasklet As a user, I'd like to have the ability to mass ingest data from various database systems","so that I m not restricted with the current approach jdbchdfs that is dependent on JDBC drivers. Spike Scope Identify integration options Collaborate to determine the design Document outcome design specs","Add for who this story is","well_formed","no_role","high",False
25677,"Research integration options for Sqoop tasklet As a user, I'd like to have the ability to mass ingest data from various database systems so that I m not restricted with the current approach jdbchdfs that is dependent on JDBC drivers. Spike Scope Identify integration options Collaborate to determine the design Document outcome design specs ",NULL,"Research integration options for Sqoop tasklet As a user, I'd like to have the ability to mass ingest data from various database systems","so that I m not restricted with the current approach jdbchdfs that is dependent on JDBC drivers. Spike Scope Identify integration options Collaborate to determine the design Document outcome design specs","Research integration options for Sqoop tasklet As a user, I'd like to have the ability to mass ingest data from various database systems so that I m not restricted with the current approach jdbchdfs that is dependent on JDBC drivers<span class='highlight-text severity-high'>. Spike Scope Identify integration options Collaborate to determine the design Document outcome design specs </span>","minimal","punctuation","high",False
25677,"Research integration options for Sqoop tasklet As a user, I'd like to have the ability to mass ingest data from various database systems so that I m not restricted with the current approach jdbchdfs that is dependent on JDBC drivers. Spike Scope Identify integration options Collaborate to determine the design Document outcome design specs ",NULL,"Research integration options for Sqoop tasklet As a user, I'd like to have the ability to mass ingest data from various database systems","so that I m not restricted with the current approach jdbchdfs that is dependent on JDBC drivers. Spike Scope Identify integration options Collaborate to determine the design Document outcome design specs","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25682,"Support Spring Boot s single user security configurations As a user, I'd like to have the option to provide single user security configurations so that I can override them as needed. Reference Spring Boot Security Scope Configurations can be provided through servers.yml file.",NULL,"Support Spring Boot s single user security configurations As a user, I'd like to have the option to provide single user security configurations","so that I can override them as needed. Reference Spring Boot Security Scope Configurations can be provided through servers.yml file.","Add for who this story is","well_formed","no_role","high",False
25682,"Support Spring Boot s single user security configurations As a user, I'd like to have the option to provide single user security configurations so that I can override them as needed. Reference Spring Boot Security Scope Configurations can be provided through servers.yml file.",NULL,"Support Spring Boot s single user security configurations As a user, I'd like to have the option to provide single user security configurations","so that I can override them as needed. Reference Spring Boot Security Scope Configurations can be provided through servers.yml file.","Support Spring Boot s single user security configurations As a user, I'd like to have the option to provide single user security configurations so that I can override them as needed<span class='highlight-text severity-high'>. Reference Spring Boot Security Scope Configurations can be provided through servers.yml file.</span>","minimal","punctuation","high",False
25682,"Support Spring Boot s single user security configurations As a user, I'd like to have the option to provide single user security configurations so that I can override them as needed. Reference Spring Boot Security Scope Configurations can be provided through servers.yml file.",NULL,"Support Spring Boot s single user security configurations As a user, I'd like to have the option to provide single user security configurations","so that I can override them as needed. Reference Spring Boot Security Scope Configurations can be provided through servers.yml file.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25679,"Add Cassandra sink As a user, I'd like to have the option of Cassandra sink, so I can leverage the NoSQL database to write high volumes of variable data segments in high velocity.",NULL,"Add Cassandra sink As a user, I'd like to have the option of Cassandra sink,","so I can leverage the NoSQL database to write high volumes of variable data segments in high velocity.","Add for who this story is","well_formed","no_role","high",False
25680,"Create documentation on the general DSL syntax The asciidoc wiki should have a section included in the Sidebar.asciidoc as well that describes the general usage of the DSL syntax.",NULL,"Create documentation on the general DSL syntax The asciidoc wiki should have a section included in the Sidebar.asciidoc as well that describes the general usage of the DSL syntax.",NULL,"Add for who this story is","well_formed","no_role","high",False
25685,"Upgrade to spring boot 1.1.7.RELEASE As a user, I'd like to have latest Spring Boot RELEASE pulled as a dependency so that I can inherit and implement the OOTB security features.",NULL,"Upgrade to spring boot 1.1.7.RELEASE As a user, I'd like to have latest Spring Boot RELEASE pulled as a dependency","so that I can inherit and implement the OOTB security features.","Add for who this story is","well_formed","no_role","high",False
25685,"Upgrade to spring boot 1.1.7.RELEASE As a user, I'd like to have latest Spring Boot RELEASE pulled as a dependency so that I can inherit and implement the OOTB security features.",NULL,"Upgrade to spring boot 1.1.7.RELEASE As a user, I'd like to have latest Spring Boot RELEASE pulled as a dependency","so that I can inherit and implement the OOTB security features.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25683,"XD Shell needs to be be able to authenticate using basic auth to admin server As a user, I want to be able to provide security credentials to the XD Shell so that I can interact with an xd admin server that is secured via basic auth Technical implementation Add password and username to the admin config command. ",NULL,"XD Shell needs to be be able to authenticate using basic auth to admin server As a user, I want to be able to provide security credentials to the XD Shell","so that I can interact with an xd admin server that is secured via basic auth Technical implementation Add password and username to the admin config command.","Add for who this story is","well_formed","no_role","high",False
25683,"XD Shell needs to be be able to authenticate using basic auth to admin server As a user, I want to be able to provide security credentials to the XD Shell so that I can interact with an xd admin server that is secured via basic auth Technical implementation Add password and username to the admin config command. ",NULL,"XD Shell needs to be be able to authenticate using basic auth to admin server As a user, I want to be able to provide security credentials to the XD Shell","so that I can interact with an xd admin server that is secured via basic auth Technical implementation Add password and username to the admin config command.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25684,"Upgrade to spring boot 1.1.7.SNAPSHOT As a user, I'd like to have latest Spring Boot snapshot pulled as a dependency so that I can inherit and implement the OOTB security features.",NULL,"Upgrade to spring boot 1.1.7.SNAPSHOT As a user, I'd like to have latest Spring Boot snapshot pulled as a dependency","so that I can inherit and implement the OOTB security features.","Add for who this story is","well_formed","no_role","high",False
25684,"Upgrade to spring boot 1.1.7.SNAPSHOT As a user, I'd like to have latest Spring Boot snapshot pulled as a dependency so that I can inherit and implement the OOTB security features.",NULL,"Upgrade to spring boot 1.1.7.SNAPSHOT As a user, I'd like to have latest Spring Boot snapshot pulled as a dependency","so that I can inherit and implement the OOTB security features.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25710,"Upgrade to Spring 4.1.2, SI 4.1.0, SA 1.4.0 As a user, I'd like to have Spring Core upgraded to 4.1.1 milestone so that I can benefit from performance improvements associated with compiled SpEL and other enhancements. ",NULL,"Upgrade to Spring 4.1.2, SI 4.1.0, SA 1.4.0 As a user, I'd like to have Spring Core upgraded to 4.1.1 milestone","so that I can benefit from performance improvements associated with compiled SpEL and other enhancements.","Add for who this story is","well_formed","no_role","high",False
25710,"Upgrade to Spring 4.1.2, SI 4.1.0, SA 1.4.0 As a user, I'd like to have Spring Core upgraded to 4.1.1 milestone so that I can benefit from performance improvements associated with compiled SpEL and other enhancements. ",NULL,"Upgrade to Spring 4.1.2, SI 4.1.0, SA 1.4.0 As a user, I'd like to have Spring Core upgraded to 4.1.1 milestone","so that I can benefit from performance improvements associated with compiled SpEL and other enhancements.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25711,"Add docs for Deleting a simple stream. curl X DELETE ",NULL,"Add docs for Deleting a simple stream. curl X DELETE ",NULL,"Add for who this story is","well_formed","no_role","high",False
25711,"Add docs for Deleting a simple stream. curl X DELETE ",NULL,"Add docs for Deleting a simple stream. curl X DELETE ",NULL,"Add docs for Deleting a simple stream<span class='highlight-text severity-high'>. curl X DELETE </span>","minimal","punctuation","high",False
25713,"REST Make the Job Execution REST endpoint pagination aware Implement pagination for ",NULL,"REST Make the Job Execution REST endpoint pagination aware Implement pagination for ",NULL,"Add for who this story is","well_formed","no_role","high",False
25712,"REST Make the Configurations REST endpoint pagination aware Add pagination for Related to XD 1864",NULL,"REST Make the Configurations REST endpoint pagination aware Add pagination for Related to XD 1864",NULL,"Add for who this story is","well_formed","no_role","high",False
25689,"Provide Docker image for developers As a user, I need a sandbox Docker Image so that I can get started to experiment XD deployment with the following setup Ubuntu OS Full XD Jar Java 7.x Redis RabbitMQ",NULL,"Provide Docker image for developers As a user, I need a sandbox Docker Image","so that I can get started to experiment XD deployment with the following setup Ubuntu OS Full XD Jar Java 7.x Redis RabbitMQ","Add for who this story is","well_formed","no_role","high",False
25689,"Provide Docker image for developers As a user, I need a sandbox Docker Image so that I can get started to experiment XD deployment with the following setup Ubuntu OS Full XD Jar Java 7.x Redis RabbitMQ",NULL,"Provide Docker image for developers As a user, I need a sandbox Docker Image","so that I can get started to experiment XD deployment with the following setup Ubuntu OS Full XD Jar Java 7.x Redis RabbitMQ","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25700,"Surpress tap WARNING message in local mode ",NULL,"Surpress tap WARNING message in local mode ",NULL,"Add for who this story is","well_formed","no_role","high",False
25692,"Evaluate Spring Boot dependency upgrade As a user, I'd like to evaluate Spring Boot dependency upgrades so that I can make sure there aren t any side effects or impacts to existing functionalities. ",NULL,"Evaluate Spring Boot dependency upgrade As a user, I'd like to evaluate Spring Boot dependency upgrades","so that I can make sure there aren t any side effects or impacts to existing functionalities.","Add for who this story is","well_formed","no_role","high",False
25692,"Evaluate Spring Boot dependency upgrade As a user, I'd like to evaluate Spring Boot dependency upgrades so that I can make sure there aren t any side effects or impacts to existing functionalities. ",NULL,"Evaluate Spring Boot dependency upgrade As a user, I'd like to evaluate Spring Boot dependency upgrades","so that I can make sure there aren t any side effects or impacts to existing functionalities.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25690,"Add support for tap foo.bar syntax in the DSL ",NULL,"Add support for tap foo.bar syntax in the DSL ",NULL,"Add for who this story is","well_formed","no_role","high",False
25693,"Add config dir to classpath to support custom The transform, filter, and script processor modules support passing in a for script variables. We need a default location on the classpath for users to provide custom properties files.",NULL,"Add config dir to classpath to support custom The transform, filter, and script processor modules support passing in a for script variables. We need a default location on the classpath for users to provide custom properties files.",NULL,"Add for who this story is","well_formed","no_role","high",False
25693,"Add config dir to classpath to support custom The transform, filter, and script processor modules support passing in a for script variables. We need a default location on the classpath for users to provide custom properties files.",NULL,"Add config dir to classpath to support custom The transform, filter, and script processor modules support passing in a for script variables. We need a default location on the classpath for users to provide custom properties files.",NULL,"Add config dir to classpath to support custom The transform, filter,<span class='highlight-text severity-high'> and </span>script processor modules support passing in a for script variables. We need a default location on the classpath for users to provide custom properties files.","atomic","conjunctions","high",False
25693,"Add config dir to classpath to support custom The transform, filter, and script processor modules support passing in a for script variables. We need a default location on the classpath for users to provide custom properties files.",NULL,"Add config dir to classpath to support custom The transform, filter, and script processor modules support passing in a for script variables. We need a default location on the classpath for users to provide custom properties files.",NULL,"Add config dir to classpath to support custom The transform, filter, and script processor modules support passing in a for script variables<span class='highlight-text severity-high'>. We need a default location on the classpath for users to provide custom properties files.</span>","minimal","punctuation","high",False
25697,"Expose property to change commit interval As a user, I'd like to override the default commit interval so that I can configure commit interval depending on data volume. Note This would apply for all OOTB jobs that has partition support. The property could be part of servers.yml file.",NULL,"Expose property to change commit interval As a user, I'd like to override the default commit interval","so that I can configure commit interval depending on data volume. Note This would apply for all OOTB jobs that has partition support. The property could be part of servers.yml file.","Add for who this story is","well_formed","no_role","high",False
25697,"Expose property to change commit interval As a user, I'd like to override the default commit interval so that I can configure commit interval depending on data volume. Note This would apply for all OOTB jobs that has partition support. The property could be part of servers.yml file.",NULL,"Expose property to change commit interval As a user, I'd like to override the default commit interval","so that I can configure commit interval depending on data volume. Note This would apply for all OOTB jobs that has partition support. The property could be part of servers.yml file.","Expose property to change commit interval As a user, I'd like to override the default commit interval so that I can configure commit interval depending on data volume<span class='highlight-text severity-high'>. Note This would apply for all OOTB jobs that has partition support. The property could be part of servers.yml file.</span>","minimal","punctuation","high",False
25697,"Expose property to change commit interval As a user, I'd like to override the default commit interval so that I can configure commit interval depending on data volume. Note This would apply for all OOTB jobs that has partition support. The property could be part of servers.yml file.",NULL,"Expose property to change commit interval As a user, I'd like to override the default commit interval","so that I can configure commit interval depending on data volume. Note This would apply for all OOTB jobs that has partition support. The property could be part of servers.yml file.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25694,"Add support for Pivotal HD 2.1 XD 1.0.2 Release XD 1.0.2 Release PHD 2.1 Upgrade Action Items Update to SHDP 2.0.3 Add Hadoop 2.5 hadoop25 Change PHD 2.x from phd20 to phd21 Test PHD 2.0 with phd21 Document that both PHD 2.1 and PHD 2.0 is supported with phd21 ",NULL,"Add support for Pivotal HD 2.1 XD 1.0.2 Release XD 1.0.2 Release PHD 2.1 Upgrade Action Items Update to SHDP 2.0.3 Add Hadoop 2.5 hadoop25 Change PHD 2.x from phd20 to phd21 Test PHD 2.0 with phd21 Document that both PHD 2.1 and PHD 2.0 is supported with phd21 ",NULL,"Add for who this story is","well_formed","no_role","high",False
25694,"Add support for Pivotal HD 2.1 XD 1.0.2 Release XD 1.0.2 Release PHD 2.1 Upgrade Action Items Update to SHDP 2.0.3 Add Hadoop 2.5 hadoop25 Change PHD 2.x from phd20 to phd21 Test PHD 2.0 with phd21 Document that both PHD 2.1 and PHD 2.0 is supported with phd21 ",NULL,"Add support for Pivotal HD 2.1 XD 1.0.2 Release XD 1.0.2 Release PHD 2.1 Upgrade Action Items Update to SHDP 2.0.3 Add Hadoop 2.5 hadoop25 Change PHD 2.x from phd20 to phd21 Test PHD 2.0 with phd21 Document that both PHD 2.1 and PHD 2.0 is supported with phd21 ",NULL,"Add support for Pivotal HD 2.1 XD 1.0.2 Release XD 1.0.2 Release PHD 2.1 Upgrade Action Items Update to SHDP 2.0.3 Add Hadoop 2.5 hadoop25 Change PHD 2.x from phd20 to phd21 Test PHD 2.0 with phd21 Document that both PHD 2.1<span class='highlight-text severity-high'> and </span>PHD 2.0 is supported with phd21 ","atomic","conjunctions","high",False
25695,"Add remote partitioning on jdbchdfs job As a user, I'd like to have the option to supply data partitioning strategy so that I can parallelize ingest of data from RDBMS to HDFS.",NULL,"Add remote partitioning on jdbchdfs job As a user, I'd like to have the option to supply data partitioning strategy","so that I can parallelize ingest of data from RDBMS to HDFS.","Add for who this story is","well_formed","no_role","high",False
25695,"Add remote partitioning on jdbchdfs job As a user, I'd like to have the option to supply data partitioning strategy so that I can parallelize ingest of data from RDBMS to HDFS.",NULL,"Add remote partitioning on jdbchdfs job As a user, I'd like to have the option to supply data partitioning strategy","so that I can parallelize ingest of data from RDBMS to HDFS.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25696,"Add support to load a twitter.properties file in the source ",NULL,"Add support to load a twitter.properties file in the source ",NULL,"Add for who this story is","well_formed","no_role","high",False
25698,"Document how to enable SSL and Basic authentication As a user, I want to know my configuration options are for enabling SSL HTTPS and Basic authentication for administration endpoints, so that I can secure my application.",NULL,"Document how to enable SSL and Basic authentication As a user, I want to know my configuration options are for enabling SSL HTTPS and Basic authentication for administration endpoints,","so that I can secure my application.","Add for who this story is","well_formed","no_role","high",False
25698,"Document how to enable SSL and Basic authentication As a user, I want to know my configuration options are for enabling SSL HTTPS and Basic authentication for administration endpoints, so that I can secure my application.",NULL,"Document how to enable SSL and Basic authentication As a user, I want to know my configuration options are for enabling SSL HTTPS and Basic authentication for administration endpoints,","so that I can secure my application.","Document how to enable SSL<span class='highlight-text severity-high'> and </span>Basic authentication As a user, I want to know my configuration options are for enabling SSL HTTPS and Basic authentication for administration endpoints, so that I can secure my application.","atomic","conjunctions","high",False
25698,"Document how to enable SSL and Basic authentication As a user, I want to know my configuration options are for enabling SSL HTTPS and Basic authentication for administration endpoints, so that I can secure my application.",NULL,"Document how to enable SSL and Basic authentication As a user, I want to know my configuration options are for enabling SSL HTTPS and Basic authentication for administration endpoints,","so that I can secure my application.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25699,"Fix REST endpoint with security enabled Once the container s management server is secured, the admin server needs to know which REST template to use to get the message rates from the deployed modules inside the containers.",NULL,"Fix REST endpoint with security enabled Once the container s management server is secured, the admin server needs to know which REST template to use to get the message rates from the deployed modules inside the containers.",NULL,"Add for who this story is","well_formed","no_role","high",False
25701,"Fix failing script integration test See ",NULL,"Fix failing script integration test See ",NULL,"Add for who this story is","well_formed","no_role","high",False
25703,"Add Python processor As a user, I'd like to have a Python processor so that I can efficiently perform data computations and statistical analysis. Investigate the right approach native or via stdin stdout that fits Spring XD model. Integrate Java and Python ",NULL,"Add Python processor As a user, I'd like to have a Python processor","so that I can efficiently perform data computations and statistical analysis. Investigate the right approach native or via stdin stdout that fits Spring XD model. Integrate Java and Python","Add for who this story is","well_formed","no_role","high",False
25703,"Add Python processor As a user, I'd like to have a Python processor so that I can efficiently perform data computations and statistical analysis. Investigate the right approach native or via stdin stdout that fits Spring XD model. Integrate Java and Python ",NULL,"Add Python processor As a user, I'd like to have a Python processor","so that I can efficiently perform data computations and statistical analysis. Investigate the right approach native or via stdin stdout that fits Spring XD model. Integrate Java and Python","Add Python processor As a user, I'd like to have a Python processor so that I can efficiently perform data computations and statistical analysis<span class='highlight-text severity-high'>. Investigate the right approach native or via stdin stdout that fits Spring XD model. Integrate Java and Python </span>","minimal","punctuation","high",False
25703,"Add Python processor As a user, I'd like to have a Python processor so that I can efficiently perform data computations and statistical analysis. Investigate the right approach native or via stdin stdout that fits Spring XD model. Integrate Java and Python ",NULL,"Add Python processor As a user, I'd like to have a Python processor","so that I can efficiently perform data computations and statistical analysis. Investigate the right approach native or via stdin stdout that fits Spring XD model. Integrate Java and Python","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25704,"Add acceptance test to extract and assert payload from JSON object To enrich the acceptance test, I'd like to evaluate JSON object to extract Good and Bad instead of just relying on a basic filter test to assert the payload content. ",NULL,"Add acceptance test to extract and assert payload from JSON object To enrich the acceptance test, I'd like to evaluate JSON object to extract Good and Bad instead of just relying on a basic filter test to assert the payload content. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25704,"Add acceptance test to extract and assert payload from JSON object To enrich the acceptance test, I'd like to evaluate JSON object to extract Good and Bad instead of just relying on a basic filter test to assert the payload content. ",NULL,"Add acceptance test to extract and assert payload from JSON object To enrich the acceptance test, I'd like to evaluate JSON object to extract Good and Bad instead of just relying on a basic filter test to assert the payload content. ",NULL,"Add acceptance test to extract<span class='highlight-text severity-high'> and </span>assert payload from JSON object To enrich the acceptance test, I'd like to evaluate JSON object to extract Good and Bad instead of just relying on a basic filter test to assert the payload content. ","atomic","conjunctions","high",False
25702,"Add twitter oauth properties file to config dir Those property keys should then be provided as defaults for the placeholders in ",NULL,"Add twitter oauth properties file to config dir Those property keys should then be provided as defaults for the placeholders in ",NULL,"Add for who this story is","well_formed","no_role","high",False
25688,"UI Add Tooltip Directive Small follow up story to XD 2094 to improve tooltip handling.",NULL,"UI Add Tooltip Directive Small follow up story to XD 2094 to improve tooltip handling.",NULL,"Add for who this story is","well_formed","no_role","high",False
25691,"Research the approach for XD Runtime on Mesos As a user, I need a document covering our recommendations for deploying a XD cluster using Mesos with the Marathon Framework. ",NULL,"Research the approach for XD Runtime on Mesos As a user, I need a document covering our recommendations for deploying a XD cluster using Mesos with the Marathon Framework. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25722,"Vary producers size DB 5 Use the number of consumers gave a maximum throughput in the previous test say 10 consumers , message size 100 bytes, Prefetch 100. Send 1M messages Vary the number of producers. Measure the msg sec rate and calculate the data transfer rate in MB sec. Number of producers 2 4 6 10 50 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",NULL,"Vary producers size DB 5 Use the number of consumers gave a maximum throughput in the previous test say 10 consumers , message size 100 bytes, Prefetch 100. Send 1M messages Vary the number of producers. Measure the msg sec rate and calculate the data transfer rate in MB sec. Number of producers 2 4 6 10 50 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",NULL,"Add for who this story is","well_formed","no_role","high",False
25722,"Vary producers size DB 5 Use the number of consumers gave a maximum throughput in the previous test say 10 consumers , message size 100 bytes, Prefetch 100. Send 1M messages Vary the number of producers. Measure the msg sec rate and calculate the data transfer rate in MB sec. Number of producers 2 4 6 10 50 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",NULL,"Vary producers size DB 5 Use the number of consumers gave a maximum throughput in the previous test say 10 consumers , message size 100 bytes, Prefetch 100. Send 1M messages Vary the number of producers. Measure the msg sec rate and calculate the data transfer rate in MB sec. Number of producers 2 4 6 10 50 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",NULL,"Vary producers size DB 5 Use the number of consumers gave a maximum throughput in the previous test say 10 consumers , message size 100 bytes, Prefetch 100. Send 1M messages Vary the number of producers. Measure the msg sec rate<span class='highlight-text severity-high'> and </span>calculate the data transfer rate in MB sec. Number of producers 2 4 6 10 50 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.","atomic","conjunctions","high",False
25722,"Vary producers size DB 5 Use the number of consumers gave a maximum throughput in the previous test say 10 consumers , message size 100 bytes, Prefetch 100. Send 1M messages Vary the number of producers. Measure the msg sec rate and calculate the data transfer rate in MB sec. Number of producers 2 4 6 10 50 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",NULL,"Vary producers size DB 5 Use the number of consumers gave a maximum throughput in the previous test say 10 consumers , message size 100 bytes, Prefetch 100. Send 1M messages Vary the number of producers. Measure the msg sec rate and calculate the data transfer rate in MB sec. Number of producers 2 4 6 10 50 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",NULL,"Vary producers size DB 5 Use the number of consumers gave a maximum throughput in the previous test say 10 consumers , message size 100 bytes, Prefetch 100<span class='highlight-text severity-high'>. Send 1M messages Vary the number of producers. Measure the msg sec rate and calculate the data transfer rate in MB sec. Number of producers 2 4 6 10 50 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.</span>","minimal","punctuation","high",False
25720,"Vary message size DB 2 Use a single producer, single consumer, prefetch size 50. Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes. Vary the message size and measure the msg sec rate and calculate data transfer rate in MB sec. Message Sizes 100 bytes 1000 10,000 100,000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",NULL,"Vary message size DB 2 Use a single producer, single consumer, prefetch size 50. Send 1M messages and increase or decrease","so that a given test iteration takes about 2 minutes. Vary the message size and measure the msg sec rate and calculate data transfer rate in MB sec. Message Sizes 100 bytes 1000 10,000 100,000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.","Add for who this story is","well_formed","no_role","high",False
25720,"Vary message size DB 2 Use a single producer, single consumer, prefetch size 50. Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes. Vary the message size and measure the msg sec rate and calculate data transfer rate in MB sec. Message Sizes 100 bytes 1000 10,000 100,000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",NULL,"Vary message size DB 2 Use a single producer, single consumer, prefetch size 50. Send 1M messages and increase or decrease","so that a given test iteration takes about 2 minutes. Vary the message size and measure the msg sec rate and calculate data transfer rate in MB sec. Message Sizes 100 bytes 1000 10,000 100,000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.","Vary message size DB 2 Use a single producer, single consumer, prefetch size 50. Send 1M messages<span class='highlight-text severity-high'> and </span>increase<span class='highlight-text severity-high'> or </span>decrease so that a given test iteration takes about 2 minutes. Vary the message size and measure the msg sec rate and calculate data transfer rate in MB sec. Message Sizes 100 bytes 1000 10,000 100,000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.","atomic","conjunctions","high",False
25720,"Vary message size DB 2 Use a single producer, single consumer, prefetch size 50. Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes. Vary the message size and measure the msg sec rate and calculate data transfer rate in MB sec. Message Sizes 100 bytes 1000 10,000 100,000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",NULL,"Vary message size DB 2 Use a single producer, single consumer, prefetch size 50. Send 1M messages and increase or decrease","so that a given test iteration takes about 2 minutes. Vary the message size and measure the msg sec rate and calculate data transfer rate in MB sec. Message Sizes 100 bytes 1000 10,000 100,000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.","Vary message size DB 2 Use a single producer, single consumer, prefetch size 50<span class='highlight-text severity-high'>. Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes. Vary the message size and measure the msg sec rate and calculate data transfer rate in MB sec. Message Sizes 100 bytes 1000 10,000 100,000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.</span>","minimal","punctuation","high",False
25720,"Vary message size DB 2 Use a single producer, single consumer, prefetch size 50. Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes. Vary the message size and measure the msg sec rate and calculate data transfer rate in MB sec. Message Sizes 100 bytes 1000 10,000 100,000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",NULL,"Vary message size DB 2 Use a single producer, single consumer, prefetch size 50. Send 1M messages and increase or decrease","so that a given test iteration takes about 2 minutes. Vary the message size and measure the msg sec rate and calculate data transfer rate in MB sec. Message Sizes 100 bytes 1000 10,000 100,000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25727,"Create a maintenance branch As a developer, I'd like to have a maintenance branch so that I can commit MINOR release ex 1.0.2 code changes instead of committing to MASTER.",NULL,"Create a maintenance branch As a developer, I'd like to have a maintenance branch","so that I can commit MINOR release ex 1.0.2 code changes instead of committing to MASTER.","Add for who this story is","well_formed","no_role","high",False
25727,"Create a maintenance branch As a developer, I'd like to have a maintenance branch so that I can commit MINOR release ex 1.0.2 code changes instead of committing to MASTER.",NULL,"Create a maintenance branch As a developer, I'd like to have a maintenance branch","so that I can commit MINOR release ex 1.0.2 code changes instead of committing to MASTER.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25721,"Vary prefetch size DB 3 Use a single producer, single consumer, message size of 1000 bytes. Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes. Vary the prefetch size. Measure the msg sec rate and calculate the data transfer rate in MB sec. Prefetch Sizes 1 10 50 100 10000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",NULL,"Vary prefetch size DB 3 Use a single producer, single consumer, message size of 1000 bytes. Send 1M messages and increase or decrease","so that a given test iteration takes about 2 minutes. Vary the prefetch size. Measure the msg sec rate and calculate the data transfer rate in MB sec. Prefetch Sizes 1 10 50 100 10000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.","Add for who this story is","well_formed","no_role","high",False
25721,"Vary prefetch size DB 3 Use a single producer, single consumer, message size of 1000 bytes. Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes. Vary the prefetch size. Measure the msg sec rate and calculate the data transfer rate in MB sec. Prefetch Sizes 1 10 50 100 10000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",NULL,"Vary prefetch size DB 3 Use a single producer, single consumer, message size of 1000 bytes. Send 1M messages and increase or decrease","so that a given test iteration takes about 2 minutes. Vary the prefetch size. Measure the msg sec rate and calculate the data transfer rate in MB sec. Prefetch Sizes 1 10 50 100 10000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.","Vary prefetch size DB 3 Use a single producer, single consumer, message size of 1000 bytes. Send 1M messages<span class='highlight-text severity-high'> and </span>increase<span class='highlight-text severity-high'> or </span>decrease so that a given test iteration takes about 2 minutes. Vary the prefetch size. Measure the msg sec rate and calculate the data transfer rate in MB sec. Prefetch Sizes 1 10 50 100 10000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.","atomic","conjunctions","high",False
25721,"Vary prefetch size DB 3 Use a single producer, single consumer, message size of 1000 bytes. Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes. Vary the prefetch size. Measure the msg sec rate and calculate the data transfer rate in MB sec. Prefetch Sizes 1 10 50 100 10000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",NULL,"Vary prefetch size DB 3 Use a single producer, single consumer, message size of 1000 bytes. Send 1M messages and increase or decrease","so that a given test iteration takes about 2 minutes. Vary the prefetch size. Measure the msg sec rate and calculate the data transfer rate in MB sec. Prefetch Sizes 1 10 50 100 10000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.","Vary prefetch size DB 3 Use a single producer, single consumer, message size of 1000 bytes<span class='highlight-text severity-high'>. Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes. Vary the prefetch size. Measure the msg sec rate and calculate the data transfer rate in MB sec. Prefetch Sizes 1 10 50 100 10000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.</span>","minimal","punctuation","high",False
25721,"Vary prefetch size DB 3 Use a single producer, single consumer, message size of 1000 bytes. Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes. Vary the prefetch size. Measure the msg sec rate and calculate the data transfer rate in MB sec. Prefetch Sizes 1 10 50 100 10000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",NULL,"Vary prefetch size DB 3 Use a single producer, single consumer, message size of 1000 bytes. Send 1M messages and increase or decrease","so that a given test iteration takes about 2 minutes. Vary the prefetch size. Measure the msg sec rate and calculate the data transfer rate in MB sec. Prefetch Sizes 1 10 50 100 10000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25729,"Add s so they will be on the XD classpath This is needed for the use of the scheme to talk to HDFS over http.",NULL,"Add s","so they will be on the XD classpath This is needed for the use of the scheme to talk to HDFS over http.","Add for who this story is","well_formed","no_role","high",False
25729,"Add s so they will be on the XD classpath This is needed for the use of the scheme to talk to HDFS over http.",NULL,"Add s","so they will be on the XD classpath This is needed for the use of the scheme to talk to HDFS over http.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25723,"Research adding support for to configure Modules Please refer to the GH Issue reported here ",NULL,"Research adding support for to configure Modules Please refer to the GH Issue reported here ",NULL,"Add for who this story is","well_formed","no_role","high",False
25732,"Vary message size EC DB 2 Use a single producer, single consumer, prefetch size 50. Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes. Vary the message size and measure the msg sec rate and calculate data transfer rate in MB sec. Message Sizes 100 bytes 1000 10,000 100,000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",NULL,"Vary message size EC DB 2 Use a single producer, single consumer, prefetch size 50. Send 1M messages and increase or decrease","so that a given test iteration takes about 2 minutes. Vary the message size and measure the msg sec rate and calculate data transfer rate in MB sec. Message Sizes 100 bytes 1000 10,000 100,000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.","Add for who this story is","well_formed","no_role","high",False
25732,"Vary message size EC DB 2 Use a single producer, single consumer, prefetch size 50. Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes. Vary the message size and measure the msg sec rate and calculate data transfer rate in MB sec. Message Sizes 100 bytes 1000 10,000 100,000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",NULL,"Vary message size EC DB 2 Use a single producer, single consumer, prefetch size 50. Send 1M messages and increase or decrease","so that a given test iteration takes about 2 minutes. Vary the message size and measure the msg sec rate and calculate data transfer rate in MB sec. Message Sizes 100 bytes 1000 10,000 100,000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.","Vary message size EC DB 2 Use a single producer, single consumer, prefetch size 50. Send 1M messages<span class='highlight-text severity-high'> and </span>increase<span class='highlight-text severity-high'> or </span>decrease so that a given test iteration takes about 2 minutes. Vary the message size and measure the msg sec rate and calculate data transfer rate in MB sec. Message Sizes 100 bytes 1000 10,000 100,000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.","atomic","conjunctions","high",False
25732,"Vary message size EC DB 2 Use a single producer, single consumer, prefetch size 50. Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes. Vary the message size and measure the msg sec rate and calculate data transfer rate in MB sec. Message Sizes 100 bytes 1000 10,000 100,000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",NULL,"Vary message size EC DB 2 Use a single producer, single consumer, prefetch size 50. Send 1M messages and increase or decrease","so that a given test iteration takes about 2 minutes. Vary the message size and measure the msg sec rate and calculate data transfer rate in MB sec. Message Sizes 100 bytes 1000 10,000 100,000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.","Vary message size EC DB 2 Use a single producer, single consumer, prefetch size 50<span class='highlight-text severity-high'>. Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes. Vary the message size and measure the msg sec rate and calculate data transfer rate in MB sec. Message Sizes 100 bytes 1000 10,000 100,000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.</span>","minimal","punctuation","high",False
25732,"Vary message size EC DB 2 Use a single producer, single consumer, prefetch size 50. Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes. Vary the message size and measure the msg sec rate and calculate data transfer rate in MB sec. Message Sizes 100 bytes 1000 10,000 100,000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",NULL,"Vary message size EC DB 2 Use a single producer, single consumer, prefetch size 50. Send 1M messages and increase or decrease","so that a given test iteration takes about 2 minutes. Vary the message size and measure the msg sec rate and calculate data transfer rate in MB sec. Message Sizes 100 bytes 1000 10,000 100,000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25724,"Infrastructure for RabbitMQ Cluster DB Pre requisite for Rabbit MQ Benchmarks Infrastructure setup Configuration changes Tool chain setup",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25724,"Infrastructure for RabbitMQ Cluster DB Pre requisite for Rabbit MQ Benchmarks Infrastructure setup Configuration changes Tool chain setup",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25731,"Upgrade to Spring Integration 4.1.0 As to prepare for 1.1 release, we would like to upgrade to Spring Integration 4.1.0 RC so that we can leverage the new features, enhancement and bug fixes. ",NULL,"Upgrade to Spring Integration 4.1.0 As to prepare for 1.1 release, we would like to upgrade to Spring Integration 4.1.0 RC","so that we can leverage the new features, enhancement and bug fixes.","Add for who this story is","well_formed","no_role","high",False
25731,"Upgrade to Spring Integration 4.1.0 As to prepare for 1.1 release, we would like to upgrade to Spring Integration 4.1.0 RC so that we can leverage the new features, enhancement and bug fixes. ",NULL,"Upgrade to Spring Integration 4.1.0 As to prepare for 1.1 release, we would like to upgrade to Spring Integration 4.1.0 RC","so that we can leverage the new features, enhancement and bug fixes.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25725,"Infrastructure for RabbitMQ Cluster ECB Pre requisite for Rabbit MQ Benchmarks Infrastructure setup Configuration changes Tool chain setup IPerf",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25725,"Infrastructure for RabbitMQ Cluster ECB Pre requisite for Rabbit MQ Benchmarks Infrastructure setup Configuration changes Tool chain setup IPerf",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25728,"Remove deprecated functions As a follow up action from module registry refactoring we would have to clean up deprecated functions ex download of module definitions within our codebase. It may also be necessary to clean up Shell and Admin UI modules. ",NULL,"Remove deprecated functions As a follow up action from module registry refactoring we would have to clean up deprecated functions ex download of module definitions within our codebase. It may also be necessary to clean up Shell and Admin UI modules. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25728,"Remove deprecated functions As a follow up action from module registry refactoring we would have to clean up deprecated functions ex download of module definitions within our codebase. It may also be necessary to clean up Shell and Admin UI modules. ",NULL,"Remove deprecated functions As a follow up action from module registry refactoring we would have to clean up deprecated functions ex download of module definitions within our codebase. It may also be necessary to clean up Shell and Admin UI modules. ",NULL,"Remove deprecated functions As a follow up action from module registry refactoring we would have to clean up deprecated functions ex download of module definitions within our codebase<span class='highlight-text severity-high'>. It may also be necessary to clean up Shell and Admin UI modules. </span>","minimal","punctuation","high",False
25735,"Vary queue number on 32 core machine ECB 8 Rerun test XD 2278 on a EC2 32 core machine and see when we max out.",NULL,"Vary queue number on 32 core machine ECB 8 Rerun test XD 2278 on a EC2 32 core machine and see when we max out.",NULL,"Add for who this story is","well_formed","no_role","high",False
25735,"Vary queue number on 32 core machine ECB 8 Rerun test XD 2278 on a EC2 32 core machine and see when we max out.",NULL,"Vary queue number on 32 core machine ECB 8 Rerun test XD 2278 on a EC2 32 core machine and see when we max out.",NULL,"Vary queue number on 32 core machine ECB 8 Rerun test XD 2278 on a EC2 32 core machine<span class='highlight-text severity-high'> and </span>see when we max out.","atomic","conjunctions","high",False
25739,"Review POC and identify scope for gpload as OOTB Batch Job As a user, I'd like to mass ingest data from databases and others into so that I don t have to write custom code and as well as be able to ingest in an efficient way.",NULL,"Review POC and identify scope for gpload as OOTB Batch Job As a user, I'd like to mass ingest data from databases and others into","so that I don t have to write custom code and as well as be able to ingest in an efficient way.","Add for who this story is","well_formed","no_role","high",False
25739,"Review POC and identify scope for gpload as OOTB Batch Job As a user, I'd like to mass ingest data from databases and others into so that I don t have to write custom code and as well as be able to ingest in an efficient way.",NULL,"Review POC and identify scope for gpload as OOTB Batch Job As a user, I'd like to mass ingest data from databases and others into","so that I don t have to write custom code and as well as be able to ingest in an efficient way.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25741,"add file source and sink modules ",NULL,"add file source and sink modules ",NULL,"Add for who this story is","well_formed","no_role","high",False
25737,"Add RabbitMQ based implementation of ChannelRegistry ",NULL,"Add RabbitMQ based implementation of ChannelRegistry ",NULL,"Add for who this story is","well_formed","no_role","high",False
25738,"Add config parameter to enable disable message rates in cluster view As a user, I'd like to have a config parameter preferably in servers.yml file so that I can enable disable message rates in the cluster view. ",NULL,"Add config parameter to enable disable message rates in cluster view As a user, I'd like to have a config parameter preferably in servers.yml file","so that I can enable disable message rates in the cluster view.","Add for who this story is","well_formed","no_role","high",False
25738,"Add config parameter to enable disable message rates in cluster view As a user, I'd like to have a config parameter preferably in servers.yml file so that I can enable disable message rates in the cluster view. ",NULL,"Add config parameter to enable disable message rates in cluster view As a user, I'd like to have a config parameter preferably in servers.yml file","so that I can enable disable message rates in the cluster view.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25742,"Add RabbitMQ source module configurable parameters should include the queue name s and optional binding key pattern connection info, such as host and port, should also be configurable but with defaults localhost and default port , and that should likely fallback to a rabbit.properties file in the XD HOME config directory",NULL,"Add RabbitMQ source module configurable parameters should include the queue name s and optional binding key pattern connection info, such as host and port, should also be configurable but with defaults localhost and default port , and that should likely fallback to a rabbit.properties file in the XD HOME config directory",NULL,"Add for who this story is","well_formed","no_role","high",False
25742,"Add RabbitMQ source module configurable parameters should include the queue name s and optional binding key pattern connection info, such as host and port, should also be configurable but with defaults localhost and default port , and that should likely fallback to a rabbit.properties file in the XD HOME config directory",NULL,"Add RabbitMQ source module configurable parameters should include the queue name s and optional binding key pattern connection info, such as host and port, should also be configurable but with defaults localhost and default port , and that should likely fallback to a rabbit.properties file in the XD HOME config directory",NULL,"Add RabbitMQ source module configurable parameters should include the queue name s<span class='highlight-text severity-high'> and </span>optional binding key pattern connection info, such as host and port, should also be configurable but with defaults localhost and default port , and that should likely fallback to a rabbit.properties file in the XD HOME config directory","atomic","conjunctions","high",False
25740,"Placeholder for 1.0.2 and 1.1M1 release testing effort ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25740,"Placeholder for 1.0.2 and 1.1M1 release testing effort ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25744,"UI Update AngularJS to v1.3 ",NULL,"UI Update AngularJS to v1.3 ",NULL,"Add for who this story is","well_formed","no_role","high",False
25743,"Research Spark integration options Spike scope Brainstorm Identify options Document ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25743,"Research Spark integration options Spike scope Brainstorm Identify options Document ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25745,"Research refactoring effort for Kafka source to use simple consumer instead of high level API As a user, I'd like to use Kafka source through simple consumer API as opposed to high level so that I can gain full control to offsets and partition assignment deterministically. Spike scope Study simple consumer API functionality Document findings, approach and next steps",NULL,"Research refactoring effort for Kafka source to use simple consumer instead of high level API As a user, I'd like to use Kafka source through simple consumer API as opposed to high level","so that I can gain full control to offsets and partition assignment deterministically. Spike scope Study simple consumer API functionality Document findings, approach and next steps","Add for who this story is","well_formed","no_role","high",False
25745,"Research refactoring effort for Kafka source to use simple consumer instead of high level API As a user, I'd like to use Kafka source through simple consumer API as opposed to high level so that I can gain full control to offsets and partition assignment deterministically. Spike scope Study simple consumer API functionality Document findings, approach and next steps",NULL,"Research refactoring effort for Kafka source to use simple consumer instead of high level API As a user, I'd like to use Kafka source through simple consumer API as opposed to high level","so that I can gain full control to offsets and partition assignment deterministically. Spike scope Study simple consumer API functionality Document findings, approach and next steps","Research refactoring effort for Kafka source to use simple consumer instead of high level API As a user, I'd like to use Kafka source through simple consumer API as opposed to high level so that I can gain full control to offsets and partition assignment deterministically<span class='highlight-text severity-high'>. Spike scope Study simple consumer API functionality Document findings, approach and next steps</span>","minimal","punctuation","high",False
25745,"Research refactoring effort for Kafka source to use simple consumer instead of high level API As a user, I'd like to use Kafka source through simple consumer API as opposed to high level so that I can gain full control to offsets and partition assignment deterministically. Spike scope Study simple consumer API functionality Document findings, approach and next steps",NULL,"Research refactoring effort for Kafka source to use simple consumer instead of high level API As a user, I'd like to use Kafka source through simple consumer API as opposed to high level","so that I can gain full control to offsets and partition assignment deterministically. Spike scope Study simple consumer API functionality Document findings, approach and next steps","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25749,"Add Twitter gardenhose source module we have a prototype gardenhose adapter that was built directly upon RestTemplate streaming on a background thread , but Spring Social Twitter has an issue on its 1.1 roadmap that is relevant ",NULL,"Add Twitter gardenhose source module we have a prototype gardenhose adapter that was built directly upon RestTemplate streaming on a background thread , but Spring Social Twitter has an issue on its 1.1 roadmap that is relevant ",NULL,"Add for who this story is","well_formed","no_role","high",False
25746,"Add via a REST API so that I can install the custom module in cluster. ",NULL,"Add via a REST API","so that I can install the custom module in cluster.","Add for who this story is","well_formed","no_role","high",False
25746,"Add via a REST API so that I can install the custom module in cluster. ",NULL,"Add via a REST API","so that I can install the custom module in cluster.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25748,"Create sample app to demonstrate Kafka integration As a user, I'd like to have a sample app GitHub project so that I can use it as a reference while provisioning Spring XD cluster with Kafka. Consider Kafka as message bus Kafka as source ",NULL,"Create sample app to demonstrate Kafka integration As a user, I'd like to have a sample app GitHub project","so that I can use it as a reference while provisioning Spring XD cluster with Kafka. Consider Kafka as message bus Kafka as source","Add for who this story is","well_formed","no_role","high",False
25748,"Create sample app to demonstrate Kafka integration As a user, I'd like to have a sample app GitHub project so that I can use it as a reference while provisioning Spring XD cluster with Kafka. Consider Kafka as message bus Kafka as source ",NULL,"Create sample app to demonstrate Kafka integration As a user, I'd like to have a sample app GitHub project","so that I can use it as a reference while provisioning Spring XD cluster with Kafka. Consider Kafka as message bus Kafka as source","Create sample app to demonstrate Kafka integration As a user, I'd like to have a sample app GitHub project so that I can use it as a reference while provisioning Spring XD cluster with Kafka<span class='highlight-text severity-high'>. Consider Kafka as message bus Kafka as source </span>","minimal","punctuation","high",False
25748,"Create sample app to demonstrate Kafka integration As a user, I'd like to have a sample app GitHub project so that I can use it as a reference while provisioning Spring XD cluster with Kafka. Consider Kafka as message bus Kafka as source ",NULL,"Create sample app to demonstrate Kafka integration As a user, I'd like to have a sample app GitHub project","so that I can use it as a reference while provisioning Spring XD cluster with Kafka. Consider Kafka as message bus Kafka as source","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25734,"Vary producer size EC DB 5 Use the number of consumers gave a maximum throughput in the previous test say 10 consumers , message size 100 bytes, Prefetch 100. Send 1M messages Vary the number of producers. Measure the msg sec rate and calculate the data transfer rate in MB sec. Number of producers 2 4 6 10 50 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",NULL,"Vary producer size EC DB 5 Use the number of consumers gave a maximum throughput in the previous test say 10 consumers , message size 100 bytes, Prefetch 100. Send 1M messages Vary the number of producers. Measure the msg sec rate and calculate the data transfer rate in MB sec. Number of producers 2 4 6 10 50 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",NULL,"Add for who this story is","well_formed","no_role","high",False
25734,"Vary producer size EC DB 5 Use the number of consumers gave a maximum throughput in the previous test say 10 consumers , message size 100 bytes, Prefetch 100. Send 1M messages Vary the number of producers. Measure the msg sec rate and calculate the data transfer rate in MB sec. Number of producers 2 4 6 10 50 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",NULL,"Vary producer size EC DB 5 Use the number of consumers gave a maximum throughput in the previous test say 10 consumers , message size 100 bytes, Prefetch 100. Send 1M messages Vary the number of producers. Measure the msg sec rate and calculate the data transfer rate in MB sec. Number of producers 2 4 6 10 50 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",NULL,"Vary producer size EC DB 5 Use the number of consumers gave a maximum throughput in the previous test say 10 consumers , message size 100 bytes, Prefetch 100. Send 1M messages Vary the number of producers. Measure the msg sec rate<span class='highlight-text severity-high'> and </span>calculate the data transfer rate in MB sec. Number of producers 2 4 6 10 50 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.","atomic","conjunctions","high",False
25734,"Vary producer size EC DB 5 Use the number of consumers gave a maximum throughput in the previous test say 10 consumers , message size 100 bytes, Prefetch 100. Send 1M messages Vary the number of producers. Measure the msg sec rate and calculate the data transfer rate in MB sec. Number of producers 2 4 6 10 50 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",NULL,"Vary producer size EC DB 5 Use the number of consumers gave a maximum throughput in the previous test say 10 consumers , message size 100 bytes, Prefetch 100. Send 1M messages Vary the number of producers. Measure the msg sec rate and calculate the data transfer rate in MB sec. Number of producers 2 4 6 10 50 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",NULL,"Vary producer size EC DB 5 Use the number of consumers gave a maximum throughput in the previous test say 10 consumers , message size 100 bytes, Prefetch 100<span class='highlight-text severity-high'>. Send 1M messages Vary the number of producers. Measure the msg sec rate and calculate the data transfer rate in MB sec. Number of producers 2 4 6 10 50 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.</span>","minimal","punctuation","high",False
25736,"Simple OOTB job for testing Similar to , we should ship a simple batch job that appends a timestamp to a file. This will make it much easier to validate job functionality, especially in automated tests.",NULL,"Simple OOTB job for testing Similar to , we should ship a simple batch job that appends a timestamp to a file. This will make it much easier to validate job functionality, especially in automated tests.",NULL,"Add for who this story is","well_formed","no_role","high",False
25736,"Simple OOTB job for testing Similar to , we should ship a simple batch job that appends a timestamp to a file. This will make it much easier to validate job functionality, especially in automated tests.",NULL,"Simple OOTB job for testing Similar to , we should ship a simple batch job that appends a timestamp to a file. This will make it much easier to validate job functionality, especially in automated tests.",NULL,"Simple OOTB job for testing Similar to , we should ship a simple batch job that appends a timestamp to a file<span class='highlight-text severity-high'>. This will make it much easier to validate job functionality, especially in automated tests.</span>","minimal","punctuation","high",False
25747,"Add support for PHD 2.1 XD 1.1 M1 Release XD 1.1 M1 Release PHD 2.1 Upgrade Action Items Update to SHDP 2.1.M2, Add Hadoop 2.5 hadoop25 Remove hadoop22 Remove PHD 1.0 phd1 Change PHD 2.x from phd20 to phd21 Test PHD 2.0 with phd21",NULL,"Add support for PHD 2.1 XD 1.1 M1 Release XD 1.1 M1 Release PHD 2.1 Upgrade Action Items Update to SHDP 2.1.M2, Add Hadoop 2.5 hadoop25 Remove hadoop22 Remove PHD 1.0 phd1 Change PHD 2.x from phd20 to phd21 Test PHD 2.0 with phd21",NULL,"Add for who this story is","well_formed","no_role","high",False
25759,"AdminUI Provide Server Side Cron Expression Validation It is easy to get a cron expression wrong. Provide validation of the cron expression on the Schedule Job page using async validation. Submit the cron expression to the server side and validate that the expression is valid. Send a success message back we may even send back some meta data e.g. when is the next execution going to take place ",NULL,"AdminUI Provide Server Side Cron Expression Validation It is easy to get a cron expression wrong. Provide validation of the cron expression on the Schedule Job page using async validation. Submit the cron expression to the server side and validate that the expression is valid. Send a success message back we may even send back some meta data e.g. when is the next execution going to take place ",NULL,"Add for who this story is","well_formed","no_role","high",False
25759,"AdminUI Provide Server Side Cron Expression Validation It is easy to get a cron expression wrong. Provide validation of the cron expression on the Schedule Job page using async validation. Submit the cron expression to the server side and validate that the expression is valid. Send a success message back we may even send back some meta data e.g. when is the next execution going to take place ",NULL,"AdminUI Provide Server Side Cron Expression Validation It is easy to get a cron expression wrong. Provide validation of the cron expression on the Schedule Job page using async validation. Submit the cron expression to the server side and validate that the expression is valid. Send a success message back we may even send back some meta data e.g. when is the next execution going to take place ",NULL,"AdminUI Provide Server Side Cron Expression Validation It is easy to get a cron expression wrong. Provide validation of the cron expression on the Schedule Job page using async validation. Submit the cron expression to the server side<span class='highlight-text severity-high'> and </span>validate that the expression is valid. Send a success message back we may even send back some meta data e.g. when is the next execution going to take place ","atomic","conjunctions","high",False
25759,"AdminUI Provide Server Side Cron Expression Validation It is easy to get a cron expression wrong. Provide validation of the cron expression on the Schedule Job page using async validation. Submit the cron expression to the server side and validate that the expression is valid. Send a success message back we may even send back some meta data e.g. when is the next execution going to take place ",NULL,"AdminUI Provide Server Side Cron Expression Validation It is easy to get a cron expression wrong. Provide validation of the cron expression on the Schedule Job page using async validation. Submit the cron expression to the server side and validate that the expression is valid. Send a success message back we may even send back some meta data e.g. when is the next execution going to take place ",NULL,"AdminUI Provide Server Side Cron Expression Validation It is easy to get a cron expression wrong<span class='highlight-text severity-high'>. Provide validation of the cron expression on the Schedule Job page using async validation. Submit the cron expression to the server side and validate that the expression is valid. Send a success message back we may even send back some meta data e.g. when is the next execution going to take place </span>","minimal","punctuation","high",False
25751,"Add Greenplum Sink User should have the option of Greenplum DB sink so they can write data directly to Greenplum DB via the pgfdist gploader Greenplum bulk loader . The existing JDBC sinks are not suitable for high volume loads. The JDBC approach utilizes the master segment of Greenplum for loading datasets instead of the bulk loader utility.",NULL,"Add Greenplum Sink User should have the option of Greenplum DB sink","so they can write data directly to Greenplum DB via the pgfdist gploader Greenplum bulk loader . The existing JDBC sinks are not suitable for high volume loads. The JDBC approach utilizes the master segment of Greenplum for loading datasets instead of the bulk loader utility.","Add for who this story is","well_formed","no_role","high",False
25751,"Add Greenplum Sink User should have the option of Greenplum DB sink so they can write data directly to Greenplum DB via the pgfdist gploader Greenplum bulk loader . The existing JDBC sinks are not suitable for high volume loads. The JDBC approach utilizes the master segment of Greenplum for loading datasets instead of the bulk loader utility.",NULL,"Add Greenplum Sink User should have the option of Greenplum DB sink","so they can write data directly to Greenplum DB via the pgfdist gploader Greenplum bulk loader . The existing JDBC sinks are not suitable for high volume loads. The JDBC approach utilizes the master segment of Greenplum for loading datasets instead of the bulk loader utility.","Add Greenplum Sink User should have the option of Greenplum DB sink so they can write data directly to Greenplum DB via the pgfdist gploader Greenplum bulk loader <span class='highlight-text severity-high'>. The existing JDBC sinks are not suitable for high volume loads. The JDBC approach utilizes the master segment of Greenplum for loading datasets instead of the bulk loader utility.</span>","minimal","punctuation","high",False
25751,"Add Greenplum Sink User should have the option of Greenplum DB sink so they can write data directly to Greenplum DB via the pgfdist gploader Greenplum bulk loader . The existing JDBC sinks are not suitable for high volume loads. The JDBC approach utilizes the master segment of Greenplum for loading datasets instead of the bulk loader utility.",NULL,"Add Greenplum Sink User should have the option of Greenplum DB sink","so they can write data directly to Greenplum DB via the pgfdist gploader Greenplum bulk loader . The existing JDBC sinks are not suitable for high volume loads. The JDBC approach utilizes the master segment of Greenplum for loading datasets instead of the bulk loader utility.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25757,"Update Hadoop in CI machines Placeholder to update to Apache 2.5.1 on CI machines. Next steps It looks like the still file has 2.2.0; update it to 2.5.1 I guess we just bumped the spring data hadoop dependency; check for relevant other dependencies ",NULL,"Update Hadoop in CI machines Placeholder to update to Apache 2.5.1 on CI machines. Next steps It looks like the still file has 2.2.0; update it to 2.5.1 I guess we just bumped the spring data hadoop dependency; check for relevant other dependencies ",NULL,"Add for who this story is","well_formed","no_role","high",False
25757,"Update Hadoop in CI machines Placeholder to update to Apache 2.5.1 on CI machines. Next steps It looks like the still file has 2.2.0; update it to 2.5.1 I guess we just bumped the spring data hadoop dependency; check for relevant other dependencies ",NULL,"Update Hadoop in CI machines Placeholder to update to Apache 2.5.1 on CI machines. Next steps It looks like the still file has 2.2.0; update it to 2.5.1 I guess we just bumped the spring data hadoop dependency; check for relevant other dependencies ",NULL,"Update Hadoop in CI machines Placeholder to update to Apache 2<span class='highlight-text severity-high'>.5.1 on CI machines. Next steps It looks like the still file has 2.2.0; update it to 2.5.1 I guess we just bumped the spring data hadoop dependency; check for relevant other dependencies </span>","minimal","punctuation","high",False
25755,"UI Create a dedicated scheduling page for Jobs Create a dedicated Scheduling Page for Jobs. Currently we create a form underneath the deployments table. That is a bit unwieldy when many deployed jobs are shown in the table. Similar to XD 2320",NULL,"UI Create a dedicated scheduling page for Jobs Create a dedicated Scheduling Page for Jobs. Currently we create a form underneath the deployments table. That is a bit unwieldy when many deployed jobs are shown in the table. Similar to XD 2320",NULL,"Add for who this story is","well_formed","no_role","high",False
25755,"UI Create a dedicated scheduling page for Jobs Create a dedicated Scheduling Page for Jobs. Currently we create a form underneath the deployments table. That is a bit unwieldy when many deployed jobs are shown in the table. Similar to XD 2320",NULL,"UI Create a dedicated scheduling page for Jobs Create a dedicated Scheduling Page for Jobs. Currently we create a form underneath the deployments table. That is a bit unwieldy when many deployed jobs are shown in the table. Similar to XD 2320",NULL,"UI Create a dedicated scheduling page for Jobs Create a dedicated Scheduling Page for Jobs<span class='highlight-text severity-high'>. Currently we create a form underneath the deployments table. That is a bit unwieldy when many deployed jobs are shown in the table. Similar to XD 2320</span>","minimal","punctuation","high",False
25762,"Upgrade to Gradle 2.2 Looks like upgrade to Gradle 2.2 is not a simple version change, e.g. I see FAILURE Build failed with an exception. Where Build file line 219 What went wrong A problem occurred evaluating root project spring xd . Could not find method for arguments project on root project spring xd . ",NULL,"Upgrade to Gradle 2.2 Looks like upgrade to Gradle 2.2 is not a simple version change, e.g. I see FAILURE Build failed with an exception. Where Build file line 219 What went wrong A problem occurred evaluating root project spring xd . Could not find method for arguments project on root project spring xd . ",NULL,"Add for who this story is","well_formed","no_role","high",False
25762,"Upgrade to Gradle 2.2 Looks like upgrade to Gradle 2.2 is not a simple version change, e.g. I see FAILURE Build failed with an exception. Where Build file line 219 What went wrong A problem occurred evaluating root project spring xd . Could not find method for arguments project on root project spring xd . ",NULL,"Upgrade to Gradle 2.2 Looks like upgrade to Gradle 2.2 is not a simple version change, e.g. I see FAILURE Build failed with an exception. Where Build file line 219 What went wrong A problem occurred evaluating root project spring xd . Could not find method for arguments project on root project spring xd . ",NULL,"Upgrade to Gradle 2<span class='highlight-text severity-high'>.2 Looks like upgrade to Gradle 2.2 is not a simple version change, e.g. I see FAILURE Build failed with an exception. Where Build file line 219 What went wrong A problem occurred evaluating root project spring xd . Could not find method for arguments project on root project spring xd . </span>","minimal","punctuation","high",False
25756,"Set auto startup to false in Kafka source We have to explicitly set it to false, in order to avoid an early start of the poller and the associated ",NULL,"Set auto startup to false in Kafka source We have to explicitly set it to false,","in order to avoid an early start of the poller and the associated","Add for who this story is","well_formed","no_role","high",False
25756,"Set auto startup to false in Kafka source We have to explicitly set it to false, in order to avoid an early start of the poller and the associated ",NULL,"Set auto startup to false in Kafka source We have to explicitly set it to false,","in order to avoid an early start of the poller and the associated","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25758,"Zip created by Publish 1.1 only contains the shell. XD, gemfire, directories in the zip file are missing.",NULL,"Zip created by Publish 1.1 only contains the shell. XD, gemfire, directories in the zip file are missing.",NULL,"Add for who this story is","well_formed","no_role","high",False
25758,"Zip created by Publish 1.1 only contains the shell. XD, gemfire, directories in the zip file are missing.",NULL,"Zip created by Publish 1.1 only contains the shell. XD, gemfire, directories in the zip file are missing.",NULL,"Zip created by Publish 1<span class='highlight-text severity-high'>.1 only contains the shell. XD, gemfire, directories in the zip file are missing.</span>","minimal","punctuation","high",False
25761,"Update Performance AMI to include Kafka Create an AMI that will contain the Kafka Executable as well as the Kafka performance test tools.",NULL,"Update Performance AMI to include Kafka Create an AMI that will contain the Kafka Executable as well as the Kafka performance test tools.",NULL,"Add for who this story is","well_formed","no_role","high",False
25753,"Add spring xd python to the distribution ",NULL,"Add spring xd python to the distribution ",NULL,"Add for who this story is","well_formed","no_role","high",False
25752,"Create Boot Starters for Modules Create various boot starter projects for module developers. This should include templates for source, processor, sink, and job and ideally different options for each. For example, a processor configured with XML, SI Java DSL, or SI Java DSL with lambdas. ",NULL,"Create Boot Starters for Modules Create various boot starter projects for module developers. This should include templates for source, processor, sink, and job and ideally different options for each. For example, a processor configured with XML, SI Java DSL, or SI Java DSL with lambdas. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25786,"Create pipes and filters DSL for ingestion Initial simple handcoded implementation for straight through pipe and filter model, e.g. a b c",NULL,"Create pipes and filters DSL for ingestion Initial simple handcoded implementation for straight through pipe and filter model, e.g. a b c",NULL,"Add for who this story is","well_formed","no_role","high",False
26066,"Add a new variation of DSL parser for Flo As a Flo developer, I'd like to have a new DSL parser, so I can easily detect incorrect module option values when supplied from the Flo UI. Example MyStream mail log log If parsed separately which Flo UI does , the current parser endpoint will barf on the second stream because it doesn t know about the first stream MyStream . ",NULL,"Add a new variation of DSL parser for Flo As a Flo developer, I'd like to have a new DSL parser,","so I can easily detect incorrect module option values when supplied from the Flo UI. Example MyStream mail log log If parsed separately which Flo UI does , the current parser endpoint will barf on the second stream because it doesn t know about the first stream MyStream .","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26070,"Create a simple counter service A simple counters can a number. Implementations for in memory and redis.",NULL,"Create a simple counter service A simple counters can a number. Implementations for in memory and redis.",NULL,"Add for who this story is","well_formed","no_role","high",False
25752,"Create Boot Starters for Modules Create various boot starter projects for module developers. This should include templates for source, processor, sink, and job and ideally different options for each. For example, a processor configured with XML, SI Java DSL, or SI Java DSL with lambdas. ",NULL,"Create Boot Starters for Modules Create various boot starter projects for module developers. This should include templates for source, processor, sink, and job and ideally different options for each. For example, a processor configured with XML, SI Java DSL, or SI Java DSL with lambdas. ",NULL,"Create Boot Starters for Modules Create various boot starter projects for module developers. This should include templates for source, processor, sink,<span class='highlight-text severity-high'> and </span>job and ideally different options for each. For example, a processor configured with XML, SI Java DSL,<span class='highlight-text severity-high'> or </span>SI Java DSL with lambdas. ","atomic","conjunctions","high",False
25752,"Create Boot Starters for Modules Create various boot starter projects for module developers. This should include templates for source, processor, sink, and job and ideally different options for each. For example, a processor configured with XML, SI Java DSL, or SI Java DSL with lambdas. ",NULL,"Create Boot Starters for Modules Create various boot starter projects for module developers. This should include templates for source, processor, sink, and job and ideally different options for each. For example, a processor configured with XML, SI Java DSL, or SI Java DSL with lambdas. ",NULL,"Create Boot Starters for Modules Create various boot starter projects for module developers<span class='highlight-text severity-high'>. This should include templates for source, processor, sink, and job and ideally different options for each. For example, a processor configured with XML, SI Java DSL, or SI Java DSL with lambdas. </span>","minimal","punctuation","high",False
25760,"Add test coverage for Kafka source and sink modules As a PM, I'd like to have test coverage for both Kafka source and sink modules so that we can assert its functionality as part of the CI builds. ",NULL,"Add test coverage for Kafka source and sink modules As a PM, I'd like to have test coverage for both Kafka source and sink modules","so that we can assert its functionality as part of the CI builds.","Add for who this story is","well_formed","no_role","high",False
25760,"Add test coverage for Kafka source and sink modules As a PM, I'd like to have test coverage for both Kafka source and sink modules so that we can assert its functionality as part of the CI builds. ",NULL,"Add test coverage for Kafka source and sink modules As a PM, I'd like to have test coverage for both Kafka source and sink modules","so that we can assert its functionality as part of the CI builds.","Add test coverage for Kafka source<span class='highlight-text severity-high'> and </span>sink modules As a PM, I'd like to have test coverage for both Kafka source and sink modules so that we can assert its functionality as part of the CI builds. ","atomic","conjunctions","high",False
25760,"Add test coverage for Kafka source and sink modules As a PM, I'd like to have test coverage for both Kafka source and sink modules so that we can assert its functionality as part of the CI builds. ",NULL,"Add test coverage for Kafka source and sink modules As a PM, I'd like to have test coverage for both Kafka source and sink modules","so that we can assert its functionality as part of the CI builds.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25754,"UI Create a dedicated Launch Page for Jobs Create a dedicated Launch Page for Jobs. Currently we create a launch form underneath the deployments table. That is a bit unwieldy when many deployed jobs are shown in the table.",NULL,"UI Create a dedicated Launch Page for Jobs Create a dedicated Launch Page for Jobs. Currently we create a launch form underneath the deployments table. That is a bit unwieldy when many deployed jobs are shown in the table.",NULL,"Add for who this story is","well_formed","no_role","high",False
25754,"UI Create a dedicated Launch Page for Jobs Create a dedicated Launch Page for Jobs. Currently we create a launch form underneath the deployments table. That is a bit unwieldy when many deployed jobs are shown in the table.",NULL,"UI Create a dedicated Launch Page for Jobs Create a dedicated Launch Page for Jobs. Currently we create a launch form underneath the deployments table. That is a bit unwieldy when many deployed jobs are shown in the table.",NULL,"UI Create a dedicated Launch Page for Jobs Create a dedicated Launch Page for Jobs<span class='highlight-text severity-high'>. Currently we create a launch form underneath the deployments table. That is a bit unwieldy when many deployed jobs are shown in the table.</span>","minimal","punctuation","high",False
25764,"Ensure that branch specific documentation is pulled and generated ",NULL,"Ensure that branch specific documentation is pulled and generated ",NULL,"Add for who this story is","well_formed","no_role","high",False
25764,"Ensure that branch specific documentation is pulled and generated ",NULL,"Ensure that branch specific documentation is pulled and generated ",NULL,"Ensure that branch specific documentation is pulled<span class='highlight-text severity-high'> and </span>generated ","atomic","conjunctions","high",False
25766,"POM generation creates the correct dependency list We are referencing Spring.IO deps when we shouldn t since we moved to a different version of boot than in in the platform .",NULL,"POM generation creates the correct dependency list We are referencing Spring.IO deps when we shouldn t since we moved to a different version of boot than in in the platform .",NULL,"Add for who this story is","well_formed","no_role","high",False
25765,"Document 1.1 major features As a user, I'd like to refer to documentation in wiki so that I can configure the new sources, sinks and processor modules and as well as any new features. ",NULL,"Document 1.1 major features As a user, I'd like to refer to documentation in wiki","so that I can configure the new sources, sinks and processor modules and as well as any new features.","Add for who this story is","well_formed","no_role","high",False
25765,"Document 1.1 major features As a user, I'd like to refer to documentation in wiki so that I can configure the new sources, sinks and processor modules and as well as any new features. ",NULL,"Document 1.1 major features As a user, I'd like to refer to documentation in wiki","so that I can configure the new sources, sinks and processor modules and as well as any new features.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25767,"Property replacement does not happen in XML class attribute After updating to Boot 1.2 RC1 the following replacement doesn t work. bean class which appears in the rabbit source and sink. Feels like a core spring thing, but that was updated earlier. Current workaround that was commited already so the build can pass is bean id clazz constructor arg value bean bean ",NULL,"Property replacement does not happen in XML class attribute After updating to Boot 1.2 RC1 the following replacement doesn t work. bean class which appears in the rabbit","source and sink. Feels like a core spring thing, but that was updated earlier. Current workaround that was commited already so the build can pass is bean id clazz constructor arg value bean bean","Add for who this story is","well_formed","no_role","high",False
25767,"Property replacement does not happen in XML class attribute After updating to Boot 1.2 RC1 the following replacement doesn t work. bean class which appears in the rabbit source and sink. Feels like a core spring thing, but that was updated earlier. Current workaround that was commited already so the build can pass is bean id clazz constructor arg value bean bean ",NULL,"Property replacement does not happen in XML class attribute After updating to Boot 1.2 RC1 the following replacement doesn t work. bean class which appears in the rabbit","source and sink. Feels like a core spring thing, but that was updated earlier. Current workaround that was commited already so the build can pass is bean id clazz constructor arg value bean bean","Property replacement does not happen in XML class attribute After updating to Boot 1<span class='highlight-text severity-high'>.2 RC1 the following replacement doesn t work. bean class which appears in the rabbit source and sink. Feels like a core spring thing, but that was updated earlier. Current workaround that was commited already so the build can pass is bean id clazz constructor arg value bean bean </span>","minimal","punctuation","high",False
25767,"Property replacement does not happen in XML class attribute After updating to Boot 1.2 RC1 the following replacement doesn t work. bean class which appears in the rabbit source and sink. Feels like a core spring thing, but that was updated earlier. Current workaround that was commited already so the build can pass is bean id clazz constructor arg value bean bean ",NULL,"Property replacement does not happen in XML class attribute After updating to Boot 1.2 RC1 the following replacement doesn t work. bean class which appears in the rabbit","source and sink. Feels like a core spring thing, but that was updated earlier. Current workaround that was commited already so the build can pass is bean id clazz constructor arg value bean bean","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25768,"EC2 Integration Tests fail after Boot 1.2 upgrade Many of the tests fail with Cannot find template location class path resource please add some templates, check your Groovy configuration, or set Somehow we need to disable this check, using the property suggested.",NULL,"EC2 Integration Tests fail after Boot 1.2 upgrade Many of the tests fail with Cannot find template location class path resource please add some templates, check your Groovy configuration, or set Somehow we need to disable this check, using the property suggested.",NULL,"Add for who this story is","well_formed","no_role","high",False
25768,"EC2 Integration Tests fail after Boot 1.2 upgrade Many of the tests fail with Cannot find template location class path resource please add some templates, check your Groovy configuration, or set Somehow we need to disable this check, using the property suggested.",NULL,"EC2 Integration Tests fail after Boot 1.2 upgrade Many of the tests fail with Cannot find template location class path resource please add some templates, check your Groovy configuration, or set Somehow we need to disable this check, using the property suggested.",NULL,"EC2 Integration Tests fail after Boot 1.2 upgrade Many of the tests fail with Cannot find template location class path resource please add some templates, check your Groovy configuration,<span class='highlight-text severity-high'> or </span>set Somehow we need to disable this check, using the property suggested.","atomic","conjunctions","high",False
25772,"Created Acceptance CI test environment for 1.0.x Create the infrastructure Mongo, Hadoop, ActiveMQ, Gemfire, Mysql, etc in EC2 for the 1.0.2 acceptance tests Retrofit the 1.0.2 to use the new infrastructure Create a 1.0.2 branch for XD EC2",NULL,"Created Acceptance CI test environment for 1.0.x Create the infrastructure Mongo, Hadoop, ActiveMQ, Gemfire, Mysql, etc in EC2 for the 1.0.2 acceptance tests Retrofit the 1.0.2 to use the new infrastructure Create a 1.0.2 branch for XD EC2",NULL,"Add for who this story is","well_formed","no_role","high",False
25770,"Pre allocate partitions for Kafka source As a user, I want Spring XD to pre allocate a set of partitions between the Kafka source modules when a stream is deployed, so that deployment is simpler, and rebalancing doesn t take place. ",NULL,"Pre allocate partitions for Kafka source As a user, I want Spring XD to pre allocate a set of partitions between the Kafka source modules when a stream is deployed,","so that deployment is simpler, and rebalancing doesn t take place.","Add for who this story is","well_formed","no_role","high",False
25770,"Pre allocate partitions for Kafka source As a user, I want Spring XD to pre allocate a set of partitions between the Kafka source modules when a stream is deployed, so that deployment is simpler, and rebalancing doesn t take place. ",NULL,"Pre allocate partitions for Kafka source As a user, I want Spring XD to pre allocate a set of partitions between the Kafka source modules when a stream is deployed,","so that deployment is simpler, and rebalancing doesn t take place.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25776,"Remove Test Scripts From XD The acceptance tests cover the entire suite of script tests. Thus they are no longer needed. The only test that was remaining was posting 10 messages to a http source and writing to a long and making sure we didn t get an error. This test httpbash was never called from the scripts CI build.",NULL,"Remove Test Scripts From XD The acceptance tests cover the entire suite of script tests. Thus they are no longer needed. The only test that was remaining was posting 10 messages to a http source and writing to a long and making sure we didn t get an error. This test httpbash was never called from the scripts CI build.",NULL,"Add for who this story is","well_formed","no_role","high",False
25776,"Remove Test Scripts From XD The acceptance tests cover the entire suite of script tests. Thus they are no longer needed. The only test that was remaining was posting 10 messages to a http source and writing to a long and making sure we didn t get an error. This test httpbash was never called from the scripts CI build.",NULL,"Remove Test Scripts From XD The acceptance tests cover the entire suite of script tests. Thus they are no longer needed. The only test that was remaining was posting 10 messages to a http source and writing to a long and making sure we didn t get an error. This test httpbash was never called from the scripts CI build.",NULL,"Remove Test Scripts From XD The acceptance tests cover the entire suite of script tests. Thus they are no longer needed. The only test that was remaining was posting 10 messages to a http source<span class='highlight-text severity-high'> and </span>writing to a long and making sure we didn t get an error. This test httpbash was never called from the scripts CI build.","atomic","conjunctions","high",False
25776,"Remove Test Scripts From XD The acceptance tests cover the entire suite of script tests. Thus they are no longer needed. The only test that was remaining was posting 10 messages to a http source and writing to a long and making sure we didn t get an error. This test httpbash was never called from the scripts CI build.",NULL,"Remove Test Scripts From XD The acceptance tests cover the entire suite of script tests. Thus they are no longer needed. The only test that was remaining was posting 10 messages to a http source and writing to a long and making sure we didn t get an error. This test httpbash was never called from the scripts CI build.",NULL,"Remove Test Scripts From XD The acceptance tests cover the entire suite of script tests<span class='highlight-text severity-high'>. Thus they are no longer needed. The only test that was remaining was posting 10 messages to a http source and writing to a long and making sure we didn t get an error. This test httpbash was never called from the scripts CI build.</span>","minimal","punctuation","high",False
25773,"Remove usage of location ... in module defitions This doesn t follow the conventions we have with other modules and it also means it isn t easy to override via environment variables etc. This is in HDFS and some others.",NULL,"Remove usage of location ... in module defitions This doesn t follow the conventions we have with other modules and it also means it isn t easy to override via environment variables etc. This is in HDFS and some others.",NULL,"Add for who this story is","well_formed","no_role","high",False
25773,"Remove usage of location ... in module defitions This doesn t follow the conventions we have with other modules and it also means it isn t easy to override via environment variables etc. This is in HDFS and some others.",NULL,"Remove usage of location ... in module defitions This doesn t follow the conventions we have with other modules and it also means it isn t easy to override via environment variables etc. This is in HDFS and some others.",NULL,"Remove usage of location ... in module defitions This doesn t follow the conventions we have with other modules<span class='highlight-text severity-high'> and </span>it also means it isn t easy to override via environment variables etc. This is in HDFS and some others.","atomic","conjunctions","high",False
25773,"Remove usage of location ... in module defitions This doesn t follow the conventions we have with other modules and it also means it isn t easy to override via environment variables etc. This is in HDFS and some others.",NULL,"Remove usage of location ... in module defitions This doesn t follow the conventions we have with other modules and it also means it isn t easy to override via environment variables etc. This is in HDFS and some others.",NULL,"Remove usage of location <span class='highlight-text severity-high'>... in module defitions This doesn t follow the conventions we have with other modules and it also means it isn t easy to override via environment variables etc. This is in HDFS and some others.</span>","minimal","punctuation","high",False
25774,"Investigate test failure in CI builds is failing intermittently. Why?",NULL,"Investigate test failure in CI builds is failing intermittently. Why?",NULL,"Add for who this story is","well_formed","no_role","high",False
25774,"Investigate test failure in CI builds is failing intermittently. Why?",NULL,"Investigate test failure in CI builds is failing intermittently. Why?",NULL,"Investigate test failure in CI builds is failing intermittently<span class='highlight-text severity-high'>. Why?</span>","minimal","punctuation","high",False
26680,"Documentation for file source should have file added to the list and also the corresponding section that shows some basic usage.",NULL,"Documentation for file source should have file added to the list and also the corresponding section that shows some basic usage.",NULL,"Add for who this story is","well_formed","no_role","high",False
26680,"Documentation for file source should have file added to the list and also the corresponding section that shows some basic usage.",NULL,"Documentation for file source should have file added to the list and also the corresponding section that shows some basic usage.",NULL,"Documentation for file source should have file added to the list<span class='highlight-text severity-high'> and </span>also the corresponding section that shows some basic usage.","atomic","conjunctions","high",False
25775,"Research Spark integration options phase 2 As a continuation, we would like to further investigate Spark, develop POC and identify the best appropriate design and implementation for XD.",NULL,"Research Spark integration options phase 2 As a continuation, we would like to further investigate Spark, develop POC and identify the best appropriate design and implementation for XD.",NULL,"Add for who this story is","well_formed","no_role","high",False
25775,"Research Spark integration options phase 2 As a continuation, we would like to further investigate Spark, develop POC and identify the best appropriate design and implementation for XD.",NULL,"Research Spark integration options phase 2 As a continuation, we would like to further investigate Spark, develop POC and identify the best appropriate design and implementation for XD.",NULL,"Research Spark integration options phase 2 As a continuation, we would like to further investigate Spark, develop POC<span class='highlight-text severity-high'> and </span>identify the best appropriate design and implementation for XD.","atomic","conjunctions","high",False
25769,"Create an Aggregate Counter An aggregate counter rolls up counts into discrete time buckets. There is an existing POC implementation in Java based off the library The README there has a good description of the desired feature set.",NULL,"Create an Aggregate Counter An aggregate counter rolls up counts into discrete time buckets. There is an existing POC implementation in Java based off the library The README there has a good description of the desired feature set.",NULL,"Add for who this story is","well_formed","no_role","high",False
25769,"Create an Aggregate Counter An aggregate counter rolls up counts into discrete time buckets. There is an existing POC implementation in Java based off the library The README there has a good description of the desired feature set.",NULL,"Create an Aggregate Counter An aggregate counter rolls up counts into discrete time buckets. There is an existing POC implementation in Java based off the library The README there has a good description of the desired feature set.",NULL,"Create an Aggregate Counter An aggregate counter rolls up counts into discrete time buckets<span class='highlight-text severity-high'>. There is an existing POC implementation in Java based off the library The README there has a good description of the desired feature set.</span>","minimal","punctuation","high",False
26681,"Create a rabbit sink module and documentation should have rabbit added to the list and also the corresponding section that shows some basic usage.",NULL,"Create a rabbit sink module and documentation should have rabbit added to the list and also the corresponding section that shows some basic usage.",NULL,"Add for who this story is","well_formed","no_role","high",False
26681,"Create a rabbit sink module and documentation should have rabbit added to the list and also the corresponding section that shows some basic usage.",NULL,"Create a rabbit sink module and documentation should have rabbit added to the list and also the corresponding section that shows some basic usage.",NULL,"Create a rabbit sink module<span class='highlight-text severity-high'> and </span>documentation should have rabbit added to the list and also the corresponding section that shows some basic usage.","atomic","conjunctions","high",False
25786,"Create pipes and filters DSL for ingestion Initial simple handcoded implementation for straight through pipe and filter model, e.g. a b c",NULL,"Create pipes and filters DSL for ingestion Initial simple handcoded implementation for straight through pipe and filter model, e.g. a b c",NULL,"Create pipes and filters DSL for ingestion Initial simple handcoded implementation for straight through pipe and filter model, e<span class='highlight-text severity-high'>.g. a b c</span>","minimal","punctuation","high",False
25785,"TCP Client source module throws Version XD 1.1 M1 Problem Trying to use tcp client source module and observing an exception while deploying the stream. Stream Definition curl data data decoder LF port 8080 log data deploy true decoder LF port 8080 The same curl command works fine against XD 1.0.1 release. ",NULL,"TCP Client source module throws Version XD 1.1 M1 Problem Trying to use tcp client source module and observing an exception while deploying the stream. Stream Definition curl data data decoder LF port 8080 log data deploy true decoder LF port 8080 The same curl command works fine against XD 1.0.1 release. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25785,"TCP Client source module throws Version XD 1.1 M1 Problem Trying to use tcp client source module and observing an exception while deploying the stream. Stream Definition curl data data decoder LF port 8080 log data deploy true decoder LF port 8080 The same curl command works fine against XD 1.0.1 release. ",NULL,"TCP Client source module throws Version XD 1.1 M1 Problem Trying to use tcp client source module and observing an exception while deploying the stream. Stream Definition curl data data decoder LF port 8080 log data deploy true decoder LF port 8080 The same curl command works fine against XD 1.0.1 release. ",NULL,"TCP Client source module throws Version XD 1.1 M1 Problem Trying to use tcp client source module<span class='highlight-text severity-high'> and </span>observing an exception while deploying the stream. Stream Definition curl data data decoder LF port 8080 log data deploy true decoder LF port 8080 The same curl command works fine against XD 1.0.1 release. ","atomic","conjunctions","high",False
25785,"TCP Client source module throws Version XD 1.1 M1 Problem Trying to use tcp client source module and observing an exception while deploying the stream. Stream Definition curl data data decoder LF port 8080 log data deploy true decoder LF port 8080 The same curl command works fine against XD 1.0.1 release. ",NULL,"TCP Client source module throws Version XD 1.1 M1 Problem Trying to use tcp client source module and observing an exception while deploying the stream. Stream Definition curl data data decoder LF port 8080 log data deploy true decoder LF port 8080 The same curl command works fine against XD 1.0.1 release. ",NULL,"TCP Client source module throws Version XD 1<span class='highlight-text severity-high'>.1 M1 Problem Trying to use tcp client source module and observing an exception while deploying the stream. Stream Definition curl data data decoder LF port 8080 log data deploy true decoder LF port 8080 The same curl command works fine against XD 1.0.1 release. </span>","minimal","punctuation","high",False
25781,"Document custom module install procedures As a user, I'd like to refer to documentation so that I can build the custom module based on recommended standards and patterns.",NULL,"Document custom module install procedures As a user, I'd like to refer to documentation","so that I can build the custom module based on recommended standards and patterns.","Add for who this story is","well_formed","no_role","high",False
25781,"Document custom module install procedures As a user, I'd like to refer to documentation so that I can build the custom module based on recommended standards and patterns.",NULL,"Document custom module install procedures As a user, I'd like to refer to documentation","so that I can build the custom module based on recommended standards and patterns.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25780,"Re run Kafka baseline tests in new infrastructure As a developer, I'd like to setup a performance testing infrastructure rackspace , so I can start benching Kafka baselines and continue with XD use cases.",NULL,"Re run Kafka baseline tests in new infrastructure As a developer, I'd like to setup a performance testing infrastructure rackspace ,","so I can start benching Kafka baselines and continue with XD use cases.","Add for who this story is","well_formed","no_role","high",False
25780,"Re run Kafka baseline tests in new infrastructure As a developer, I'd like to setup a performance testing infrastructure rackspace , so I can start benching Kafka baselines and continue with XD use cases.",NULL,"Re run Kafka baseline tests in new infrastructure As a developer, I'd like to setup a performance testing infrastructure rackspace ,","so I can start benching Kafka baselines and continue with XD use cases.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25787,"Research options to improve CI reliability As a build master, I'd like to research CI options so that I can improve CI build stability and reliability. Potential Option npm cache Caching previously installed dependencies, npm cache doesn t require downloading the internet each time we build.",NULL,"Research options to improve CI reliability As a build master, I'd like to research CI options","so that I can improve CI build stability and reliability. Potential Option npm cache Caching previously installed dependencies, npm cache doesn t require downloading the internet each time we build.","Add for who this story is","well_formed","no_role","high",False
25787,"Research options to improve CI reliability As a build master, I'd like to research CI options so that I can improve CI build stability and reliability. Potential Option npm cache Caching previously installed dependencies, npm cache doesn t require downloading the internet each time we build.",NULL,"Research options to improve CI reliability As a build master, I'd like to research CI options","so that I can improve CI build stability and reliability. Potential Option npm cache Caching previously installed dependencies, npm cache doesn t require downloading the internet each time we build.","Research options to improve CI reliability As a build master, I'd like to research CI options so that I can improve CI build stability and reliability<span class='highlight-text severity-high'>. Potential Option npm cache Caching previously installed dependencies, npm cache doesn t require downloading the internet each time we build.</span>","minimal","punctuation","high",False
25787,"Research options to improve CI reliability As a build master, I'd like to research CI options so that I can improve CI build stability and reliability. Potential Option npm cache Caching previously installed dependencies, npm cache doesn t require downloading the internet each time we build.",NULL,"Research options to improve CI reliability As a build master, I'd like to research CI options","so that I can improve CI build stability and reliability. Potential Option npm cache Caching previously installed dependencies, npm cache doesn t require downloading the internet each time we build.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25784,"Add hosted in HDFS so that I can deploy the module to newly arriving containers. ",NULL,"Add hosted in HDFS","so that I can deploy the module to newly arriving containers.","Add for who this story is","well_formed","no_role","high",False
25784,"Add hosted in HDFS so that I can deploy the module to newly arriving containers. ",NULL,"Add hosted in HDFS","so that I can deploy the module to newly arriving containers.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25782,"Need TCP Client Source Acceptance test ",NULL,"Need TCP Client Source Acceptance test ",NULL,"Add for who this story is","well_formed","no_role","high",False
26682,"Deployed streams should be restarted on container start When using Redis store, stored deployed streams should be deployed on container restart.",NULL,"Deployed streams should be restarted on container start When using Redis store, stored deployed streams should be deployed on container restart.",NULL,"Add for who this story is","well_formed","no_role","high",False
25788,"EC2 CI build improvements As a developer, I'd like to include the following improvements as part of the EC2 CI infrastructure, so that we can reliably run the CI builds and also assert over feature functionalities. Scope Enable distributed jvm test Change from using artifactory gradle task to a command task that calls . gradlew Test w embedded hadoop off Turn on maxParallelForks ",NULL,"EC2 CI build improvements As a developer, I'd like to include the following improvements as part of the EC2 CI infrastructure,","so that we can reliably run the CI builds and also assert over feature functionalities. Scope Enable distributed jvm test Change from using artifactory gradle task to a command task that calls . gradlew Test w embedded hadoop off Turn on maxParallelForks","Add for who this story is","well_formed","no_role","high",False
25788,"EC2 CI build improvements As a developer, I'd like to include the following improvements as part of the EC2 CI infrastructure, so that we can reliably run the CI builds and also assert over feature functionalities. Scope Enable distributed jvm test Change from using artifactory gradle task to a command task that calls . gradlew Test w embedded hadoop off Turn on maxParallelForks ",NULL,"EC2 CI build improvements As a developer, I'd like to include the following improvements as part of the EC2 CI infrastructure,","so that we can reliably run the CI builds and also assert over feature functionalities. Scope Enable distributed jvm test Change from using artifactory gradle task to a command task that calls . gradlew Test w embedded hadoop off Turn on maxParallelForks","EC2 CI build improvements As a developer, I'd like to include the following improvements as part of the EC2 CI infrastructure, so that we can reliably run the CI builds and also assert over feature functionalities<span class='highlight-text severity-high'>. Scope Enable distributed jvm test Change from using artifactory gradle task to a command task that calls . gradlew Test w embedded hadoop off Turn on maxParallelForks </span>","minimal","punctuation","high",False
25788,"EC2 CI build improvements As a developer, I'd like to include the following improvements as part of the EC2 CI infrastructure, so that we can reliably run the CI builds and also assert over feature functionalities. Scope Enable distributed jvm test Change from using artifactory gradle task to a command task that calls . gradlew Test w embedded hadoop off Turn on maxParallelForks ",NULL,"EC2 CI build improvements As a developer, I'd like to include the following improvements as part of the EC2 CI infrastructure,","so that we can reliably run the CI builds and also assert over feature functionalities. Scope Enable distributed jvm test Change from using artifactory gradle task to a command task that calls . gradlew Test w embedded hadoop off Turn on maxParallelForks","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26686,"Refactor test cases to move away from inheritance model of utility methods for streams, counters Model the API more akin to SpringXDOperations api.",NULL,"Refactor test cases to move away from inheritance model of utility methods for streams, counters Model the API more akin to SpringXDOperations api.",NULL,"Add for who this story is","well_formed","no_role","high",False
26683,"Update to Spring Shell 1.1.0.M1 release ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26683,"Update to Spring Shell 1.1.0.M1 release ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26684,"Add list command for AggregateCounter ",NULL,"Add list command for AggregateCounter ",NULL,"Add for who this story is","well_formed","no_role","high",False
26685,"Use the tuple data structure to process data in a spring batch step Do not require a POJO in order to do end to end processing in a batch step.",NULL,"Use the tuple data structure to process data in a spring batch step Do not require a POJO","in order to do end to end processing in a batch step.","Add for who this story is","well_formed","no_role","high",False
26685,"Use the tuple data structure to process data in a spring batch step Do not require a POJO in order to do end to end processing in a batch step.",NULL,"Use the tuple data structure to process data in a spring batch step Do not require a POJO","in order to do end to end processing in a batch step.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26704,"Configure Jackson ObjectMappers to Allow Single Quotes Allow Json payloads from external sources, e.g., http post to contain single quoted field names and values. This is required where XD uses Jackson to convert payloads from Json to object or Tuples.",NULL,"Configure Jackson ObjectMappers to Allow Single Quotes Allow Json payloads from external sources, e.g., http post to contain single quoted field names and values. This is required where XD uses Jackson to convert payloads from Json to object or Tuples.",NULL,"Add for who this story is","well_formed","no_role","high",False
26704,"Configure Jackson ObjectMappers to Allow Single Quotes Allow Json payloads from external sources, e.g., http post to contain single quoted field names and values. This is required where XD uses Jackson to convert payloads from Json to object or Tuples.",NULL,"Configure Jackson ObjectMappers to Allow Single Quotes Allow Json payloads from external sources, e.g., http post to contain single quoted field names and values. This is required where XD uses Jackson to convert payloads from Json to object or Tuples.",NULL,"Configure Jackson ObjectMappers to Allow Single Quotes Allow Json payloads from external sources, e.g., http post to contain single quoted field names<span class='highlight-text severity-high'> and </span>values. This is required where XD uses Jackson to convert payloads from Json to object<span class='highlight-text severity-high'> or </span>Tuples.","atomic","conjunctions","high",False
26704,"Configure Jackson ObjectMappers to Allow Single Quotes Allow Json payloads from external sources, e.g., http post to contain single quoted field names and values. This is required where XD uses Jackson to convert payloads from Json to object or Tuples.",NULL,"Configure Jackson ObjectMappers to Allow Single Quotes Allow Json payloads from external sources, e.g., http post to contain single quoted field names and values. This is required where XD uses Jackson to convert payloads from Json to object or Tuples.",NULL,"Configure Jackson ObjectMappers to Allow Single Quotes Allow Json payloads from external sources, e<span class='highlight-text severity-high'>.g., http post to contain single quoted field names and values. This is required where XD uses Jackson to convert payloads from Json to object or Tuples.</span>","minimal","punctuation","high",False
25778,"Add batching support for Rabbit Message Bus As a user, I'd like to have microbatching capability so that I can ingest based on batch intervals for enhanced performance throughput. ",NULL,"Add batching support for Rabbit Message Bus As a user, I'd like to have microbatching capability","so that I can ingest based on batch intervals for enhanced performance throughput.","Add for who this story is","well_formed","no_role","high",False
25778,"Add batching support for Rabbit Message Bus As a user, I'd like to have microbatching capability so that I can ingest based on batch intervals for enhanced performance throughput. ",NULL,"Add batching support for Rabbit Message Bus As a user, I'd like to have microbatching capability","so that I can ingest based on batch intervals for enhanced performance throughput.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25779,"Decouple messagebus dependencies Refactoring scope spring xd dirt Message bus dependencies The goal is to decouple them from startup phase to further enhance initialization time. ",NULL,"Decouple messagebus dependencies Refactoring scope spring xd dirt Message bus dependencies The goal is to decouple them from startup phase to further enhance initialization time. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25783,"Acceptance test for Kafka source and sink ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25783,"Acceptance test for Kafka source and sink ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25796,"Add JMS source module ",NULL,"Add JMS source module ",NULL,"Add for who this story is","well_formed","no_role","high",False
25791,"Enhance module upload to support exploded dirs on the shell side Would be nice to have the shell zip the contents of a directory if not already in zipped form. This way, the development cycle if one decided to use upload is quicker and edits can be done in place.",NULL,"Enhance module upload to support exploded dirs on the shell side Would be nice to have the shell zip the contents of a directory if not already in zipped form. This way, the development cycle if one decided to use upload is quicker and edits can be done in place.",NULL,"Add for who this story is","well_formed","no_role","high",False
25791,"Enhance module upload to support exploded dirs on the shell side Would be nice to have the shell zip the contents of a directory if not already in zipped form. This way, the development cycle if one decided to use upload is quicker and edits can be done in place.",NULL,"Enhance module upload to support exploded dirs on the shell side Would be nice to have the shell zip the contents of a directory if not already in zipped form. This way, the development cycle if one decided to use upload is quicker and edits can be done in place.",NULL,"Enhance module upload to support exploded dirs on the shell side Would be nice to have the shell zip the contents of a directory if not already in zipped form. This way, the development cycle if one decided to use upload is quicker<span class='highlight-text severity-high'> and </span>edits can be done in place.","atomic","conjunctions","high",False
25791,"Enhance module upload to support exploded dirs on the shell side Would be nice to have the shell zip the contents of a directory if not already in zipped form. This way, the development cycle if one decided to use upload is quicker and edits can be done in place.",NULL,"Enhance module upload to support exploded dirs on the shell side Would be nice to have the shell zip the contents of a directory if not already in zipped form. This way, the development cycle if one decided to use upload is quicker and edits can be done in place.",NULL,"Enhance module upload to support exploded dirs on the shell side Would be nice to have the shell zip the contents of a directory if not already in zipped form<span class='highlight-text severity-high'>. This way, the development cycle if one decided to use upload is quicker and edits can be done in place.</span>","minimal","punctuation","high",False
25790,"Provide an XD Starter POM for module projects Provide A maven pom to support module projects that will declare the Spring XD dependencies as provided, configure the boot plugin for MODULE layout and other boilerplate build configuration. This should include a similar feature for gradle.",NULL,"Provide an XD Starter POM for module projects Provide A maven pom to support module projects that will declare the Spring XD dependencies as provided, configure the boot plugin for MODULE layout and other boilerplate build configuration. This should include a similar feature for gradle.",NULL,"Add for who this story is","well_formed","no_role","high",False
25790,"Provide an XD Starter POM for module projects Provide A maven pom to support module projects that will declare the Spring XD dependencies as provided, configure the boot plugin for MODULE layout and other boilerplate build configuration. This should include a similar feature for gradle.",NULL,"Provide an XD Starter POM for module projects Provide A maven pom to support module projects that will declare the Spring XD dependencies as provided, configure the boot plugin for MODULE layout and other boilerplate build configuration. This should include a similar feature for gradle.",NULL,"Provide an XD Starter POM for module projects Provide A maven pom to support module projects that will declare the Spring XD dependencies as provided, configure the boot plugin for MODULE layout<span class='highlight-text severity-high'> and </span>other boilerplate build configuration. This should include a similar feature for gradle.","atomic","conjunctions","high",False
25790,"Provide an XD Starter POM for module projects Provide A maven pom to support module projects that will declare the Spring XD dependencies as provided, configure the boot plugin for MODULE layout and other boilerplate build configuration. This should include a similar feature for gradle.",NULL,"Provide an XD Starter POM for module projects Provide A maven pom to support module projects that will declare the Spring XD dependencies as provided, configure the boot plugin for MODULE layout and other boilerplate build configuration. This should include a similar feature for gradle.",NULL,"Provide an XD Starter POM for module projects Provide A maven pom to support module projects that will declare the Spring XD dependencies as provided, configure the boot plugin for MODULE layout and other boilerplate build configuration<span class='highlight-text severity-high'>. This should include a similar feature for gradle.</span>","minimal","punctuation","high",False
25793,"Make Redis RichGauge repository cluster safe The current implementation makes individual reads from redis and then writes back the average, so in a cluster environment the reads and writes are not serialized, client reads and writes for specific keys can interfere with each other. Investigate options, such as use of redis transactions or use of lua scripting to solve this problem.",NULL,"Make Redis RichGauge repository cluster safe The current implementation makes individual reads from redis and then writes back the average,","so in a cluster environment the reads and writes are not serialized, client reads and writes for specific keys can interfere with each other. Investigate options, such as use of redis transactions or use of lua scripting to solve this problem.","Add for who this story is","well_formed","no_role","high",False
25858,"Remove MongoDB from main DIRT classpath MongoDb driver is present on DIRT s classpath, while it should not should be present on mongo related modules though . This is blocked by the shortcoming described here ",NULL,"Remove MongoDB from main DIRT classpath MongoDb driver is present on DIRT s classpath, while it should not should be present on mongo related modules though . This is blocked by the shortcoming described here ",NULL,"Add for who this story is","well_formed","no_role","high",False
26095,"Move Reactor based processor module from spring xd modules to core As a developer, I'd like to move the project reactor based data processor module from spring xd module repo to the core, so I can natively use Reactor s Stream API to build processor modules. ",NULL,"Move Reactor based proces","sor module from spring xd modules to core As a developer, I'd like to move the project reactor based data processor module from spring xd module repo to the core, so I can natively use Reactor s Stream API to build processor modules.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25793,"Make Redis RichGauge repository cluster safe The current implementation makes individual reads from redis and then writes back the average, so in a cluster environment the reads and writes are not serialized, client reads and writes for specific keys can interfere with each other. Investigate options, such as use of redis transactions or use of lua scripting to solve this problem.",NULL,"Make Redis RichGauge repository cluster safe The current implementation makes individual reads from redis and then writes back the average,","so in a cluster environment the reads and writes are not serialized, client reads and writes for specific keys can interfere with each other. Investigate options, such as use of redis transactions or use of lua scripting to solve this problem.","Make Redis RichGauge repository cluster safe The current implementation makes individual reads from redis<span class='highlight-text severity-high'> and </span>then writes back the average, so in a cluster environment the reads and writes are not serialized, client reads and writes for specific keys can interfere with each other. Investigate options, such as use of redis transactions<span class='highlight-text severity-high'> or </span>use of lua scripting to solve this problem.","atomic","conjunctions","high",False
25793,"Make Redis RichGauge repository cluster safe The current implementation makes individual reads from redis and then writes back the average, so in a cluster environment the reads and writes are not serialized, client reads and writes for specific keys can interfere with each other. Investigate options, such as use of redis transactions or use of lua scripting to solve this problem.",NULL,"Make Redis RichGauge repository cluster safe The current implementation makes individual reads from redis and then writes back the average,","so in a cluster environment the reads and writes are not serialized, client reads and writes for specific keys can interfere with each other. Investigate options, such as use of redis transactions or use of lua scripting to solve this problem.","Make Redis RichGauge repository cluster safe The current implementation makes individual reads from redis and then writes back the average, so in a cluster environment the reads and writes are not serialized, client reads and writes for specific keys can interfere with each other<span class='highlight-text severity-high'>. Investigate options, such as use of redis transactions or use of lua scripting to solve this problem.</span>","minimal","punctuation","high",False
25793,"Make Redis RichGauge repository cluster safe The current implementation makes individual reads from redis and then writes back the average, so in a cluster environment the reads and writes are not serialized, client reads and writes for specific keys can interfere with each other. Investigate options, such as use of redis transactions or use of lua scripting to solve this problem.",NULL,"Make Redis RichGauge repository cluster safe The current implementation makes individual reads from redis and then writes back the average,","so in a cluster environment the reads and writes are not serialized, client reads and writes for specific keys can interfere with each other. Investigate options, such as use of redis transactions or use of lua scripting to solve this problem.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25792,"Rename metrics repositories setValue x, y, z to something less javabean ",NULL,"Rename metrics repositories setValue x, y, z to something less javabean ",NULL,"Add for who this story is","well_formed","no_role","high",False
25795,"Kafka Sink Support async Producer The kafka sink supports properties for an async producer e.g. . Async producers batch messages at the risk of message loss . Add a new property element ",NULL,"Kafka Sink Support async Producer The kafka sink supports properties for an async producer e.g. . Async producers batch messages at the risk of message loss . Add a new property element ",NULL,"Add for who this story is","well_formed","no_role","high",False
25795,"Kafka Sink Support async Producer The kafka sink supports properties for an async producer e.g. . Async producers batch messages at the risk of message loss . Add a new property element ",NULL,"Kafka Sink Support async Producer The kafka sink supports properties for an async producer e.g. . Async producers batch messages at the risk of message loss . Add a new property element ",NULL,"Kafka Sink Support async Producer The kafka sink supports properties for an async producer e<span class='highlight-text severity-high'>.g. . Async producers batch messages at the risk of message loss . Add a new property element </span>","minimal","punctuation","high",False
25794,"Fix Redis FieldValueCounter repo save method That method is actually currently never called, but The case where a mapping already exists is not covered outstanding TODO comment the semantics of the method should just be to save and override ",NULL,"Fix Redis FieldValueCounter repo save method That method is actually currently never called, but The case where a mapping already exists is not covered outstanding TODO comment the semantics of the method should just be to save and override ",NULL,"Add for who this story is","well_formed","no_role","high",False
25798,"Profile Improve performance of TupleBuilder See discussion at 1 there seems to be unused SimpleDateFormat in TupleBuilder which hurst perf 2 More generally, should take some time to profile micro benchmark TupleBuilder",NULL,"Profile Improve performance of TupleBuilder See discussion at 1 there seems to be unused SimpleDateFormat in TupleBuilder which hurst perf 2 More generally, should take some time to profile micro benchmark TupleBuilder",NULL,"Add for who this story is","well_formed","no_role","high",False
25797,"UI Provide fixed version numbers for NPM and Bower dependencies ",NULL,"UI Provide fixed version numbers for NPM and Bower dependencies ",NULL,"Add for who this story is","well_formed","no_role","high",False
25802,"Create a Sqoop job and required batch tasklet integration code Based on the POC from XD 2124 we should create the actual implementation. Things to consider to store in step context capture Log output MapReduce job counters capture last value from incremental imports ",NULL,"Create a Sqoop job and required batch tasklet integration code Based on the POC from XD 2124 we should create the actual implementation. Things to consider to store in step context capture Log output MapReduce job counters capture last value from incremental imports ",NULL,"Add for who this story is","well_formed","no_role","high",False
25802,"Create a Sqoop job and required batch tasklet integration code Based on the POC from XD 2124 we should create the actual implementation. Things to consider to store in step context capture Log output MapReduce job counters capture last value from incremental imports ",NULL,"Create a Sqoop job and required batch tasklet integration code Based on the POC from XD 2124 we should create the actual implementation. Things to consider to store in step context capture Log output MapReduce job counters capture last value from incremental imports ",NULL,"Create a Sqoop job<span class='highlight-text severity-high'> and </span>required batch tasklet integration code Based on the POC from XD 2124 we should create the actual implementation. Things to consider to store in step context capture Log output MapReduce job counters capture last value from incremental imports ","atomic","conjunctions","high",False
25802,"Create a Sqoop job and required batch tasklet integration code Based on the POC from XD 2124 we should create the actual implementation. Things to consider to store in step context capture Log output MapReduce job counters capture last value from incremental imports ",NULL,"Create a Sqoop job and required batch tasklet integration code Based on the POC from XD 2124 we should create the actual implementation. Things to consider to store in step context capture Log output MapReduce job counters capture last value from incremental imports ",NULL,"Create a Sqoop job and required batch tasklet integration code Based on the POC from XD 2124 we should create the actual implementation<span class='highlight-text severity-high'>. Things to consider to store in step context capture Log output MapReduce job counters capture last value from incremental imports </span>","minimal","punctuation","high",False
25799,"Travis CI improvements Travis CI recently introduced docker based builds. This prevents root access which we don t need , but allows caching which we could not use before and seems to come with beefier machine specs",NULL,"Travis CI improvements Travis CI recently introduced docker based builds. This prevents root access which we don t need , but allows caching which we could not use before and seems to come with beefier machine specs",NULL,"Add for who this story is","well_formed","no_role","high",False
25799,"Travis CI improvements Travis CI recently introduced docker based builds. This prevents root access which we don t need , but allows caching which we could not use before and seems to come with beefier machine specs",NULL,"Travis CI improvements Travis CI recently introduced docker based builds. This prevents root access which we don t need , but allows caching which we could not use before and seems to come with beefier machine specs",NULL,"Travis CI improvements Travis CI recently introduced docker based builds. This prevents root access which we don t need , but allows caching which we could not use before<span class='highlight-text severity-high'> and </span>seems to come with beefier machine specs","atomic","conjunctions","high",False
25799,"Travis CI improvements Travis CI recently introduced docker based builds. This prevents root access which we don t need , but allows caching which we could not use before and seems to come with beefier machine specs",NULL,"Travis CI improvements Travis CI recently introduced docker based builds. This prevents root access which we don t need , but allows caching which we could not use before and seems to come with beefier machine specs",NULL,"Travis CI improvements Travis CI recently introduced docker based builds<span class='highlight-text severity-high'>. This prevents root access which we don t need , but allows caching which we could not use before and seems to come with beefier machine specs</span>","minimal","punctuation","high",False
25801,"Mysql Libraries not shipped with XD by default The reference states the following s for the HSQLDB, MySql, and Postgres are already on the XD classpath It looks like this is true for Postgres and HSQLDB, but I can t see a driver for MySQL shipped with the distribution.",NULL,"Mysql Libraries not shipped with XD by default The reference states the following s for the HSQLDB, MySql, and Postgres are already on the XD classpath It looks like this is true for Postgres and HSQLDB, but I can t see a driver for MySQL shipped with the distribution.",NULL,"Add for who this story is","well_formed","no_role","high",False
25801,"Mysql Libraries not shipped with XD by default The reference states the following s for the HSQLDB, MySql, and Postgres are already on the XD classpath It looks like this is true for Postgres and HSQLDB, but I can t see a driver for MySQL shipped with the distribution.",NULL,"Mysql Libraries not shipped with XD by default The reference states the following s for the HSQLDB, MySql, and Postgres are already on the XD classpath It looks like this is true for Postgres and HSQLDB, but I can t see a driver for MySQL shipped with the distribution.",NULL,"Mysql Libraries not shipped with XD by default The reference states the following s for the HSQLDB, MySql,<span class='highlight-text severity-high'> and </span>Postgres are already on the XD classpath It looks like this is true for Postgres and HSQLDB, but I can t see a driver for MySQL shipped with the distribution.","atomic","conjunctions","high",False
25801,"Mysql Libraries not shipped with XD by default The reference states the following s for the HSQLDB, MySql, and Postgres are already on the XD classpath It looks like this is true for Postgres and HSQLDB, but I can t see a driver for MySQL shipped with the distribution.",NULL,"Mysql Libraries not shipped with XD by default The reference states the following s for the HSQLDB, MySql, and Postgres are already on the XD classpath It looks like this is true for Postgres and HSQLDB, but I can t see a driver for MySQL shipped with the distribution.",NULL,"Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25803,"Workaround latest boot snapshot issue The workaround explicitly updates spring core latest boot needs it merges all application.yml documents that are not profile specific under on spring key the latest boot requires it, at least for now. Boot may go back, see ",NULL,"Workaround latest boot snapshot issue The workaround explicitly updates spring core latest boot needs it merges all application.yml documents that are not profile specific under on spring key the latest boot requires it, at least for now. Boot may go back, see ",NULL,"Add for who this story is","well_formed","no_role","high",False
25803,"Workaround latest boot snapshot issue The workaround explicitly updates spring core latest boot needs it merges all application.yml documents that are not profile specific under on spring key the latest boot requires it, at least for now. Boot may go back, see ",NULL,"Workaround latest boot snapshot issue The workaround explicitly updates spring core latest boot needs it merges all application.yml documents that are not profile specific under on spring key the latest boot requires it, at least for now. Boot may go back, see ",NULL,"Workaround latest boot snapshot issue The workaround explicitly updates spring core latest boot needs it merges all application<span class='highlight-text severity-high'>.yml documents that are not profile specific under on spring key the latest boot requires it, at least for now. Boot may go back, see </span>","minimal","punctuation","high",False
25804,"Define developer facing interfaces for Spark Streaming modules ",NULL,"Define developer facing interfaces for Spark Streaming modules ",NULL,"Add for who this story is","well_formed","no_role","high",False
25800,"Use repo.spring.io as NPM repository In order to improve the build reliability, we should be using the NPM repo provided by repo.spring.io See for further details.",NULL,NULL,"In order to improve the build reliability, we should be using the NPM repo provided by repo.spring.io See for further details.","Add what you want to achieve","well_formed","no_means","high",False
25800,"Use repo.spring.io as NPM repository In order to improve the build reliability, we should be using the NPM repo provided by repo.spring.io See for further details.",NULL,NULL,"In order to improve the build reliability, we should be using the NPM repo provided by repo.spring.io See for further details.","Add for who this story is","well_formed","no_role","high",False
25800,"Use repo.spring.io as NPM repository In order to improve the build reliability, we should be using the NPM repo provided by repo.spring.io See for further details.",NULL,NULL,"In order to improve the build reliability, we should be using the NPM repo provided by repo.spring.io See for further details.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25807,"Deploy Batch Jobs on XD As a developer, I need a way to deploy job configurations as well as the related custom code to XD. ",NULL,"Deploy Batch Jobs on XD As a developer, I need a way to deploy job configurations as well as the related custom code to XD. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25810,"Acceptance test for Kafka as a message bus As a QA, I'd like to include acceptance test coverage for Kafka as a message bus so that I can validate the functionality as part of every CI build.",NULL,"Acceptance test for Kafka as a message bus As a QA, I'd like to include acceptance test coverage for Kafka as a message bus","so that I can validate the functionality as part of every CI build.","Add for who this story is","well_formed","no_role","high",False
25810,"Acceptance test for Kafka as a message bus As a QA, I'd like to include acceptance test coverage for Kafka as a message bus so that I can validate the functionality as part of every CI build.",NULL,"Acceptance test for Kafka as a message bus As a QA, I'd like to include acceptance test coverage for Kafka as a message bus","so that I can validate the functionality as part of every CI build.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25808,"Acceptance test for spark app batch job As a QA, I'd like to include acceptance test coverage for spark app batch job so that I can validate the functionality as part of every CI build. ",NULL,"Acceptance test for spark app batch job As a QA, I'd like to include acceptance test coverage for spark app batch job","so that I can validate the functionality as part of every CI build.","Add for who this story is","well_formed","no_role","high",False
25808,"Acceptance test for spark app batch job As a QA, I'd like to include acceptance test coverage for spark app batch job so that I can validate the functionality as part of every CI build. ",NULL,"Acceptance test for spark app batch job As a QA, I'd like to include acceptance test coverage for spark app batch job","so that I can validate the functionality as part of every CI build.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25812,"Implement a Spark Streaming Driver application that can be controlled as an XD module instance This should include lifecycle management, so that when the module s stream is undeployed, the Spark Streaming application should be stopped, etc. Deploying a number of module instances should result in multiple receiver tasks, and those should bind to the bus using the consumer side partitioning metadata. ",NULL,"Implement a Spark Streaming Driver application that can be controlled as an XD module instance This should include lifecycle management,","so that when the module s stream is undeployed, the Spark Streaming application should be stopped, etc. Deploying a number of module instances should result in multiple receiver tasks, and those should bind to the bus using the consumer side partitioning metadata.","Add for who this story is","well_formed","no_role","high",False
25812,"Implement a Spark Streaming Driver application that can be controlled as an XD module instance This should include lifecycle management, so that when the module s stream is undeployed, the Spark Streaming application should be stopped, etc. Deploying a number of module instances should result in multiple receiver tasks, and those should bind to the bus using the consumer side partitioning metadata. ",NULL,"Implement a Spark Streaming Driver application that can be controlled as an XD module instance This should include lifecycle management,","so that when the module s stream is undeployed, the Spark Streaming application should be stopped, etc. Deploying a number of module instances should result in multiple receiver tasks, and those should bind to the bus using the consumer side partitioning metadata.","Implement a Spark Streaming Driver application that can be controlled as an XD module instance This should include lifecycle management, so that when the module s stream is undeployed, the Spark Streaming application should be stopped, etc<span class='highlight-text severity-high'>. Deploying a number of module instances should result in multiple receiver tasks, and those should bind to the bus using the consumer side partitioning metadata. </span>","minimal","punctuation","high",False
25812,"Implement a Spark Streaming Driver application that can be controlled as an XD module instance This should include lifecycle management, so that when the module s stream is undeployed, the Spark Streaming application should be stopped, etc. Deploying a number of module instances should result in multiple receiver tasks, and those should bind to the bus using the consumer side partitioning metadata. ",NULL,"Implement a Spark Streaming Driver application that can be controlled as an XD module instance This should include lifecycle management,","so that when the module s stream is undeployed, the Spark Streaming application should be stopped, etc. Deploying a number of module instances should result in multiple receiver tasks, and those should bind to the bus using the consumer side partitioning metadata.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25816,"Kafka Bus Add support for ACK mode As a user, I'd like to have the option to ACK messages so that I can guarantee that the message request sent is successful. ",NULL,"Kafka Bus Add support for ACK mode As a user, I'd like to have the option to ACK messages","so that I can guarantee that the message request sent is successful.","Add for who this story is","well_formed","no_role","high",False
25816,"Kafka Bus Add support for ACK mode As a user, I'd like to have the option to ACK messages so that I can guarantee that the message request sent is successful. ",NULL,"Kafka Bus Add support for ACK mode As a user, I'd like to have the option to ACK messages","so that I can guarantee that the message request sent is successful.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25811,"Implement a dirt plugin for Spark Streaming support ",NULL,"Implement a dirt plugin for Spark Streaming support ",NULL,"Add for who this story is","well_formed","no_role","high",False
25813,"Kafka Profiling for Base Distributed base benchmarks ",NULL,"Kafka Profiling for Base Distributed base benchmarks ",NULL,"Add for who this story is","well_formed","no_role","high",False
25819,"Add support to stop existing Sqoop jobs As a user, I'd like to have the option to stop an existing Sqoop job so that I can clean up resources at the time of completion.",NULL,"Add support to stop existing Sqoop jobs As a user, I'd like to have the option to stop an existing Sqoop job","so that I can clean up resources at the time of completion.","Add for who this story is","well_formed","no_role","high",False
25819,"Add support to stop existing Sqoop jobs As a user, I'd like to have the option to stop an existing Sqoop job so that I can clean up resources at the time of completion.",NULL,"Add support to stop existing Sqoop jobs As a user, I'd like to have the option to stop an existing Sqoop job","so that I can clean up resources at the time of completion.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25814,"Need to be able to specify password for Redis Running on Cloud Foundry and other managed environments we need to be able to specify a Redis password in addition to host and port.",NULL,"Need to be able to specify password for Redis Running on Cloud Foundry and other managed environments we need to be able to specify a Redis password in addition to host and port.",NULL,"Add for who this story is","well_formed","no_role","high",False
25814,"Need to be able to specify password for Redis Running on Cloud Foundry and other managed environments we need to be able to specify a Redis password in addition to host and port.",NULL,"Need to be able to specify password for Redis Running on Cloud Foundry and other managed environments we need to be able to specify a Redis password in addition to host and port.",NULL,"Need to be able to specify password for Redis Running on Cloud Foundry<span class='highlight-text severity-high'> and </span>other managed environments we need to be able to specify a Redis password in addition to host and port.","atomic","conjunctions","high",False
25820,"Add support to access Sqoop logs As a user, I'd like to access Sqoop logs so that I can troubleshoot or evaluate the errors or current state respectively. We will have to identify how to capture the Sqoop logs and stream them to our logging mechanism.",NULL,"Add support to access Sqoop logs As a user, I'd like to access Sqoop logs","so that I can troubleshoot or evaluate the errors or current state respectively. We will have to identify how to capture the Sqoop logs and stream them to our logging mechanism.","Add for who this story is","well_formed","no_role","high",False
25820,"Add support to access Sqoop logs As a user, I'd like to access Sqoop logs so that I can troubleshoot or evaluate the errors or current state respectively. We will have to identify how to capture the Sqoop logs and stream them to our logging mechanism.",NULL,"Add support to access Sqoop logs As a user, I'd like to access Sqoop logs","so that I can troubleshoot or evaluate the errors or current state respectively. We will have to identify how to capture the Sqoop logs and stream them to our logging mechanism.","Add support to access Sqoop logs As a user, I'd like to access Sqoop logs so that I can troubleshoot or evaluate the errors or current state respectively<span class='highlight-text severity-high'>. We will have to identify how to capture the Sqoop logs and stream them to our logging mechanism.</span>","minimal","punctuation","high",False
25820,"Add support to access Sqoop logs As a user, I'd like to access Sqoop logs so that I can troubleshoot or evaluate the errors or current state respectively. We will have to identify how to capture the Sqoop logs and stream them to our logging mechanism.",NULL,"Add support to access Sqoop logs As a user, I'd like to access Sqoop logs","so that I can troubleshoot or evaluate the errors or current state respectively. We will have to identify how to capture the Sqoop logs and stream them to our logging mechanism.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25818,"Add batching support to Spring AMQP Rabbit As a user, I'd like to have the option to setup batching so that I can ingest data in batches as opposed to payload at a time.",NULL,"Add batching support to Spring AMQP Rabbit As a user, I'd like to have the option to setup batching","so that I can ingest data in batches as opposed to payload at a time.","Add for who this story is","well_formed","no_role","high",False
25818,"Add batching support to Spring AMQP Rabbit As a user, I'd like to have the option to setup batching so that I can ingest data in batches as opposed to payload at a time.",NULL,"Add batching support to Spring AMQP Rabbit As a user, I'd like to have the option to setup batching","so that I can ingest data in batches as opposed to payload at a time.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25821,"Provide a Spring Shell implementation for XD Need to create a basic Spring Shell implementation to provide easier access to the XD REST API via an XD REST API Client library. ",NULL,"Provide a Spring Shell implementation for XD Need to create a basic Spring Shell implementation to provide easier access to the XD REST API via an XD REST API Client library. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25822,"Benchmark Sqoop vs. jdbchdfs As a QA, I'd like to benchmark Sqoop vs. jdbchdfs batch job so that I can compare and contrast performance stats. ",NULL,"Benchmark Sqoop vs. jdbchdfs As a QA, I'd like to benchmark Sqoop vs. jdbchdfs batch job","so that I can compare and contrast performance stats.","Add for who this story is","well_formed","no_role","high",False
25822,"Benchmark Sqoop vs. jdbchdfs As a QA, I'd like to benchmark Sqoop vs. jdbchdfs batch job so that I can compare and contrast performance stats. ",NULL,"Benchmark Sqoop vs. jdbchdfs As a QA, I'd like to benchmark Sqoop vs. jdbchdfs batch job","so that I can compare and contrast performance stats.","Benchmark Sqoop vs<span class='highlight-text severity-high'>. jdbchdfs As a QA, I'd like to benchmark Sqoop vs. jdbchdfs batch job so that I can compare and contrast performance stats. </span>","minimal","punctuation","high",False
25822,"Benchmark Sqoop vs. jdbchdfs As a QA, I'd like to benchmark Sqoop vs. jdbchdfs batch job so that I can compare and contrast performance stats. ",NULL,"Benchmark Sqoop vs. jdbchdfs As a QA, I'd like to benchmark Sqoop vs. jdbchdfs batch job","so that I can compare and contrast performance stats.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25817,"Add support for bindRequestor and bindReplier As a user, I'd like to have the option to implement bindRequestor and bindReplier so that I can bind a producer that expects async replies and bind a consumer that handles requests from a requestor and asynchronously sends replies respectively. ",NULL,"Add support for bindRequestor and bindReplier As a user, I'd like to have the option to implement bindRequestor and bindReplier","so that I can bind a producer that expects async replies and bind a consumer that handles requests from a requestor and asynchronously sends replies respectively.","Add for who this story is","well_formed","no_role","high",False
25817,"Add support for bindRequestor and bindReplier As a user, I'd like to have the option to implement bindRequestor and bindReplier so that I can bind a producer that expects async replies and bind a consumer that handles requests from a requestor and asynchronously sends replies respectively. ",NULL,"Add support for bindRequestor and bindReplier As a user, I'd like to have the option to implement bindRequestor and bindReplier","so that I can bind a producer that expects async replies and bind a consumer that handles requests from a requestor and asynchronously sends replies respectively.","Add support for bindRequestor<span class='highlight-text severity-high'> and </span>bindReplier As a user, I'd like to have the option to implement bindRequestor and bindReplier so that I can bind a producer that expects async replies and bind a consumer that handles requests from a requestor and asynchronously sends replies respectively. ","atomic","conjunctions","high",False
25817,"Add support for bindRequestor and bindReplier As a user, I'd like to have the option to implement bindRequestor and bindReplier so that I can bind a producer that expects async replies and bind a consumer that handles requests from a requestor and asynchronously sends replies respectively. ",NULL,"Add support for bindRequestor and bindReplier As a user, I'd like to have the option to implement bindRequestor and bindReplier","so that I can bind a producer that expects async replies and bind a consumer that handles requests from a requestor and asynchronously sends replies respectively.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25809,"As a user of XD, I want to be able to use a job as a source. To do so, we need the output of a job to be written to a message channel ","As a user of XD,","I want to be able to use a job as a","source. To do so, we need the output of a job to be written to a message channel","As a user of XD, I want to be able to use a job as a source<span class='highlight-text severity-high'>. To do so, we need the output of a job to be written to a message channel </span>","minimal","punctuation","high",False
25824,"Add codec option to hdfs dataset sink As a user, I would like to be able disable snappy compression when using hdfs dataset sink with Avro files. I d also like to be able to provide a different codec.",NULL,"Add codec option to hdfs dataset sink As a user, I would like to be able disable snappy compression when using hdfs dataset sink with Avro files. I d also like to be able to provide a different codec.",NULL,"Add for who this story is","well_formed","no_role","high",False
25824,"Add codec option to hdfs dataset sink As a user, I would like to be able disable snappy compression when using hdfs dataset sink with Avro files. I d also like to be able to provide a different codec.",NULL,"Add codec option to hdfs dataset sink As a user, I would like to be able disable snappy compression when using hdfs dataset sink with Avro files. I d also like to be able to provide a different codec.",NULL,"Add codec option to hdfs dataset sink As a user, I would like to be able disable snappy compression when using hdfs dataset sink with Avro files<span class='highlight-text severity-high'>. I d also like to be able to provide a different codec.</span>","minimal","punctuation","high",False
25825,"Update spring data hadoop version to 2.1.0.M3 ",NULL,"Update spring data hadoop version to 2.1.0.M3 ",NULL,"Add for who this story is","well_formed","no_role","high",False
25826,"Update spring data hadoop version to 2.0.4 for XD 1.0.3 ",NULL,"Update spring data hadoop version to 2.0.4 for XD 1.0.3 ",NULL,"Add for who this story is","well_formed","no_role","high",False
25827,"Create for Reactor based XD processor sink modules The module should be flexible to act as a sink as well as a processor. ErrorHandling will be considered as part of another JIRA",NULL,"Create for Reactor based XD processor sink modules The module should be flexible to act as a sink as well as a processor. ErrorHandling will be considered as part of another JIRA",NULL,"Add for who this story is","well_formed","no_role","high",False
25827,"Create for Reactor based XD processor sink modules The module should be flexible to act as a sink as well as a processor. ErrorHandling will be considered as part of another JIRA",NULL,"Create for Reactor based XD processor sink modules The module should be flexible to act as a sink as well as a processor. ErrorHandling will be considered as part of another JIRA",NULL,"Create for Reactor based XD processor sink modules The module should be flexible to act as a sink as well as a processor<span class='highlight-text severity-high'>. ErrorHandling will be considered as part of another JIRA</span>","minimal","punctuation","high",False
25828,"Create sample module in spring xd modules for a Reactor Stream processor A sample, perhaps taken from Pivotal Labs use case in Denver, that would calculate some time window averages for a many individual senor values .",NULL,"Create sample module in spring xd modules for a Reactor Stream processor A sample, perhaps taken from Pivotal Labs use case in Denver, that would calculate some time window averages for a many individual senor values .",NULL,"Add for who this story is","well_formed","no_role","high",False
25829,"Reference documentation on creating Reactive Stream processor sink ",NULL,"Reference documentation on creating Reactive Stream processor sink ",NULL,"Add for who this story is","well_formed","no_role","high",False
25830,"Initial client library for XD REST API Need to create a basic client library to provide easier access to the XD REST API. ",NULL,"Initial client library for XD REST API Need to create a basic client library to provide easier access to the XD REST API. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25832,"Refactor use of in integration tests Some cleanup to make the tests a bit easer to read.",NULL,"Refactor use of in integration tests Some cleanup to make the tests a bit easer to read.",NULL,"Add for who this story is","well_formed","no_role","high",False
25831,"Update Reactor Stream processor to use latest snapshots The code base is changing a bit, so using 2.0 M1 for development is stable up until all major JIRA issues have bee completed. Then we should track snapshots in preparation to move to 2.0. M2 when it gets released.",NULL,"Update Reactor Stream proces","sor to use latest snapshots The code base is changing a bit, so using 2.0 M1 for development is stable up until all major JIRA issues have bee completed. Then we should track snapshots in preparation to move to 2.0. M2 when it gets released.","Add for who this story is","well_formed","no_role","high",False
25831,"Update Reactor Stream processor to use latest snapshots The code base is changing a bit, so using 2.0 M1 for development is stable up until all major JIRA issues have bee completed. Then we should track snapshots in preparation to move to 2.0. M2 when it gets released.",NULL,"Update Reactor Stream proces","sor to use latest snapshots The code base is changing a bit, so using 2.0 M1 for development is stable up until all major JIRA issues have bee completed. Then we should track snapshots in preparation to move to 2.0. M2 when it gets released.","Update Reactor Stream processor to use latest snapshots The code base is changing a bit, so using 2<span class='highlight-text severity-high'>.0 M1 for development is stable up until all major JIRA issues have bee completed. Then we should track snapshots in preparation to move to 2.0. M2 when it gets released.</span>","minimal","punctuation","high",False
25831,"Update Reactor Stream processor to use latest snapshots The code base is changing a bit, so using 2.0 M1 for development is stable up until all major JIRA issues have bee completed. Then we should track snapshots in preparation to move to 2.0. M2 when it gets released.",NULL,"Update Reactor Stream proces","sor to use latest snapshots The code base is changing a bit, so using 2.0 M1 for development is stable up until all major JIRA issues have bee completed. Then we should track snapshots in preparation to move to 2.0. M2 when it gets released.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25836,"Upgrade to Boot 1.2.0 RELEASE and the dependencies As a XD Admin, I'd like to upgrade to Spring Boot 1.2.0 RELEASE and the associated dependencies so that we can catch up with the latest features, bug fixes and enhancements. Following XD dependencies needs upgraded to sync up with Boot 1.2.0 RELEASE ",NULL,"Upgrade to Boot 1.2.0 RELEASE and the dependencies As a XD Admin, I'd like to upgrade to Spring Boot 1.2.0 RELEASE and the associated dependencies","so that we can catch up with the latest features, bug fixes and enhancements. Following XD dependencies needs upgraded to sync up with Boot 1.2.0 RELEASE","Add for who this story is","well_formed","no_role","high",False
25836,"Upgrade to Boot 1.2.0 RELEASE and the dependencies As a XD Admin, I'd like to upgrade to Spring Boot 1.2.0 RELEASE and the associated dependencies so that we can catch up with the latest features, bug fixes and enhancements. Following XD dependencies needs upgraded to sync up with Boot 1.2.0 RELEASE ",NULL,"Upgrade to Boot 1.2.0 RELEASE and the dependencies As a XD Admin, I'd like to upgrade to Spring Boot 1.2.0 RELEASE and the associated dependencies","so that we can catch up with the latest features, bug fixes and enhancements. Following XD dependencies needs upgraded to sync up with Boot 1.2.0 RELEASE","Upgrade to Boot 1.2.0 RELEASE<span class='highlight-text severity-high'> and </span>the dependencies As a XD Admin, I'd like to upgrade to Spring Boot 1.2.0 RELEASE and the associated dependencies so that we can catch up with the latest features, bug fixes and enhancements. Following XD dependencies needs upgraded to sync up with Boot 1.2.0 RELEASE ","atomic","conjunctions","high",False
25836,"Upgrade to Boot 1.2.0 RELEASE and the dependencies As a XD Admin, I'd like to upgrade to Spring Boot 1.2.0 RELEASE and the associated dependencies so that we can catch up with the latest features, bug fixes and enhancements. Following XD dependencies needs upgraded to sync up with Boot 1.2.0 RELEASE ",NULL,"Upgrade to Boot 1.2.0 RELEASE and the dependencies As a XD Admin, I'd like to upgrade to Spring Boot 1.2.0 RELEASE and the associated dependencies","so that we can catch up with the latest features, bug fixes and enhancements. Following XD dependencies needs upgraded to sync up with Boot 1.2.0 RELEASE","Upgrade to Boot 1<span class='highlight-text severity-high'>.2.0 RELEASE and the dependencies As a XD Admin, I'd like to upgrade to Spring Boot 1.2.0 RELEASE and the associated dependencies so that we can catch up with the latest features, bug fixes and enhancements. Following XD dependencies needs upgraded to sync up with Boot 1.2.0 RELEASE </span>","minimal","punctuation","high",False
25836,"Upgrade to Boot 1.2.0 RELEASE and the dependencies As a XD Admin, I'd like to upgrade to Spring Boot 1.2.0 RELEASE and the associated dependencies so that we can catch up with the latest features, bug fixes and enhancements. Following XD dependencies needs upgraded to sync up with Boot 1.2.0 RELEASE ",NULL,"Upgrade to Boot 1.2.0 RELEASE and the dependencies As a XD Admin, I'd like to upgrade to Spring Boot 1.2.0 RELEASE and the associated dependencies","so that we can catch up with the latest features, bug fixes and enhancements. Following XD dependencies needs upgraded to sync up with Boot 1.2.0 RELEASE","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25833,"Investigate lack of falling back to origin master when building docs on a branch When building on a branch, the docs should be defaulting to build from origin master, but that doesn t seem to be happening. Instead an explicit is required to be specified on the command line. ",NULL,"Investigate lack of falling back to origin master when building docs on a branch When building on a branch, the docs should be defaulting to build from origin master, but that doesn t seem to be happening. Instead an explicit is required to be specified on the command line. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25833,"Investigate lack of falling back to origin master when building docs on a branch When building on a branch, the docs should be defaulting to build from origin master, but that doesn t seem to be happening. Instead an explicit is required to be specified on the command line. ",NULL,"Investigate lack of falling back to origin master when building docs on a branch When building on a branch, the docs should be defaulting to build from origin master, but that doesn t seem to be happening. Instead an explicit is required to be specified on the command line. ",NULL,"Investigate lack of falling back to origin master when building docs on a branch When building on a branch, the docs should be defaulting to build from origin master, but that doesn t seem to be happening<span class='highlight-text severity-high'>. Instead an explicit is required to be specified on the command line. </span>","minimal","punctuation","high",False
25840,"Add support for stream creation For stream creation we need to be able to specify source sink processor filter transformer script etc. ",NULL,"Add support for stream creation For stream creation we need to be able to specify source sink processor filter transformer script etc. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25837,"to use embedded Kafka server Test is failing since Kafka isn t installed on the CI server. Using an embedded server will make the testing more robust vs. needing an external server.",NULL,"to use embedded Kafka server Test is failing since Kafka isn t installed on the CI server. Using an embedded server will make the testing more robust vs. needing an external server.",NULL,"Add for who this story is","well_formed","no_role","high",False
25837,"to use embedded Kafka server Test is failing since Kafka isn t installed on the CI server. Using an embedded server will make the testing more robust vs. needing an external server.",NULL,"to use embedded Kafka server Test is failing since Kafka isn t installed on the CI server. Using an embedded server will make the testing more robust vs. needing an external server.",NULL,"to use embedded Kafka server Test is failing since Kafka isn t installed on the CI server<span class='highlight-text severity-high'>. Using an embedded server will make the testing more robust vs. needing an external server.</span>","minimal","punctuation","high",False
25838,"Upgrade CI Acceptance AMI to HVM Replace the current paravirtual AMI used for CI tests needed to be replaced with a HVM based AMI Paravirtual is being phased out by Amazon. Also so we can utilize VPC and placement groups in the future. ",NULL,"Upgrade CI Acceptance AMI to HVM Replace the current paravirtual AMI used for CI tests needed to be replaced with a HVM based AMI Paravirtual is being phased out by Amazon. Al","so so we can utilize VPC and placement groups in the future.","Add for who this story is","well_formed","no_role","high",False
25838,"Upgrade CI Acceptance AMI to HVM Replace the current paravirtual AMI used for CI tests needed to be replaced with a HVM based AMI Paravirtual is being phased out by Amazon. Also so we can utilize VPC and placement groups in the future. ",NULL,"Upgrade CI Acceptance AMI to HVM Replace the current paravirtual AMI used for CI tests needed to be replaced with a HVM based AMI Paravirtual is being phased out by Amazon. Al","so so we can utilize VPC and placement groups in the future.","Upgrade CI Acceptance AMI to HVM Replace the current paravirtual AMI used for CI tests needed to be replaced with a HVM based AMI Paravirtual is being phased out by Amazon<span class='highlight-text severity-high'>. Also so we can utilize VPC and placement groups in the future. </span>","minimal","punctuation","high",False
25838,"Upgrade CI Acceptance AMI to HVM Replace the current paravirtual AMI used for CI tests needed to be replaced with a HVM based AMI Paravirtual is being phased out by Amazon. Also so we can utilize VPC and placement groups in the future. ",NULL,"Upgrade CI Acceptance AMI to HVM Replace the current paravirtual AMI used for CI tests needed to be replaced with a HVM based AMI Paravirtual is being phased out by Amazon. Al","so so we can utilize VPC and placement groups in the future.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25839,"MQTT Support the New Spring Integration 4.1 Features HA Configuration, async sends. ",NULL,"MQTT Support the New Spring Integration 4.1 Features HA Configuration, async sends. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25823,"Define developer facing interfaces for Reactor Stream processors What is the core interface contract users will be exposed to when creating a processor module that uses Reactor s Stream API. Some consideration for error handling should be considered as it maybe outside normal exception throwing signatures.",NULL,"Define developer facing interfaces for Reactor Stream processors What is the core interface contract users will be exposed to when creating a processor module that uses Reactor s Stream API. Some consideration for error handling should be considered as it maybe outside normal exception throwing signatures.",NULL,"Add for who this story is","well_formed","no_role","high",False
25823,"Define developer facing interfaces for Reactor Stream processors What is the core interface contract users will be exposed to when creating a processor module that uses Reactor s Stream API. Some consideration for error handling should be considered as it maybe outside normal exception throwing signatures.",NULL,"Define developer facing interfaces for Reactor Stream processors What is the core interface contract users will be exposed to when creating a processor module that uses Reactor s Stream API. Some consideration for error handling should be considered as it maybe outside normal exception throwing signatures.",NULL,"Define developer facing interfaces for Reactor Stream processors What is the core interface contract users will be exposed to when creating a processor module that uses Reactor s Stream API<span class='highlight-text severity-high'>. Some consideration for error handling should be considered as it maybe outside normal exception throwing signatures.</span>","minimal","punctuation","high",False
25835,"Set up a project for XD REST client library ",NULL,"Set up a project for XD REST client library ",NULL,"Add for who this story is","well_formed","no_role","high",False
25858,"Remove MongoDB from main DIRT classpath MongoDb driver is present on DIRT s classpath, while it should not should be present on mongo related modules though . This is blocked by the shortcoming described here ",NULL,"Remove MongoDB from main DIRT classpath MongoDb driver is present on DIRT s classpath, while it should not should be present on mongo related modules though . This is blocked by the shortcoming described here ",NULL,"Remove MongoDB from main DIRT classpath MongoDb driver is present on DIRT s classpath, while it should not should be present on mongo related modules though <span class='highlight-text severity-high'>. This is blocked by the shortcoming described here </span>","minimal","punctuation","high",False
25843,"Upgrade to Gradle 2.2 ",NULL,"Upgrade to Gradle 2.2 ",NULL,"Add for who this story is","well_formed","no_role","high",False
25844,"Add gradle build support for custom module projects As a user, I'd like to have a gradle build option so that I can support module projects that will declare the Spring XD dependencies as provided, configure the boot plugin for MODULE layout and other boilerplate build configuration. This is dependent on Boot s module layout scoping issue ",NULL,"Add gradle build support for custom module projects As a user, I'd like to have a gradle build option","so that I can support module projects that will declare the Spring XD dependencies as provided, configure the boot plugin for MODULE layout and other boilerplate build configuration. This is dependent on Boot s module layout scoping issue","Add for who this story is","well_formed","no_role","high",False
25844,"Add gradle build support for custom module projects As a user, I'd like to have a gradle build option so that I can support module projects that will declare the Spring XD dependencies as provided, configure the boot plugin for MODULE layout and other boilerplate build configuration. This is dependent on Boot s module layout scoping issue ",NULL,"Add gradle build support for custom module projects As a user, I'd like to have a gradle build option","so that I can support module projects that will declare the Spring XD dependencies as provided, configure the boot plugin for MODULE layout and other boilerplate build configuration. This is dependent on Boot s module layout scoping issue","Add gradle build support for custom module projects As a user, I'd like to have a gradle build option so that I can support module projects that will declare the Spring XD dependencies as provided, configure the boot plugin for MODULE layout and other boilerplate build configuration<span class='highlight-text severity-high'>. This is dependent on Boot s module layout scoping issue </span>","minimal","punctuation","high",False
25844,"Add gradle build support for custom module projects As a user, I'd like to have a gradle build option so that I can support module projects that will declare the Spring XD dependencies as provided, configure the boot plugin for MODULE layout and other boilerplate build configuration. This is dependent on Boot s module layout scoping issue ",NULL,"Add gradle build support for custom module projects As a user, I'd like to have a gradle build option","so that I can support module projects that will declare the Spring XD dependencies as provided, configure the boot plugin for MODULE layout and other boilerplate build configuration. This is dependent on Boot s module layout scoping issue","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25846,"Upgrade to Reactor 2.0 M2 ",NULL,"Upgrade to Reactor 2.0 M2 ",NULL,"Add for who this story is","well_formed","no_role","high",False
25851,"Investigate why CPU startup is high for admin and container servers As a performance tester, I'd like to investigate why there s high CPU startup time for both admin and container servers. Perhaps profiling would assist isolating the bottlenecks. Scope Identify the bottlenecks Document reasons List pros cons",NULL,"Investigate why CPU startup is high for admin and container servers As a performance tester, I'd like to investigate why there s high CPU startup time for both admin and container servers. Perhaps profiling would assist isolating the bottlenecks. Scope Identify the bottlenecks Document reasons List pros cons",NULL,"Add for who this story is","well_formed","no_role","high",False
25851,"Investigate why CPU startup is high for admin and container servers As a performance tester, I'd like to investigate why there s high CPU startup time for both admin and container servers. Perhaps profiling would assist isolating the bottlenecks. Scope Identify the bottlenecks Document reasons List pros cons",NULL,"Investigate why CPU startup is high for admin and container servers As a performance tester, I'd like to investigate why there s high CPU startup time for both admin and container servers. Perhaps profiling would assist isolating the bottlenecks. Scope Identify the bottlenecks Document reasons List pros cons",NULL,"Investigate why CPU startup is high for admin<span class='highlight-text severity-high'> and </span>container servers As a performance tester, I'd like to investigate why there s high CPU startup time for both admin and container servers. Perhaps profiling would assist isolating the bottlenecks. Scope Identify the bottlenecks Document reasons List pros cons","atomic","conjunctions","high",False
25851,"Investigate why CPU startup is high for admin and container servers As a performance tester, I'd like to investigate why there s high CPU startup time for both admin and container servers. Perhaps profiling would assist isolating the bottlenecks. Scope Identify the bottlenecks Document reasons List pros cons",NULL,"Investigate why CPU startup is high for admin and container servers As a performance tester, I'd like to investigate why there s high CPU startup time for both admin and container servers. Perhaps profiling would assist isolating the bottlenecks. Scope Identify the bottlenecks Document reasons List pros cons",NULL,"Investigate why CPU startup is high for admin and container servers As a performance tester, I'd like to investigate why there s high CPU startup time for both admin and container servers<span class='highlight-text severity-high'>. Perhaps profiling would assist isolating the bottlenecks. Scope Identify the bottlenecks Document reasons List pros cons</span>","minimal","punctuation","high",False
25847,"Define developer facing interfaces for RxJava processors As a user, I'd like to implement the core interface contract so that I can create a processor module that uses RxJava API.",NULL,"Define developer facing interfaces for RxJava processors As a user, I'd like to implement the core interface contract","so that I can create a processor module that uses RxJava API.","Add for who this story is","well_formed","no_role","high",False
25847,"Define developer facing interfaces for RxJava processors As a user, I'd like to implement the core interface contract so that I can create a processor module that uses RxJava API.",NULL,"Define developer facing interfaces for RxJava processors As a user, I'd like to implement the core interface contract","so that I can create a processor module that uses RxJava API.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25854,"Reference documentation on RxJava Stream processor ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25854,"Reference documentation on RxJava Stream processor ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25853,"Add in HDFS so that I can rely on the HA feature to reliably read and reinstall under failure scenarios. ",NULL,"Add in HDFS","so that I can rely on the HA feature to reliably read and reinstall under failure scenarios.","Add for who this story is","well_formed","no_role","high",False
25853,"Add in HDFS so that I can rely on the HA feature to reliably read and reinstall under failure scenarios. ",NULL,"Add in HDFS","so that I can rely on the HA feature to reliably read and reinstall under failure scenarios.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25848,"Create MessageHandler for RxJava based processor modules As a user, I'd like to have a flexible RxJava module so that it can as a processor. ",NULL,"Create MessageHandler for RxJava based processor modules As a user, I'd like to have a flexible RxJava module","so that it can as a processor.","Add for who this story is","well_formed","no_role","high",False
25848,"Create MessageHandler for RxJava based processor modules As a user, I'd like to have a flexible RxJava module so that it can as a processor. ",NULL,"Create MessageHandler for RxJava based processor modules As a user, I'd like to have a flexible RxJava module","so that it can as a processor.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25849,"Create a loadGenerator source module Create a load generator source module that will generate messages and dispatch messages to a XD stream. ",NULL,"Create a loadGenerator source module Create a load generator source module that will generate messages and dispatch messages to a XD stream. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25849,"Create a loadGenerator source module Create a load generator source module that will generate messages and dispatch messages to a XD stream. ",NULL,"Create a loadGenerator source module Create a load generator source module that will generate messages and dispatch messages to a XD stream. ",NULL,"Create a loadGenerator source module Create a load generator source module that will generate messages<span class='highlight-text severity-high'> and </span>dispatch messages to a XD stream. ","atomic","conjunctions","high",False
25850,"Create AMI for Spark Server installed ",NULL,"Create AMI for Spark Server installed ",NULL,"Add for who this story is","well_formed","no_role","high",False
25859,"Add support to test XD on YARN in EC2 As a developer, I'd like to have acceptance test coverage for XD YARN on EC2 so that I can verify simple XD features running on YARN on every build cycle.",NULL,"Add support to test XD on YARN in EC2 As a developer, I'd like to have acceptance test coverage for XD YARN on EC2","so that I can verify simple XD features running on YARN on every build cycle.","Add for who this story is","well_formed","no_role","high",False
25859,"Add support to test XD on YARN in EC2 As a developer, I'd like to have acceptance test coverage for XD YARN on EC2 so that I can verify simple XD features running on YARN on every build cycle.",NULL,"Add support to test XD on YARN in EC2 As a developer, I'd like to have acceptance test coverage for XD YARN on EC2","so that I can verify simple XD features running on YARN on every build cycle.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25855,"Upgrade to Reactor 2.0 RC1 As a developer, I'd like to upgrade to Reactor 2.0 RC1 release so that we can synchronize with stable dependencies.",NULL,"Upgrade to Reactor 2.0 RC1 As a developer, I'd like to upgrade to Reactor 2.0 RC1 release","so that we can synchronize with stable dependencies.","Add for who this story is","well_formed","no_role","high",False
25855,"Upgrade to Reactor 2.0 RC1 As a developer, I'd like to upgrade to Reactor 2.0 RC1 release so that we can synchronize with stable dependencies.",NULL,"Upgrade to Reactor 2.0 RC1 As a developer, I'd like to upgrade to Reactor 2.0 RC1 release","so that we can synchronize with stable dependencies.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25860,"Yarn Environment for XD Acceptance Tests Create an 2.6 Yarn Environment on EC2 for which XD can be deployed for acceptance tests.",NULL,"Yarn Environment for XD Acceptance Tests Create an 2.6 Yarn Environment on EC2 for which XD can be deployed for acceptance tests.",NULL,"Add for who this story is","well_formed","no_role","high",False
25857,"Move the Hadoop test dependencies to a different project As a developer, I'd like to isolate the Hadoop tests in a different project so that the DIRT project doesn t have to depend upon, thus eliminating the incorrect CP file generation in eclipse. ",NULL,"Move the Hadoop test dependencies to a different project As a developer, I'd like to isolate the Hadoop tests in a different project","so that the DIRT project doesn t have to depend upon, thus eliminating the incorrect CP file generation in eclipse.","Add for who this story is","well_formed","no_role","high",False
25857,"Move the Hadoop test dependencies to a different project As a developer, I'd like to isolate the Hadoop tests in a different project so that the DIRT project doesn t have to depend upon, thus eliminating the incorrect CP file generation in eclipse. ",NULL,"Move the Hadoop test dependencies to a different project As a developer, I'd like to isolate the Hadoop tests in a different project","so that the DIRT project doesn t have to depend upon, thus eliminating the incorrect CP file generation in eclipse.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25862,"Create the base implementation for XDCommands for the shell This is the basic setup of the commands file no specific command implementations",NULL,"Create the base implementation for XDCommands for the shell This is the basic setup of the commands file no specific command implementations",NULL,"Add for who this story is","well_formed","no_role","high",False
25861,"Update to Spring Boot 1.2.1.RELEASE ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25861,"Update to Spring Boot 1.2.1.RELEASE ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25856,"Create a banner page for XD Shell ",NULL,"Create a banner page for XD Shell ",NULL,"Add for who this story is","well_formed","no_role","high",False
25841,"Add support for message compression As a user, I'd like to have the option to compress messages so that I can influence the performance throughput. It d be beneficial to have support for gzip, zip compression, and decompression.",NULL,"Add support for message compression As a user, I'd like to have the option to compress messages","so that I can influence the performance throughput. It d be beneficial to have support for gzip, zip compression, and decompression.","Add for who this story is","well_formed","no_role","high",False
25841,"Add support for message compression As a user, I'd like to have the option to compress messages so that I can influence the performance throughput. It d be beneficial to have support for gzip, zip compression, and decompression.",NULL,"Add support for message compression As a user, I'd like to have the option to compress messages","so that I can influence the performance throughput. It d be beneficial to have support for gzip, zip compression, and decompression.","Add support for message compression As a user, I'd like to have the option to compress messages so that I can influence the performance throughput<span class='highlight-text severity-high'>. It d be beneficial to have support for gzip, zip compression, and decompression.</span>","minimal","punctuation","high",False
25841,"Add support for message compression As a user, I'd like to have the option to compress messages so that I can influence the performance throughput. It d be beneficial to have support for gzip, zip compression, and decompression.",NULL,"Add support for message compression As a user, I'd like to have the option to compress messages","so that I can influence the performance throughput. It d be beneficial to have support for gzip, zip compression, and decompression.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25864,"Set fixed NPM version for Grunt Gradle Plugin Ensure build works in Windows environments",NULL,"Set fixed NPM version for Grunt Gradle Plugin Ensure build works in Windows environments",NULL,"Add for who this story is","well_formed","no_role","high",False
25866,"Add command for stream creation ",NULL,"Add command for stream creation ",NULL,"Add for who this story is","well_formed","no_role","high",False
25865,"Add RxJava based Stream processor module As a user, I'd like to use RxJava based processor module so that I can leverage RxJava APIs for data computations. ",NULL,"Add RxJava based Stream processor module As a user, I'd like to use RxJava based processor module","so that I can leverage RxJava APIs for data computations.","Add for who this story is","well_formed","no_role","high",False
25865,"Add RxJava based Stream processor module As a user, I'd like to use RxJava based processor module so that I can leverage RxJava APIs for data computations. ",NULL,"Add RxJava based Stream processor module As a user, I'd like to use RxJava based processor module","so that I can leverage RxJava APIs for data computations.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25868,"Remove all deprecated compile warnings Run a clean gradle build to identify all warnings.",NULL,"Remove all deprecated compile warnings Run a clean gradle build to identify all warnings.",NULL,"Add for who this story is","well_formed","no_role","high",False
25867,"Upgrade grunt node plugins Upgrade in 1.0.x branch what was done in this commit on master. ",NULL,"Upgrade grunt node plugins Upgrade in 1.0.x branch what was done in this commit on master. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25870,"Add command for tap creation ",NULL,"Add command for tap creation ",NULL,"Add for who this story is","well_formed","no_role","high",False
25869,"Create sample application for RxJava Create port of based on RxJava",NULL,"Create sample application for RxJava Create port of based on RxJava",NULL,"Add for who this story is","well_formed","no_role","high",False
25876,"Basic Performance Test For syslog injestion ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25876,"Basic Performance Test For syslog injestion ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25873,"Update spring data hadoop version to 2.1.0.RC1 Update spring data hadoop version to 2.1.0.RC1. This also includes updating the following adding hadoop26 Apache Hadoop 2.6.0 as distro adding hdp22 Hortonworks HDP 2.2 as distro set default distro to hadoop26 update cdh5 to version 5.3.0 remove older distros hadoop24, hdp21 ",NULL,"Update spring data hadoop version to 2.1.0.RC1 Update spring data hadoop version to 2.1.0.RC1. This also includes updating the following adding hadoop26 Apache Hadoop 2.6.0 as distro adding hdp22 Hortonworks HDP 2.2 as distro set default distro to hadoop26 update cdh5 to version 5.3.0 remove older distros hadoop24, hdp21 ",NULL,"Add for who this story is","well_formed","no_role","high",False
25873,"Update spring data hadoop version to 2.1.0.RC1 Update spring data hadoop version to 2.1.0.RC1. This also includes updating the following adding hadoop26 Apache Hadoop 2.6.0 as distro adding hdp22 Hortonworks HDP 2.2 as distro set default distro to hadoop26 update cdh5 to version 5.3.0 remove older distros hadoop24, hdp21 ",NULL,"Update spring data hadoop version to 2.1.0.RC1 Update spring data hadoop version to 2.1.0.RC1. This also includes updating the following adding hadoop26 Apache Hadoop 2.6.0 as distro adding hdp22 Hortonworks HDP 2.2 as distro set default distro to hadoop26 update cdh5 to version 5.3.0 remove older distros hadoop24, hdp21 ",NULL,"Update spring data hadoop version to 2<span class='highlight-text severity-high'>.1.0.RC1 Update spring data hadoop version to 2.1.0.RC1. This also includes updating the following adding hadoop26 Apache Hadoop 2.6.0 as distro adding hdp22 Hortonworks HDP 2.2 as distro set default distro to hadoop26 update cdh5 to version 5.3.0 remove older distros hadoop24, hdp21 </span>","minimal","punctuation","high",False
25878,"Backport XD 2411 to 1.0.x branch This fix for RichGauge should go into the 1.0.x line.",NULL,"Backport XD 2411 to 1.0.x branch This fix for RichGauge should go into the 1.0.x line.",NULL,"Add for who this story is","well_formed","no_role","high",False
25874,"Test recent Hadoop distro changes Test basic functionality hdfs sink, jdbchdfs job on hadoop26, hdp22, cdh5, phd21 Test XD on YARN on hadoop26, hdp22, cdh5 and phd21 ",NULL,"Test recent Hadoop distro changes Test basic functionality hdfs sink, jdbchdfs job on hadoop26, hdp22, cdh5, phd21 Test XD on YARN on hadoop26, hdp22, cdh5 and phd21 ",NULL,"Add for who this story is","well_formed","no_role","high",False
25882,"Create reactor module in spring xd modules project ",NULL,"Create reactor module in spring xd modules project ",NULL,"Add for who this story is","well_formed","no_role","high",False
25883,"Update Spring Batch to 3.0.3.RELEASE ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25883,"Update Spring Batch to 3.0.3.RELEASE ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25881,"Use Kryo instance pooling to reduce instantiation overhead ",NULL,"Use Kryo instance pooling to reduce instantiation overhead ",NULL,"Add for who this story is","well_formed","no_role","high",False
25879,"Add support to track history in message headers As a user, I'd like to have an option to track history so that I get the visibility of stream name, module name etc. added as part of the message header.",NULL,"Add support to track history in message headers As a user, I'd like to have an option to track history","so that I get the visibility of stream name, module name etc. added as part of the message header.","Add for who this story is","well_formed","no_role","high",False
25879,"Add support to track history in message headers As a user, I'd like to have an option to track history so that I get the visibility of stream name, module name etc. added as part of the message header.",NULL,"Add support to track history in message headers As a user, I'd like to have an option to track history","so that I get the visibility of stream name, module name etc. added as part of the message header.","Add support to track history in message headers As a user, I'd like to have an option to track history so that I get the visibility of stream name, module name etc<span class='highlight-text severity-high'>. added as part of the message header.</span>","minimal","punctuation","high",False
25879,"Add support to track history in message headers As a user, I'd like to have an option to track history so that I get the visibility of stream name, module name etc. added as part of the message header.",NULL,"Add support to track history in message headers As a user, I'd like to have an option to track history","so that I get the visibility of stream name, module name etc. added as part of the message header.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25880,"Add command for deleting a stream ",NULL,"Add command for deleting a stream ",NULL,"Add for who this story is","well_formed","no_role","high",False
25884,"Convert current REST servlet to Spring MVC ",NULL,"Convert current REST servlet to Spring MVC ",NULL,"Add for who this story is","well_formed","no_role","high",False
25886,"Test Redis Sentinel setup and document recommended configuration Configure Redis Cluster with Sentinal v 2.8.19. Verify fail over, experiment with settings. Useful reference All analytics test cases should be run as well as test that deploy streams that make use of redis analytics. There might be some minor code changes required as mentioned in the flickr article.",NULL,"Test Redis Sentinel setup and document recommended configuration Configure Redis Cluster with Sentinal v 2.8.19. Verify fail over, experiment with settings. Useful reference All analytics test cases should be run as well as test that deploy streams that make use of redis analytics. There might be some minor code changes required as mentioned in the flickr article.",NULL,"Add for who this story is","well_formed","no_role","high",False
25886,"Test Redis Sentinel setup and document recommended configuration Configure Redis Cluster with Sentinal v 2.8.19. Verify fail over, experiment with settings. Useful reference All analytics test cases should be run as well as test that deploy streams that make use of redis analytics. There might be some minor code changes required as mentioned in the flickr article.",NULL,"Test Redis Sentinel setup and document recommended configuration Configure Redis Cluster with Sentinal v 2.8.19. Verify fail over, experiment with settings. Useful reference All analytics test cases should be run as well as test that deploy streams that make use of redis analytics. There might be some minor code changes required as mentioned in the flickr article.",NULL,"Test Redis Sentinel setup and document recommended configuration Configure Redis Cluster with Sentinal v 2<span class='highlight-text severity-high'>.8.19. Verify fail over, experiment with settings. Useful reference All analytics test cases should be run as well as test that deploy streams that make use of redis analytics. There might be some minor code changes required as mentioned in the flickr article.</span>","minimal","punctuation","high",False
25872,"Bump Spring Integration to 4.1.2; Spring AMQP to 1.4.2 ",NULL,"Bump Spring Integration to 4.1.2; Spring AMQP to 1.4.2 ",NULL,"Add for who this story is","well_formed","no_role","high",False
25872,"Bump Spring Integration to 4.1.2; Spring AMQP to 1.4.2 ",NULL,"Bump Spring Integration to 4.1.2; Spring AMQP to 1.4.2 ",NULL,"Bump Spring Integration to 4.1.2<span class='highlight-text severity-high'>; Spring AMQP to 1.4.2 </span>","minimal","punctuation","high",False
25863,"Create a new Broadcast stream per thread The data that is entering a broadcast stream can only occur from one thread at a time to prevent race conditions inside the stream implementation. The current handler shares a single broadcast stream. Change to create a new one per thread usage.",NULL,"Create a new Broadcast stream per thread The data that is entering a broadcast stream can only occur from one thread at a time to prevent race conditions inside the stream implementation. The current handler shares a single broadcast stream. Change to create a new one per thread usage.",NULL,"Add for who this story is","well_formed","no_role","high",False
25863,"Create a new Broadcast stream per thread The data that is entering a broadcast stream can only occur from one thread at a time to prevent race conditions inside the stream implementation. The current handler shares a single broadcast stream. Change to create a new one per thread usage.",NULL,"Create a new Broadcast stream per thread The data that is entering a broadcast stream can only occur from one thread at a time to prevent race conditions inside the stream implementation. The current handler shares a single broadcast stream. Change to create a new one per thread usage.",NULL,"Create a new Broadcast stream per thread The data that is entering a broadcast stream can only occur from one thread at a time to prevent race conditions inside the stream implementation<span class='highlight-text severity-high'>. The current handler shares a single broadcast stream. Change to create a new one per thread usage.</span>","minimal","punctuation","high",False
25875,"Create a that uses a Serialized Broadcaster This is a parallel implementation to the RxJava That will allow multiple threads to broadcast an event but allow processing to occur one at a time on any thread.",NULL,"Create a that uses a Serialized Broadcaster This is a parallel implementation to the RxJava That will allow multiple threads to broadcast an event but allow processing to occur one at a time on any thread.",NULL,"Add for who this story is","well_formed","no_role","high",False
25877,"Add command for listing streams Add command for listing streams ",NULL,"Add command for listing streams Add command for listing streams ",NULL,"Add for who this story is","well_formed","no_role","high",False
25885,"Add Kafka Native Metadata Store ",NULL,"Add Kafka Native Metadata Store ",NULL,"Add for who this story is","well_formed","no_role","high",False
25889,"For time being checkin UI build artifacts ",NULL,"For time being checkin UI build artifacts ",NULL,"Add for who this story is","well_formed","no_role","high",False
25890,"Shell processor is not thread safe Multiple threads invoke the shell processor result in I O errors and or data corruption. send and receive should be synchronized. ",NULL,"Shell processor is not thread safe Multiple threads invoke the shell processor result in I O errors and or data corruption. send and receive should be synchronized. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25890,"Shell processor is not thread safe Multiple threads invoke the shell processor result in I O errors and or data corruption. send and receive should be synchronized. ",NULL,"Shell processor is not thread safe Multiple threads invoke the shell processor result in I O errors and or data corruption. send and receive should be synchronized. ",NULL,"Shell processor is not thread safe Multiple threads invoke the shell processor result in I O errors<span class='highlight-text severity-high'> and </span>span class='highlight-text severity-high'> or </span>data corruption. send and receive should be synchronized. ","atomic","conjunctions","high",False
25890,"Shell processor is not thread safe Multiple threads invoke the shell processor result in I O errors and or data corruption. send and receive should be synchronized. ",NULL,"Shell processor is not thread safe Multiple threads invoke the shell processor result in I O errors and or data corruption. send and receive should be synchronized. ",NULL,"Shell processor is not thread safe Multiple threads invoke the shell processor result in I O errors and or data corruption<span class='highlight-text severity-high'>. send and receive should be synchronized. </span>","minimal","punctuation","high",False
25892,"Acceptance tests need to create or use an existing topic prior to executing test ",NULL,"Acceptance tests need to create or use an existing topic prior to executing test ",NULL,"Add for who this story is","well_formed","no_role","high",False
25892,"Acceptance tests need to create or use an existing topic prior to executing test ",NULL,"Acceptance tests need to create or use an existing topic prior to executing test ",NULL,"Acceptance tests need to create<span class='highlight-text severity-high'> or </span>use an existing topic prior to executing test ","atomic","conjunctions","high",False
25893,"We Need a See etc.",NULL,"We Need a See etc.",NULL,"Add for who this story is","well_formed","no_role","high",False
25894,"Add Kafka based implementation for ",NULL,"Add Kafka based implementation for ",NULL,"Add for who this story is","well_formed","no_role","high",False
25895,"Retrieve description of all registered modules GET streams modules and GET streams The former returning links to the latter ",NULL,"Retrieve description of all registered modules GET streams modules and GET streams The former returning links to the latter ",NULL,"Add for who this story is","well_formed","no_role","high",False
25895,"Retrieve description of all registered modules GET streams modules and GET streams The former returning links to the latter ",NULL,"Retrieve description of all registered modules GET streams modules and GET streams The former returning links to the latter ",NULL,"Retrieve description of all registered modules GET streams modules<span class='highlight-text severity-high'> and </span>GET streams The former returning links to the latter ","atomic","conjunctions","high",False
25896,"Spike Research request reply support to Kafka Message Bus The scope is to research the available options to provide request reply support for Kafka. Document findings POCs Previous Desc The bindRequestor and bindReplier methods of the message bus need to be implemented.",NULL,"Spike Research request reply support to Kafka Message Bus The scope is to research the available options to provide request reply support for Kafka. Document findings POCs Previous Desc The bindRequestor and bindReplier methods of the message bus need to be implemented.",NULL,"Add for who this story is","well_formed","no_role","high",False
25896,"Spike Research request reply support to Kafka Message Bus The scope is to research the available options to provide request reply support for Kafka. Document findings POCs Previous Desc The bindRequestor and bindReplier methods of the message bus need to be implemented.",NULL,"Spike Research request reply support to Kafka Message Bus The scope is to research the available options to provide request reply support for Kafka. Document findings POCs Previous Desc The bindRequestor and bindReplier methods of the message bus need to be implemented.",NULL,"Spike Research request reply support to Kafka Message Bus The scope is to research the available options to provide request reply support for Kafka. Document findings POCs Previous Desc The bindRequestor<span class='highlight-text severity-high'> and </span>bindReplier methods of the message bus need to be implemented.","atomic","conjunctions","high",False
25896,"Spike Research request reply support to Kafka Message Bus The scope is to research the available options to provide request reply support for Kafka. Document findings POCs Previous Desc The bindRequestor and bindReplier methods of the message bus need to be implemented.",NULL,"Spike Research request reply support to Kafka Message Bus The scope is to research the available options to provide request reply support for Kafka. Document findings POCs Previous Desc The bindRequestor and bindReplier methods of the message bus need to be implemented.",NULL,"Spike Research request reply support to Kafka Message Bus The scope is to research the available options to provide request reply support for Kafka<span class='highlight-text severity-high'>. Document findings POCs Previous Desc The bindRequestor and bindReplier methods of the message bus need to be implemented.</span>","minimal","punctuation","high",False
25903,"Update copyright message in PDF from 2014 to 2015 As a PM, I'd like to have the copyright message in the reference guide PDF updated to include 2015 instead of 2014. ",NULL,"Update copyright message in PDF from 2014 to 2015 As a PM, I'd like to have the copyright message in the reference guide PDF updated to include 2015 instead of 2014. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25902,"Create Spark Streaming example As a developer, I'd like to build Spark Streaming as data processors in XD so that we can demonstrate some of the capabilities. Implement using Java Java Lambdas Scala",NULL,"Create Spark Streaming example As a developer, I'd like to build Spark Streaming as data processors in XD","so that we can demonstrate some of the capabilities. Implement using Java Java Lambdas Scala","Add for who this story is","well_formed","no_role","high",False
25902,"Create Spark Streaming example As a developer, I'd like to build Spark Streaming as data processors in XD so that we can demonstrate some of the capabilities. Implement using Java Java Lambdas Scala",NULL,"Create Spark Streaming example As a developer, I'd like to build Spark Streaming as data processors in XD","so that we can demonstrate some of the capabilities. Implement using Java Java Lambdas Scala","Create Spark Streaming example As a developer, I'd like to build Spark Streaming as data processors in XD so that we can demonstrate some of the capabilities<span class='highlight-text severity-high'>. Implement using Java Java Lambdas Scala</span>","minimal","punctuation","high",False
25902,"Create Spark Streaming example As a developer, I'd like to build Spark Streaming as data processors in XD so that we can demonstrate some of the capabilities. Implement using Java Java Lambdas Scala",NULL,"Create Spark Streaming example As a developer, I'd like to build Spark Streaming as data processors in XD","so that we can demonstrate some of the capabilities. Implement using Java Java Lambdas Scala","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25899,"Create a sample to invoke Pig script job from XD As a user, I'd like to refer to a Pig script job sample so that I can use that as a reference to integrate Pig jobs in XD.",NULL,"Create a sample to invoke Pig script job from XD As a user, I'd like to refer to a Pig script job sample","so that I can use that as a reference to integrate Pig jobs in XD.","Add for who this story is","well_formed","no_role","high",False
25899,"Create a sample to invoke Pig script job from XD As a user, I'd like to refer to a Pig script job sample so that I can use that as a reference to integrate Pig jobs in XD.",NULL,"Create a sample to invoke Pig script job from XD As a user, I'd like to refer to a Pig script job sample","so that I can use that as a reference to integrate Pig jobs in XD.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25908,"Add scala support for spark streaming module As a scala developer, someone could easily deploy the spark streaming module developed using scala. ",NULL,"Add scala support for spark streaming module As a scala developer, someone could easily deploy the spark streaming module developed using scala. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25901,"Add build support for XD in Windows As a user, I'd like to build XD in Windows machine so that I can develop, test, and contributed to OSS.",NULL,"Add build support for XD in Windows As a user, I'd like to build XD in Windows machine","so that I can develop, test, and contributed to OSS.","Add for who this story is","well_formed","no_role","high",False
25901,"Add build support for XD in Windows As a user, I'd like to build XD in Windows machine so that I can develop, test, and contributed to OSS.",NULL,"Add build support for XD in Windows As a user, I'd like to build XD in Windows machine","so that I can develop, test, and contributed to OSS.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25904,"Upgrade to SI Kafka GA release As a developer, I'd like to upgrade to Kafka s SI GA release so that I can sync up with the latest bits. The scope is to backport Kafka XD changes to SI Kafka and then upgrade to the GA release.",NULL,"Upgrade to SI Kafka GA release As a developer, I'd like to upgrade to Kafka s SI GA release","so that I can sync up with the latest bits. The scope is to backport Kafka XD changes to SI Kafka and then upgrade to the GA release.","Add for who this story is","well_formed","no_role","high",False
25904,"Upgrade to SI Kafka GA release As a developer, I'd like to upgrade to Kafka s SI GA release so that I can sync up with the latest bits. The scope is to backport Kafka XD changes to SI Kafka and then upgrade to the GA release.",NULL,"Upgrade to SI Kafka GA release As a developer, I'd like to upgrade to Kafka s SI GA release","so that I can sync up with the latest bits. The scope is to backport Kafka XD changes to SI Kafka and then upgrade to the GA release.","Upgrade to SI Kafka GA release As a developer, I'd like to upgrade to Kafka s SI GA release so that I can sync up with the latest bits<span class='highlight-text severity-high'>. The scope is to backport Kafka XD changes to SI Kafka and then upgrade to the GA release.</span>","minimal","punctuation","high",False
25904,"Upgrade to SI Kafka GA release As a developer, I'd like to upgrade to Kafka s SI GA release so that I can sync up with the latest bits. The scope is to backport Kafka XD changes to SI Kafka and then upgrade to the GA release.",NULL,"Upgrade to SI Kafka GA release As a developer, I'd like to upgrade to Kafka s SI GA release","so that I can sync up with the latest bits. The scope is to backport Kafka XD changes to SI Kafka and then upgrade to the GA release.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25905,"Upgrade to SHDP GA Release As a developer, I'd like to upgrade to SHDP GA release so that I can sync up with the latest bits. ",NULL,"Upgrade to SHDP GA Release As a developer, I'd like to upgrade to SHDP GA release","so that I can sync up with the latest bits.","Add for who this story is","well_formed","no_role","high",False
25905,"Upgrade to SHDP GA Release As a developer, I'd like to upgrade to SHDP GA release so that I can sync up with the latest bits. ",NULL,"Upgrade to SHDP GA Release As a developer, I'd like to upgrade to SHDP GA release","so that I can sync up with the latest bits.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25906,"Job as a Source As an XD developer, I need to be able to use a batch job to stream data as a source. ",NULL,"Job as a Source As an XD developer, I need to be able to use a batch job to stream data as a source. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26028,"Complete remaining work for the DEBS challenge As a developer, I'd like to complete the remaining work with DEBS challenge, so I can submit by the deadline.",NULL,"Complete remaining work for the DEBS challenge As a developer, I'd like to complete the remaining work with DEBS challenge,","so I can submit by the deadline.","Add for who this story is","well_formed","no_role","high",False
26028,"Complete remaining work for the DEBS challenge As a developer, I'd like to complete the remaining work with DEBS challenge, so I can submit by the deadline.",NULL,"Complete remaining work for the DEBS challenge As a developer, I'd like to complete the remaining work with DEBS challenge,","so I can submit by the deadline.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25891,"Spring MVC infrastructure tests ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25891,"Spring MVC infrastructure tests ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25897,"Document migration strategy for custom modules from 1.0 to 1.1 As a user, I'd like to migrate from 1.0 to 1.1 and be able to port my custom modules so that I can operationalize existing data pipelines and also take advantage of latest XD features.",NULL,"Document migration strategy for custom modules from 1.0 to 1.1 As a user, I'd like to migrate from 1.0 to 1.1 and be able to port my custom modules","so that I can operationalize existing data pipelines and also take advantage of latest XD features.","Add for who this story is","well_formed","no_role","high",False
25976,"Measure performance baseline for a simple stream As a developer, I'd like to measure performance numbers for a simple stream so that I can characterize the overall throughput. ",NULL,"Measure performance baseline for a simple stream As a developer, I'd like to measure performance numbers for a simple stream","so that I can characterize the overall throughput.","Add for who this story is","well_formed","no_role","high",False
25897,"Document migration strategy for custom modules from 1.0 to 1.1 As a user, I'd like to migrate from 1.0 to 1.1 and be able to port my custom modules so that I can operationalize existing data pipelines and also take advantage of latest XD features.",NULL,"Document migration strategy for custom modules from 1.0 to 1.1 As a user, I'd like to migrate from 1.0 to 1.1 and be able to port my custom modules","so that I can operationalize existing data pipelines and also take advantage of latest XD features.","Document migration strategy for custom modules from 1.0 to 1.1 As a user, I'd like to migrate from 1.0 to 1.1<span class='highlight-text severity-high'> and </span>be able to port my custom modules so that I can operationalize existing data pipelines and also take advantage of latest XD features.","atomic","conjunctions","high",False
25897,"Document migration strategy for custom modules from 1.0 to 1.1 As a user, I'd like to migrate from 1.0 to 1.1 and be able to port my custom modules so that I can operationalize existing data pipelines and also take advantage of latest XD features.",NULL,"Document migration strategy for custom modules from 1.0 to 1.1 As a user, I'd like to migrate from 1.0 to 1.1 and be able to port my custom modules","so that I can operationalize existing data pipelines and also take advantage of latest XD features.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25898,"Update to latest version Use latest version, might need to exclude version from other dependencies, e.g. SI, in ",NULL,"Update to latest version Use latest version, might need to exclude version from other dependencies, e.g. SI, in ",NULL,"Add for who this story is","well_formed","no_role","high",False
25898,"Update to latest version Use latest version, might need to exclude version from other dependencies, e.g. SI, in ",NULL,"Update to latest version Use latest version, might need to exclude version from other dependencies, e.g. SI, in ",NULL,"Update to latest version Use latest version, might need to exclude version from other dependencies, e<span class='highlight-text severity-high'>.g. SI, in </span>","minimal","punctuation","high",False
25907,"Bump Spring AMQP to 1.4.3 When available",NULL,"Bump Spring AMQP to 1.4.3 When available",NULL,"Add for who this story is","well_formed","no_role","high",False
25911,"Document recommended ulimit setting for XD As a developer, I'd like to refer to wiki so that I can configure machines with recommended ulimit setting for XD s distributed setup. Note Recommended ulimit setting is 10K under Troubleshooting new section Exception reason to increase ulimit 8 25 52,266 1.1.0.SNAP ERROR Exception deploying module Too many open files ",NULL,"Document recommended ulimit setting for XD As a developer, I'd like to refer to wiki","so that I can configure machines with recommended ulimit setting for XD s distributed setup. Note Recommended ulimit setting is 10K under Troubleshooting new section Exception reason to increase ulimit 8 25 52,266 1.1.0.SNAP ERROR Exception deploying module Too many open files","Add for who this story is","well_formed","no_role","high",False
25911,"Document recommended ulimit setting for XD As a developer, I'd like to refer to wiki so that I can configure machines with recommended ulimit setting for XD s distributed setup. Note Recommended ulimit setting is 10K under Troubleshooting new section Exception reason to increase ulimit 8 25 52,266 1.1.0.SNAP ERROR Exception deploying module Too many open files ",NULL,"Document recommended ulimit setting for XD As a developer, I'd like to refer to wiki","so that I can configure machines with recommended ulimit setting for XD s distributed setup. Note Recommended ulimit setting is 10K under Troubleshooting new section Exception reason to increase ulimit 8 25 52,266 1.1.0.SNAP ERROR Exception deploying module Too many open files","Document recommended ulimit setting for XD As a developer, I'd like to refer to wiki so that I can configure machines with recommended ulimit setting for XD s distributed setup<span class='highlight-text severity-high'>. Note Recommended ulimit setting is 10K under Troubleshooting new section Exception reason to increase ulimit 8 25 52,266 1.1.0.SNAP ERROR Exception deploying module Too many open files </span>","minimal","punctuation","high",False
25911,"Document recommended ulimit setting for XD As a developer, I'd like to refer to wiki so that I can configure machines with recommended ulimit setting for XD s distributed setup. Note Recommended ulimit setting is 10K under Troubleshooting new section Exception reason to increase ulimit 8 25 52,266 1.1.0.SNAP ERROR Exception deploying module Too many open files ",NULL,"Document recommended ulimit setting for XD As a developer, I'd like to refer to wiki","so that I can configure machines with recommended ulimit setting for XD s distributed setup. Note Recommended ulimit setting is 10K under Troubleshooting new section Exception reason to increase ulimit 8 25 52,266 1.1.0.SNAP ERROR Exception deploying module Too many open files","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25912,"Set to JDK 1.7 Min JDK version for XD 1.1 is 7. Change the to 1.7 but leave at 1.6. Changes are also needed in the mdule parent pom and gradle plugins.",NULL,"Set to JDK 1.7 Min JDK version for XD 1.1 is 7. Change the to 1.7 but leave at 1.6. Changes are also needed in the mdule parent pom and gradle plugins.",NULL,"Add for who this story is","well_formed","no_role","high",False
25912,"Set to JDK 1.7 Min JDK version for XD 1.1 is 7. Change the to 1.7 but leave at 1.6. Changes are also needed in the mdule parent pom and gradle plugins.",NULL,"Set to JDK 1.7 Min JDK version for XD 1.1 is 7. Change the to 1.7 but leave at 1.6. Changes are also needed in the mdule parent pom and gradle plugins.",NULL,"Set to JDK 1<span class='highlight-text severity-high'>.7 Min JDK version for XD 1.1 is 7. Change the to 1.7 but leave at 1.6. Changes are also needed in the mdule parent pom and gradle plugins.</span>","minimal","punctuation","high",False
25914,"Fix jsonPath evaluation following JsonPath version upgrade ",NULL,"Fix jsonPath evaluation following JsonPath version upgrade ",NULL,"Add for who this story is","well_formed","no_role","high",False
25913,"Update log4j properties to include DATE in the logs As a user, I'd like to see the date in logs so that I can troubleshoot issues that had occurred on a specific day and time. Property that needs adjusted ",NULL,"Update log4j properties to include DATE in the logs As a user, I'd like to see the date in logs","so that I can troubleshoot issues that had occurred on a specific day and time. Property that needs adjusted","Add for who this story is","well_formed","no_role","high",False
25913,"Update log4j properties to include DATE in the logs As a user, I'd like to see the date in logs so that I can troubleshoot issues that had occurred on a specific day and time. Property that needs adjusted ",NULL,"Update log4j properties to include DATE in the logs As a user, I'd like to see the date in logs","so that I can troubleshoot issues that had occurred on a specific day and time. Property that needs adjusted","Update log4j properties to include DATE in the logs As a user, I'd like to see the date in logs so that I can troubleshoot issues that had occurred on a specific day and time<span class='highlight-text severity-high'>. Property that needs adjusted </span>","minimal","punctuation","high",False
25913,"Update log4j properties to include DATE in the logs As a user, I'd like to see the date in logs so that I can troubleshoot issues that had occurred on a specific day and time. Property that needs adjusted ",NULL,"Update log4j properties to include DATE in the logs As a user, I'd like to see the date in logs","so that I can troubleshoot issues that had occurred on a specific day and time. Property that needs adjusted","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25918,"Run Kafka tests with Kafka Server as separate process As a developer, I'd like to run Kafka tests with Kafka Server as a separate running process so that I can improve build experience. ",NULL,"Run Kafka tests with Kafka Server as separate process As a developer, I'd like to run Kafka tests with Kafka Server as a separate running process","so that I can improve build experience.","Add for who this story is","well_formed","no_role","high",False
25918,"Run Kafka tests with Kafka Server as separate process As a developer, I'd like to run Kafka tests with Kafka Server as a separate running process so that I can improve build experience. ",NULL,"Run Kafka tests with Kafka Server as separate process As a developer, I'd like to run Kafka tests with Kafka Server as a separate running process","so that I can improve build experience.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25919,"Spring XD module parent should use for versioning As a developer, I'd like the so that I don t have to update them manually anymore.",NULL,"Spring XD module parent should use for versioning As a developer, I'd like the","so that I don t have to update them manually anymore.","Add for who this story is","well_formed","no_role","high",False
25919,"Spring XD module parent should use for versioning As a developer, I'd like the so that I don t have to update them manually anymore.",NULL,"Spring XD module parent should use for versioning As a developer, I'd like the","so that I don t have to update them manually anymore.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25923,"Gemfire CQ module for ingestion ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25923,"Gemfire CQ module for ingestion ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25916,"Restrict entry filter in loading module artifacts see ",NULL,"Restrict entry filter in loading module artifacts see ",NULL,"Add for who this story is","well_formed","no_role","high",False
25917,"Upgrade to the latest Gradle 2.x Release Gradle 2.x is required for the latest Sonar version sonar.spring.io We may need to wait for a fix in Groovy itself 2.4.1 Please see the following links for details ",NULL,"Upgrade to the latest Gradle 2.x Release Gradle 2.x is required for the latest Sonar version sonar.spring.io We may need to wait for a fix in Groovy itself 2.4.1 Please see the following links for details ",NULL,"Add for who this story is","well_formed","no_role","high",False
25922,"Review and fix Sonar violations As a developer, I'd like to review the current sonar violations so that I can fix the relevant and update the irrelevant ones as invalid.",NULL,"Review and fix Sonar violations As a developer, I'd like to review the current sonar violations","so that I can fix the relevant and update the irrelevant ones as invalid.","Add for who this story is","well_formed","no_role","high",False
25922,"Review and fix Sonar violations As a developer, I'd like to review the current sonar violations so that I can fix the relevant and update the irrelevant ones as invalid.",NULL,"Review and fix Sonar violations As a developer, I'd like to review the current sonar violations","so that I can fix the relevant and update the irrelevant ones as invalid.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25921,"Kafka Tests should use an external broker As a developer, I want to have to run Kafka tests on an external broker, so that I reduce the footprint of the build process. ",NULL,"Kafka Tests should use an external broker As a developer, I want to have to run Kafka tests on an external broker,","so that I reduce the footprint of the build process.","Add for who this story is","well_formed","no_role","high",False
25921,"Kafka Tests should use an external broker As a developer, I want to have to run Kafka tests on an external broker, so that I reduce the footprint of the build process. ",NULL,"Kafka Tests should use an external broker As a developer, I want to have to run Kafka tests on an external broker,","so that I reduce the footprint of the build process.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25920,"Downgrade reactor based modules to reactor 1.x GA Can revert part of the commit that went into upgrading to reactor 2.0 ",NULL,"Downgrade reactor based modules to reactor 1.x GA Can revert part of the commit that went into upgrading to reactor 2.0 ",NULL,"Add for who this story is","well_formed","no_role","high",False
25925,"Remove spark and hadoop dependencies from custom module classpath remove spark and hadoop requirements from and gradle module plugin",NULL,"Remove spark and hadoop dependencies from custom module classpath remove spark and hadoop requirements from and gradle module plugin",NULL,"Add for who this story is","well_formed","no_role","high",False
25925,"Remove spark and hadoop dependencies from custom module classpath remove spark and hadoop requirements from and gradle module plugin",NULL,"Remove spark and hadoop dependencies from custom module classpath remove spark and hadoop requirements from and gradle module plugin",NULL,"Remove spark<span class='highlight-text severity-high'> and </span>hadoop dependencies from custom module classpath remove spark and hadoop requirements from and gradle module plugin","atomic","conjunctions","high",False
25924,"The HDFS Sink should support a file naming strategy to distinguish between file currently being written and completed files A file that is in the process of being written to should have a customized suffix added to the name, e.g. temp . Once the file is closed, the suffix is removed and replaced with another value default value can be dependent on the serialization format used, but can be customized",NULL,"The HDFS Sink should support a file naming strategy to distinguish between file currently being written and completed files A file that is in the process of being written to should have a customized suffix added to the name, e.g. temp . Once the file is closed, the suffix is removed and replaced with another value default value can be dependent on the serialization format used, but can be customized",NULL,"Add for who this story is","well_formed","no_role","high",False
25924,"The HDFS Sink should support a file naming strategy to distinguish between file currently being written and completed files A file that is in the process of being written to should have a customized suffix added to the name, e.g. temp . Once the file is closed, the suffix is removed and replaced with another value default value can be dependent on the serialization format used, but can be customized",NULL,"The HDFS Sink should support a file naming strategy to distinguish between file currently being written and completed files A file that is in the process of being written to should have a customized suffix added to the name, e.g. temp . Once the file is closed, the suffix is removed and replaced with another value default value can be dependent on the serialization format used, but can be customized",NULL,"The HDFS Sink should support a file naming strategy to distinguish between file currently being written<span class='highlight-text severity-high'> and </span>completed files A file that is in the process of being written to should have a customized suffix added to the name, e.g. temp . Once the file is closed, the suffix is removed and replaced with another value default value can be dependent on the serialization format used, but can be customized","atomic","conjunctions","high",False
25924,"The HDFS Sink should support a file naming strategy to distinguish between file currently being written and completed files A file that is in the process of being written to should have a customized suffix added to the name, e.g. temp . Once the file is closed, the suffix is removed and replaced with another value default value can be dependent on the serialization format used, but can be customized",NULL,"The HDFS Sink should support a file naming strategy to distinguish between file currently being written and completed files A file that is in the process of being written to should have a customized suffix added to the name, e.g. temp . Once the file is closed, the suffix is removed and replaced with another value default value can be dependent on the serialization format used, but can be customized",NULL,"The HDFS Sink should support a file naming strategy to distinguish between file currently being written and completed files A file that is in the process of being written to should have a customized suffix added to the name, e<span class='highlight-text severity-high'>.g. temp . Once the file is closed, the suffix is removed and replaced with another value default value can be dependent on the serialization format used, but can be customized</span>","minimal","punctuation","high",False
25909,"Resolve classloading issues for custom Hadoop based batch jobs There are several issues making it hard to impossible to create batch jobs that use Pig, Hive, HBase or other technologies supported by Spring for Apache Hadoop project. We need to make the corresponding dependencies available on the Hadoop classpath.",NULL,"Resolve classloading issues for custom Hadoop based batch jobs There are several issues making it hard to impossible to create batch jobs that use Pig, Hive, HBase or other technologies supported by Spring for Apache Hadoop project. We need to make the corresponding dependencies available on the Hadoop classpath.",NULL,"Add for who this story is","well_formed","no_role","high",False
25909,"Resolve classloading issues for custom Hadoop based batch jobs There are several issues making it hard to impossible to create batch jobs that use Pig, Hive, HBase or other technologies supported by Spring for Apache Hadoop project. We need to make the corresponding dependencies available on the Hadoop classpath.",NULL,"Resolve classloading issues for custom Hadoop based batch jobs There are several issues making it hard to impossible to create batch jobs that use Pig, Hive, HBase or other technologies supported by Spring for Apache Hadoop project. We need to make the corresponding dependencies available on the Hadoop classpath.",NULL,"Resolve classloading issues for custom Hadoop based batch jobs There are several issues making it hard to impossible to create batch jobs that use Pig, Hive, HBase<span class='highlight-text severity-high'> or </span>other technologies supported by Spring for Apache Hadoop project. We need to make the corresponding dependencies available on the Hadoop classpath.","atomic","conjunctions","high",False
25909,"Resolve classloading issues for custom Hadoop based batch jobs There are several issues making it hard to impossible to create batch jobs that use Pig, Hive, HBase or other technologies supported by Spring for Apache Hadoop project. We need to make the corresponding dependencies available on the Hadoop classpath.",NULL,"Resolve classloading issues for custom Hadoop based batch jobs There are several issues making it hard to impossible to create batch jobs that use Pig, Hive, HBase or other technologies supported by Spring for Apache Hadoop project. We need to make the corresponding dependencies available on the Hadoop classpath.",NULL,"Resolve classloading issues for custom Hadoop based batch jobs There are several issues making it hard to impossible to create batch jobs that use Pig, Hive, HBase or other technologies supported by Spring for Apache Hadoop project<span class='highlight-text severity-high'>. We need to make the corresponding dependencies available on the Hadoop classpath.</span>","minimal","punctuation","high",False
25915,"Create JobDefinition repository Create JobDefinition repository As XD, I need a persistent way to register job definitions beyond the map registry implementation provided by Spring Batch . ",NULL,"Create JobDefinition repository Create JobDefinition repository As XD, I need a persistent way to register job definitions beyond the map registry implementation provided by Spring Batch . ",NULL,"Add for who this story is","well_formed","no_role","high",False
25933,"Create a Batch example to demonstrate JDBC HDFS As a developer, I'd like to create a example to demonstrate JDBC to HDFS data movement.",NULL,"Create a Batch example to demonstrate JDBC HDFS As a developer, I'd like to create a example to demonstrate JDBC to HDFS data movement.",NULL,"Add for who this story is","well_formed","no_role","high",False
25928,"Move documentation from wiki to main repo As a consequence, change gradle script regarding generation of documentation remove pushGeneratedDocs task, etc remove link rewriting that is no longer needed ",NULL,"Move documentation from wiki to main repo As a consequence, change gradle script regarding generation of documentation remove pushGeneratedDocs task, etc remove link rewriting that is no longer needed ",NULL,"Add for who this story is","well_formed","no_role","high",False
25927,"Create Sqoop example As a developer, I'd like to build batch sample using Sqoop so that we can demonstrate some of the capabilities. Use cases to consider JDBC to HDFS HDFS to JDBC ",NULL,"Create Sqoop example As a developer, I'd like to build batch sample using Sqoop","so that we can demonstrate some of the capabilities. Use cases to consider JDBC to HDFS HDFS to JDBC","Add for who this story is","well_formed","no_role","high",False
25927,"Create Sqoop example As a developer, I'd like to build batch sample using Sqoop so that we can demonstrate some of the capabilities. Use cases to consider JDBC to HDFS HDFS to JDBC ",NULL,"Create Sqoop example As a developer, I'd like to build batch sample using Sqoop","so that we can demonstrate some of the capabilities. Use cases to consider JDBC to HDFS HDFS to JDBC","Create Sqoop example As a developer, I'd like to build batch sample using Sqoop so that we can demonstrate some of the capabilities<span class='highlight-text severity-high'>. Use cases to consider JDBC to HDFS HDFS to JDBC </span>","minimal","punctuation","high",False
25927,"Create Sqoop example As a developer, I'd like to build batch sample using Sqoop so that we can demonstrate some of the capabilities. Use cases to consider JDBC to HDFS HDFS to JDBC ",NULL,"Create Sqoop example As a developer, I'd like to build batch sample using Sqoop","so that we can demonstrate some of the capabilities. Use cases to consider JDBC to HDFS HDFS to JDBC","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25929,"Improve Redis Bus Error Log Entry to deliver message; retries exhausted; message sent to queue ERRORS name , Should be to deliver message; retries exhausted; message sent to queue ERRORS name , So the actual name is logged. ",NULL,"Improve Redis Bus Error Log Entry to deliver message; retries exhausted; message sent to queue ERRORS name , Should be to deliver message; retries exhausted; message sent to queue ERRORS name ,","So the actual name is logged.","Add for who this story is","well_formed","no_role","high",False
25976,"Measure performance baseline for a simple stream As a developer, I'd like to measure performance numbers for a simple stream so that I can characterize the overall throughput. ",NULL,"Measure performance baseline for a simple stream As a developer, I'd like to measure performance numbers for a simple stream","so that I can characterize the overall throughput.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25979,"Updated XD EC2 XD deployment for 1.2 Mask out all properties for XD EC2",NULL,"Updated XD EC2 XD deployment for 1.2 Mask out all properties for XD EC2",NULL,"Add for who this story is","well_formed","no_role","high",False
25929,"Improve Redis Bus Error Log Entry to deliver message; retries exhausted; message sent to queue ERRORS name , Should be to deliver message; retries exhausted; message sent to queue ERRORS name , So the actual name is logged. ",NULL,"Improve Redis Bus Error Log Entry to deliver message; retries exhausted; message sent to queue ERRORS name , Should be to deliver message; retries exhausted; message sent to queue ERRORS name ,","So the actual name is logged.","Improve Redis Bus Error Log Entry to deliver message<span class='highlight-text severity-high'>; retries exhausted; message sent to queue ERRORS name , Should be to deliver message; retries exhausted; message sent to queue ERRORS name , So the actual name is logged. </span>","minimal","punctuation","high",False
25929,"Improve Redis Bus Error Log Entry to deliver message; retries exhausted; message sent to queue ERRORS name , Should be to deliver message; retries exhausted; message sent to queue ERRORS name , So the actual name is logged. ",NULL,"Improve Redis Bus Error Log Entry to deliver message; retries exhausted; message sent to queue ERRORS name , Should be to deliver message; retries exhausted; message sent to queue ERRORS name ,","So the actual name is logged.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25930,"The HDFS Sink should support a number of rollover options A strategy to roll over files that allows the user to choose between 1 the size of the file 2 the number of events items in the file 3 an idle timeout value that if exceeded, will close the file",NULL,"The HDFS Sink should support a number of rollover options A strategy to roll over files that allows the user to choose between 1 the size of the file 2 the number of events items in the file 3 an idle timeout value that if exceeded, will close the file",NULL,"Add for who this story is","well_formed","no_role","high",False
25931,"Replicate Storm examples in XD As a field engineer, I'd like to have a comparison of Storm examples in Spring XD so that it is easy to relate from implementation standpoint. ",NULL,"Replicate Storm examples in XD As a field engineer, I'd like to have a comparison of Storm examples in Spring XD","so that it is easy to relate from implementation standpoint.","Add for who this story is","well_formed","no_role","high",False
25931,"Replicate Storm examples in XD As a field engineer, I'd like to have a comparison of Storm examples in Spring XD so that it is easy to relate from implementation standpoint. ",NULL,"Replicate Storm examples in XD As a field engineer, I'd like to have a comparison of Storm examples in Spring XD","so that it is easy to relate from implementation standpoint.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25932,"Add Smart Grid demo to XD samples repo As a PM, I'd like to have the Smart Grid demo from s1 2014 ported into Spring XD samples repo.",NULL,"Add Smart Grid demo to XD samples repo As a PM, I'd like to have the Smart Grid demo from s1 2014 ported into Spring XD samples repo.",NULL,"Add for who this story is","well_formed","no_role","high",False
25938,"Increase the The is set to 300000 as default 5min . This is way to short for long running steps. We should increase this default.",NULL,"Increase the The is set to 300000 as default 5min . This is way to short for long running steps. We should increase this default.",NULL,"Add for who this story is","well_formed","no_role","high",False
25938,"Increase the The is set to 300000 as default 5min . This is way to short for long running steps. We should increase this default.",NULL,"Increase the The is set to 300000 as default 5min . This is way to short for long running steps. We should increase this default.",NULL,"Increase the The is set to 300000 as default 5min <span class='highlight-text severity-high'>. This is way to short for long running steps. We should increase this default.</span>","minimal","punctuation","high",False
25935,"Add a separate clean Admin command to clean up queues topics As a user, I'd like to clean up message bus resources associated with the stream so that when the stream is destroyed so does the coupled queues topics.",NULL,"Add a separate clean Admin command to clean up queues topics As a user, I'd like to clean up message bus resources associated with the stream","so that when the stream is destroyed so does the coupled queues topics.","Add for who this story is","well_formed","no_role","high",False
25935,"Add a separate clean Admin command to clean up queues topics As a user, I'd like to clean up message bus resources associated with the stream so that when the stream is destroyed so does the coupled queues topics.",NULL,"Add a separate clean Admin command to clean up queues topics As a user, I'd like to clean up message bus resources associated with the stream","so that when the stream is destroyed so does the coupled queues topics.","Add a separate clean Admin command to clean up queues topics As a user, I'd like to clean up message bus resources associated with the stream<span class='highlight-text severity-high'> so that </span>when the stream is destroyed<span class='highlight-text severity-high'> so </span>does the coupled queues topics.","minimal","indicator_repetition","high",False
25935,"Add a separate clean Admin command to clean up queues topics As a user, I'd like to clean up message bus resources associated with the stream so that when the stream is destroyed so does the coupled queues topics.",NULL,"Add a separate clean Admin command to clean up queues topics As a user, I'd like to clean up message bus resources associated with the stream","so that when the stream is destroyed so does the coupled queues topics.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25940,"Allow deletion of all metrics of a kind To be added in as well as the various shell commands counter all delete , etc... ",NULL,"Allow deletion of all metrics of a kind To be added in as well as the various shell commands counter all delete , etc... ",NULL,"Add for who this story is","well_formed","no_role","high",False
25936,"Invoke Rabbit REST API to clean up resources As a user, I'd like to clean up stale queues topics associated with the stream so when the stream gets destroyed I can clean up resources. ",NULL,"Invoke Rabbit REST API to clean up re","sources As a user, I'd like to clean up stale queues topics associated with the stream so when the stream gets destroyed I can clean up resources.","Add for who this story is","well_formed","no_role","high",False
25936,"Invoke Rabbit REST API to clean up resources As a user, I'd like to clean up stale queues topics associated with the stream so when the stream gets destroyed I can clean up resources. ",NULL,"Invoke Rabbit REST API to clean up re","sources As a user, I'd like to clean up stale queues topics associated with the stream so when the stream gets destroyed I can clean up resources.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25937,"A rotation file policy based on time A strategy that will automaticaly roll over files based time of day. For example New files will be created every hour, or every 6 hours etc. The directory for files can also be rotated so that directory structures such as data can easily be supported with a minimum of configuration. ",NULL,"A rotation file policy based on time A strategy that will automaticaly roll over files based time of day. For example New files will be created every hour, or every 6 hours etc. The directory for files can also be rotated","so that directory structures such as data can easily be supported with a minimum of configuration.","Add for who this story is","well_formed","no_role","high",False
25937,"A rotation file policy based on time A strategy that will automaticaly roll over files based time of day. For example New files will be created every hour, or every 6 hours etc. The directory for files can also be rotated so that directory structures such as data can easily be supported with a minimum of configuration. ",NULL,"A rotation file policy based on time A strategy that will automaticaly roll over files based time of day. For example New files will be created every hour, or every 6 hours etc. The directory for files can also be rotated","so that directory structures such as data can easily be supported with a minimum of configuration.","A rotation file policy based on time A strategy that will automaticaly roll over files based time of day<span class='highlight-text severity-high'>. For example New files will be created every hour, or every 6 hours etc. The directory for files can also be rotated so that directory structures such as data can easily be supported with a minimum of configuration. </span>","minimal","punctuation","high",False
25937,"A rotation file policy based on time A strategy that will automaticaly roll over files based time of day. For example New files will be created every hour, or every 6 hours etc. The directory for files can also be rotated so that directory structures such as data can easily be supported with a minimum of configuration. ",NULL,"A rotation file policy based on time A strategy that will automaticaly roll over files based time of day. For example New files will be created every hour, or every 6 hours etc. The directory for files can also be rotated","so that directory structures such as data can easily be supported with a minimum of configuration.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25939,"Add support to edit stream As a user, I'd like to have the option of editing the stream so that I don t have to destroy to just change any deployment property.",NULL,"Add support to edit stream As a user, I'd like to have the option of editing the stream","so that I don t have to destroy to just change any deployment property.","Add for who this story is","well_formed","no_role","high",False
25939,"Add support to edit stream As a user, I'd like to have the option of editing the stream so that I don t have to destroy to just change any deployment property.",NULL,"Add support to edit stream As a user, I'd like to have the option of editing the stream","so that I don t have to destroy to just change any deployment property.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25941,"Update payload conversion demo to latest module spec Upload payload conversion demo such that a user can use the module upload feature against the sample.",NULL,"Update payload conversion demo to latest module spec Upload payload conversion demo such that a user can use the module upload feature against the sample.",NULL,"Add for who this story is","well_formed","no_role","high",False
25942,"File name should support common date and time format strings The file name should allow the use of date and time patterns, either JDK or Joda TBD .",NULL,"File name should support common date and time format strings The file name should allow the use of date and time patterns, either JDK or Joda TBD .",NULL,"Add for who this story is","well_formed","no_role","high",False
25942,"File name should support common date and time format strings The file name should allow the use of date and time patterns, either JDK or Joda TBD .",NULL,"File name should support common date and time format strings The file name should allow the use of date and time patterns, either JDK or Joda TBD .",NULL,"File name should support common date<span class='highlight-text severity-high'> and </span>time format strings The file name should allow the use of date and time patterns, either JDK<span class='highlight-text severity-high'> or </span>Joda TBD .","atomic","conjunctions","high",False
25934,"Add nameExpression Property to File Sink As a stream definer, when defining a stream ending with a file sink, I would like to have more flexibility for naming the file. Add an alternative attribute. See ",NULL,"Add nameExpression Property to File Sink As a stream definer, when defining a stream ending with a file sink, I would like to have more flexibility for naming the file. Add an alternative attribute. See ",NULL,"Add for who this story is","well_formed","no_role","high",False
25934,"Add nameExpression Property to File Sink As a stream definer, when defining a stream ending with a file sink, I would like to have more flexibility for naming the file. Add an alternative attribute. See ",NULL,"Add nameExpression Property to File Sink As a stream definer, when defining a stream ending with a file sink, I would like to have more flexibility for naming the file. Add an alternative attribute. See ",NULL,"Add nameExpression Property to File Sink As a stream definer, when defining a stream ending with a file sink, I would like to have more flexibility for naming the file<span class='highlight-text severity-high'>. Add an alternative attribute. See </span>","minimal","punctuation","high",False
25945,"Create first cut on reference architectures for domain specific use cases As a field engineer, I'd like to have reference architectures built on Spring XD so that I can use that as reference building POCs. The scope is to get the raw domain specific ideas captured as first step. ",NULL,"Create first cut on reference architectures for domain specific use cases As a field engineer, I'd like to have reference architectures built on Spring XD","so that I can use that as reference building POCs. The scope is to get the raw domain specific ideas captured as first step.","Add for who this story is","well_formed","no_role","high",False
25945,"Create first cut on reference architectures for domain specific use cases As a field engineer, I'd like to have reference architectures built on Spring XD so that I can use that as reference building POCs. The scope is to get the raw domain specific ideas captured as first step. ",NULL,"Create first cut on reference architectures for domain specific use cases As a field engineer, I'd like to have reference architectures built on Spring XD","so that I can use that as reference building POCs. The scope is to get the raw domain specific ideas captured as first step.","Create first cut on reference architectures for domain specific use cases As a field engineer, I'd like to have reference architectures built on Spring XD so that I can use that as reference building POCs<span class='highlight-text severity-high'>. The scope is to get the raw domain specific ideas captured as first step. </span>","minimal","punctuation","high",False
25945,"Create first cut on reference architectures for domain specific use cases As a field engineer, I'd like to have reference architectures built on Spring XD so that I can use that as reference building POCs. The scope is to get the raw domain specific ideas captured as first step. ",NULL,"Create first cut on reference architectures for domain specific use cases As a field engineer, I'd like to have reference architectures built on Spring XD","so that I can use that as reference building POCs. The scope is to get the raw domain specific ideas captured as first step.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25946,"Add support for global wiretap config As a user, I'd like to have an optional trace as inline deployment properties for stream so that I can declare which module in the stream needs to be traced for logging or notifications. This gives the flexibility to track the stage progress between individual modules. ",NULL,"Add support for global wiretap config As a user, I'd like to have an optional trace as inline deployment properties for stream","so that I can declare which module in the stream needs to be traced for logging or notifications. This gives the flexibility to track the stage progress between individual modules.","Add for who this story is","well_formed","no_role","high",False
25946,"Add support for global wiretap config As a user, I'd like to have an optional trace as inline deployment properties for stream so that I can declare which module in the stream needs to be traced for logging or notifications. This gives the flexibility to track the stage progress between individual modules. ",NULL,"Add support for global wiretap config As a user, I'd like to have an optional trace as inline deployment properties for stream","so that I can declare which module in the stream needs to be traced for logging or notifications. This gives the flexibility to track the stage progress between individual modules.","Add support for global wiretap config As a user, I'd like to have an optional trace as inline deployment properties for stream so that I can declare which module in the stream needs to be traced for logging or notifications<span class='highlight-text severity-high'>. This gives the flexibility to track the stage progress between individual modules. </span>","minimal","punctuation","high",False
25946,"Add support for global wiretap config As a user, I'd like to have an optional trace as inline deployment properties for stream so that I can declare which module in the stream needs to be traced for logging or notifications. This gives the flexibility to track the stage progress between individual modules. ",NULL,"Add support for global wiretap config As a user, I'd like to have an optional trace as inline deployment properties for stream","so that I can declare which module in the stream needs to be traced for logging or notifications. This gives the flexibility to track the stage progress between individual modules.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25951,"Prep for DEBS Challenge As a developer, I'd like to study the taxi trips based on a stream of trip reports from New York City so that I can evaluate event based systems in the context of real time analytics using Spring XD. Challenge Details ",NULL,"Prep for DEBS Challenge As a developer, I'd like to study the taxi trips based on a stream of trip reports from New York City","so that I can evaluate event based systems in the context of real time analytics using Spring XD. Challenge Details","Add for who this story is","well_formed","no_role","high",False
25951,"Prep for DEBS Challenge As a developer, I'd like to study the taxi trips based on a stream of trip reports from New York City so that I can evaluate event based systems in the context of real time analytics using Spring XD. Challenge Details ",NULL,"Prep for DEBS Challenge As a developer, I'd like to study the taxi trips based on a stream of trip reports from New York City","so that I can evaluate event based systems in the context of real time analytics using Spring XD. Challenge Details","Prep for DEBS Challenge As a developer, I'd like to study the taxi trips based on a stream of trip reports from New York City so that I can evaluate event based systems in the context of real time analytics using Spring XD<span class='highlight-text severity-high'>. Challenge Details </span>","minimal","punctuation","high",False
25951,"Prep for DEBS Challenge As a developer, I'd like to study the taxi trips based on a stream of trip reports from New York City so that I can evaluate event based systems in the context of real time analytics using Spring XD. Challenge Details ",NULL,"Prep for DEBS Challenge As a developer, I'd like to study the taxi trips based on a stream of trip reports from New York City","so that I can evaluate event based systems in the context of real time analytics using Spring XD. Challenge Details","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25947,"Add arbitrary side channels to track module progress As a user, I'd like to have an optional arbitrary side channels created so that when creating a module channels other than the primary stream channels input, output could be added to the bus i.e. creating a tap channel within a flow . The optional side channels can be used to trace track module progress.",NULL,"Add arbitrary side channels to track module progress As a user, I'd like to have an optional arbitrary side channels created","so that when creating a module channels other than the primary stream channels input, output could be added to the bus i.e. creating a tap channel within a flow . The optional side channels can be used to trace track module progress.","Add for who this story is","well_formed","no_role","high",False
25947,"Add arbitrary side channels to track module progress As a user, I'd like to have an optional arbitrary side channels created so that when creating a module channels other than the primary stream channels input, output could be added to the bus i.e. creating a tap channel within a flow . The optional side channels can be used to trace track module progress.",NULL,"Add arbitrary side channels to track module progress As a user, I'd like to have an optional arbitrary side channels created","so that when creating a module channels other than the primary stream channels input, output could be added to the bus i.e. creating a tap channel within a flow . The optional side channels can be used to trace track module progress.","Add arbitrary side channels to track module progress As a user, I'd like to have an optional arbitrary side channels created so that when creating a module channels other than the primary stream channels input, output could be added to the bus i<span class='highlight-text severity-high'>.e. creating a tap channel within a flow . The optional side channels can be used to trace track module progress.</span>","minimal","punctuation","high",False
25947,"Add arbitrary side channels to track module progress As a user, I'd like to have an optional arbitrary side channels created so that when creating a module channels other than the primary stream channels input, output could be added to the bus i.e. creating a tap channel within a flow . The optional side channels can be used to trace track module progress.",NULL,"Add arbitrary side channels to track module progress As a user, I'd like to have an optional arbitrary side channels created","so that when creating a module channels other than the primary stream channels input, output could be added to the bus i.e. creating a tap channel within a flow . The optional side channels can be used to trace track module progress.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25954,"Document test scenarios for performance testing As a developer, I'd like to benchmark Rabbit performance so that I can use the results as reference to setup XD cluster.",NULL,"Document test scenarios for performance testing As a developer, I'd like to benchmark Rabbit performance","so that I can use the results as reference to setup XD cluster.","Add for who this story is","well_formed","no_role","high",False
25954,"Document test scenarios for performance testing As a developer, I'd like to benchmark Rabbit performance so that I can use the results as reference to setup XD cluster.",NULL,"Document test scenarios for performance testing As a developer, I'd like to benchmark Rabbit performance","so that I can use the results as reference to setup XD cluster.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25948,"Add a Sqoop example ",NULL,"Add a Sqoop example ",NULL,"Add for who this story is","well_formed","no_role","high",False
25952,"Improve acceptance testing coverage The scope is to address the sub tasks linked with this story. ",NULL,"Improve acceptance testing coverage The scope is to address the sub tasks linked with this story. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25953,"Placeholder for Spring XD Lab ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25953,"Placeholder for Spring XD Lab ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25958,"Placeholder for Lattice Diego POC 2 ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25958,"Placeholder for Lattice Diego POC 2 ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25955,"Implement Reliable spark streaming receiver The spark streaming message bus receiver isn t reliable yet. The receiver needs to handle data loss in case of worker node that has it running. We currently handle the driver failure automatically by re deploying spark streaming module. But, this is about the data loss when the worker node dies. Please see the documents here ",NULL,"Implement Reliable spark streaming receiver The spark streaming message bus receiver isn t reliable yet. The receiver needs to handle data loss in case of worker node that has it running. We currently handle the driver failure automatically by re deploying spark streaming module. But, this is about the data loss when the worker node dies. Please see the documents here ",NULL,"Add for who this story is","well_formed","no_role","high",False
25980,"Migrate wiki documentation and the chores As a developer, I'd like to migrate the wiki to project repo so that it can be tagged with the code and versioned etc. ",NULL,"Migrate wiki documentation and the chores As a developer, I'd like to migrate the wiki to project repo","so that it can be tagged with the code and versioned etc.","Add for who this story is","well_formed","no_role","high",False
25955,"Implement Reliable spark streaming receiver The spark streaming message bus receiver isn t reliable yet. The receiver needs to handle data loss in case of worker node that has it running. We currently handle the driver failure automatically by re deploying spark streaming module. But, this is about the data loss when the worker node dies. Please see the documents here ",NULL,"Implement Reliable spark streaming receiver The spark streaming message bus receiver isn t reliable yet. The receiver needs to handle data loss in case of worker node that has it running. We currently handle the driver failure automatically by re deploying spark streaming module. But, this is about the data loss when the worker node dies. Please see the documents here ",NULL,"Implement Reliable spark streaming receiver The spark streaming message bus receiver isn t reliable yet<span class='highlight-text severity-high'>. The receiver needs to handle data loss in case of worker node that has it running. We currently handle the driver failure automatically by re deploying spark streaming module. But, this is about the data loss when the worker node dies. Please see the documents here </span>","minimal","punctuation","high",False
25956,"Placeholder for Lattice Diego POC 1 ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
25956,"Placeholder for Lattice Diego POC 1 ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
25949,"Headers in a Message that will indicate which HDFS file the data should be stored in. Based on message processing, a header in a Message can be added that contains the output file name. This will work together with the hdfs writer module so it can read the header and write the contents of the message to the specified file. ",NULL,"Headers in a Message that will indicate which HDFS file the data should be stored in. Based on message processing, a header in a Message can be added that contains the output file name. This will work together with the hdfs writer module","so it can read the header and write the contents of the message to the specified file.","Add for who this story is","well_formed","no_role","high",False
25949,"Headers in a Message that will indicate which HDFS file the data should be stored in. Based on message processing, a header in a Message can be added that contains the output file name. This will work together with the hdfs writer module so it can read the header and write the contents of the message to the specified file. ",NULL,"Headers in a Message that will indicate which HDFS file the data should be stored in. Based on message processing, a header in a Message can be added that contains the output file name. This will work together with the hdfs writer module","so it can read the header and write the contents of the message to the specified file.","Headers in a Message that will indicate which HDFS file the data should be stored in<span class='highlight-text severity-high'>. Based on message processing, a header in a Message can be added that contains the output file name. This will work together with the hdfs writer module so it can read the header and write the contents of the message to the specified file. </span>","minimal","punctuation","high",False
25949,"Headers in a Message that will indicate which HDFS file the data should be stored in. Based on message processing, a header in a Message can be added that contains the output file name. This will work together with the hdfs writer module so it can read the header and write the contents of the message to the specified file. ",NULL,"Headers in a Message that will indicate which HDFS file the data should be stored in. Based on message processing, a header in a Message can be added that contains the output file name. This will work together with the hdfs writer module","so it can read the header and write the contents of the message to the specified file.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25943,"Add support to include deployment manifest from file As a user, I'd like to include the deployment manifest from the file so that I don t have spend time typing as inline properties .",NULL,"Add support to include deployment manifest from file As a user, I'd like to include the deployment manifest from the file","so that I don t have spend time typing as inline properties .","Add for who this story is","well_formed","no_role","high",False
25943,"Add support to include deployment manifest from file As a user, I'd like to include the deployment manifest from the file so that I don t have spend time typing as inline properties .",NULL,"Add support to include deployment manifest from file As a user, I'd like to include the deployment manifest from the file","so that I don t have spend time typing as inline properties .","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25957,"Support for in memory of data before writing to HDFS This should be an optimization, to be verified, that aggregating data in memory, for example at the size of a HDFS block 64Mb often will result in increased performance vs. not aggregating data for writes.",NULL,"Support for in memory of data before writing to HDFS This should be an optimization, to be verified, that aggregating data in memory, for example at the size of a HDFS block 64Mb often will result in increased performance vs. not aggregating data for writes.",NULL,"Add for who this story is","well_formed","no_role","high",False
25957,"Support for in memory of data before writing to HDFS This should be an optimization, to be verified, that aggregating data in memory, for example at the size of a HDFS block 64Mb often will result in increased performance vs. not aggregating data for writes.",NULL,"Support for in memory of data before writing to HDFS This should be an optimization, to be verified, that aggregating data in memory, for example at the size of a HDFS block 64Mb often will result in increased performance vs. not aggregating data for writes.",NULL,"Support for in memory of data before writing to HDFS This should be an optimization, to be verified, that aggregating data in memory, for example at the size of a HDFS block 64Mb often will result in increased performance vs<span class='highlight-text severity-high'>. not aggregating data for writes.</span>","minimal","punctuation","high",False
25967,"Research EC2 infrastructure required for Kafka performance tests As a developer, I'd like to research and Identify the EC2 infrastructure required so that I can run performance tests on Kafka. ",NULL,"Research EC2 infrastructure required for Kafka performance tests As a developer, I'd like to research and Identify the EC2 infrastructure required","so that I can run performance tests on Kafka.","Add for who this story is","well_formed","no_role","high",False
25967,"Research EC2 infrastructure required for Kafka performance tests As a developer, I'd like to research and Identify the EC2 infrastructure required so that I can run performance tests on Kafka. ",NULL,"Research EC2 infrastructure required for Kafka performance tests As a developer, I'd like to research and Identify the EC2 infrastructure required","so that I can run performance tests on Kafka.","Research EC2 infrastructure required for Kafka performance tests As a developer, I'd like to research<span class='highlight-text severity-high'> and </span>Identify the EC2 infrastructure required so that I can run performance tests on Kafka. ","atomic","conjunctions","high",False
25967,"Research EC2 infrastructure required for Kafka performance tests As a developer, I'd like to research and Identify the EC2 infrastructure required so that I can run performance tests on Kafka. ",NULL,"Research EC2 infrastructure required for Kafka performance tests As a developer, I'd like to research and Identify the EC2 infrastructure required","so that I can run performance tests on Kafka.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25960,"Investigate throughput performance writing to HDFS This could be an optimization, to be verified, that delegating the writing operations to Reactor e.g. with a backing ringbuffer implementation will increase the throughput performance. Other strategies, such as threads to handle writes to individual files concurrently, should be investigated.",NULL,"Investigate throughput performance writing to HDFS This could be an optimization, to be verified, that delegating the writing operations to Reactor e.g. with a backing ringbuffer implementation will increase the throughput performance. Other strategies, such as threads to handle writes to individual files concurrently, should be investigated.",NULL,"Add for who this story is","well_formed","no_role","high",False
25960,"Investigate throughput performance writing to HDFS This could be an optimization, to be verified, that delegating the writing operations to Reactor e.g. with a backing ringbuffer implementation will increase the throughput performance. Other strategies, such as threads to handle writes to individual files concurrently, should be investigated.",NULL,"Investigate throughput performance writing to HDFS This could be an optimization, to be verified, that delegating the writing operations to Reactor e.g. with a backing ringbuffer implementation will increase the throughput performance. Other strategies, such as threads to handle writes to individual files concurrently, should be investigated.",NULL,"Investigate throughput performance writing to HDFS This could be an optimization, to be verified, that delegating the writing operations to Reactor e<span class='highlight-text severity-high'>.g. with a backing ringbuffer implementation will increase the throughput performance. Other strategies, such as threads to handle writes to individual files concurrently, should be investigated.</span>","minimal","punctuation","high",False
25990,"Enable Value, etc in Module Options Metadata A placeholder to investigate what can be done with Spring configuration in Module Options Metadata classes to simplify enhance property configuration. With Configuration modules, these may now be beans in the module context. ",NULL,"Enable Value, etc in Module Options Metadata A placeholder to investigate what can be done with Spring configuration in Module Options Metadata classes to simplify enhance property configuration. With Configuration modules, these may now be beans in the module context. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25990,"Enable Value, etc in Module Options Metadata A placeholder to investigate what can be done with Spring configuration in Module Options Metadata classes to simplify enhance property configuration. With Configuration modules, these may now be beans in the module context. ",NULL,"Enable Value, etc in Module Options Metadata A placeholder to investigate what can be done with Spring configuration in Module Options Metadata classes to simplify enhance property configuration. With Configuration modules, these may now be beans in the module context. ",NULL,"Enable Value, etc in Module Options Metadata A placeholder to investigate what can be done with Spring configuration in Module Options Metadata classes to simplify enhance property configuration<span class='highlight-text severity-high'>. With Configuration modules, these may now be beans in the module context. </span>","minimal","punctuation","high",False
25961,"Update RHEL CentOS yum rpm installation instructions As a build manager, I'd like to have Spring XD RPMs published in spring.io repository so that users can directly download the bits without having to go through appsuite repo or the EULA. Location for 1.1.0 RELEASE ",NULL,"Update RHEL CentOS yum rpm installation instructions As a build manager, I'd like to have Spring XD RPMs published in spring.io repository","so that users can directly download the bits without having to go through appsuite repo or the EULA. Location for 1.1.0 RELEASE","Add for who this story is","well_formed","no_role","high",False
25961,"Update RHEL CentOS yum rpm installation instructions As a build manager, I'd like to have Spring XD RPMs published in spring.io repository so that users can directly download the bits without having to go through appsuite repo or the EULA. Location for 1.1.0 RELEASE ",NULL,"Update RHEL CentOS yum rpm installation instructions As a build manager, I'd like to have Spring XD RPMs published in spring.io repository","so that users can directly download the bits without having to go through appsuite repo or the EULA. Location for 1.1.0 RELEASE","Update RHEL CentOS yum rpm installation instructions As a build manager, I'd like to have Spring XD RPMs published in spring<span class='highlight-text severity-high'>.io repository so that users can directly download the bits without having to go through appsuite repo or the EULA. Location for 1.1.0 RELEASE </span>","minimal","punctuation","high",False
25961,"Update RHEL CentOS yum rpm installation instructions As a build manager, I'd like to have Spring XD RPMs published in spring.io repository so that users can directly download the bits without having to go through appsuite repo or the EULA. Location for 1.1.0 RELEASE ",NULL,"Update RHEL CentOS yum rpm installation instructions As a build manager, I'd like to have Spring XD RPMs published in spring.io repository","so that users can directly download the bits without having to go through appsuite repo or the EULA. Location for 1.1.0 RELEASE","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25962,"Add metadata for description of a module itself As a user, I'd like to have the description for each of the modules so that I can use it to understand the module purpose and it s capabilities presumably what is captured in javadoc for the module definition .",NULL,"Add metadata for description of a module itself As a user, I'd like to have the description for each of the modules","so that I can use it to understand the module purpose and it s capabilities presumably what is captured in javadoc for the module definition .","Add for who this story is","well_formed","no_role","high",False
25962,"Add metadata for description of a module itself As a user, I'd like to have the description for each of the modules so that I can use it to understand the module purpose and it s capabilities presumably what is captured in javadoc for the module definition .",NULL,"Add metadata for description of a module itself As a user, I'd like to have the description for each of the modules","so that I can use it to understand the module purpose and it s capabilities presumably what is captured in javadoc for the module definition .","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25964,"Reproduce baseline numbers for Kafka As a developer, I'd like to bench Kafka as message bus using in built perf testing producer consumer utilities so that I can use that as a foundation to build XD use cases and measure performance. I'd like to reproduce baseline performance metrics as identified by the Kafka engineering team ",NULL,"Reproduce baseline numbers for Kafka As a developer, I'd like to bench Kafka as message bus using in built perf testing producer consumer utilities","so that I can use that as a foundation to build XD use cases and measure performance. I'd like to reproduce baseline performance metrics as identified by the Kafka engineering team","Add for who this story is","well_formed","no_role","high",False
25964,"Reproduce baseline numbers for Kafka As a developer, I'd like to bench Kafka as message bus using in built perf testing producer consumer utilities so that I can use that as a foundation to build XD use cases and measure performance. I'd like to reproduce baseline performance metrics as identified by the Kafka engineering team ",NULL,"Reproduce baseline numbers for Kafka As a developer, I'd like to bench Kafka as message bus using in built perf testing producer consumer utilities","so that I can use that as a foundation to build XD use cases and measure performance. I'd like to reproduce baseline performance metrics as identified by the Kafka engineering team","Reproduce baseline numbers for Kafka As a developer, I'd like to bench Kafka as message bus using in built perf testing producer consumer utilities so that I can use that as a foundation to build XD use cases and measure performance<span class='highlight-text severity-high'>. I'd like to reproduce baseline performance metrics as identified by the Kafka engineering team </span>","minimal","punctuation","high",False
25964,"Reproduce baseline numbers for Kafka As a developer, I'd like to bench Kafka as message bus using in built perf testing producer consumer utilities so that I can use that as a foundation to build XD use cases and measure performance. I'd like to reproduce baseline performance metrics as identified by the Kafka engineering team ",NULL,"Reproduce baseline numbers for Kafka As a developer, I'd like to bench Kafka as message bus using in built perf testing producer consumer utilities","so that I can use that as a foundation to build XD use cases and measure performance. I'd like to reproduce baseline performance metrics as identified by the Kafka engineering team","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25971,"Add throughput receiving sink As a developer, I'd like to add load receiving sink module so that I can measure received throughput",NULL,"Add throughput receiving sink As a developer, I'd like to add load receiving sink module","so that I can measure received throughput","Add for who this story is","well_formed","no_role","high",False
25971,"Add throughput receiving sink As a developer, I'd like to add load receiving sink module so that I can measure received throughput",NULL,"Add throughput receiving sink As a developer, I'd like to add load receiving sink module","so that I can measure received throughput","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25966,"Support writing to HDFS using the GZipCodec ",NULL,"Support writing to HDFS using the GZipCodec ",NULL,"Add for who this story is","well_formed","no_role","high",False
25968,"Identify the Kafka configuration for Kafka performance tests As a developer, I'd like to identify the Kafka configurations so that I could setup infrastructure to perform performance testing. ",NULL,"Identify the Kafka configuration for Kafka performance tests As a developer, I'd like to identify the Kafka configurations","so that I could setup infrastructure to perform performance testing.","Add for who this story is","well_formed","no_role","high",False
25968,"Identify the Kafka configuration for Kafka performance tests As a developer, I'd like to identify the Kafka configurations so that I could setup infrastructure to perform performance testing. ",NULL,"Identify the Kafka configuration for Kafka performance tests As a developer, I'd like to identify the Kafka configurations","so that I could setup infrastructure to perform performance testing.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25970,"Add load generator source As a developer, I'd like to add load generator source module so that I could use it for performance testing use cases. ",NULL,"Add load generator source As a developer, I'd like to add load generator source module","so that I could use it for performance testing use cases.","Add for who this story is","well_formed","no_role","high",False
25970,"Add load generator source As a developer, I'd like to add load generator source module so that I could use it for performance testing use cases. ",NULL,"Add load generator source As a developer, I'd like to add load generator source module","so that I could use it for performance testing use cases.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25972,"Rabbit source and sink should include all headers by default Currently it is necessary to specify on the rabbit sink, otherwise no headers are mapped to AMQP. This should be the default behavior.",NULL,"Rabbit source and sink should include all headers by default Currently it is necessary to specify on the rabbit sink, otherwise no headers are mapped to AMQP. This should be the default behavior.",NULL,"Add for who this story is","well_formed","no_role","high",False
25972,"Rabbit source and sink should include all headers by default Currently it is necessary to specify on the rabbit sink, otherwise no headers are mapped to AMQP. This should be the default behavior.",NULL,"Rabbit source and sink should include all headers by default Currently it is necessary to specify on the rabbit sink, otherwise no headers are mapped to AMQP. This should be the default behavior.",NULL,"Rabbit source and sink should include all headers by default Currently it is necessary to specify on the rabbit sink, otherwise no headers are mapped to AMQP<span class='highlight-text severity-high'>. This should be the default behavior.</span>","minimal","punctuation","high",False
25991,"Add to the classpath otherwise it is missing XPathException class . ",NULL,"Add to the classpath otherwise it is missing XPathException class . ",NULL,"Add for who this story is","well_formed","no_role","high",False
25963,"Inconsistent Handling of Inherited servers.yml Properties Some modules inherit classes. Switch all modules to use the latter technique for consistency.",NULL,"Inconsistent Handling of Inherited servers.yml Properties Some modules inherit classes. Switch all modules to use the latter technique for consistency.",NULL,"Add for who this story is","well_formed","no_role","high",False
25963,"Inconsistent Handling of Inherited servers.yml Properties Some modules inherit classes. Switch all modules to use the latter technique for consistency.",NULL,"Inconsistent Handling of Inherited servers.yml Properties Some modules inherit classes. Switch all modules to use the latter technique for consistency.",NULL,"Inconsistent Handling of Inherited servers<span class='highlight-text severity-high'>.yml Properties Some modules inherit classes. Switch all modules to use the latter technique for consistency.</span>","minimal","punctuation","high",False
25969,"Create EC2 AMI image for performance testing As a developer, I'd like to create EC2 AMI with the necessary packages so that I can run the Kafka Perf tests.",NULL,"Create EC2 AMI image for performance testing As a developer, I'd like to create EC2 AMI with the necessary packages","so that I can run the Kafka Perf tests.","Add for who this story is","well_formed","no_role","high",False
25969,"Create EC2 AMI image for performance testing As a developer, I'd like to create EC2 AMI with the necessary packages so that I can run the Kafka Perf tests.",NULL,"Create EC2 AMI image for performance testing As a developer, I'd like to create EC2 AMI with the necessary packages","so that I can run the Kafka Perf tests.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25974,"Automate provisioning story for XD ",NULL,"Automate provisioning story for XD ",NULL,"Add for who this story is","well_formed","no_role","high",False
25983,"Improve the performance of jdbchdfs batch job As a user, I'd like to use a jdbchdfs batch job as a passthrough without chunk processing so that I don t have to incur the batch read write overhead.",NULL,"Improve the performance of jdbchdfs batch job As a user, I'd like to use a jdbchdfs batch job as a passthrough without chunk processing","so that I don t have to incur the batch read write overhead.","Add for who this story is","well_formed","no_role","high",False
25983,"Improve the performance of jdbchdfs batch job As a user, I'd like to use a jdbchdfs batch job as a passthrough without chunk processing so that I don t have to incur the batch read write overhead.",NULL,"Improve the performance of jdbchdfs batch job As a user, I'd like to use a jdbchdfs batch job as a passthrough without chunk processing","so that I don t have to incur the batch read write overhead.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25975,"Fix offset management for Kafka source As a developer, I'd like to fix the offset management with Kafka source module so that I can efficiently perform fetch operation from the given offsets.",NULL,"Fix offset management for Kafka source As a developer, I'd like to fix the offset management with Kafka source module","so that I can efficiently perform fetch operation from the given offsets.","Add for who this story is","well_formed","no_role","high",False
25975,"Fix offset management for Kafka source As a developer, I'd like to fix the offset management with Kafka source module so that I can efficiently perform fetch operation from the given offsets.",NULL,"Fix offset management for Kafka source As a developer, I'd like to fix the offset management with Kafka source module","so that I can efficiently perform fetch operation from the given offsets.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25980,"Migrate wiki documentation and the chores As a developer, I'd like to migrate the wiki to project repo so that it can be tagged with the code and versioned etc. ",NULL,"Migrate wiki documentation and the chores As a developer, I'd like to migrate the wiki to project repo","so that it can be tagged with the code and versioned etc.","Migrate wiki documentation<span class='highlight-text severity-high'> and </span>the chores As a developer, I'd like to migrate the wiki to project repo so that it can be tagged with the code and versioned etc. ","atomic","conjunctions","high",False
25980,"Migrate wiki documentation and the chores As a developer, I'd like to migrate the wiki to project repo so that it can be tagged with the code and versioned etc. ",NULL,"Migrate wiki documentation and the chores As a developer, I'd like to migrate the wiki to project repo","so that it can be tagged with the code and versioned etc.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25984,"upgrade to io.projectreactor breaks generated POMS . gradlew install fails for and The first case is a simple update to The 2nd causes several compilation errors that are not trivial for a Reactor noob. ",NULL,"upgrade to io.projectreactor breaks generated POMS . gradlew install fails for and The first case is a simple update to The 2nd causes several compilation errors that are not trivial for a Reactor noob. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25984,"upgrade to io.projectreactor breaks generated POMS . gradlew install fails for and The first case is a simple update to The 2nd causes several compilation errors that are not trivial for a Reactor noob. ",NULL,"upgrade to io.projectreactor breaks generated POMS . gradlew install fails for and The first case is a simple update to The 2nd causes several compilation errors that are not trivial for a Reactor noob. ",NULL,"upgrade to io.projectreactor breaks generated POMS . gradlew install fails for<span class='highlight-text severity-high'> and </span>The first case is a simple update to The 2nd causes several compilation errors that are not trivial for a Reactor noob. ","atomic","conjunctions","high",False
25984,"upgrade to io.projectreactor breaks generated POMS . gradlew install fails for and The first case is a simple update to The 2nd causes several compilation errors that are not trivial for a Reactor noob. ",NULL,"upgrade to io.projectreactor breaks generated POMS . gradlew install fails for and The first case is a simple update to The 2nd causes several compilation errors that are not trivial for a Reactor noob. ",NULL,"upgrade to io<span class='highlight-text severity-high'>.projectreactor breaks generated POMS . gradlew install fails for and The first case is a simple update to The 2nd causes several compilation errors that are not trivial for a Reactor noob. </span>","minimal","punctuation","high",False
25981,"Add support to include namenode address from a config file As a user, I'd like to add the Hadoop namenode specifics in a config file so that I don t have to incur the hassle of pointing to the namenode location every time I open a new DSL session, but it is automatically configured. ",NULL,"Add support to include namenode address from a config file As a user, I'd like to add the Hadoop namenode specifics in a config file","so that I don t have to incur the hassle of pointing to the namenode location every time I open a new DSL session, but it is automatically configured.","Add for who this story is","well_formed","no_role","high",False
25981,"Add support to include namenode address from a config file As a user, I'd like to add the Hadoop namenode specifics in a config file so that I don t have to incur the hassle of pointing to the namenode location every time I open a new DSL session, but it is automatically configured. ",NULL,"Add support to include namenode address from a config file As a user, I'd like to add the Hadoop namenode specifics in a config file","so that I don t have to incur the hassle of pointing to the namenode location every time I open a new DSL session, but it is automatically configured.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25982,"Investigate running Camus as a batch job Similar to Sqoop where we move data from RDBMS to HDFS we should look at integrating with Camus to load data from Kafka to HDFS.",NULL,"Investigate running Camus as a batch job Similar to Sqoop where we move data from RDBMS to HDFS we should look at integrating with Camus to load data from Kafka to HDFS.",NULL,"Add for who this story is","well_formed","no_role","high",False
25985,"The HDFS Sink should support writing POJOs to HDFS using Avro Serialization Writing POJOs using CDK Data Avro We should support both partitioned and un partitioned. This story addresses only un partitioned. Document limitations in terms of which Java types are supported and not supported by the Avro serialization ",NULL,"The HDFS Sink should support writing POJOs to HDFS using Avro Serialization Writing POJOs using CDK Data Avro We should support both partitioned and un partitioned. This story addresses only un partitioned. Document limitations in terms of which Java types are supported and not supported by the Avro serialization ",NULL,"Add for who this story is","well_formed","no_role","high",False
25985,"The HDFS Sink should support writing POJOs to HDFS using Avro Serialization Writing POJOs using CDK Data Avro We should support both partitioned and un partitioned. This story addresses only un partitioned. Document limitations in terms of which Java types are supported and not supported by the Avro serialization ",NULL,"The HDFS Sink should support writing POJOs to HDFS using Avro Serialization Writing POJOs using CDK Data Avro We should support both partitioned and un partitioned. This story addresses only un partitioned. Document limitations in terms of which Java types are supported and not supported by the Avro serialization ",NULL,"The HDFS Sink should support writing POJOs to HDFS using Avro Serialization Writing POJOs using CDK Data Avro We should support both partitioned<span class='highlight-text severity-high'> and </span>un partitioned. This story addresses only un partitioned. Document limitations in terms of which Java types are supported and not supported by the Avro serialization ","atomic","conjunctions","high",False
25985,"The HDFS Sink should support writing POJOs to HDFS using Avro Serialization Writing POJOs using CDK Data Avro We should support both partitioned and un partitioned. This story addresses only un partitioned. Document limitations in terms of which Java types are supported and not supported by the Avro serialization ",NULL,"The HDFS Sink should support writing POJOs to HDFS using Avro Serialization Writing POJOs using CDK Data Avro We should support both partitioned and un partitioned. This story addresses only un partitioned. Document limitations in terms of which Java types are supported and not supported by the Avro serialization ",NULL,"The HDFS Sink should support writing POJOs to HDFS using Avro Serialization Writing POJOs using CDK Data Avro We should support both partitioned and un partitioned<span class='highlight-text severity-high'>. This story addresses only un partitioned. Document limitations in terms of which Java types are supported and not supported by the Avro serialization </span>","minimal","punctuation","high",False
25987,"Improve ItemWriter in OOTB jdbchdfs to use DataStoreWriter The current jdbchdfs job does not take advantage of all the features available to write into HDFS provided by Spring Hadoop s DataStoreWriter implementations, such as partitioning. Update the jdbchdfs job to use similar to the HDFS Sink inside a new ItemWriter implementation ",NULL,"Improve ItemWriter in OOTB jdbchdfs to use DataStoreWriter The current jdbchdfs job does not take advantage of all the features available to write into HDFS provided by Spring Hadoop s DataStoreWriter implementations, such as partitioning. Update the jdbchdfs job to use similar to the HDFS Sink inside a new ItemWriter implementation ",NULL,"Add for who this story is","well_formed","no_role","high",False
25987,"Improve ItemWriter in OOTB jdbchdfs to use DataStoreWriter The current jdbchdfs job does not take advantage of all the features available to write into HDFS provided by Spring Hadoop s DataStoreWriter implementations, such as partitioning. Update the jdbchdfs job to use similar to the HDFS Sink inside a new ItemWriter implementation ",NULL,"Improve ItemWriter in OOTB jdbchdfs to use DataStoreWriter The current jdbchdfs job does not take advantage of all the features available to write into HDFS provided by Spring Hadoop s DataStoreWriter implementations, such as partitioning. Update the jdbchdfs job to use similar to the HDFS Sink inside a new ItemWriter implementation ",NULL,"Improve ItemWriter in OOTB jdbchdfs to use DataStoreWriter The current jdbchdfs job does not take advantage of all the features available to write into HDFS provided by Spring Hadoop s DataStoreWriter implementations, such as partitioning<span class='highlight-text severity-high'>. Update the jdbchdfs job to use similar to the HDFS Sink inside a new ItemWriter implementation </span>","minimal","punctuation","high",False
25988,"Composite Modules should inherit xd. properties Currently when modules are composed to a single application context, properties are not inherited. ",NULL,"Composite Modules should inherit xd. properties Currently when modules are composed to a single application context, properties are not inherited. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25988,"Composite Modules should inherit xd. properties Currently when modules are composed to a single application context, properties are not inherited. ",NULL,"Composite Modules should inherit xd. properties Currently when modules are composed to a single application context, properties are not inherited. ",NULL,"Composite Modules should inherit xd<span class='highlight-text severity-high'>. properties Currently when modules are composed to a single application context, properties are not inherited. </span>","minimal","punctuation","high",False
25989,"Remove Reactor Stream processor from ref docs to spring xd modules Not going to integrate with Reactor for stream processing.",NULL,"Remove Reactor Stream processor from ref docs to spring xd modules Not going to integrate with Reactor for stream processing.",NULL,"Add for who this story is","well_formed","no_role","high",False
25977,"Lattice Design Spike As a developer, I'd like to continue Lattice Diego POC so that I can identify the scope, risks, and the overall design for a pluggable SPI in XD runtime.",NULL,"Lattice Design Spike As a developer, I'd like to continue Lattice Diego POC","so that I can identify the scope, risks, and the overall design for a pluggable SPI in XD runtime.","Add for who this story is","well_formed","no_role","high",False
25977,"Lattice Design Spike As a developer, I'd like to continue Lattice Diego POC so that I can identify the scope, risks, and the overall design for a pluggable SPI in XD runtime.",NULL,"Lattice Design Spike As a developer, I'd like to continue Lattice Diego POC","so that I can identify the scope, risks, and the overall design for a pluggable SPI in XD runtime.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25978,"Create simple gague service A gauge just stores a number. Implementations for in memory and redis.",NULL,"Create simple gague service A gauge just stores a number. Implementations for in memory and redis.",NULL,"Add for who this story is","well_formed","no_role","high",False
25978,"Create simple gague service A gauge just stores a number. Implementations for in memory and redis.",NULL,"Create simple gague service A gauge just stores a number. Implementations for in memory and redis.",NULL,"Create simple gague service A gauge just stores a number<span class='highlight-text severity-high'>. Implementations for in memory and redis.</span>","minimal","punctuation","high",False
26007,"UI Deploy Stream Return key does not submit form ",NULL,"UI Deploy Stream Return key does not submit form ",NULL,"Add for who this story is","well_formed","no_role","high",False
25996,"XD on Lattice POC As a developer, I'd like to continue PoC, and will be focused on the design of a pluggable SPI, so it is more generally applicable than Lattice, with the Receptor API being just one implementation option. ",NULL,"XD on Lattice POC As a developer, I'd like to continue PoC, and will be focused on the design of a pluggable SPI,","so it is more generally applicable than Lattice, with the Receptor API being just one implementation option.","Add for who this story is","well_formed","no_role","high",False
25996,"XD on Lattice POC As a developer, I'd like to continue PoC, and will be focused on the design of a pluggable SPI, so it is more generally applicable than Lattice, with the Receptor API being just one implementation option. ",NULL,"XD on Lattice POC As a developer, I'd like to continue PoC, and will be focused on the design of a pluggable SPI,","so it is more generally applicable than Lattice, with the Receptor API being just one implementation option.","XD on Lattice POC As a developer, I'd like to continue PoC,<span class='highlight-text severity-high'> and </span>will be focused on the design of a pluggable SPI, so it is more generally applicable than Lattice, with the Receptor API being just one implementation option. ","atomic","conjunctions","high",False
25996,"XD on Lattice POC As a developer, I'd like to continue PoC, and will be focused on the design of a pluggable SPI, so it is more generally applicable than Lattice, with the Receptor API being just one implementation option. ",NULL,"XD on Lattice POC As a developer, I'd like to continue PoC, and will be focused on the design of a pluggable SPI,","so it is more generally applicable than Lattice, with the Receptor API being just one implementation option.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26001,"Create a POC for gpfdist sink As a user, I'd like to have the OOTB gpfdist sink module, so I can use this module to do ultra fast data movement from various sources into GPDB HAWQ.",NULL,"Create a POC for gpfdist sink As a user, I'd like to have the OOTB gpfdist sink module,","so I can use this module to do ultra fast data movement from various sources into GPDB HAWQ.","Add for who this story is","well_formed","no_role","high",False
26001,"Create a POC for gpfdist sink As a user, I'd like to have the OOTB gpfdist sink module, so I can use this module to do ultra fast data movement from various sources into GPDB HAWQ.",NULL,"Create a POC for gpfdist sink As a user, I'd like to have the OOTB gpfdist sink module,","so I can use this module to do ultra fast data movement from various sources into GPDB HAWQ.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25999,"Add support to host read python script from HDFS As a developer, I'd like to host read Python script file from HDFS, so I can use the shell processor in XD on CF to delegate data science functionality to Py runtime and receive the feedback back in XD.",NULL,"Add support to host read python script from HDFS As a developer, I'd like to host read Python script file from HDFS,","so I can use the shell processor in XD on CF to delegate data science functionality to Py runtime and receive the feedback back in XD.","Add for who this story is","well_formed","no_role","high",False
25999,"Add support to host read python script from HDFS As a developer, I'd like to host read Python script file from HDFS, so I can use the shell processor in XD on CF to delegate data science functionality to Py runtime and receive the feedback back in XD.",NULL,"Add support to host read python script from HDFS As a developer, I'd like to host read Python script file from HDFS,","so I can use the shell processor in XD on CF to delegate data science functionality to Py runtime and receive the feedback back in XD.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25998,"Update all the module documentation to include shortDescription As a developer, I'd like to update all the module docs to also include shortDescription so that it s available for users to learn more about the module.",NULL,"Update all the module documentation to include shortDescription As a developer, I'd like to update all the module docs to also include shortDescription","so that it s available for users to learn more about the module.","Add for who this story is","well_formed","no_role","high",False
25998,"Update all the module documentation to include shortDescription As a developer, I'd like to update all the module docs to also include shortDescription so that it s available for users to learn more about the module.",NULL,"Update all the module documentation to include shortDescription As a developer, I'd like to update all the module docs to also include shortDescription","so that it s available for users to learn more about the module.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26000,"Support writing to HDFS using a SequenceFile using AvroSerialization ",NULL,"Support writing to HDFS using a SequenceFile using AvroSerialization ",NULL,"Add for who this story is","well_formed","no_role","high",False
26005,"Create a gpload batch job As a developer, I'd like to create a gpload tasklet, so I can ingest data from various sources into GPDB in an efficient manner.",NULL,"Create a gpload batch job As a developer, I'd like to create a gpload tasklet,","so I can ingest data from various sources into GPDB in an efficient manner.","Add for who this story is","well_formed","no_role","high",False
26005,"Create a gpload batch job As a developer, I'd like to create a gpload tasklet, so I can ingest data from various sources into GPDB in an efficient manner.",NULL,"Create a gpload batch job As a developer, I'd like to create a gpload tasklet,","so I can ingest data from various sources into GPDB in an efficient manner.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26002,"Add support for admin ui and Flo integration As a developer, I'd like to setup UI infrastructure, so I can integrate admin ui and Flo.",NULL,"Add support for admin ui and Flo integration As a developer, I'd like to setup UI infrastructure,","so I can integrate admin ui and Flo.","Add for who this story is","well_formed","no_role","high",False
26002,"Add support for admin ui and Flo integration As a developer, I'd like to setup UI infrastructure, so I can integrate admin ui and Flo.",NULL,"Add support for admin ui and Flo integration As a developer, I'd like to setup UI infrastructure,","so I can integrate admin ui and Flo.","Add support for admin ui<span class='highlight-text severity-high'> and </span>Flo integration As a developer, I'd like to setup UI infrastructure, so I can integrate admin ui and Flo.","atomic","conjunctions","high",False
26002,"Add support for admin ui and Flo integration As a developer, I'd like to setup UI infrastructure, so I can integrate admin ui and Flo.",NULL,"Add support for admin ui and Flo integration As a developer, I'd like to setup UI infrastructure,","so I can integrate admin ui and Flo.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26006,"Add dynamic classpath support for modules As a developer, I'd like to add support for dynamic classpath for modules, so we can have the flexibility to load the right dependencies either based on module options 0 or via other properties such as including the dependencies from a specific location 1 . 0 1 ",NULL,"Add dynamic classpath support for modules As a developer, I'd like to add support for dynamic classpath for modules,","so we can have the flexibility to load the right dependencies either based on module options 0 or via other properties such as including the dependencies from a specific location 1 . 0 1","Add for who this story is","well_formed","no_role","high",False
26006,"Add dynamic classpath support for modules As a developer, I'd like to add support for dynamic classpath for modules, so we can have the flexibility to load the right dependencies either based on module options 0 or via other properties such as including the dependencies from a specific location 1 . 0 1 ",NULL,"Add dynamic classpath support for modules As a developer, I'd like to add support for dynamic classpath for modules,","so we can have the flexibility to load the right dependencies either based on module options 0 or via other properties such as including the dependencies from a specific location 1 . 0 1","Add dynamic classpath support for modules As a developer, I'd like to add support for dynamic classpath for modules, so we can have the flexibility to load the right dependencies either based on module options 0 or via other properties such as including the dependencies from a specific location 1 <span class='highlight-text severity-high'>. 0 1 </span>","minimal","punctuation","high",False
26006,"Add dynamic classpath support for modules As a developer, I'd like to add support for dynamic classpath for modules, so we can have the flexibility to load the right dependencies either based on module options 0 or via other properties such as including the dependencies from a specific location 1 . 0 1 ",NULL,"Add dynamic classpath support for modules As a developer, I'd like to add support for dynamic classpath for modules,","so we can have the flexibility to load the right dependencies either based on module options 0 or via other properties such as including the dependencies from a specific location 1 . 0 1","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26004,"Create a File source to efficiently read files As a developer, I'd like to use an efficient approach to read files, so I don t have to read line by line and keep it in memory in order to consume write the file content. Would the tasklet approach be better as opposed to transmitting data via message bus as streams ? ",NULL,"Create a File source to efficiently read files As a developer, I'd like to use an efficient approach to read files, so I don t have to read line by line and keep it in memory","in order to consume write the file content. Would the tasklet approach be better as opposed to transmitting data via message bus as streams ?","Add for who this story is","well_formed","no_role","high",False
26004,"Create a File source to efficiently read files As a developer, I'd like to use an efficient approach to read files, so I don t have to read line by line and keep it in memory in order to consume write the file content. Would the tasklet approach be better as opposed to transmitting data via message bus as streams ? ",NULL,"Create a File source to efficiently read files As a developer, I'd like to use an efficient approach to read files, so I don t have to read line by line and keep it in memory","in order to consume write the file content. Would the tasklet approach be better as opposed to transmitting data via message bus as streams ?","Create a File source to efficiently read files As a developer, I'd like to use an efficient approach to read files, so I don t have to read line by line<span class='highlight-text severity-high'> and </span>keep it in memory in order to consume write the file content. Would the tasklet approach be better as opposed to transmitting data via message bus as streams ? ","atomic","conjunctions","high",False
26049,"Revisit the requirement for ID and Timestamp attributes in Tuple As a developer, I'd like revisit the design to determine the necessity for ID and TimeStamp attributes in , so I can refactor in order to improve performance throughput.",NULL,"Revisit the requirement for ID and Timestamp attributes in Tuple As a developer, I'd like revisit the design to determine the necessity for ID and TimeStamp attributes in , so I can refactor","in order to improve performance throughput.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26054,"Document performance benchmark results As a developer, I'd like to document performance benchmark results along with the infrastructure specifics, so I can publish the blog for customers users to use it as a reference while setting up Spring XD cluster.",NULL,"Document performance benchmark results As a developer, I'd like to document performance benchmark results along with the infrastructure specifics,","so I can publish the blog for customers users to use it as a reference while setting up Spring XD cluster.","Add for who this story is","well_formed","no_role","high",False
26054,"Document performance benchmark results As a developer, I'd like to document performance benchmark results along with the infrastructure specifics, so I can publish the blog for customers users to use it as a reference while setting up Spring XD cluster.",NULL,"Document performance benchmark results As a developer, I'd like to document performance benchmark results along with the infrastructure specifics,","so I can publish the blog for customers users to use it as a reference while setting up Spring XD cluster.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26004,"Create a File source to efficiently read files As a developer, I'd like to use an efficient approach to read files, so I don t have to read line by line and keep it in memory in order to consume write the file content. Would the tasklet approach be better as opposed to transmitting data via message bus as streams ? ",NULL,"Create a File source to efficiently read files As a developer, I'd like to use an efficient approach to read files, so I don t have to read line by line and keep it in memory","in order to consume write the file content. Would the tasklet approach be better as opposed to transmitting data via message bus as streams ?","Create a File source to efficiently read files As a developer, I'd like to use an efficient approach to read files, so I don t have to read line by line and keep it in memory in order to consume write the file content<span class='highlight-text severity-high'>. Would the tasklet approach be better as opposed to transmitting data via message bus as streams ? </span>","minimal","punctuation","high",False
26004,"Create a File source to efficiently read files As a developer, I'd like to use an efficient approach to read files, so I don t have to read line by line and keep it in memory in order to consume write the file content. Would the tasklet approach be better as opposed to transmitting data via message bus as streams ? ",NULL,"Create a File source to efficiently read files As a developer, I'd like to use an efficient approach to read files, so I don t have to read line by line and keep it in memory","in order to consume write the file content. Would the tasklet approach be better as opposed to transmitting data via message bus as streams ?","Create a File source to efficiently read files As a developer, I'd like to use an efficient approach to read files,<span class='highlight-text severity-high'> so </span>I don t have to read line by line and keep it in memory<span class='highlight-text severity-high'> in order to </span>consume write the file content. Would the tasklet approach be better as opposed to transmitting data via message bus as streams ? ","minimal","indicator_repetition","high",False
26004,"Create a File source to efficiently read files As a developer, I'd like to use an efficient approach to read files, so I don t have to read line by line and keep it in memory in order to consume write the file content. Would the tasklet approach be better as opposed to transmitting data via message bus as streams ? ",NULL,"Create a File source to efficiently read files As a developer, I'd like to use an efficient approach to read files, so I don t have to read line by line and keep it in memory","in order to consume write the file content. Would the tasklet approach be better as opposed to transmitting data via message bus as streams ?","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26003,"Provide a strategy interface to obtain the key used when writing SequenceFiles the key used in writing key value pairs should be able to be specified declaratively.",NULL,"Provide a strategy interface to obtain the key used when writing SequenceFiles the key used in writing key value pairs should be able to be specified declaratively.",NULL,"Add for who this story is","well_formed","no_role","high",False
26008,"Support writing to HDFS using a SequenceFile with compression ",NULL,"Support writing to HDFS using a SequenceFile with compression ",NULL,"Add for who this story is","well_formed","no_role","high",False
26181,"Update to Reactor 2.0.4 As a developer, I'd like to upgrade to Reactor 2.0.4 release, so I could leverage the latest improvements and bug fixes.",NULL,"Update to Reactor 2.0.4 As a developer, I'd like to upgrade to Reactor 2.0.4 release,","so I could leverage the latest improvements and bug fixes.","Add for who this story is","well_formed","no_role","high",False
26181,"Update to Reactor 2.0.4 As a developer, I'd like to upgrade to Reactor 2.0.4 release, so I could leverage the latest improvements and bug fixes.",NULL,"Update to Reactor 2.0.4 As a developer, I'd like to upgrade to Reactor 2.0.4 release,","so I could leverage the latest improvements and bug fixes.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26009,"should throw an exception when no Configuration class is present I had a custom module with a typo The module deploys without error but the stream hangs since the channels, etc. are not found in the stream plugin. Very hard to debug. ",NULL,"should throw an exception when no Configuration class is present I had a custom module with a typo The module deploys without error but the stream hangs since the channels, etc. are not found in the stream plugin. Very hard to debug. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26009,"should throw an exception when no Configuration class is present I had a custom module with a typo The module deploys without error but the stream hangs since the channels, etc. are not found in the stream plugin. Very hard to debug. ",NULL,"should throw an exception when no Configuration class is present I had a custom module with a typo The module deploys without error but the stream hangs since the channels, etc. are not found in the stream plugin. Very hard to debug. ",NULL,"should throw an exception when no Configuration class is present I had a custom module with a typo The module deploys without error but the stream hangs since the channels, etc<span class='highlight-text severity-high'>. are not found in the stream plugin. Very hard to debug. </span>","minimal","punctuation","high",False
25995,"Make doc generation part of the standard build Following the recent move of the doco to the main repo, it makes sense to have the doc generation be part of the main build, at an early stage, as an incentive for developers to push doc changes as soon as they change the code. ",NULL,"Make doc generation part of the standard build Following the recent move of the doco to the main repo, it makes sense to have the doc generation be part of the main build, at an early stage, as an incentive for developers to push doc changes as soon as they change the code. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25997,"xd admin broken for HDFS module registry ",NULL,"xd admin broken for HDFS module registry ",NULL,"Add for who this story is","well_formed","no_role","high",False
26010,"Error when creating job from UI with security As a user, I logged in with ROLE CREATE and I get an error while trying job creation from admin ui. I can create job from the shell successfully. Trying the same workflow with ROLE ADMIN results with the same error as well. I don t see anything in the admin container logs about the error itself. ",NULL,"Error when creating job from UI with security As a user, I logged in with ROLE CREATE and I get an error while trying job creation from admin ui. I can create job from the shell successfully. Trying the same workflow with ROLE ADMIN results with the same error as well. I don t see anything in the admin container logs about the error itself. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26010,"Error when creating job from UI with security As a user, I logged in with ROLE CREATE and I get an error while trying job creation from admin ui. I can create job from the shell successfully. Trying the same workflow with ROLE ADMIN results with the same error as well. I don t see anything in the admin container logs about the error itself. ",NULL,"Error when creating job from UI with security As a user, I logged in with ROLE CREATE and I get an error while trying job creation from admin ui. I can create job from the shell successfully. Trying the same workflow with ROLE ADMIN results with the same error as well. I don t see anything in the admin container logs about the error itself. ",NULL,"Error when creating job from UI with security As a user, I logged in with ROLE CREATE<span class='highlight-text severity-high'> and </span>I get an error while trying job creation from admin ui. I can create job from the shell successfully. Trying the same workflow with ROLE ADMIN results with the same error as well. I don t see anything in the admin container logs about the error itself. ","atomic","conjunctions","high",False
26010,"Error when creating job from UI with security As a user, I logged in with ROLE CREATE and I get an error while trying job creation from admin ui. I can create job from the shell successfully. Trying the same workflow with ROLE ADMIN results with the same error as well. I don t see anything in the admin container logs about the error itself. ",NULL,"Error when creating job from UI with security As a user, I logged in with ROLE CREATE and I get an error while trying job creation from admin ui. I can create job from the shell successfully. Trying the same workflow with ROLE ADMIN results with the same error as well. I don t see anything in the admin container logs about the error itself. ",NULL,"Error when creating job from UI with security As a user, I logged in with ROLE CREATE and I get an error while trying job creation from admin ui<span class='highlight-text severity-high'>. I can create job from the shell successfully. Trying the same workflow with ROLE ADMIN results with the same error as well. I don t see anything in the admin container logs about the error itself. </span>","minimal","punctuation","high",False
26010,"Error when creating job from UI with security As a user, I logged in with ROLE CREATE and I get an error while trying job creation from admin ui. I can create job from the shell successfully. Trying the same workflow with ROLE ADMIN results with the same error as well. I don t see anything in the admin container logs about the error itself. ",NULL,"Error when creating job from UI with security As a user, I logged in with ROLE CREATE and I get an error while trying job creation from admin ui. I can create job from the shell successfully. Trying the same workflow with ROLE ADMIN results with the same error as well. I don t see anything in the admin container logs about the error itself. ",NULL,"Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26012,"Add support for explicit partition count configuration for Kafka bus As a developer, I'd like to add support for explicit partition count configuration, so I can use this option to cleverly route the payload to the intended consumer module .",NULL,"Add support for explicit partition count configuration for Kafka bus As a developer, I'd like to add support for explicit partition count configuration,","so I can use this option to cleverly route the payload to the intended consumer module .","Add for who this story is","well_formed","no_role","high",False
26012,"Add support for explicit partition count configuration for Kafka bus As a developer, I'd like to add support for explicit partition count configuration, so I can use this option to cleverly route the payload to the intended consumer module .",NULL,"Add support for explicit partition count configuration for Kafka bus As a developer, I'd like to add support for explicit partition count configuration,","so I can use this option to cleverly route the payload to the intended consumer module .","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26013,"Support writing to HDFS using Thrift See ",NULL,"Support writing to HDFS using Thrift See ",NULL,"Add for who this story is","well_formed","no_role","high",False
26014,"Provide an option for hdfs sink to use Syncable writes As a user, I'd like to have an option to have the hdfs sink use Syncable writes to provide better resiliency in the case of sink container failures. I m willing to accept the performance penalty if I choose this option. ",NULL,"Provide an option for hdfs sink to use Syncable writes As a user, I'd like to have an option to have the hdfs sink use Syncable writes to provide better resiliency in the case of sink container failures. I m willing to accept the performance penalty if I choose this option. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26014,"Provide an option for hdfs sink to use Syncable writes As a user, I'd like to have an option to have the hdfs sink use Syncable writes to provide better resiliency in the case of sink container failures. I m willing to accept the performance penalty if I choose this option. ",NULL,"Provide an option for hdfs sink to use Syncable writes As a user, I'd like to have an option to have the hdfs sink use Syncable writes to provide better resiliency in the case of sink container failures. I m willing to accept the performance penalty if I choose this option. ",NULL,"Provide an option for hdfs sink to use Syncable writes As a user, I'd like to have an option to have the hdfs sink use Syncable writes to provide better resiliency in the case of sink container failures<span class='highlight-text severity-high'>. I m willing to accept the performance penalty if I choose this option. </span>","minimal","punctuation","high",False
26017,"Have a version of GET modules that returns full info Similar to the that is returned when querying a single module, but would be returned when listing provided a ?full flag has been turned on ",NULL,"Have a version of GET modules that returns full info Similar to the that is returned when querying a single module, but would be returned when listing provided a ?full flag has been turned on ",NULL,"Add for who this story is","well_formed","no_role","high",False
26015,"Document dynamic classpath feature ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26015,"Document dynamic classpath feature ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26016,"Only ship relevant modules files The current build ships everything that is found in the modules directory, including build artifacts such as build or IDEA .iml files. Restrict the build to only include config , lib at the moment.",NULL,"Only ship relevant modules files The current build ships everything that is found in the modules directory, including build artifacts such as build or IDEA .iml files. Restrict the build to only include config , lib at the moment.",NULL,"Add for who this story is","well_formed","no_role","high",False
26016,"Only ship relevant modules files The current build ships everything that is found in the modules directory, including build artifacts such as build or IDEA .iml files. Restrict the build to only include config , lib at the moment.",NULL,"Only ship relevant modules files The current build ships everything that is found in the modules directory, including build artifacts such as build or IDEA .iml files. Restrict the build to only include config , lib at the moment.",NULL,"Only ship relevant modules files The current build ships everything that is found in the modules directory, including build artifacts such as build or IDEA <span class='highlight-text severity-high'>.iml files. Restrict the build to only include config , lib at the moment.</span>","minimal","punctuation","high",False
26019,"Add support for PHD 3.0 As a developer, I'd like to certify Spring XD against PHD 3.0, so I can synchronize with the latest ODP based bits. ",NULL,"Add support for PHD 3.0 As a developer, I'd like to certify Spring XD against PHD 3.0,","so I can synchronize with the latest ODP based bits.","Add for who this story is","well_formed","no_role","high",False
26019,"Add support for PHD 3.0 As a developer, I'd like to certify Spring XD against PHD 3.0, so I can synchronize with the latest ODP based bits. ",NULL,"Add support for PHD 3.0 As a developer, I'd like to certify Spring XD against PHD 3.0,","so I can synchronize with the latest ODP based bits.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26018,"Provide . This would be an optional parameter.",NULL,"Provide . This would be an optional parameter.",NULL,"Add for who this story is","well_formed","no_role","high",False
26018,"Provide . This would be an optional parameter.",NULL,"Provide . This would be an optional parameter.",NULL,"Provide <span class='highlight-text severity-high'>. This would be an optional parameter.</span>","minimal","punctuation","high",False
26025,"Upgrade to latest SI release As a developer, I'd like to upgrade to SI milestone GA release, so I can synchronize with JMX improvements. This is dependent on SI Milestone and GA release timelines.",NULL,"Upgrade to latest SI release As a developer, I'd like to upgrade to SI milestone GA release,","so I can synchronize with JMX improvements. This is dependent on SI Milestone and GA release timelines.","Add for who this story is","well_formed","no_role","high",False
26025,"Upgrade to latest SI release As a developer, I'd like to upgrade to SI milestone GA release, so I can synchronize with JMX improvements. This is dependent on SI Milestone and GA release timelines.",NULL,"Upgrade to latest SI release As a developer, I'd like to upgrade to SI milestone GA release,","so I can synchronize with JMX improvements. This is dependent on SI Milestone and GA release timelines.","Upgrade to latest SI release As a developer, I'd like to upgrade to SI milestone GA release, so I can synchronize with JMX improvements<span class='highlight-text severity-high'>. This is dependent on SI Milestone and GA release timelines.</span>","minimal","punctuation","high",False
26025,"Upgrade to latest SI release As a developer, I'd like to upgrade to SI milestone GA release, so I can synchronize with JMX improvements. This is dependent on SI Milestone and GA release timelines.",NULL,"Upgrade to latest SI release As a developer, I'd like to upgrade to SI milestone GA release,","so I can synchronize with JMX improvements. This is dependent on SI Milestone and GA release timelines.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26020,"Properly render defaults for module info that use n t etc. Characters line t, n, etc. should be either escaped, or rendered as human readable variants in module info eg newline ",NULL,"Properly render defaults for module info that use n t etc. Characters line t, n, etc. should be either escaped, or rendered as human readable variants in module info eg newline ",NULL,"Add for who this story is","well_formed","no_role","high",False
26020,"Properly render defaults for module info that use n t etc. Characters line t, n, etc. should be either escaped, or rendered as human readable variants in module info eg newline ",NULL,"Properly render defaults for module info that use n t etc. Characters line t, n, etc. should be either escaped, or rendered as human readable variants in module info eg newline ",NULL,"Properly render defaults for module info that use n t etc. Characters line t, n, etc. should be either escaped,<span class='highlight-text severity-high'> or </span>rendered as human readable variants in module info eg newline ","atomic","conjunctions","high",False
26020,"Properly render defaults for module info that use n t etc. Characters line t, n, etc. should be either escaped, or rendered as human readable variants in module info eg newline ",NULL,"Properly render defaults for module info that use n t etc. Characters line t, n, etc. should be either escaped, or rendered as human readable variants in module info eg newline ",NULL,"Properly render defaults for module info that use n t etc<span class='highlight-text severity-high'>. Characters line t, n, etc. should be either escaped, or rendered as human readable variants in module info eg newline </span>","minimal","punctuation","high",False
26024,"Create rich gauge service A rich gauge stores a number and also rmd, min, max. Implementations for in memory and redis.",NULL,"Create rich gauge service A rich gauge stores a number and also rmd, min, max. Implementations for in memory and redis.",NULL,"Add for who this story is","well_formed","no_role","high",False
26024,"Create rich gauge service A rich gauge stores a number and also rmd, min, max. Implementations for in memory and redis.",NULL,"Create rich gauge service A rich gauge stores a number and also rmd, min, max. Implementations for in memory and redis.",NULL,"Create rich gauge service A rich gauge stores a number and also rmd, min, max<span class='highlight-text severity-high'>. Implementations for in memory and redis.</span>","minimal","punctuation","high",False
26022,"Add support to capture errors stacktrace via DLQ As a user, I'd like to have the configuration option to use an alternative DLQ, so I can publish the message this time with additional headers, including one that contains the exception and stack trace . ",NULL,"Add support to capture errors stacktrace via DLQ As a user, I'd like to have the configuration option to use an alternative DLQ,","so I can publish the message this time with additional headers, including one that contains the exception and stack trace .","Add for who this story is","well_formed","no_role","high",False
26022,"Add support to capture errors stacktrace via DLQ As a user, I'd like to have the configuration option to use an alternative DLQ, so I can publish the message this time with additional headers, including one that contains the exception and stack trace . ",NULL,"Add support to capture errors stacktrace via DLQ As a user, I'd like to have the configuration option to use an alternative DLQ,","so I can publish the message this time with additional headers, including one that contains the exception and stack trace .","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26026,"Upgrade to 1.1.2 SIK release As a developer, I'd like to upgrade to SI Kafka release, so I can synchronize with latest improvements and bug fixes. ",NULL,"Upgrade to 1.1.2 SIK release As a developer, I'd like to upgrade to SI Kafka release,","so I can synchronize with latest improvements and bug fixes.","Add for who this story is","well_formed","no_role","high",False
26026,"Upgrade to 1.1.2 SIK release As a developer, I'd like to upgrade to SI Kafka release, so I can synchronize with latest improvements and bug fixes. ",NULL,"Upgrade to 1.1.2 SIK release As a developer, I'd like to upgrade to SI Kafka release,","so I can synchronize with latest improvements and bug fixes.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26027,"Upgrade to Boot 1.2.3 release As a user, I'd like to upgrade to Spring Boot 1.2.3 release, do I can leverage the latest improvements and bug fixes. We should also sync up the following dependency updates to synchronize with Boot ",NULL,"Upgrade to Boot 1.2.3 release As a user, I'd like to upgrade to Spring Boot 1.2.3 release, do I can leverage the latest improvements and bug fixes. We should also sync up the following dependency updates to synchronize with Boot ",NULL,"Add for who this story is","well_formed","no_role","high",False
26052,"Add s. The admin server already has a logging configuration which should be activated by the startup scripts, but the separate gemfire app doesn t.",NULL,"Add s. The admin server already has a logging configuration which should be activated by the startup scripts, but the separate gemfire app doesn t.",NULL,"Add for who this story is","well_formed","no_role","high",False
26027,"Upgrade to Boot 1.2.3 release As a user, I'd like to upgrade to Spring Boot 1.2.3 release, do I can leverage the latest improvements and bug fixes. We should also sync up the following dependency updates to synchronize with Boot ",NULL,"Upgrade to Boot 1.2.3 release As a user, I'd like to upgrade to Spring Boot 1.2.3 release, do I can leverage the latest improvements and bug fixes. We should also sync up the following dependency updates to synchronize with Boot ",NULL,"Upgrade to Boot 1<span class='highlight-text severity-high'>.2.3 release As a user, I'd like to upgrade to Spring Boot 1.2.3 release, do I can leverage the latest improvements and bug fixes. We should also sync up the following dependency updates to synchronize with Boot </span>","minimal","punctuation","high",False
26027,"Upgrade to Boot 1.2.3 release As a user, I'd like to upgrade to Spring Boot 1.2.3 release, do I can leverage the latest improvements and bug fixes. We should also sync up the following dependency updates to synchronize with Boot ",NULL,"Upgrade to Boot 1.2.3 release As a user, I'd like to upgrade to Spring Boot 1.2.3 release, do I can leverage the latest improvements and bug fixes. We should also sync up the following dependency updates to synchronize with Boot ",NULL,"Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26021,"Password for Sqoop Job definition is in the open While creation sqoop and providing the password for the sqoop jobs the guid does not mask the password with a .",NULL,"Password for Sqoop Job definition is in the open While creation sqoop and providing the password for the sqoop jobs the guid does not mask the password with a .",NULL,"Add for who this story is","well_formed","no_role","high",False
26021,"Password for Sqoop Job definition is in the open While creation sqoop and providing the password for the sqoop jobs the guid does not mask the password with a .",NULL,"Password for Sqoop Job definition is in the open While creation sqoop and providing the password for the sqoop jobs the guid does not mask the password with a .",NULL,"Password for Sqoop Job definition is in the open While creation sqoop<span class='highlight-text severity-high'> and </span>providing the password for the sqoop jobs the guid does not mask the password with a .","atomic","conjunctions","high",False
26180,"Add command for listing of taps ",NULL,"Add command for listing of taps ",NULL,"Add for who this story is","well_formed","no_role","high",False
26029,"Create a new CI build to verify install target As a developer, I'd like to add a new CI build to include install target, so I can verify the target expectations, as it is often time consuming to verify it in the development environment.",NULL,"Create a new CI build to verify install target As a developer, I'd like to add a new CI build to include install target,","so I can verify the target expectations, as it is often time consuming to verify it in the development environment.","Add for who this story is","well_formed","no_role","high",False
26029,"Create a new CI build to verify install target As a developer, I'd like to add a new CI build to include install target, so I can verify the target expectations, as it is often time consuming to verify it in the development environment.",NULL,"Create a new CI build to verify install target As a developer, I'd like to add a new CI build to include install target,","so I can verify the target expectations, as it is often time consuming to verify it in the development environment.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26033,"Improve performance of TupleBuilder As a developer, I'd like to bench test cases around , so I can identify the bottlenecks and tune for performance optimizations. ",NULL,"Improve performance of TupleBuilder As a developer, I'd like to bench test cases around ,","so I can identify the bottlenecks and tune for performance optimizations.","Add for who this story is","well_formed","no_role","high",False
26033,"Improve performance of TupleBuilder As a developer, I'd like to bench test cases around , so I can identify the bottlenecks and tune for performance optimizations. ",NULL,"Improve performance of TupleBuilder As a developer, I'd like to bench test cases around ,","so I can identify the bottlenecks and tune for performance optimizations.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26031,"Produce Kafka Baseline numbers on Rackspace ",NULL,"Produce Kafka Baseline numbers on Rackspace ",NULL,"Add for who this story is","well_formed","no_role","high",False
26037,"Define pluggable runtime SPI As a developer, I'd like to define pluggable runtime SPI, so I have the option to choose the implementation based on deployment targets such as CF, on prem, Mesos etc.",NULL,"Define pluggable runtime SPI As a developer, I'd like to define pluggable runtime SPI,","so I have the option to choose the implementation based on deployment targets such as CF, on prem, Mesos etc.","Add for who this story is","well_formed","no_role","high",False
26037,"Define pluggable runtime SPI As a developer, I'd like to define pluggable runtime SPI, so I have the option to choose the implementation based on deployment targets such as CF, on prem, Mesos etc.",NULL,"Define pluggable runtime SPI As a developer, I'd like to define pluggable runtime SPI,","so I have the option to choose the implementation based on deployment targets such as CF, on prem, Mesos etc.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26032,"Revisit benchmark matrix for Sqoop vs. jdbshdfs jobs As a developer, I'd like to revisit performance benchmarks with new improvements, so I can verify the optimizations around jdbchdfs .",NULL,"Revisit benchmark matrix for Sqoop vs. jdbshdfs jobs As a developer, I'd like to revisit performance benchmarks with new improvements,","so I can verify the optimizations around jdbchdfs .","Add for who this story is","well_formed","no_role","high",False
26032,"Revisit benchmark matrix for Sqoop vs. jdbshdfs jobs As a developer, I'd like to revisit performance benchmarks with new improvements, so I can verify the optimizations around jdbchdfs .",NULL,"Revisit benchmark matrix for Sqoop vs. jdbshdfs jobs As a developer, I'd like to revisit performance benchmarks with new improvements,","so I can verify the optimizations around jdbchdfs .","Revisit benchmark matrix for Sqoop vs<span class='highlight-text severity-high'>. jdbshdfs jobs As a developer, I'd like to revisit performance benchmarks with new improvements, so I can verify the optimizations around jdbchdfs .</span>","minimal","punctuation","high",False
26032,"Revisit benchmark matrix for Sqoop vs. jdbshdfs jobs As a developer, I'd like to revisit performance benchmarks with new improvements, so I can verify the optimizations around jdbchdfs .",NULL,"Revisit benchmark matrix for Sqoop vs. jdbshdfs jobs As a developer, I'd like to revisit performance benchmarks with new improvements,","so I can verify the optimizations around jdbchdfs .","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26034,"Create a pluggable runtime SPI As a developer, I'd like to migrate module deployment from the repository abstraction used for stream job definitions , so I can create it as a pluggable runtime SPI.",NULL,"Create a pluggable runtime SPI As a developer, I'd like to migrate module deployment from the repository abstraction used for stream job definitions ,","so I can create it as a pluggable runtime SPI.","Add for who this story is","well_formed","no_role","high",False
26034,"Create a pluggable runtime SPI As a developer, I'd like to migrate module deployment from the repository abstraction used for stream job definitions , so I can create it as a pluggable runtime SPI.",NULL,"Create a pluggable runtime SPI As a developer, I'd like to migrate module deployment from the repository abstraction used for stream job definitions ,","so I can create it as a pluggable runtime SPI.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26036,"Create a Java client for Receptor As a developer, I'd like to create a java client for Receptor, so I can interact with Diego runtime via Receptor API calls from XD. ",NULL,"Create a Java client for Receptor As a developer, I'd like to create a java client for Receptor,","so I can interact with Diego runtime via Receptor API calls from XD.","Add for who this story is","well_formed","no_role","high",False
26036,"Create a Java client for Receptor As a developer, I'd like to create a java client for Receptor, so I can interact with Diego runtime via Receptor API calls from XD. ",NULL,"Create a Java client for Receptor As a developer, I'd like to create a java client for Receptor,","so I can interact with Diego runtime via Receptor API calls from XD.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26035,"Create Boot based ModuleRunner As a developer, I'd like to build isolated Boot based for use in container managed environments, so I can run XD without the hard requirement for running xd containers .",NULL,"Create Boot based ModuleRunner As a developer, I'd like to build i","solated Boot based for use in container managed environments, so I can run XD without the hard requirement for running xd containers .","Add for who this story is","well_formed","no_role","high",False
26035,"Create Boot based ModuleRunner As a developer, I'd like to build isolated Boot based for use in container managed environments, so I can run XD without the hard requirement for running xd containers .",NULL,"Create Boot based ModuleRunner As a developer, I'd like to build i","solated Boot based for use in container managed environments, so I can run XD without the hard requirement for running xd containers .","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26038,"Create persistent stream repository As a developer, I'd like to create persistent repository for streams, so I could leverage the persisted metadata and reestablish the streaming pipe under failure conditions.",NULL,"Create persistent stream repository As a developer, I'd like to create persistent repository for streams,","so I could leverage the persisted metadata and reestablish the streaming pipe under failure conditions.","Add for who this story is","well_formed","no_role","high",False
26038,"Create persistent stream repository As a developer, I'd like to create persistent repository for streams, so I could leverage the persisted metadata and reestablish the streaming pipe under failure conditions.",NULL,"Create persistent stream repository As a developer, I'd like to create persistent repository for streams,","so I could leverage the persisted metadata and reestablish the streaming pipe under failure conditions.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26040,"Upgrade Spark version to 1.3.1 As a Spring XD user, I'd like to create streaming pipelines, so I can take advantage of latest specs from both XD and Spark Spark Streaming.",NULL,"Upgrade Spark version to 1.3.1 As a Spring XD user, I'd like to create streaming pipelines,","so I can take advantage of latest specs from both XD and Spark Spark Streaming.","Add for who this story is","well_formed","no_role","high",False
26040,"Upgrade Spark version to 1.3.1 As a Spring XD user, I'd like to create streaming pipelines, so I can take advantage of latest specs from both XD and Spark Spark Streaming.",NULL,"Upgrade Spark version to 1.3.1 As a Spring XD user, I'd like to create streaming pipelines,","so I can take advantage of latest specs from both XD and Spark Spark Streaming.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26039,"Clarify the use of escape quotes for properties in the Sqoop job As a developer, I'd like to add documentation on escape quotes, so when someone using Sqoop job can double escape to successfully submit the job.",NULL,"Clarify the use of escape quotes for properties in the Sqoop job As a developer, I'd like to add documentation on escape quotes,","so when someone using Sqoop job can double escape to successfully submit the job.","Add for who this story is","well_formed","no_role","high",False
26039,"Clarify the use of escape quotes for properties in the Sqoop job As a developer, I'd like to add documentation on escape quotes, so when someone using Sqoop job can double escape to successfully submit the job.",NULL,"Clarify the use of escape quotes for properties in the Sqoop job As a developer, I'd like to add documentation on escape quotes,","so when someone using Sqoop job can double escape to successfully submit the job.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26041,"Document the use of nested jobs with example As a developer, I'd like to document how to nest batch jobs and workflows in XD, so it will be easy for end users to use it as reference. ",NULL,"Document the use of nested jobs with example As a developer, I'd like to document how to nest batch jobs and workflows in XD,","so it will be easy for end users to use it as reference.","Add for who this story is","well_formed","no_role","high",False
26041,"Document the use of nested jobs with example As a developer, I'd like to document how to nest batch jobs and workflows in XD, so it will be easy for end users to use it as reference. ",NULL,"Document the use of nested jobs with example As a developer, I'd like to document how to nest batch jobs and workflows in XD,","so it will be easy for end users to use it as reference.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26042,"Parameterize import options for Sqoop As a user, I'd like to parameterize all Import Options, so I can eliminate the need for option since it gets confusing.",NULL,"Parameterize import options for Sqoop As a user, I'd like to parameterize all Import Options,","so I can eliminate the need for option since it gets confusing.","Add for who this story is","well_formed","no_role","high",False
26042,"Parameterize import options for Sqoop As a user, I'd like to parameterize all Import Options, so I can eliminate the need for option since it gets confusing.",NULL,"Parameterize import options for Sqoop As a user, I'd like to parameterize all Import Options,","so I can eliminate the need for option since it gets confusing.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26118,"Fix gradle build issues As a XD build master, I'd like to fix local . gradlew dist and distZip targets the outstanding build issues, so I can evaluate that publish builds works as expected. ",NULL,"Fix gradle build issues As a XD build master, I'd like to fix local . gradlew dist and distZip targets the outstanding build issues,","so I can evaluate that publish builds works as expected.","Add for who this story is","well_formed","no_role","high",False
26118,"Fix gradle build issues As a XD build master, I'd like to fix local . gradlew dist and distZip targets the outstanding build issues, so I can evaluate that publish builds works as expected. ",NULL,"Fix gradle build issues As a XD build master, I'd like to fix local . gradlew dist and distZip targets the outstanding build issues,","so I can evaluate that publish builds works as expected.","Fix gradle build issues As a XD build master, I'd like to fix local . gradlew dist<span class='highlight-text severity-high'> and </span>distZip targets the outstanding build issues, so I can evaluate that publish builds works as expected. ","atomic","conjunctions","high",False
26118,"Fix gradle build issues As a XD build master, I'd like to fix local . gradlew dist and distZip targets the outstanding build issues, so I can evaluate that publish builds works as expected. ",NULL,"Fix gradle build issues As a XD build master, I'd like to fix local . gradlew dist and distZip targets the outstanding build issues,","so I can evaluate that publish builds works as expected.","Fix gradle build issues As a XD build master, I'd like to fix local <span class='highlight-text severity-high'>. gradlew dist and distZip targets the outstanding build issues, so I can evaluate that publish builds works as expected. </span>","minimal","punctuation","high",False
26118,"Fix gradle build issues As a XD build master, I'd like to fix local . gradlew dist and distZip targets the outstanding build issues, so I can evaluate that publish builds works as expected. ",NULL,"Fix gradle build issues As a XD build master, I'd like to fix local . gradlew dist and distZip targets the outstanding build issues,","so I can evaluate that publish builds works as expected.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26044,"Parameterize Merge Options As a user, I'd like to parameterize Merge Options, so I can incrementally consume the delta with the help of megastore. ",NULL,"Parameterize Merge Options As a user, I'd like to parameterize Merge Options,","so I can incrementally consume the delta with the help of megastore.","Add for who this story is","well_formed","no_role","high",False
26044,"Parameterize Merge Options As a user, I'd like to parameterize Merge Options, so I can incrementally consume the delta with the help of megastore. ",NULL,"Parameterize Merge Options As a user, I'd like to parameterize Merge Options,","so I can incrementally consume the delta with the help of megastore.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26045,"Add support for expressions and dynamically evaluate at runtime As a user, I'd like to have the ability to use expressions, so I can dynamically name directories files based on the timestamp or other intermediate data point.",NULL,"Add support for expressions and dynamically evaluate at runtime As a user, I'd like to have the ability to use expressions,","so I can dynamically name directories files based on the timestamp or other intermediate data point.","Add for who this story is","well_formed","no_role","high",False
26045,"Add support for expressions and dynamically evaluate at runtime As a user, I'd like to have the ability to use expressions, so I can dynamically name directories files based on the timestamp or other intermediate data point.",NULL,"Add support for expressions and dynamically evaluate at runtime As a user, I'd like to have the ability to use expressions,","so I can dynamically name directories files based on the timestamp or other intermediate data point.","Add support for expressions<span class='highlight-text severity-high'> and </span>dynamically evaluate at runtime As a user, I'd like to have the ability to use expressions, so I can dynamically name directories files based on the timestamp<span class='highlight-text severity-high'> or </span>other intermediate data point.","atomic","conjunctions","high",False
26045,"Add support for expressions and dynamically evaluate at runtime As a user, I'd like to have the ability to use expressions, so I can dynamically name directories files based on the timestamp or other intermediate data point.",NULL,"Add support for expressions and dynamically evaluate at runtime As a user, I'd like to have the ability to use expressions,","so I can dynamically name directories files based on the timestamp or other intermediate data point.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26043,"Parameterize codegen options As a user, I'd like to parameterize CodeGen Options, so I can generate code on the fly as needed. ",NULL,"Parameterize codegen options As a user, I'd like to parameterize CodeGen Options,","so I can generate code on the fly as needed.","Add for who this story is","well_formed","no_role","high",False
26043,"Parameterize codegen options As a user, I'd like to parameterize CodeGen Options, so I can generate code on the fly as needed. ",NULL,"Parameterize codegen options As a user, I'd like to parameterize CodeGen Options,","so I can generate code on the fly as needed.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26048,"Refactor MessageBus to avoid unnecessary use of MessageBuilder As a developer, I'd like to refactor the programmatic means by which the MessageBus transforms the Message so throughput performance can be optimized. ",NULL,"Refactor MessageBus to avoid unnecessary use of MessageBuilder As a developer, I'd like to refactor the programmatic means by which the MessageBus transforms the Message","so throughput performance can be optimized.","Add for who this story is","well_formed","no_role","high",False
26048,"Refactor MessageBus to avoid unnecessary use of MessageBuilder As a developer, I'd like to refactor the programmatic means by which the MessageBus transforms the Message so throughput performance can be optimized. ",NULL,"Refactor MessageBus to avoid unnecessary use of MessageBuilder As a developer, I'd like to refactor the programmatic means by which the MessageBus transforms the Message","so throughput performance can be optimized.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26050,"Create samples and document Kryo optimization guidelines As a developer, I'd like to document the Kryo optimization guidelines, so the end users can refer to it while tuning to improve performance.",NULL,"Create samples and document Kryo optimization guidelines As a developer, I'd like to document the Kryo optimization guidelines,","so the end users can refer to it while tuning to improve performance.","Add for who this story is","well_formed","no_role","high",False
26050,"Create samples and document Kryo optimization guidelines As a developer, I'd like to document the Kryo optimization guidelines, so the end users can refer to it while tuning to improve performance.",NULL,"Create samples and document Kryo optimization guidelines As a developer, I'd like to document the Kryo optimization guidelines,","so the end users can refer to it while tuning to improve performance.","Create samples<span class='highlight-text severity-high'> and </span>document Kryo optimization guidelines As a developer, I'd like to document the Kryo optimization guidelines, so the end users can refer to it while tuning to improve performance.","atomic","conjunctions","high",False
26050,"Create samples and document Kryo optimization guidelines As a developer, I'd like to document the Kryo optimization guidelines, so the end users can refer to it while tuning to improve performance.",NULL,"Create samples and document Kryo optimization guidelines As a developer, I'd like to document the Kryo optimization guidelines,","so the end users can refer to it while tuning to improve performance.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26049,"Revisit the requirement for ID and Timestamp attributes in Tuple As a developer, I'd like revisit the design to determine the necessity for ID and TimeStamp attributes in , so I can refactor in order to improve performance throughput.",NULL,"Revisit the requirement for ID and Timestamp attributes in Tuple As a developer, I'd like revisit the design to determine the necessity for ID and TimeStamp attributes in , so I can refactor","in order to improve performance throughput.","Add for who this story is","well_formed","no_role","high",False
26049,"Revisit the requirement for ID and Timestamp attributes in Tuple As a developer, I'd like revisit the design to determine the necessity for ID and TimeStamp attributes in , so I can refactor in order to improve performance throughput.",NULL,"Revisit the requirement for ID and Timestamp attributes in Tuple As a developer, I'd like revisit the design to determine the necessity for ID and TimeStamp attributes in , so I can refactor","in order to improve performance throughput.","Revisit the requirement for ID<span class='highlight-text severity-high'> and </span>Timestamp attributes in Tuple As a developer, I'd like revisit the design to determine the necessity for ID and TimeStamp attributes in , so I can refactor in order to improve performance throughput.","atomic","conjunctions","high",False
26049,"Revisit the requirement for ID and Timestamp attributes in Tuple As a developer, I'd like revisit the design to determine the necessity for ID and TimeStamp attributes in , so I can refactor in order to improve performance throughput.",NULL,"Revisit the requirement for ID and Timestamp attributes in Tuple As a developer, I'd like revisit the design to determine the necessity for ID and TimeStamp attributes in , so I can refactor","in order to improve performance throughput.","Revisit the requirement for ID and Timestamp attributes in Tuple As a developer, I'd like revisit the design to determine the necessity for ID and TimeStamp attributes in ,<span class='highlight-text severity-high'> so </span>I can refactor<span class='highlight-text severity-high'> in order to </span>improve performance throughput.","minimal","indicator_repetition","high",False
26052,"Add s. The admin server already has a logging configuration which should be activated by the startup scripts, but the separate gemfire app doesn t.",NULL,"Add s. The admin server already has a logging configuration which should be activated by the startup scripts, but the separate gemfire app doesn t.",NULL,"Add s<span class='highlight-text severity-high'>. The admin server already has a logging configuration which should be activated by the startup scripts, but the separate gemfire app doesn t.</span>","minimal","punctuation","high",False
26051,"Upgrade to Kafka 0.8.2 As a developer, I'd like to upgrade to Kafka 0.8.2, so I can leverage the latest features in order to test the performance characteristics.",NULL,"Upgrade to Kafka 0.8.2 As a developer, I'd like to upgrade to Kafka 0.8.2, so I can leverage the latest features","in order to test the performance characteristics.","Add for who this story is","well_formed","no_role","high",False
26051,"Upgrade to Kafka 0.8.2 As a developer, I'd like to upgrade to Kafka 0.8.2, so I can leverage the latest features in order to test the performance characteristics.",NULL,"Upgrade to Kafka 0.8.2 As a developer, I'd like to upgrade to Kafka 0.8.2, so I can leverage the latest features","in order to test the performance characteristics.","Upgrade to Kafka 0.8.2 As a developer, I'd like to upgrade to Kafka 0.8.2,<span class='highlight-text severity-high'> so </span>I can leverage the latest features<span class='highlight-text severity-high'> in order to </span>test the performance characteristics.","minimal","indicator_repetition","high",False
26051,"Upgrade to Kafka 0.8.2 As a developer, I'd like to upgrade to Kafka 0.8.2, so I can leverage the latest features in order to test the performance characteristics.",NULL,"Upgrade to Kafka 0.8.2 As a developer, I'd like to upgrade to Kafka 0.8.2, so I can leverage the latest features","in order to test the performance characteristics.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26057,"Document the use of properties file as deployment manifest As a user, I'd like to refer to the documentation to configure the properties file, so I can use it as recommended to represent the deployment manifest.",NULL,"Document the use of properties file as deployment manifest As a user, I'd like to refer to the documentation to configure the properties file,","so I can use it as recommended to represent the deployment manifest.","Add for who this story is","well_formed","no_role","high",False
26057,"Document the use of properties file as deployment manifest As a user, I'd like to refer to the documentation to configure the properties file, so I can use it as recommended to represent the deployment manifest.",NULL,"Document the use of properties file as deployment manifest As a user, I'd like to refer to the documentation to configure the properties file,","so I can use it as recommended to represent the deployment manifest.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26056,"File sink should support rollover I wanted to have a rollover feature when I was streaming tweets to a file overnight, just to avoid dealing with a single enormous file in case I collected more data than my demo could handle and needed to split it up .",NULL,"File sink should support rollover I wanted to have a rollover feature when I was streaming tweets to a file overnight, just to avoid dealing with a single enormous file in case I collected more data than my demo could handle and needed to split it up .",NULL,"Add for who this story is","well_formed","no_role","high",False
26056,"File sink should support rollover I wanted to have a rollover feature when I was streaming tweets to a file overnight, just to avoid dealing with a single enormous file in case I collected more data than my demo could handle and needed to split it up .",NULL,"File sink should support rollover I wanted to have a rollover feature when I was streaming tweets to a file overnight, just to avoid dealing with a single enormous file in case I collected more data than my demo could handle and needed to split it up .",NULL,"File sink should support rollover I wanted to have a rollover feature when I was streaming tweets to a file overnight, just to avoid dealing with a single enormous file in case I collected more data than my demo could handle<span class='highlight-text severity-high'> and </span>needed to split it up .","atomic","conjunctions","high",False
26053,"Benchmark against Kafka 0.8.2 release As a developer, I'd like to rerun baseline , Tuple , and Serialized payloads, so I can compare the differences in performance between 0.8.1 and 0.8.2 Kafka releases. Note 1.1.1 Benched against 0.8.1 1.2 Benched against 0.8.2 ",NULL,"Benchmark against Kafka 0.8.2 release As a developer, I'd like to rerun baseline , Tuple , and Serialized payloads,","so I can compare the differences in performance between 0.8.1 and 0.8.2 Kafka releases. Note 1.1.1 Benched against 0.8.1 1.2 Benched against 0.8.2","Add for who this story is","well_formed","no_role","high",False
26053,"Benchmark against Kafka 0.8.2 release As a developer, I'd like to rerun baseline , Tuple , and Serialized payloads, so I can compare the differences in performance between 0.8.1 and 0.8.2 Kafka releases. Note 1.1.1 Benched against 0.8.1 1.2 Benched against 0.8.2 ",NULL,"Benchmark against Kafka 0.8.2 release As a developer, I'd like to rerun baseline , Tuple , and Serialized payloads,","so I can compare the differences in performance between 0.8.1 and 0.8.2 Kafka releases. Note 1.1.1 Benched against 0.8.1 1.2 Benched against 0.8.2","Benchmark against Kafka 0.8.2 release As a developer, I'd like to rerun baseline , Tuple ,<span class='highlight-text severity-high'> and </span>Serialized payloads, so I can compare the differences in performance between 0.8.1 and 0.8.2 Kafka releases. Note 1.1.1 Benched against 0.8.1 1.2 Benched against 0.8.2 ","atomic","conjunctions","high",False
26053,"Benchmark against Kafka 0.8.2 release As a developer, I'd like to rerun baseline , Tuple , and Serialized payloads, so I can compare the differences in performance between 0.8.1 and 0.8.2 Kafka releases. Note 1.1.1 Benched against 0.8.1 1.2 Benched against 0.8.2 ",NULL,"Benchmark against Kafka 0.8.2 release As a developer, I'd like to rerun baseline , Tuple , and Serialized payloads,","so I can compare the differences in performance between 0.8.1 and 0.8.2 Kafka releases. Note 1.1.1 Benched against 0.8.1 1.2 Benched against 0.8.2","Benchmark against Kafka 0<span class='highlight-text severity-high'>.8.2 release As a developer, I'd like to rerun baseline , Tuple , and Serialized payloads, so I can compare the differences in performance between 0.8.1 and 0.8.2 Kafka releases. Note 1.1.1 Benched against 0.8.1 1.2 Benched against 0.8.2 </span>","minimal","punctuation","high",False
26053,"Benchmark against Kafka 0.8.2 release As a developer, I'd like to rerun baseline , Tuple , and Serialized payloads, so I can compare the differences in performance between 0.8.1 and 0.8.2 Kafka releases. Note 1.1.1 Benched against 0.8.1 1.2 Benched against 0.8.2 ",NULL,"Benchmark against Kafka 0.8.2 release As a developer, I'd like to rerun baseline , Tuple , and Serialized payloads,","so I can compare the differences in performance between 0.8.1 and 0.8.2 Kafka releases. Note 1.1.1 Benched against 0.8.1 1.2 Benched against 0.8.2","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26055,"Spike Come up with a design for stateful stream processing As a developer, I'd like to study the state management requirements, so I can brainstorm and identify the design to natively add stateful stream processing support in XD. ",NULL,"Spike Come up with a design for stateful stream processing As a developer, I'd like to study the state management requirements,","so I can brainstorm and identify the design to natively add stateful stream processing support in XD.","Add for who this story is","well_formed","no_role","high",False
26055,"Spike Come up with a design for stateful stream processing As a developer, I'd like to study the state management requirements, so I can brainstorm and identify the design to natively add stateful stream processing support in XD. ",NULL,"Spike Come up with a design for stateful stream processing As a developer, I'd like to study the state management requirements,","so I can brainstorm and identify the design to natively add stateful stream processing support in XD.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26059,"Submit java receptor client for CF incubation As a user, I'd like to use the Java receptor client, so I can interact with Diego runtime using the Java receptor REST APIs.",NULL,"Submit java receptor client for CF incubation As a user, I'd like to use the Java receptor client,","so I can interact with Diego runtime using the Java receptor REST APIs.","Add for who this story is","well_formed","no_role","high",False
26059,"Submit java receptor client for CF incubation As a user, I'd like to use the Java receptor client, so I can interact with Diego runtime using the Java receptor REST APIs.",NULL,"Submit java receptor client for CF incubation As a user, I'd like to use the Java receptor client,","so I can interact with Diego runtime using the Java receptor REST APIs.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26060,"Refactor gardenhose into more generic twitterstream source Twitter s streaming APIs have more capabilities than just the plain In particular we should support the filter.json option and the use of track as well as other request parameters delimited, language etc .",NULL,"Refactor gardenhose into more generic twitterstream source Twitter s streaming APIs have more capabilities than just the plain In particular we should support the filter.json option and the use of track as well as other request parameters delimited, language etc .",NULL,"Add for who this story is","well_formed","no_role","high",False
26060,"Refactor gardenhose into more generic twitterstream source Twitter s streaming APIs have more capabilities than just the plain In particular we should support the filter.json option and the use of track as well as other request parameters delimited, language etc .",NULL,"Refactor gardenhose into more generic twitterstream source Twitter s streaming APIs have more capabilities than just the plain In particular we should support the filter.json option and the use of track as well as other request parameters delimited, language etc .",NULL,"Refactor gardenhose into more generic twitterstream source Twitter s streaming APIs have more capabilities than just the plain In particular we should support the filter.json option<span class='highlight-text severity-high'> and </span>the use of track as well as other request parameters delimited, language etc .","atomic","conjunctions","high",False
26058,"Run the sqoop job against secured cluster As a user, I'd like to run the sqoop jobs against secured hdfs cluster, so I can restrict access to only authorized users. ",NULL,"Run the sqoop job against secured cluster As a user, I'd like to run the sqoop jobs against secured hdfs cluster,","so I can restrict access to only authorized users.","Add for who this story is","well_formed","no_role","high",False
26058,"Run the sqoop job against secured cluster As a user, I'd like to run the sqoop jobs against secured hdfs cluster, so I can restrict access to only authorized users. ",NULL,"Run the sqoop job against secured cluster As a user, I'd like to run the sqoop jobs against secured hdfs cluster,","so I can restrict access to only authorized users.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26046,"Error Message for Missing Job Description needs to be updated When using the rest interface to create a Job with an empty description, used to generate the following exception, Definition can not be empty . Now generates XD112E pos 0 Unexpectedly ran out of input^ . The correct error should be, definition cannot be blank or null ",NULL,"Error Message for Missing Job Description needs to be updated When using the rest interface to create a Job with an empty description, used to generate the following exception, Definition can not be empty . Now generates XD112E pos 0 Unexpectedly ran out of input^ . The correct error should be, definition cannot be blank or null ",NULL,"Add for who this story is","well_formed","no_role","high",False
26046,"Error Message for Missing Job Description needs to be updated When using the rest interface to create a Job with an empty description, used to generate the following exception, Definition can not be empty . Now generates XD112E pos 0 Unexpectedly ran out of input^ . The correct error should be, definition cannot be blank or null ",NULL,"Error Message for Missing Job Description needs to be updated When using the rest interface to create a Job with an empty description, used to generate the following exception, Definition can not be empty . Now generates XD112E pos 0 Unexpectedly ran out of input^ . The correct error should be, definition cannot be blank or null ",NULL,"Error Message for Missing Job Description needs to be updated When using the rest interface to create a Job with an empty description, used to generate the following exception, Definition can not be empty <span class='highlight-text severity-high'>. Now generates XD112E pos 0 Unexpectedly ran out of input^ . The correct error should be, definition cannot be blank or null </span>","minimal","punctuation","high",False
26062,"Update spring data hadoop to version 2.1.2.RELEASE ",NULL,"Update spring data hadoop to version 2.1.2.RELEASE ",NULL,"Add for who this story is","well_formed","no_role","high",False
26063,"Experiment with re parsing of streams when needed As a follow up to XD 2877, experiment with the removal of the list of modules from BaseDefinition and reparse as needed. Branch is here ",NULL,"Experiment with re parsing of streams when needed As a follow up to XD 2877, experiment with the removal of the list of modules from BaseDefinition and reparse as needed. Branch is here ",NULL,"Add for who this story is","well_formed","no_role","high",False
26063,"Experiment with re parsing of streams when needed As a follow up to XD 2877, experiment with the removal of the list of modules from BaseDefinition and reparse as needed. Branch is here ",NULL,"Experiment with re parsing of streams when needed As a follow up to XD 2877, experiment with the removal of the list of modules from BaseDefinition and reparse as needed. Branch is here ",NULL,"Experiment with re parsing of streams when needed As a follow up to XD 2877, experiment with the removal of the list of modules from BaseDefinition<span class='highlight-text severity-high'> and </span>reparse as needed. Branch is here ","atomic","conjunctions","high",False
26063,"Experiment with re parsing of streams when needed As a follow up to XD 2877, experiment with the removal of the list of modules from BaseDefinition and reparse as needed. Branch is here ",NULL,"Experiment with re parsing of streams when needed As a follow up to XD 2877, experiment with the removal of the list of modules from BaseDefinition and reparse as needed. Branch is here ",NULL,"Experiment with re parsing of streams when needed As a follow up to XD 2877, experiment with the removal of the list of modules from BaseDefinition and reparse as needed<span class='highlight-text severity-high'>. Branch is here </span>","minimal","punctuation","high",False
26064,"Update acceptance test to use new JMX Module name format the update to the JMX was introduced in XD 2941. Also noticed that we should have been checking source and not sink . This was also resolved.",NULL,"Update acceptance test to use new JMX Module name format the update to the JMX was introduced in XD 2941. Also noticed that we should have been checking source and not sink . This was also resolved.",NULL,"Add for who this story is","well_formed","no_role","high",False
26064,"Update acceptance test to use new JMX Module name format the update to the JMX was introduced in XD 2941. Also noticed that we should have been checking source and not sink . This was also resolved.",NULL,"Update acceptance test to use new JMX Module name format the update to the JMX was introduced in XD 2941. Also noticed that we should have been checking source and not sink . This was also resolved.",NULL,"Update acceptance test to use new JMX Module name format the update to the JMX was introduced in XD 2941. Also noticed that we should have been checking source<span class='highlight-text severity-high'> and </span>not sink . This was also resolved.","atomic","conjunctions","high",False
26064,"Update acceptance test to use new JMX Module name format the update to the JMX was introduced in XD 2941. Also noticed that we should have been checking source and not sink . This was also resolved.",NULL,"Update acceptance test to use new JMX Module name format the update to the JMX was introduced in XD 2941. Also noticed that we should have been checking source and not sink . This was also resolved.",NULL,"Update acceptance test to use new JMX Module name format the update to the JMX was introduced in XD 2941<span class='highlight-text severity-high'>. Also noticed that we should have been checking source and not sink . This was also resolved.</span>","minimal","punctuation","high",False
26067,"Verify module count works on 10 Containers This tests should prove that Kafka can handle a module count greater than one with the proper concurrency settings. load generator should be used as the foundation for this test with the following settings An environment should be provisioned to support the containers, Zookeeper and Kafka. ",NULL,"Verify module count works on 10 Containers This tests should prove that Kafka can handle a module count greater than one with the proper concurrency settings. load generator should be used as the foundation for this test with the following settings An environment should be provisioned to support the containers, Zookeeper and Kafka. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26067,"Verify module count works on 10 Containers This tests should prove that Kafka can handle a module count greater than one with the proper concurrency settings. load generator should be used as the foundation for this test with the following settings An environment should be provisioned to support the containers, Zookeeper and Kafka. ",NULL,"Verify module count works on 10 Containers This tests should prove that Kafka can handle a module count greater than one with the proper concurrency settings. load generator should be used as the foundation for this test with the following settings An environment should be provisioned to support the containers, Zookeeper and Kafka. ",NULL,"Verify module count works on 10 Containers This tests should prove that Kafka can handle a module count greater than one with the proper concurrency settings<span class='highlight-text severity-high'>. load generator should be used as the foundation for this test with the following settings An environment should be provisioned to support the containers, Zookeeper and Kafka. </span>","minimal","punctuation","high",False
26065,"Add support for multiple topics in Kafka source As a user, I'd like to consume multiple topic partitions, so I can have the option to consume from multiple data endpoints and still be able to serve the data via single queue.",NULL,"Add support for multiple topics in Kafka","source As a user, I'd like to consume multiple topic partitions, so I can have the option to consume from multiple data endpoints and still be able to serve the data via single queue.","Add for who this story is","well_formed","no_role","high",False
26065,"Add support for multiple topics in Kafka source As a user, I'd like to consume multiple topic partitions, so I can have the option to consume from multiple data endpoints and still be able to serve the data via single queue.",NULL,"Add support for multiple topics in Kafka","source As a user, I'd like to consume multiple topic partitions, so I can have the option to consume from multiple data endpoints and still be able to serve the data via single queue.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26069,"Benchmark with and without JMX activated As a developer, I'd like to benchmark a stream with and without enabled, so I can test in isolation, and document the differences in performance.",NULL,"Benchmark with and without JMX activated As a developer, I'd like to benchmark a stream with and without enabled,","so I can test in isolation, and document the differences in performance.","Add for who this story is","well_formed","no_role","high",False
26069,"Benchmark with and without JMX activated As a developer, I'd like to benchmark a stream with and without enabled, so I can test in isolation, and document the differences in performance.",NULL,"Benchmark with and without JMX activated As a developer, I'd like to benchmark a stream with and without enabled,","so I can test in isolation, and document the differences in performance.","Benchmark with<span class='highlight-text severity-high'> and </span>without JMX activated As a developer, I'd like to benchmark a stream with and without enabled, so I can test in isolation, and document the differences in performance.","atomic","conjunctions","high",False
26069,"Benchmark with and without JMX activated As a developer, I'd like to benchmark a stream with and without enabled, so I can test in isolation, and document the differences in performance.",NULL,"Benchmark with and without JMX activated As a developer, I'd like to benchmark a stream with and without enabled,","so I can test in isolation, and document the differences in performance.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26066,"Add a new variation of DSL parser for Flo As a Flo developer, I'd like to have a new DSL parser, so I can easily detect incorrect module option values when supplied from the Flo UI. Example MyStream mail log log If parsed separately which Flo UI does , the current parser endpoint will barf on the second stream because it doesn t know about the first stream MyStream . ",NULL,"Add a new variation of DSL parser for Flo As a Flo developer, I'd like to have a new DSL parser,","so I can easily detect incorrect module option values when supplied from the Flo UI. Example MyStream mail log log If parsed separately which Flo UI does , the current parser endpoint will barf on the second stream because it doesn t know about the first stream MyStream .","Add for who this story is","well_formed","no_role","high",False
26066,"Add a new variation of DSL parser for Flo As a Flo developer, I'd like to have a new DSL parser, so I can easily detect incorrect module option values when supplied from the Flo UI. Example MyStream mail log log If parsed separately which Flo UI does , the current parser endpoint will barf on the second stream because it doesn t know about the first stream MyStream . ",NULL,"Add a new variation of DSL parser for Flo As a Flo developer, I'd like to have a new DSL parser,","so I can easily detect incorrect module option values when supplied from the Flo UI. Example MyStream mail log log If parsed separately which Flo UI does , the current parser endpoint will barf on the second stream because it doesn t know about the first stream MyStream .","Add a new variation of DSL parser for Flo As a Flo developer, I'd like to have a new DSL parser, so I can easily detect incorrect module option values when supplied from the Flo UI<span class='highlight-text severity-high'>. Example MyStream mail log log If parsed separately which Flo UI does , the current parser endpoint will barf on the second stream because it doesn t know about the first stream MyStream . </span>","minimal","punctuation","high",False
26070,"Create a simple counter service A simple counters can a number. Implementations for in memory and redis.",NULL,"Create a simple counter service A simple counters can a number. Implementations for in memory and redis.",NULL,"Create a simple counter service A simple counters can a number<span class='highlight-text severity-high'>. Implementations for in memory and redis.</span>","minimal","punctuation","high",False
26068,"TupleCode should retain custom formatting settings As a developer, I'd like to handle the non default tuples in an uniform manner, so they re not reset after deserialization. ",NULL,"TupleCode should retain custom formatting settings As a developer, I'd like to handle the non default tuples in an uniform manner,","so they re not reset after deserialization.","Add for who this story is","well_formed","no_role","high",False
26068,"TupleCode should retain custom formatting settings As a developer, I'd like to handle the non default tuples in an uniform manner, so they re not reset after deserialization. ",NULL,"TupleCode should retain custom formatting settings As a developer, I'd like to handle the non default tuples in an uniform manner,","so they re not reset after deserialization.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26072,"Add support for using Sqoop metastore As a user, I'd like to have the option to change the default Sqoop metastore , so I can implement a DB of my choice and not tied to default specifications. Refer to this thread for more details. ",NULL,"Add support for using Sqoop metastore As a user, I'd like to have the option to change the default Sqoop metastore ,","so I can implement a DB of my choice and not tied to default specifications. Refer to this thread for more details.","Add for who this story is","well_formed","no_role","high",False
26072,"Add support for using Sqoop metastore As a user, I'd like to have the option to change the default Sqoop metastore , so I can implement a DB of my choice and not tied to default specifications. Refer to this thread for more details. ",NULL,"Add support for using Sqoop metastore As a user, I'd like to have the option to change the default Sqoop metastore ,","so I can implement a DB of my choice and not tied to default specifications. Refer to this thread for more details.","Add support for using Sqoop metastore As a user, I'd like to have the option to change the default Sqoop metastore , so I can implement a DB of my choice and not tied to default specifications<span class='highlight-text severity-high'>. Refer to this thread for more details. </span>","minimal","punctuation","high",False
26072,"Add support for using Sqoop metastore As a user, I'd like to have the option to change the default Sqoop metastore , so I can implement a DB of my choice and not tied to default specifications. Refer to this thread for more details. ",NULL,"Add support for using Sqoop metastore As a user, I'd like to have the option to change the default Sqoop metastore ,","so I can implement a DB of my choice and not tied to default specifications. Refer to this thread for more details.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26074,"Request to create a repo for Spring XD performance testing It would be nice if we have a git repo for Spring XD performance testing. This would enable us to have a common repository rather than inside spring xd as a subproject for all performance related code specific to any module, message middleware etc., ",NULL,"Request to create a repo for Spring XD performance testing It would be nice if we have a git repo for Spring XD performance testing. This would enable us to have a common repository rather than inside spring xd as a subproject for all performance related code specific to any module, message middleware etc., ",NULL,"Add for who this story is","well_formed","no_role","high",False
26074,"Request to create a repo for Spring XD performance testing It would be nice if we have a git repo for Spring XD performance testing. This would enable us to have a common repository rather than inside spring xd as a subproject for all performance related code specific to any module, message middleware etc., ",NULL,"Request to create a repo for Spring XD performance testing It would be nice if we have a git repo for Spring XD performance testing. This would enable us to have a common repository rather than inside spring xd as a subproject for all performance related code specific to any module, message middleware etc., ",NULL,"Request to create a repo for Spring XD performance testing It would be nice if we have a git repo for Spring XD performance testing<span class='highlight-text severity-high'>. This would enable us to have a common repository rather than inside spring xd as a subproject for all performance related code specific to any module, message middleware etc., </span>","minimal","punctuation","high",False
26075,"Support ref true false for sftp source The file and ftp sources allow working with either the java.io.File or its contents. For consistency, the sftp source should support the same mechanism. ",NULL,"Support ref true false for sftp source The file and ftp sources allow working with either the java.io.File or its contents. For consistency, the sftp source should support the same mechanism. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26075,"Support ref true false for sftp source The file and ftp sources allow working with either the java.io.File or its contents. For consistency, the sftp source should support the same mechanism. ",NULL,"Support ref true false for sftp source The file and ftp sources allow working with either the java.io.File or its contents. For consistency, the sftp source should support the same mechanism. ",NULL,"Support ref true false for sftp source The file<span class='highlight-text severity-high'> and </span>ftp sources allow working with either the java.io.File<span class='highlight-text severity-high'> or </span>its contents. For consistency, the sftp source should support the same mechanism. ","atomic","conjunctions","high",False
26075,"Support ref true false for sftp source The file and ftp sources allow working with either the java.io.File or its contents. For consistency, the sftp source should support the same mechanism. ",NULL,"Support ref true false for sftp source The file and ftp sources allow working with either the java.io.File or its contents. For consistency, the sftp source should support the same mechanism. ",NULL,"Support ref true false for sftp source The file and ftp sources allow working with either the java<span class='highlight-text severity-high'>.io.File or its contents. For consistency, the sftp source should support the same mechanism. </span>","minimal","punctuation","high",False
26077,"Document Kafka message bus properties For example, how to specify the partition count for topics that are created by the message bus.",NULL,"Document Kafka message bus properties For example, how to specify the partition count for topics that are created by the message bus.",NULL,"Add for who this story is","well_formed","no_role","high",False
26078,"Fix package tangles See ",NULL,"Fix package tangles See ",NULL,"Add for who this story is","well_formed","no_role","high",False
26076,"Add documentation for connecting to HDFS with HA Namenode ",NULL,"Add documentation for connecting to HDFS with HA Namenode ",NULL,"Add for who this story is","well_formed","no_role","high",False
26071,"Enhance TupleCodec performance Profile TupleCodec and implement performance optimizations",NULL,"Enhance TupleCodec performance Profile TupleCodec and implement performance optimizations",NULL,"Add for who this story is","well_formed","no_role","high",False
26071,"Enhance TupleCodec performance Profile TupleCodec and implement performance optimizations",NULL,"Enhance TupleCodec performance Profile TupleCodec and implement performance optimizations",NULL,"Enhance TupleCodec performance Profile TupleCodec<span class='highlight-text severity-high'> and </span>implement performance optimizations","atomic","conjunctions","high",False
26081,"User wants ability to create a mock source To send a pre set message to process es ",NULL,"User wants ability to create a mock source To send a pre set message to process es ",NULL,"Add for who this story is","well_formed","no_role","high",False
26080,"Document how to use the module registry backed by HDFS As a user, I'd like to refer to the documentation, so I can configure HDFS backed module registry XD 2287 as recommended. ",NULL,"Document how to use the module registry backed by HDFS As a user, I'd like to refer to the documentation,","so I can configure HDFS backed module registry XD 2287 as recommended.","Add for who this story is","well_formed","no_role","high",False
26080,"Document how to use the module registry backed by HDFS As a user, I'd like to refer to the documentation, so I can configure HDFS backed module registry XD 2287 as recommended. ",NULL,"Document how to use the module registry backed by HDFS As a user, I'd like to refer to the documentation,","so I can configure HDFS backed module registry XD 2287 as recommended.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26083,"Add new REST API to get all the counters, gauges, and rich gauges As a user, I'd like to have a REST API to get all the counters , gauges , and rich gauges in a single request, so I don t have to issue multiple request to fetch each one of the metrics by name id for custom dashboards. ",NULL,"Add new REST API to get all the counters, gauges, and rich gauges As a user, I'd like to have a REST API to get all the counters , gauges , and rich gauges in a single request,","so I don t have to issue multiple request to fetch each one of the metrics by name id for custom dashboards.","Add for who this story is","well_formed","no_role","high",False
26083,"Add new REST API to get all the counters, gauges, and rich gauges As a user, I'd like to have a REST API to get all the counters , gauges , and rich gauges in a single request, so I don t have to issue multiple request to fetch each one of the metrics by name id for custom dashboards. ",NULL,"Add new REST API to get all the counters, gauges, and rich gauges As a user, I'd like to have a REST API to get all the counters , gauges , and rich gauges in a single request,","so I don t have to issue multiple request to fetch each one of the metrics by name id for custom dashboards.","Add new REST API to get all the counters, gauges,<span class='highlight-text severity-high'> and </span>rich gauges As a user, I'd like to have a REST API to get all the counters , gauges , and rich gauges in a single request, so I don t have to issue multiple request to fetch each one of the metrics by name id for custom dashboards. ","atomic","conjunctions","high",False
26083,"Add new REST API to get all the counters, gauges, and rich gauges As a user, I'd like to have a REST API to get all the counters , gauges , and rich gauges in a single request, so I don t have to issue multiple request to fetch each one of the metrics by name id for custom dashboards. ",NULL,"Add new REST API to get all the counters, gauges, and rich gauges As a user, I'd like to have a REST API to get all the counters , gauges , and rich gauges in a single request,","so I don t have to issue multiple request to fetch each one of the metrics by name id for custom dashboards.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26082,"SSL Config for RabbitMessageBus Connections is Ignored ",NULL,"SSL Config for RabbitMessageBus Connections is Ignored ",NULL,"Add for who this story is","well_formed","no_role","high",False
26084,"Update Spring Integration Spring AMQP Versions 4.1.4 and 1.4.5 respectively.",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26084,"Update Spring Integration Spring AMQP Versions 4.1.4 and 1.4.5 respectively.",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26090,"Upgrade to Reactor 2.0.1 ",NULL,"Upgrade to Reactor 2.0.1 ",NULL,"Add for who this story is","well_formed","no_role","high",False
26085,"User wants ability to create a in process sink or tap So that we can validate the message content in the stream",NULL,"User wants ability to create a in process sink or tap","So that we can validate the message content in the stream","Add for who this story is","well_formed","no_role","high",False
26085,"User wants ability to create a in process sink or tap So that we can validate the message content in the stream",NULL,"User wants ability to create a in process sink or tap","So that we can validate the message content in the stream","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26086,"Upgrade to Spring Data Fowler Release Spring Data Gemfire is version 8.0.0 in Folwer, which is the same as in BDS Should check minor version number in BDS . ATM we are using gemfire 7.0.x",NULL,"Upgrade to Spring Data Fowler Release Spring Data Gemfire is version 8.0.0 in Folwer, which is the same as in BDS Should check minor version number in BDS . ATM we are using gemfire 7.0.x",NULL,"Add for who this story is","well_formed","no_role","high",False
26086,"Upgrade to Spring Data Fowler Release Spring Data Gemfire is version 8.0.0 in Folwer, which is the same as in BDS Should check minor version number in BDS . ATM we are using gemfire 7.0.x",NULL,"Upgrade to Spring Data Fowler Release Spring Data Gemfire is version 8.0.0 in Folwer, which is the same as in BDS Should check minor version number in BDS . ATM we are using gemfire 7.0.x",NULL,"Upgrade to Spring Data Fowler Release Spring Data Gemfire is version 8<span class='highlight-text severity-high'>.0.0 in Folwer, which is the same as in BDS Should check minor version number in BDS . ATM we are using gemfire 7.0.x</span>","minimal","punctuation","high",False
26087,"Fix section headers in reference TOC Fix section headers in reference TOC See There should be chapter section title before this. See There should be chapter section title before this.",NULL,"Fix section headers in reference TOC Fix section headers in reference TOC See There should be chapter section title before this. See There should be chapter section title before this.",NULL,"Add for who this story is","well_formed","no_role","high",False
26087,"Fix section headers in reference TOC Fix section headers in reference TOC See There should be chapter section title before this. See There should be chapter section title before this.",NULL,"Fix section headers in reference TOC Fix section headers in reference TOC See There should be chapter section title before this. See There should be chapter section title before this.",NULL,"Fix section headers in reference TOC Fix section headers in reference TOC See There should be chapter section title before this<span class='highlight-text severity-high'>. See There should be chapter section title before this.</span>","minimal","punctuation","high",False
26088,"User wants ability to test processors Be able to point to the processor xml file, e.g. and have access to a source channel that drives messages into the processor and a output channel where output messages are send. The outbound channel is queue backed. Test sending JSON to a processor module that uses Tuples. ",NULL,"User wants ability to test processors Be able to point to the processor xml file, e.g. and have access to a source channel that drives messages into the processor and a output channel where output messages are send. The outbound channel is queue backed. Test sending JSON to a processor module that uses Tuples. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26088,"User wants ability to test processors Be able to point to the processor xml file, e.g. and have access to a source channel that drives messages into the processor and a output channel where output messages are send. The outbound channel is queue backed. Test sending JSON to a processor module that uses Tuples. ",NULL,"User wants ability to test processors Be able to point to the processor xml file, e.g. and have access to a source channel that drives messages into the processor and a output channel where output messages are send. The outbound channel is queue backed. Test sending JSON to a processor module that uses Tuples. ",NULL,"User wants ability to test processors Be able to point to the processor xml file, e.g.<span class='highlight-text severity-high'> and </span>have access to a source channel that drives messages into the processor and a output channel where output messages are send. The outbound channel is queue backed. Test sending JSON to a processor module that uses Tuples. ","atomic","conjunctions","high",False
26088,"User wants ability to test processors Be able to point to the processor xml file, e.g. and have access to a source channel that drives messages into the processor and a output channel where output messages are send. The outbound channel is queue backed. Test sending JSON to a processor module that uses Tuples. ",NULL,"User wants ability to test processors Be able to point to the processor xml file, e.g. and have access to a source channel that drives messages into the processor and a output channel where output messages are send. The outbound channel is queue backed. Test sending JSON to a processor module that uses Tuples. ",NULL,"User wants ability to test processors Be able to point to the processor xml file, e<span class='highlight-text severity-high'>.g. and have access to a source channel that drives messages into the processor and a output channel where output messages are send. The outbound channel is queue backed. Test sending JSON to a processor module that uses Tuples. </span>","minimal","punctuation","high",False
26092,"Complete Camera Ready DEBS submission Complete and submit DEBS 2015 paper as described here ",NULL,"Complete Camera Ready DEBS submission Complete and submit DEBS 2015 paper as described here ",NULL,"Add for who this story is","well_formed","no_role","high",False
26091,"Document GF specific configuration properties As a user, I'd like to use the GF source along with native GF authentication enabled, so I can consume data from GF in a secured way. I'd like to refer to documentation on where the GF specific native and security properties needs configured. See this SC post for more details.",NULL,"Document GF specific configuration properties As a user, I'd like to use the GF","source along with native GF authentication enabled, so I can consume data from GF in a secured way. I'd like to refer to documentation on where the GF specific native and security properties needs configured. See this SC post for more details.","Add for who this story is","well_formed","no_role","high",False
26091,"Document GF specific configuration properties As a user, I'd like to use the GF source along with native GF authentication enabled, so I can consume data from GF in a secured way. I'd like to refer to documentation on where the GF specific native and security properties needs configured. See this SC post for more details.",NULL,"Document GF specific configuration properties As a user, I'd like to use the GF","source along with native GF authentication enabled, so I can consume data from GF in a secured way. I'd like to refer to documentation on where the GF specific native and security properties needs configured. See this SC post for more details.","Document GF specific configuration properties As a user, I'd like to use the GF source along with native GF authentication enabled, so I can consume data from GF in a secured way<span class='highlight-text severity-high'>. I'd like to refer to documentation on where the GF specific native and security properties needs configured. See this SC post for more details.</span>","minimal","punctuation","high",False
26091,"Document GF specific configuration properties As a user, I'd like to use the GF source along with native GF authentication enabled, so I can consume data from GF in a secured way. I'd like to refer to documentation on where the GF specific native and security properties needs configured. See this SC post for more details.",NULL,"Document GF specific configuration properties As a user, I'd like to use the GF","source along with native GF authentication enabled, so I can consume data from GF in a secured way. I'd like to refer to documentation on where the GF specific native and security properties needs configured. See this SC post for more details.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26096,"Move gpfdist sink from spring xd modules repo to the core As a developer, I'd like to move the project reactor based gpfdist from spring xd module repo to the core, so I can natively use this sink to write to GPDB HAWQ. ",NULL,"Move gpfdist sink from spring xd modules repo to the core As a developer, I'd like to move the project reactor based gpfdist from spring xd module repo to the core,","so I can natively use this sink to write to GPDB HAWQ.","Add for who this story is","well_formed","no_role","high",False
26096,"Move gpfdist sink from spring xd modules repo to the core As a developer, I'd like to move the project reactor based gpfdist from spring xd module repo to the core, so I can natively use this sink to write to GPDB HAWQ. ",NULL,"Move gpfdist sink from spring xd modules repo to the core As a developer, I'd like to move the project reactor based gpfdist from spring xd module repo to the core,","so I can natively use this sink to write to GPDB HAWQ.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26094,"User wants ability to test sinks Handled by 1245",NULL,"User wants ability to test sinks Handled by 1245",NULL,"Add for who this story is","well_formed","no_role","high",False
26119,"Optionally Add Spring Integration MBean Exporters to Common ApplicationContext Probably needs support for Spring Profiles.",NULL,"Optionally Add Spring Integration MBean Exporters to Common ApplicationContext Probably needs support for Spring Profiles.",NULL,"Add for who this story is","well_formed","no_role","high",False
26095,"Move Reactor based processor module from spring xd modules to core As a developer, I'd like to move the project reactor based data processor module from spring xd module repo to the core, so I can natively use Reactor s Stream API to build processor modules. ",NULL,"Move Reactor based proces","sor module from spring xd modules to core As a developer, I'd like to move the project reactor based data processor module from spring xd module repo to the core, so I can natively use Reactor s Stream API to build processor modules.","Add for who this story is","well_formed","no_role","high",False
26093,"Profile byte array on In Memory and Kafka Transport Identify and report hotspots while running the load generator source and the throughput sink on Singlenode In Memory Transport Singlenode Kafka Transport Admin Container Kafka Transport",NULL,"Profile byte array on In Memory and Kafka Transport Identify and report hotspots while running the load generator source and the throughput sink on Singlenode In Memory Transport Singlenode Kafka Transport Admin Container Kafka Transport",NULL,"Add for who this story is","well_formed","no_role","high",False
26089,"Create Boot based ModuleRunner Phase III As a user, I'd like to use Boot based for use in container managed environments, so I can run XD without xd containers . Scope ",NULL,"Create Boot based ModuleRunner Phase III As a user, I'd like to use Boot based for use in container managed environments,","so I can run XD without xd containers . Scope","Add for who this story is","well_formed","no_role","high",False
26089,"Create Boot based ModuleRunner Phase III As a user, I'd like to use Boot based for use in container managed environments, so I can run XD without xd containers . Scope ",NULL,"Create Boot based ModuleRunner Phase III As a user, I'd like to use Boot based for use in container managed environments,","so I can run XD without xd containers . Scope","Create Boot based ModuleRunner Phase III As a user, I'd like to use Boot based for use in container managed environments, so I can run XD without xd containers <span class='highlight-text severity-high'>. Scope </span>","minimal","punctuation","high",False
26089,"Create Boot based ModuleRunner Phase III As a user, I'd like to use Boot based for use in container managed environments, so I can run XD without xd containers . Scope ",NULL,"Create Boot based ModuleRunner Phase III As a user, I'd like to use Boot based for use in container managed environments,","so I can run XD without xd containers . Scope","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26100,"User to send a message directly to module and receive a message from a module ",NULL,"User to send a message directly to module and receive a message from a module ",NULL,"Add for who this story is","well_formed","no_role","high",False
26100,"User to send a message directly to module and receive a message from a module ",NULL,"User to send a message directly to module and receive a message from a module ",NULL,"User to send a message directly to module<span class='highlight-text severity-high'> and </span>receive a message from a module ","atomic","conjunctions","high",False
26099,"Make Enum Conversions for ModuleOptions more lenient If you have a an option mode textLine , presently the enum MUST be named textLine . I think it would improve the user experience if we allowed users to pass in values such as mode textLine mode text line mode TEXT LINE ",NULL,"Make Enum Conversions for ModuleOptions more lenient If you have a an option mode textLine , presently the enum MUST be named textLine . I think it would improve the user experience if we allowed users to pass in values such as mode textLine mode text line mode TEXT LINE ",NULL,"Add for who this story is","well_formed","no_role","high",False
26099,"Make Enum Conversions for ModuleOptions more lenient If you have a an option mode textLine , presently the enum MUST be named textLine . I think it would improve the user experience if we allowed users to pass in values such as mode textLine mode text line mode TEXT LINE ",NULL,"Make Enum Conversions for ModuleOptions more lenient If you have a an option mode textLine , presently the enum MUST be named textLine . I think it would improve the user experience if we allowed users to pass in values such as mode textLine mode text line mode TEXT LINE ",NULL,"Make Enum Conversions for ModuleOptions more lenient If you have a an option mode textLine , presently the enum MUST be named textLine <span class='highlight-text severity-high'>. I think it would improve the user experience if we allowed users to pass in values such as mode textLine mode text line mode TEXT LINE </span>","minimal","punctuation","high",False
26101,"Spike Produce Rabbit baseline on rackspace infrastructure As a developer, I'd like to bench Rabbit on rackspace infrastructure, so I can have a sense on how it scales as we add more xd container nodes.",NULL,"Spike Produce Rabbit baseline on rackspace infrastructure As a developer, I'd like to bench Rabbit on rackspace infrastructure,","so I can have a sense on how it scales as we add more xd container nodes.","Add for who this story is","well_formed","no_role","high",False
26101,"Spike Produce Rabbit baseline on rackspace infrastructure As a developer, I'd like to bench Rabbit on rackspace infrastructure, so I can have a sense on how it scales as we add more xd container nodes.",NULL,"Spike Produce Rabbit baseline on rackspace infrastructure As a developer, I'd like to bench Rabbit on rackspace infrastructure,","so I can have a sense on how it scales as we add more xd container nodes.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26102,"Flo parser improvements As a Flo developer, I'd like to add improvements to existing Flo parser endpoints, so I can streamline the error reporting strategy.",NULL,"Flo parser improvements As a Flo developer, I'd like to add improvements to existing Flo parser endpoints,","so I can streamline the error reporting strategy.","Add for who this story is","well_formed","no_role","high",False
26102,"Flo parser improvements As a Flo developer, I'd like to add improvements to existing Flo parser endpoints, so I can streamline the error reporting strategy.",NULL,"Flo parser improvements As a Flo developer, I'd like to add improvements to existing Flo parser endpoints,","so I can streamline the error reporting strategy.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26104,"User wants ability to test multiple processors in a chain ",NULL,"User wants ability to test multiple processors in a chain ",NULL,"Add for who this story is","well_formed","no_role","high",False
26103,"Default HDFS as custom module registry for YARN deployments As a developer, I'd like to default to HDFS as distributed remote location for custom module registry, so I can use xd shell or the REST API directly to upload the custom module bits. I would also like to remove custom modules.zip artifact from YARN distribution.",NULL,"Default HDFS as custom module registry for YARN deployments As a developer, I'd like to default to HDFS as distributed remote location for custom module registry,","so I can use xd shell or the REST API directly to upload the custom module bits. I would also like to remove custom modules.zip artifact from YARN distribution.","Add for who this story is","well_formed","no_role","high",False
26103,"Default HDFS as custom module registry for YARN deployments As a developer, I'd like to default to HDFS as distributed remote location for custom module registry, so I can use xd shell or the REST API directly to upload the custom module bits. I would also like to remove custom modules.zip artifact from YARN distribution.",NULL,"Default HDFS as custom module registry for YARN deployments As a developer, I'd like to default to HDFS as distributed remote location for custom module registry,","so I can use xd shell or the REST API directly to upload the custom module bits. I would also like to remove custom modules.zip artifact from YARN distribution.","Default HDFS as custom module registry for YARN deployments As a developer, I'd like to default to HDFS as distributed remote location for custom module registry, so I can use xd shell or the REST API directly to upload the custom module bits<span class='highlight-text severity-high'>. I would also like to remove custom modules.zip artifact from YARN distribution.</span>","minimal","punctuation","high",False
26103,"Default HDFS as custom module registry for YARN deployments As a developer, I'd like to default to HDFS as distributed remote location for custom module registry, so I can use xd shell or the REST API directly to upload the custom module bits. I would also like to remove custom modules.zip artifact from YARN distribution.",NULL,"Default HDFS as custom module registry for YARN deployments As a developer, I'd like to default to HDFS as distributed remote location for custom module registry,","so I can use xd shell or the REST API directly to upload the custom module bits. I would also like to remove custom modules.zip artifact from YARN distribution.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26107,"Update build to use SHDP 2.2.0.RC1 ",NULL,"Update build to use SHDP 2.2.0.RC1 ",NULL,"Add for who this story is","well_formed","no_role","high",False
26108,"Update to Reactor 2.0.2 ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26108,"Update to Reactor 2.0.2 ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26109,"Support for to work with concurrent producing threads Also provide better lifecycle shutdown mgmt of handler.",NULL,"Support for to work with concurrent producing threads Also provide better lifecycle shutdown mgmt of handler.",NULL,"Add for who this story is","well_formed","no_role","high",False
26111,"Create field value counters A field value counter is useful for bar chart graphs, Strings on x axis and count on y axis. Maps well to zset in redis. Implementations for in memory and redis.",NULL,"Create field value counters A field value counter is useful for bar chart graphs, Strings on x axis and count on y axis. Maps well to zset in redis. Implementations for in memory and redis.",NULL,"Add for who this story is","well_formed","no_role","high",False
26111,"Create field value counters A field value counter is useful for bar chart graphs, Strings on x axis and count on y axis. Maps well to zset in redis. Implementations for in memory and redis.",NULL,"Create field value counters A field value counter is useful for bar chart graphs, Strings on x axis and count on y axis. Maps well to zset in redis. Implementations for in memory and redis.",NULL,"Create field value counters A field value counter is useful for bar chart graphs, Strings on x axis and count on y axis<span class='highlight-text severity-high'>. Maps well to zset in redis. Implementations for in memory and redis.</span>","minimal","punctuation","high",False
26110,"Message Bus optimizations Kafka Redis ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26110,"Message Bus optimizations Kafka Redis ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26116,"Turn off JMX by default As a developer, I'd like to have JMX turned off by default, so I can take advantage of the performance throughput benefits. ",NULL,"Turn off JMX by default As a developer, I'd like to have JMX turned off by default,","so I can take advantage of the performance throughput benefits.","Add for who this story is","well_formed","no_role","high",False
26116,"Turn off JMX by default As a developer, I'd like to have JMX turned off by default, so I can take advantage of the performance throughput benefits. ",NULL,"Turn off JMX by default As a developer, I'd like to have JMX turned off by default,","so I can take advantage of the performance throughput benefits.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26112,"Fix Gradle dist build task ",NULL,"Fix Gradle dist build task ",NULL,"Add for who this story is","well_formed","no_role","high",False
26114,"Adapt to XD Reactor processor fixes and improvements As a developer, I'd like to upgrade to 2.0.3 release of Reactor, so I can inherit the latest optimizations to further improve XD performance characteristics. ",NULL,"Adapt to XD Reactor proces","sor fixes and improvements As a developer, I'd like to upgrade to 2.0.3 release of Reactor, so I can inherit the latest optimizations to further improve XD performance characteristics.","Add for who this story is","well_formed","no_role","high",False
26114,"Adapt to XD Reactor processor fixes and improvements As a developer, I'd like to upgrade to 2.0.3 release of Reactor, so I can inherit the latest optimizations to further improve XD performance characteristics. ",NULL,"Adapt to XD Reactor proces","sor fixes and improvements As a developer, I'd like to upgrade to 2.0.3 release of Reactor, so I can inherit the latest optimizations to further improve XD performance characteristics.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26113,"Benchmark XD RC1 using Kafka 0.8.2 as transport As a developer, I'd like to rerun baseline , Tuple , and Serialized payloads, so I can compare the differences in performance between 0.8.1 and 0.8.2 Kafka releases. Sinks to be included in test In Memory Transport Hdfs sink Direct Binding Transport Hdfs Sink Kafka Hdfs Sink",NULL,"Benchmark XD RC1 using Kafka 0.8.2 as transport As a developer, I'd like to rerun baseline , Tuple , and Serialized payloads,","so I can compare the differences in performance between 0.8.1 and 0.8.2 Kafka releases. Sinks to be included in test In Memory Transport Hdfs sink Direct Binding Transport Hdfs Sink Kafka Hdfs Sink","Add for who this story is","well_formed","no_role","high",False
26113,"Benchmark XD RC1 using Kafka 0.8.2 as transport As a developer, I'd like to rerun baseline , Tuple , and Serialized payloads, so I can compare the differences in performance between 0.8.1 and 0.8.2 Kafka releases. Sinks to be included in test In Memory Transport Hdfs sink Direct Binding Transport Hdfs Sink Kafka Hdfs Sink",NULL,"Benchmark XD RC1 using Kafka 0.8.2 as transport As a developer, I'd like to rerun baseline , Tuple , and Serialized payloads,","so I can compare the differences in performance between 0.8.1 and 0.8.2 Kafka releases. Sinks to be included in test In Memory Transport Hdfs sink Direct Binding Transport Hdfs Sink Kafka Hdfs Sink","Benchmark XD RC1 using Kafka 0.8.2 as transport As a developer, I'd like to rerun baseline , Tuple ,<span class='highlight-text severity-high'> and </span>Serialized payloads, so I can compare the differences in performance between 0.8.1 and 0.8.2 Kafka releases. Sinks to be included in test In Memory Transport Hdfs sink Direct Binding Transport Hdfs Sink Kafka Hdfs Sink","atomic","conjunctions","high",False
26113,"Benchmark XD RC1 using Kafka 0.8.2 as transport As a developer, I'd like to rerun baseline , Tuple , and Serialized payloads, so I can compare the differences in performance between 0.8.1 and 0.8.2 Kafka releases. Sinks to be included in test In Memory Transport Hdfs sink Direct Binding Transport Hdfs Sink Kafka Hdfs Sink",NULL,"Benchmark XD RC1 using Kafka 0.8.2 as transport As a developer, I'd like to rerun baseline , Tuple , and Serialized payloads,","so I can compare the differences in performance between 0.8.1 and 0.8.2 Kafka releases. Sinks to be included in test In Memory Transport Hdfs sink Direct Binding Transport Hdfs Sink Kafka Hdfs Sink","Benchmark XD RC1 using Kafka 0<span class='highlight-text severity-high'>.8.2 as transport As a developer, I'd like to rerun baseline , Tuple , and Serialized payloads, so I can compare the differences in performance between 0.8.1 and 0.8.2 Kafka releases. Sinks to be included in test In Memory Transport Hdfs sink Direct Binding Transport Hdfs Sink Kafka Hdfs Sink</span>","minimal","punctuation","high",False
26113,"Benchmark XD RC1 using Kafka 0.8.2 as transport As a developer, I'd like to rerun baseline , Tuple , and Serialized payloads, so I can compare the differences in performance between 0.8.1 and 0.8.2 Kafka releases. Sinks to be included in test In Memory Transport Hdfs sink Direct Binding Transport Hdfs Sink Kafka Hdfs Sink",NULL,"Benchmark XD RC1 using Kafka 0.8.2 as transport As a developer, I'd like to rerun baseline , Tuple , and Serialized payloads,","so I can compare the differences in performance between 0.8.1 and 0.8.2 Kafka releases. Sinks to be included in test In Memory Transport Hdfs sink Direct Binding Transport Hdfs Sink Kafka Hdfs Sink","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26117,"Support XD JMX ENABLED configuration XD EC2 needs to allow user to set the XD JMX ENABLED flag in the environment prior to admin or container startups. ",NULL,"Support XD JMX ENABLED configuration XD EC2 needs to allow user to set the XD JMX ENABLED flag in the environment prior to admin or container startups. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26106,"Add incremental load feature to batch docs The incremental load introduced with XD 2309 should be added to the batch docs",NULL,"Add incremental load feature to batch docs The incremental load introduced with XD 2309 should be added to the batch docs",NULL,"Add for who this story is","well_formed","no_role","high",False
26097,"Add a new source module to capture video frame from camera or video files This is a source module for video ingestion the modules captures video frames from a camera or from a video file. For camera, the frames are grabbed from the rtsp video stream. This module will generate message with the frame image encoded with JPEG as the payload. ",NULL,"Add a new source module to capture video frame from camera or video files This is a source module for video ingestion the modules captures video frames from a camera or from a video file. For camera, the frames are grabbed from the rtsp video stream. This module will generate message with the frame image encoded with JPEG as the payload. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26097,"Add a new source module to capture video frame from camera or video files This is a source module for video ingestion the modules captures video frames from a camera or from a video file. For camera, the frames are grabbed from the rtsp video stream. This module will generate message with the frame image encoded with JPEG as the payload. ",NULL,"Add a new source module to capture video frame from camera or video files This is a source module for video ingestion the modules captures video frames from a camera or from a video file. For camera, the frames are grabbed from the rtsp video stream. This module will generate message with the frame image encoded with JPEG as the payload. ",NULL,"Add a new source module to capture video frame from camera<span class='highlight-text severity-high'> or </span>video files This is a source module for video ingestion the modules captures video frames from a camera or from a video file. For camera, the frames are grabbed from the rtsp video stream. This module will generate message with the frame image encoded with JPEG as the payload. ","atomic","conjunctions","high",False
26097,"Add a new source module to capture video frame from camera or video files This is a source module for video ingestion the modules captures video frames from a camera or from a video file. For camera, the frames are grabbed from the rtsp video stream. This module will generate message with the frame image encoded with JPEG as the payload. ",NULL,"Add a new source module to capture video frame from camera or video files This is a source module for video ingestion the modules captures video frames from a camera or from a video file. For camera, the frames are grabbed from the rtsp video stream. This module will generate message with the frame image encoded with JPEG as the payload. ",NULL,"Add a new source module to capture video frame from camera or video files This is a source module for video ingestion the modules captures video frames from a camera or from a video file<span class='highlight-text severity-high'>. For camera, the frames are grabbed from the rtsp video stream. This module will generate message with the frame image encoded with JPEG as the payload. </span>","minimal","punctuation","high",False
26105,"UI Add Analytics Tab ",NULL,"UI Add Analytics Tab ",NULL,"Add for who this story is","well_formed","no_role","high",False
26115,"Update to Reactor 2.0.3 ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26115,"Update to Reactor 2.0.3 ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26128,"Add Jolokia Agent Depending on Run Mode WAR Vs. JVM Jolokia Agent Jolokia Vs. JVM MBeanServer Probably needs support for Spring Profiles.",NULL,"Add Jolokia Agent Depending on Run Mode WAR Vs. JVM Jolokia Agent Jolokia Vs. JVM MBeanServer Probably needs support for Spring Profiles.",NULL,"Add for who this story is","well_formed","no_role","high",False
26128,"Add Jolokia Agent Depending on Run Mode WAR Vs. JVM Jolokia Agent Jolokia Vs. JVM MBeanServer Probably needs support for Spring Profiles.",NULL,"Add Jolokia Agent Depending on Run Mode WAR Vs. JVM Jolokia Agent Jolokia Vs. JVM MBeanServer Probably needs support for Spring Profiles.",NULL,"Add Jolokia Agent Depending on Run Mode WAR Vs<span class='highlight-text severity-high'>. JVM Jolokia Agent Jolokia Vs. JVM MBeanServer Probably needs support for Spring Profiles.</span>","minimal","punctuation","high",False
26130,"Create a landing section for OOTB batch jobs As a user, I'd like to refer to OOTB batch jobs and the documentation, so I can jump to the right job section and review details. ",NULL,"Create a landing section for OOTB batch jobs As a user, I'd like to refer to OOTB batch jobs and the documentation,","so I can jump to the right job section and review details.","Add for who this story is","well_formed","no_role","high",False
26130,"Create a landing section for OOTB batch jobs As a user, I'd like to refer to OOTB batch jobs and the documentation, so I can jump to the right job section and review details. ",NULL,"Create a landing section for OOTB batch jobs As a user, I'd like to refer to OOTB batch jobs and the documentation,","so I can jump to the right job section and review details.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26134,"Document the new analytics tab features As a user, I'd like to refer to the analytics tab docs, so I can understand how to use various widgets from streaming pipeline. ",NULL,"Document the new analytics tab features As a user, I'd like to refer to the analytics tab docs,","so I can understand how to use various widgets from streaming pipeline.","Add for who this story is","well_formed","no_role","high",False
26134,"Document the new analytics tab features As a user, I'd like to refer to the analytics tab docs, so I can understand how to use various widgets from streaming pipeline. ",NULL,"Document the new analytics tab features As a user, I'd like to refer to the analytics tab docs,","so I can understand how to use various widgets from streaming pipeline.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26131,"Add Spring Integration MBean Exporters to Module Global option? Override for individual modules? module types?",NULL,"Add Spring Integration MBean Exporters to Module Global option? Override for individual modules? module types?",NULL,"Add for who this story is","well_formed","no_role","high",False
26131,"Add Spring Integration MBean Exporters to Module Global option? Override for individual modules? module types?",NULL,"Add Spring Integration MBean Exporters to Module Global option? Override for individual modules? module types?",NULL,"Add Spring Integration MBean Exporters to Module Global option<span class='highlight-text severity-high'>? Override for individual modules? module types?</span>","minimal","punctuation","high",False
26135,"Add ManagedComponent. Metric, Operation etc to Appropriate DIRT Classes Expose runtime stats for core components.",NULL,"Add ManagedComponent. Metric, Operation etc to Appropriate DIRT Classes Expose runtime stats for core components.",NULL,"Add for who this story is","well_formed","no_role","high",False
26135,"Add ManagedComponent. Metric, Operation etc to Appropriate DIRT Classes Expose runtime stats for core components.",NULL,"Add ManagedComponent. Metric, Operation etc to Appropriate DIRT Classes Expose runtime stats for core components.",NULL,"Add ManagedComponent<span class='highlight-text severity-high'>. Metric, Operation etc to Appropriate DIRT Classes Expose runtime stats for core components.</span>","minimal","punctuation","high",False
26133,"Better classloader strategy for XD admin container This is in reference to the investigation done as part of XD 2548",NULL,"Better classloader strategy for XD admin container This is in reference to the investigation done as part of XD 2548",NULL,"Add for who this story is","well_formed","no_role","high",False
26139,"Batch job filepollhdfs docs are outdated The stream definition example uses old style syntax, should be mode ref instead of ref true ",NULL,"Batch job filepollhdfs docs are outdated The stream definition example uses old style syntax, should be mode ref instead of ref true ",NULL,"Add for who this story is","well_formed","no_role","high",False
26136,"Create a landing page with links for all OOTB modules As a user, I'd like to have a landing page with higher order links for sources, processors, sinks and jobs, so I can jump to right section from one place. ",NULL,"Create a landing page with links for all OOTB modules As a user, I'd like to have a landing page with higher order links for","sources, processors, sinks and jobs, so I can jump to right section from one place.","Add for who this story is","well_formed","no_role","high",False
26136,"Create a landing page with links for all OOTB modules As a user, I'd like to have a landing page with higher order links for sources, processors, sinks and jobs, so I can jump to right section from one place. ",NULL,"Create a landing page with links for all OOTB modules As a user, I'd like to have a landing page with higher order links for","sources, processors, sinks and jobs, so I can jump to right section from one place.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26137,"Composing Jobs via the DSL As a developer, I want to be able to construct jobs using a DSL similar to the current syntax for streams. ",NULL,"Composing Jobs via the DSL As a developer, I want to be able to construct jobs using a DSL similar to the current syntax for streams. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26137,"Composing Jobs via the DSL As a developer, I want to be able to construct jobs using a DSL similar to the current syntax for streams. ",NULL,"Composing Jobs via the DSL As a developer, I want to be able to construct jobs using a DSL similar to the current syntax for streams. ",NULL,"Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26140,"Package Shell binary next to xd admin and xd container The shell should be an executable delivered out of the box in much the same way that xd container and xd admin are right now. If we follow how redis mongo distribut the shell, it sits side by side with the other binaries",NULL,"Package Shell binary next to xd admin and xd container The shell should be an executable delivered out of the box in much the same way that xd container and xd admin are right now. If we follow how redis mongo distribut the shell, it sits side by side with the other binaries",NULL,"Add for who this story is","well_formed","no_role","high",False
26140,"Package Shell binary next to xd admin and xd container The shell should be an executable delivered out of the box in much the same way that xd container and xd admin are right now. If we follow how redis mongo distribut the shell, it sits side by side with the other binaries",NULL,"Package Shell binary next to xd admin and xd container The shell should be an executable delivered out of the box in much the same way that xd container and xd admin are right now. If we follow how redis mongo distribut the shell, it sits side by side with the other binaries",NULL,"Package Shell binary next to xd admin<span class='highlight-text severity-high'> and </span>xd container The shell should be an executable delivered out of the box in much the same way that xd container and xd admin are right now. If we follow how redis mongo distribut the shell, it sits side by side with the other binaries","atomic","conjunctions","high",False
26140,"Package Shell binary next to xd admin and xd container The shell should be an executable delivered out of the box in much the same way that xd container and xd admin are right now. If we follow how redis mongo distribut the shell, it sits side by side with the other binaries",NULL,"Package Shell binary next to xd admin and xd container The shell should be an executable delivered out of the box in much the same way that xd container and xd admin are right now. If we follow how redis mongo distribut the shell, it sits side by side with the other binaries",NULL,"Package Shell binary next to xd admin and xd container The shell should be an executable delivered out of the box in much the same way that xd container and xd admin are right now<span class='highlight-text severity-high'>. If we follow how redis mongo distribut the shell, it sits side by side with the other binaries</span>","minimal","punctuation","high",False
26141,"Update Modules Build and Package sections Some info is obsolete and add more content re. dependency management",NULL,"Update Modules Build and Package sections Some info is obsolete and add more content re. dependency management",NULL,"Add for who this story is","well_formed","no_role","high",False
26141,"Update Modules Build and Package sections Some info is obsolete and add more content re. dependency management",NULL,"Update Modules Build and Package sections Some info is obsolete and add more content re. dependency management",NULL,"Update Modules Build<span class='highlight-text severity-high'> and </span>Package sections Some info is obsolete and add more content re. dependency management","atomic","conjunctions","high",False
26141,"Update Modules Build and Package sections Some info is obsolete and add more content re. dependency management",NULL,"Update Modules Build and Package sections Some info is obsolete and add more content re. dependency management",NULL,"Update Modules Build and Package sections Some info is obsolete and add more content re<span class='highlight-text severity-high'>. dependency management</span>","minimal","punctuation","high",False
26143,"Update to Spring Integration Kafka 1.2.0 GA As a developer, I'd like to update to SI Kafka extension 1.2.0, so I can leverage the latest performance improvements.",NULL,"Update to Spring Integration Kafka 1.2.0 GA As a developer, I'd like to update to SI Kafka extension 1.2.0,","so I can leverage the latest performance improvements.","Add for who this story is","well_formed","no_role","high",False
26143,"Update to Spring Integration Kafka 1.2.0 GA As a developer, I'd like to update to SI Kafka extension 1.2.0, so I can leverage the latest performance improvements.",NULL,"Update to Spring Integration Kafka 1.2.0 GA As a developer, I'd like to update to SI Kafka extension 1.2.0,","so I can leverage the latest performance improvements.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26142,"Update to Spring Integration 4.1.5 As a developer, I'd like to update to the 4.1.5 SI release, so I can pickup the latest improvements to message channels.",NULL,"Update to Spring Integration 4.1.5 As a developer, I'd like to update to the 4.1.5 SI release,","so I can pickup the latest improvements to message channels.","Add for who this story is","well_formed","no_role","high",False
26142,"Update to Spring Integration 4.1.5 As a developer, I'd like to update to the 4.1.5 SI release, so I can pickup the latest improvements to message channels.",NULL,"Update to Spring Integration 4.1.5 As a developer, I'd like to update to the 4.1.5 SI release,","so I can pickup the latest improvements to message channels.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26145,"How to get in the module s container ID, and module id As a developer, I in the new development of component how to get the module id and container id Because components need to generate log, log information must include the unique identifier xd runtime modules ",NULL,"How to get in the module s container ID, and module id As a developer, I in the new development of component how to get the module id and container id Because components need to generate log, log information must include the unique identifier xd runtime modules ",NULL,"Add for who this story is","well_formed","no_role","high",False
26145,"How to get in the module s container ID, and module id As a developer, I in the new development of component how to get the module id and container id Because components need to generate log, log information must include the unique identifier xd runtime modules ",NULL,"How to get in the module s container ID, and module id As a developer, I in the new development of component how to get the module id and container id Because components need to generate log, log information must include the unique identifier xd runtime modules ",NULL,"How to get in the module s container ID,<span class='highlight-text severity-high'> and </span>module id As a developer, I in the new development of component how to get the module id and container id Because components need to generate log, log information must include the unique identifier xd runtime modules ","atomic","conjunctions","high",False
26144,"Update to Spring Hadoop 2.2.0 GA As a developer, I'd like to update to Spring Hadoop 2.2.0 GA release, so I can leverage the latest improvements. ",NULL,"Update to Spring Hadoop 2.2.0 GA As a developer, I'd like to update to Spring Hadoop 2.2.0 GA release,","so I can leverage the latest improvements.","Add for who this story is","well_formed","no_role","high",False
26144,"Update to Spring Hadoop 2.2.0 GA As a developer, I'd like to update to Spring Hadoop 2.2.0 GA release, so I can leverage the latest improvements. ",NULL,"Update to Spring Hadoop 2.2.0 GA As a developer, I'd like to update to Spring Hadoop 2.2.0 GA release,","so I can leverage the latest improvements.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26132,"Upgrade to 3.1.1 of the Gradle Artifactory Plugin This addresses The plugin issue to disable spring xd pom.xml",NULL,"Upgrade to 3.1.1 of the Gradle Artifactory Plugin This addresses The plugin issue to disable spring xd pom.xml",NULL,"Add for who this story is","well_formed","no_role","high",False
26127,"Update RPM script to include number of containers to be started As a user, I'd like to start multiple instances of s through the RPM scripts, so I can easily spin up instances on the same node vm.",NULL,"Update RPM script to include number of containers to be started As a user, I'd like to start multiple instances of s through the RPM scripts,","so I can easily spin up instances on the same node vm.","Add for who this story is","well_formed","no_role","high",False
26127,"Update RPM script to include number of containers to be started As a user, I'd like to start multiple instances of s through the RPM scripts, so I can easily spin up instances on the same node vm.",NULL,"Update RPM script to include number of containers to be started As a user, I'd like to start multiple instances of s through the RPM scripts,","so I can easily spin up instances on the same node vm.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26138,"Remove in the lib cdh5 directory we need to remove that from the dist",NULL,"Remove in the lib cdh5 directory we need to remove that from the dist",NULL,"Add for who this story is","well_formed","no_role","high",False
26147,"Reorganize OOTB module list in docs Sort alphabetically, nest Available modules section appropriately. Optionally, move to a whole different PART in reference doc",NULL,"Reorganize OOTB module list in docs Sort alphabetically, nest Available modules section appropriately. Optionally, move to a whole different PART in reference doc",NULL,"Add for who this story is","well_formed","no_role","high",False
26147,"Reorganize OOTB module list in docs Sort alphabetically, nest Available modules section appropriately. Optionally, move to a whole different PART in reference doc",NULL,"Reorganize OOTB module list in docs Sort alphabetically, nest Available modules section appropriately. Optionally, move to a whole different PART in reference doc",NULL,"Reorganize OOTB module list in docs Sort alphabetically, nest Available modules section appropriately<span class='highlight-text severity-high'>. Optionally, move to a whole different PART in reference doc</span>","minimal","punctuation","high",False
26148,"Add CI Acceptance Test for 1.2.x Need acceptance tests to run on the 1.2.X branch. Needs to be setup as a child of the Publish 1.2.x",NULL,"Add CI Acceptance Test for 1.2.x Need acceptance tests to run on the 1.2.X branch. Needs to be setup as a child of the Publish 1.2.x",NULL,"Add for who this story is","well_formed","no_role","high",False
26148,"Add CI Acceptance Test for 1.2.x Need acceptance tests to run on the 1.2.X branch. Needs to be setup as a child of the Publish 1.2.x",NULL,"Add CI Acceptance Test for 1.2.x Need acceptance tests to run on the 1.2.X branch. Needs to be setup as a child of the Publish 1.2.x",NULL,"Add CI Acceptance Test for 1<span class='highlight-text severity-high'>.2.x Need acceptance tests to run on the 1.2.X branch. Needs to be setup as a child of the Publish 1.2.x</span>","minimal","punctuation","high",False
26151,"Synchronize XD and XD Ambari RPMs into a single repo As a PM, I'd like to have XD and XD Ambari RPM scripts into a single public repo, so that users can go to a single location to use the respective build scripts.",NULL,"Synchronize XD and XD Ambari RPMs into a single repo As a PM, I'd like to have XD and XD Ambari RPM scripts into a single public repo,","so that users can go to a single location to use the respective build scripts.","Add for who this story is","well_formed","no_role","high",False
26151,"Synchronize XD and XD Ambari RPMs into a single repo As a PM, I'd like to have XD and XD Ambari RPM scripts into a single public repo, so that users can go to a single location to use the respective build scripts.",NULL,"Synchronize XD and XD Ambari RPMs into a single repo As a PM, I'd like to have XD and XD Ambari RPM scripts into a single public repo,","so that users can go to a single location to use the respective build scripts.","Synchronize XD<span class='highlight-text severity-high'> and </span>XD Ambari RPMs into a single repo As a PM, I'd like to have XD and XD Ambari RPM scripts into a single public repo, so that users can go to a single location to use the respective build scripts.","atomic","conjunctions","high",False
26151,"Synchronize XD and XD Ambari RPMs into a single repo As a PM, I'd like to have XD and XD Ambari RPM scripts into a single public repo, so that users can go to a single location to use the respective build scripts.",NULL,"Synchronize XD and XD Ambari RPMs into a single repo As a PM, I'd like to have XD and XD Ambari RPM scripts into a single public repo,","so that users can go to a single location to use the respective build scripts.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26150,"Kafka bus defaults configurable at producer consumer level As a developer, I want to be able to override Kafka bus defaults for module consumers and producers, so that I can finely tune performance and behaviour. Such properties should include for consumers for producers",NULL,"Kafka bus defaults configurable at producer consumer level As a developer, I want to be able to override Kafka bus defaults for module consumers and producers,","so that I can finely tune performance and behaviour. Such properties should include for consumers for producers","Add for who this story is","well_formed","no_role","high",False
26150,"Kafka bus defaults configurable at producer consumer level As a developer, I want to be able to override Kafka bus defaults for module consumers and producers, so that I can finely tune performance and behaviour. Such properties should include for consumers for producers",NULL,"Kafka bus defaults configurable at producer consumer level As a developer, I want to be able to override Kafka bus defaults for module consumers and producers,","so that I can finely tune performance and behaviour. Such properties should include for consumers for producers","Kafka bus defaults configurable at producer consumer level As a developer, I want to be able to override Kafka bus defaults for module consumers and producers, so that I can finely tune performance and behaviour<span class='highlight-text severity-high'>. Such properties should include for consumers for producers</span>","minimal","punctuation","high",False
26150,"Kafka bus defaults configurable at producer consumer level As a developer, I want to be able to override Kafka bus defaults for module consumers and producers, so that I can finely tune performance and behaviour. Such properties should include for consumers for producers",NULL,"Kafka bus defaults configurable at producer consumer level As a developer, I want to be able to override Kafka bus defaults for module consumers and producers,","so that I can finely tune performance and behaviour. Such properties should include for consumers for producers","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26152,"Publish performance benchmarks As a developer, I'd like to publish performance benchmarks along with the infrastructure specifics, so the users can use it as a reference while setting up Spring XD cluster. ",NULL,"Publish performance benchmarks As a developer, I'd like to publish performance benchmarks along with the infrastructure specifics,","so the users can use it as a reference while setting up Spring XD cluster.","Add for who this story is","well_formed","no_role","high",False
26152,"Publish performance benchmarks As a developer, I'd like to publish performance benchmarks along with the infrastructure specifics, so the users can use it as a reference while setting up Spring XD cluster. ",NULL,"Publish performance benchmarks As a developer, I'd like to publish performance benchmarks along with the infrastructure specifics,","so the users can use it as a reference while setting up Spring XD cluster.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26153,"Add Documentation Chapter on Executing Batch Jobs Add Documentation Chapter on Executing Batch Jobs ",NULL,"Add Documentation Chapter on Executing Batch Jobs Add Documentation Chapter on Executing Batch Jobs ",NULL,"Add for who this story is","well_formed","no_role","high",False
26154,"Update Spark streaming documentation As a user I need to know the Spark streaming features like adding tap at the spark module output and the examples need to be updated. The documentation also needs some more information on Reliable receiver.",NULL,"Update Spark streaming documentation As a user I need to know the Spark streaming features like adding tap at the spark module output and the examples need to be updated. The documentation also needs some more information on Reliable receiver.",NULL,"Add for who this story is","well_formed","no_role","high",False
26154,"Update Spark streaming documentation As a user I need to know the Spark streaming features like adding tap at the spark module output and the examples need to be updated. The documentation also needs some more information on Reliable receiver.",NULL,"Update Spark streaming documentation As a user I need to know the Spark streaming features like adding tap at the spark module output and the examples need to be updated. The documentation also needs some more information on Reliable receiver.",NULL,"Update Spark streaming documentation As a user I need to know the Spark streaming features like adding tap at the spark module output<span class='highlight-text severity-high'> and </span>the examples need to be updated. The documentation also needs some more information on Reliable receiver.","atomic","conjunctions","high",False
26154,"Update Spark streaming documentation As a user I need to know the Spark streaming features like adding tap at the spark module output and the examples need to be updated. The documentation also needs some more information on Reliable receiver.",NULL,"Update Spark streaming documentation As a user I need to know the Spark streaming features like adding tap at the spark module output and the examples need to be updated. The documentation also needs some more information on Reliable receiver.",NULL,"Update Spark streaming documentation As a user I need to know the Spark streaming features like adding tap at the spark module output and the examples need to be updated<span class='highlight-text severity-high'>. The documentation also needs some more information on Reliable receiver.</span>","minimal","punctuation","high",False
26155,"Provide a source option to enable the SOF EOF markers when splitting a file into lines Depends on INT 3727",NULL,"Provide a source option to enable the SOF EOF markers when splitting a file into lines Depends on INT 3727",NULL,"Add for who this story is","well_formed","no_role","high",False
26158,"Spring xd, to configure the stream drag and graphic spring xd Can drag way to configure flow in the form of figure? Similar to configure a workflow graphical interface Looking forward to reply",NULL,"Spring xd, to configure the stream drag and graphic spring xd Can drag way to configure flow in the form of figure? Similar to configure a workflow graphical interface Looking forward to reply",NULL,"Add for who this story is","well_formed","no_role","high",False
26158,"Spring xd, to configure the stream drag and graphic spring xd Can drag way to configure flow in the form of figure? Similar to configure a workflow graphical interface Looking forward to reply",NULL,"Spring xd, to configure the stream drag and graphic spring xd Can drag way to configure flow in the form of figure? Similar to configure a workflow graphical interface Looking forward to reply",NULL,"Spring xd, to configure the stream drag<span class='highlight-text severity-high'> and </span>graphic spring xd Can drag way to configure flow in the form of figure? Similar to configure a workflow graphical interface Looking forward to reply","atomic","conjunctions","high",False
26158,"Spring xd, to configure the stream drag and graphic spring xd Can drag way to configure flow in the form of figure? Similar to configure a workflow graphical interface Looking forward to reply",NULL,"Spring xd, to configure the stream drag and graphic spring xd Can drag way to configure flow in the form of figure? Similar to configure a workflow graphical interface Looking forward to reply",NULL,"Spring xd, to configure the stream drag and graphic spring xd Can drag way to configure flow in the form of figure<span class='highlight-text severity-high'>? Similar to configure a workflow graphical interface Looking forward to reply</span>","minimal","punctuation","high",False
26159,"Upgrade to Spring Boot 1.2.5 Spring Boot 1.2.4 and earlier does not allow for the retrieval of boolean values from the vcap environment. This means that when XD Admin tries to retrieve the value of for example it will fail, as that value returns a boolean. Spring Boot 1.2.5 as yet unreleased contains a fix for this issue ",NULL,"Upgrade to Spring Boot 1.2.5 Spring Boot 1.2.4 and earlier does not allow for the retrieval of boolean values from the vcap environment. This means that when XD Admin tries to retrieve the value of for example it will fail, as that value returns a boolean. Spring Boot 1.2.5 as yet unreleased contains a fix for this issue ",NULL,"Add for who this story is","well_formed","no_role","high",False
26159,"Upgrade to Spring Boot 1.2.5 Spring Boot 1.2.4 and earlier does not allow for the retrieval of boolean values from the vcap environment. This means that when XD Admin tries to retrieve the value of for example it will fail, as that value returns a boolean. Spring Boot 1.2.5 as yet unreleased contains a fix for this issue ",NULL,"Upgrade to Spring Boot 1.2.5 Spring Boot 1.2.4 and earlier does not allow for the retrieval of boolean values from the vcap environment. This means that when XD Admin tries to retrieve the value of for example it will fail, as that value returns a boolean. Spring Boot 1.2.5 as yet unreleased contains a fix for this issue ",NULL,"Upgrade to Spring Boot 1.2.5 Spring Boot 1.2.4<span class='highlight-text severity-high'> and </span>earlier does not allow for the retrieval of boolean values from the vcap environment. This means that when XD Admin tries to retrieve the value of for example it will fail, as that value returns a boolean. Spring Boot 1.2.5 as yet unreleased contains a fix for this issue ","atomic","conjunctions","high",False
26159,"Upgrade to Spring Boot 1.2.5 Spring Boot 1.2.4 and earlier does not allow for the retrieval of boolean values from the vcap environment. This means that when XD Admin tries to retrieve the value of for example it will fail, as that value returns a boolean. Spring Boot 1.2.5 as yet unreleased contains a fix for this issue ",NULL,"Upgrade to Spring Boot 1.2.5 Spring Boot 1.2.4 and earlier does not allow for the retrieval of boolean values from the vcap environment. This means that when XD Admin tries to retrieve the value of for example it will fail, as that value returns a boolean. Spring Boot 1.2.5 as yet unreleased contains a fix for this issue ",NULL,"Upgrade to Spring Boot 1<span class='highlight-text severity-high'>.2.5 Spring Boot 1.2.4 and earlier does not allow for the retrieval of boolean values from the vcap environment. This means that when XD Admin tries to retrieve the value of for example it will fail, as that value returns a boolean. Spring Boot 1.2.5 as yet unreleased contains a fix for this issue </span>","minimal","punctuation","high",False
26160,"Update spring xd yarn servers.yml with settings for HDP 2.2.6.0 We need to add the settings needed to run XD on YARN when using Hortonworks HDP 2.2.6.0 which is the version you now get when installing with Ambari.",NULL,"Update spring xd yarn servers.yml with settings for HDP 2.2.6.0 We need to add the settings needed to run XD on YARN when using Hortonworks HDP 2.2.6.0 which is the version you now get when installing with Ambari.",NULL,"Add for who this story is","well_formed","no_role","high",False
26161,"Testers need ability to wait for a file to be created in XD directory User s need ability to wait for user specified time in millis for a file to be created in the XD directory. If file is not created in allotted time then return false else return true. Also check to see if a file exists in the XD directory. ",NULL,"Testers need ability to wait for a file to be created in XD directory User s need ability to wait for user specified time in millis for a file to be created in the XD directory. If file is not created in allotted time then return false else return true. Also check to see if a file exists in the XD directory. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26161,"Testers need ability to wait for a file to be created in XD directory User s need ability to wait for user specified time in millis for a file to be created in the XD directory. If file is not created in allotted time then return false else return true. Also check to see if a file exists in the XD directory. ",NULL,"Testers need ability to wait for a file to be created in XD directory User s need ability to wait for user specified time in millis for a file to be created in the XD directory. If file is not created in allotted time then return false else return true. Also check to see if a file exists in the XD directory. ",NULL,"Testers need ability to wait for a file to be created in XD directory User s need ability to wait for user specified time in millis for a file to be created in the XD directory<span class='highlight-text severity-high'>. If file is not created in allotted time then return false else return true. Also check to see if a file exists in the XD directory. </span>","minimal","punctuation","high",False
26162,"Add command for deleting a tap ",NULL,"Add command for deleting a tap ",NULL,"Add for who this story is","well_formed","no_role","high",False
26149,"Update Master Environment for 2.0 CI Acceptance Tests ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26149,"Update Master Environment for 2.0 CI Acceptance Tests ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26157,"Create Splunk sink module This would be based off the splunk project. The use of this adapter for storing tweet data is in We should be able to reproduce the use case as done in that demo",NULL,"Create Splunk sink module This would be based off the splunk project. The use of this adapter for storing tweet data is in We should be able to reproduce the use case as done in that demo",NULL,"Add for who this story is","well_formed","no_role","high",False
26157,"Create Splunk sink module This would be based off the splunk project. The use of this adapter for storing tweet data is in We should be able to reproduce the use case as done in that demo",NULL,"Create Splunk sink module This would be based off the splunk project. The use of this adapter for storing tweet data is in We should be able to reproduce the use case as done in that demo",NULL,"Create Splunk sink module This would be based off the splunk project<span class='highlight-text severity-high'>. The use of this adapter for storing tweet data is in We should be able to reproduce the use case as done in that demo</span>","minimal","punctuation","high",False
26156,"Make RabbitMessageBus RabbitMQ Config Properties Optional When the bus is used outside of the XD container e.g. spring bus , the inheritance from Spring Boot configuration is broken no application.yml or servers.yml on the cp . Make the bus properties optional Add ",NULL,"Make RabbitMessageBus RabbitMQ Config Properties Optional When the bus is used outside of the XD container e.g. spring bus , the inheritance from Spring Boot configuration is broken no application.yml or servers.yml on the cp . Make the bus properties optional Add ",NULL,"Add for who this story is","well_formed","no_role","high",False
26156,"Make RabbitMessageBus RabbitMQ Config Properties Optional When the bus is used outside of the XD container e.g. spring bus , the inheritance from Spring Boot configuration is broken no application.yml or servers.yml on the cp . Make the bus properties optional Add ",NULL,"Make RabbitMessageBus RabbitMQ Config Properties Optional When the bus is used outside of the XD container e.g. spring bus , the inheritance from Spring Boot configuration is broken no application.yml or servers.yml on the cp . Make the bus properties optional Add ",NULL,"Make RabbitMessageBus RabbitMQ Config Properties Optional When the bus is used outside of the XD container e<span class='highlight-text severity-high'>.g. spring bus , the inheritance from Spring Boot configuration is broken no application.yml or servers.yml on the cp . Make the bus properties optional Add </span>","minimal","punctuation","high",False
26166,"Move MASTER branch CI builds to EC2 based infrastructure As a developer, I'd like to migrate the current MASTER branch CI builds to EC2 instances, so I can manage them all in one place reliably.",NULL,"Move MASTER branch CI builds to EC2 based infrastructure As a developer, I'd like to migrate the current MASTER branch CI builds to EC2 instances,","so I can manage them all in one place reliably.","Add for who this story is","well_formed","no_role","high",False
26166,"Move MASTER branch CI builds to EC2 based infrastructure As a developer, I'd like to migrate the current MASTER branch CI builds to EC2 instances, so I can manage them all in one place reliably.",NULL,"Move MASTER branch CI builds to EC2 based infrastructure As a developer, I'd like to migrate the current MASTER branch CI builds to EC2 instances,","so I can manage them all in one place reliably.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26164,"Spike Investigate bootification of module options As a developer, I'd like to handle module options via pure boot property source management, so I can leverage Boot s module METADATA option to inject module options as opposed to maintaining them in core Spring XD runtime CP. ",NULL,"Spike Investigate bootification of module options As a developer, I'd like to handle module options via pure boot property","source management, so I can leverage Boot s module METADATA option to inject module options as opposed to maintaining them in core Spring XD runtime CP.","Add for who this story is","well_formed","no_role","high",False
26164,"Spike Investigate bootification of module options As a developer, I'd like to handle module options via pure boot property source management, so I can leverage Boot s module METADATA option to inject module options as opposed to maintaining them in core Spring XD runtime CP. ",NULL,"Spike Investigate bootification of module options As a developer, I'd like to handle module options via pure boot property","source management, so I can leverage Boot s module METADATA option to inject module options as opposed to maintaining them in core Spring XD runtime CP.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26171,"Investigate the steps to Ambari upgrade Spring XD As a user, I'd like to upgrade Spring XD from 1.2 RC to 1.2 GA using the Ambari plugin, so I can work on the latest release bits. I'd like to refer to the documentation to do so.",NULL,"Investigate the steps to Ambari upgrade Spring XD As a user, I'd like to upgrade Spring XD from 1.2 RC to 1.2 GA using the Ambari plugin,","so I can work on the latest release bits. I'd like to refer to the documentation to do so.","Add for who this story is","well_formed","no_role","high",False
26171,"Investigate the steps to Ambari upgrade Spring XD As a user, I'd like to upgrade Spring XD from 1.2 RC to 1.2 GA using the Ambari plugin, so I can work on the latest release bits. I'd like to refer to the documentation to do so.",NULL,"Investigate the steps to Ambari upgrade Spring XD As a user, I'd like to upgrade Spring XD from 1.2 RC to 1.2 GA using the Ambari plugin,","so I can work on the latest release bits. I'd like to refer to the documentation to do so.","Investigate the steps to Ambari upgrade Spring XD As a user, I'd like to upgrade Spring XD from 1<span class='highlight-text severity-high'>.2 RC to 1.2 GA using the Ambari plugin, so I can work on the latest release bits. I'd like to refer to the documentation to do so.</span>","minimal","punctuation","high",False
26171,"Investigate the steps to Ambari upgrade Spring XD As a user, I'd like to upgrade Spring XD from 1.2 RC to 1.2 GA using the Ambari plugin, so I can work on the latest release bits. I'd like to refer to the documentation to do so.",NULL,"Investigate the steps to Ambari upgrade Spring XD As a user, I'd like to upgrade Spring XD from 1.2 RC to 1.2 GA using the Ambari plugin,","so I can work on the latest release bits. I'd like to refer to the documentation to do so.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26165,"Spike Investigate and the XD fit As a developer, I'd like to have a central place to manage external properties for applications across all the environments, so I can provide server and client side support for externalized configuration for XD Admin and XD Container servers. ",NULL,"Spike Investigate and the XD fit As a developer, I'd like to have a central place to manage external properties for applications across all the environments,","so I can provide server and client side support for externalized configuration for XD Admin and XD Container servers.","Add for who this story is","well_formed","no_role","high",False
26165,"Spike Investigate and the XD fit As a developer, I'd like to have a central place to manage external properties for applications across all the environments, so I can provide server and client side support for externalized configuration for XD Admin and XD Container servers. ",NULL,"Spike Investigate and the XD fit As a developer, I'd like to have a central place to manage external properties for applications across all the environments,","so I can provide server and client side support for externalized configuration for XD Admin and XD Container servers.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26167,"Spike Investigate the use of config server for modules As a developer, I'd like to use server for spring bus modules, so I can centrally manage external properties.",NULL,"Spike Investigate the use of config server for modules As a developer, I'd like to use server for spring bus modules,","so I can centrally manage external properties.","Add for who this story is","well_formed","no_role","high",False
26167,"Spike Investigate the use of config server for modules As a developer, I'd like to use server for spring bus modules, so I can centrally manage external properties.",NULL,"Spike Investigate the use of config server for modules As a developer, I'd like to use server for spring bus modules,","so I can centrally manage external properties.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26168,"Support for GET of taps ",NULL,"Support for GET of taps ",NULL,"Add for who this story is","well_formed","no_role","high",False
26169,"Investigate performance of channel metrics in SI 4.2 As a developer, I'd like to investigate channel performance issues in SI 4.2, so I can determine the bottlenecks and take corrective actions to improve overall channel performance. ",NULL,"Investigate performance of channel metrics in SI 4.2 As a developer, I'd like to investigate channel performance issues in SI 4.2,","so I can determine the bottlenecks and take corrective actions to improve overall channel performance.","Add for who this story is","well_formed","no_role","high",False
26169,"Investigate performance of channel metrics in SI 4.2 As a developer, I'd like to investigate channel performance issues in SI 4.2, so I can determine the bottlenecks and take corrective actions to improve overall channel performance. ",NULL,"Investigate performance of channel metrics in SI 4.2 As a developer, I'd like to investigate channel performance issues in SI 4.2,","so I can determine the bottlenecks and take corrective actions to improve overall channel performance.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26173,"Support for DELETE of taps ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26173,"Support for DELETE of taps ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26175,"Move input output type conversion from XD to As a developer, I'd like to move input output type conversion from Spring XD repo to so I can implement a custom module which produces or consumes a custom domain object.",NULL,"Move input output type conversion from XD to As a developer, I'd like to move input output type conversion from Spring XD repo to","so I can implement a custom module which produces or consumes a custom domain object.","Add for who this story is","well_formed","no_role","high",False
26175,"Move input output type conversion from XD to As a developer, I'd like to move input output type conversion from Spring XD repo to so I can implement a custom module which produces or consumes a custom domain object.",NULL,"Move input output type conversion from XD to As a developer, I'd like to move input output type conversion from Spring XD repo to","so I can implement a custom module which produces or consumes a custom domain object.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26170,"Review spring bus design specs As a spring bus lead, I'd like to review the current spring bus architecture and the design specs, so I can address any foundation level gaps.",NULL,"Review spring bus design specs As a spring bus lead, I'd like to review the current spring bus architecture and the design specs,","so I can address any foundation level gaps.","Add for who this story is","well_formed","no_role","high",False
26170,"Review spring bus design specs As a spring bus lead, I'd like to review the current spring bus architecture and the design specs, so I can address any foundation level gaps.",NULL,"Review spring bus design specs As a spring bus lead, I'd like to review the current spring bus architecture and the design specs,","so I can address any foundation level gaps.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26176,"Move serialization codec from XD to As a developer, I'd like to move serialization codec from Spring XD repo into spring bus, so I can update Spring XD to inherit the via maven dependency.",NULL,"Move serialization codec from XD to As a developer, I'd like to move serialization codec from Spring XD repo into spring bus,","so I can update Spring XD to inherit the via maven dependency.","Add for who this story is","well_formed","no_role","high",False
26176,"Move serialization codec from XD to As a developer, I'd like to move serialization codec from Spring XD repo into spring bus, so I can update Spring XD to inherit the via maven dependency.",NULL,"Move serialization codec from XD to As a developer, I'd like to move serialization codec from Spring XD repo into spring bus,","so I can update Spring XD to inherit the via maven dependency.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26174,"Move message bus implemenation from XD to As a developer, I'd like to move message bus from Spring XD repo into spring bus, so I can update Spring XD to inherit the via maven dependency. ",NULL,"Move message bus implemenation from XD to As a developer, I'd like to move message bus from Spring XD repo into spring bus,","so I can update Spring XD to inherit the via maven dependency.","Add for who this story is","well_formed","no_role","high",False
26174,"Move message bus implemenation from XD to As a developer, I'd like to move message bus from Spring XD repo into spring bus, so I can update Spring XD to inherit the via maven dependency. ",NULL,"Move message bus implemenation from XD to As a developer, I'd like to move message bus from Spring XD repo into spring bus,","so I can update Spring XD to inherit the via maven dependency.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26179,"Spike XD Admin SPI to discover s c s modules As a s c s user, I'd like to investigate the possibility of s c s modules self registering themselves to service discovery, so I could use Spring XD runtime running on CF to discover and orchestrate such modules through streams.",NULL,"Spike XD Admin SPI to discover s c s modules As a s c s user, I'd like to investigate the possibility of s c s modules self registering themselves to service discovery,","so I could use Spring XD runtime running on CF to discover and orchestrate such modules through streams.","Add for who this story is","well_formed","no_role","high",False
26179,"Spike XD Admin SPI to discover s c s modules As a s c s user, I'd like to investigate the possibility of s c s modules self registering themselves to service discovery, so I could use Spring XD runtime running on CF to discover and orchestrate such modules through streams.",NULL,"Spike XD Admin SPI to discover s c s modules As a s c s user, I'd like to investigate the possibility of s c s modules self registering themselves to service discovery,","so I could use Spring XD runtime running on CF to discover and orchestrate such modules through streams.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26178,"Spike Kickoff distributed Receptor implementation of Admin SPI As a Spring XD user, I'd like to use Diego based Receptor implementation of XD Admin SPI based on ModuleLauncher , so I can run data pipeline use cases running on CF Lattice Diego. ",NULL,"Spike Kickoff distributed Receptor implementation of Admin SPI As a Spring XD user, I'd like to use Diego based Receptor implementation of XD Admin SPI based on ModuleLauncher ,","so I can run data pipeline use cases running on CF Lattice Diego.","Add for who this story is","well_formed","no_role","high",False
26178,"Spike Kickoff distributed Receptor implementation of Admin SPI As a Spring XD user, I'd like to use Diego based Receptor implementation of XD Admin SPI based on ModuleLauncher , so I can run data pipeline use cases running on CF Lattice Diego. ",NULL,"Spike Kickoff distributed Receptor implementation of Admin SPI As a Spring XD user, I'd like to use Diego based Receptor implementation of XD Admin SPI based on ModuleLauncher ,","so I can run data pipeline use cases running on CF Lattice Diego.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26172,"Add create and deploy to TapsController POST?",NULL,"Add create and deploy to TapsController POST?",NULL,"Add for who this story is","well_formed","no_role","high",False
26172,"Add create and deploy to TapsController POST?",NULL,"Add create and deploy to TapsController POST?",NULL,"Add create<span class='highlight-text severity-high'> and </span>deploy to TapsController POST?","atomic","conjunctions","high",False
26163,"Spike Investigate Boot export metrics and the XD fit As a user, I'd like to have the module app specific metrics consumed directly from Boot actuator export API, so I can have insight on how it is performing, being used and that it works etc. ",NULL,"Spike Investigate Boot export metrics and the XD fit As a user, I'd like to have the module app specific metrics consumed directly from Boot actuator export API,","so I can have insight on how it is performing, being used and that it works etc.","Add for who this story is","well_formed","no_role","high",False
26163,"Spike Investigate Boot export metrics and the XD fit As a user, I'd like to have the module app specific metrics consumed directly from Boot actuator export API, so I can have insight on how it is performing, being used and that it works etc. ",NULL,"Spike Investigate Boot export metrics and the XD fit As a user, I'd like to have the module app specific metrics consumed directly from Boot actuator export API,","so I can have insight on how it is performing, being used and that it works etc.","Spike Investigate Boot export metrics<span class='highlight-text severity-high'> and </span>the XD fit As a user, I'd like to have the module app specific metrics consumed directly from Boot actuator export API, so I can have insight on how it is performing, being used and that it works etc. ","atomic","conjunctions","high",False
26163,"Spike Investigate Boot export metrics and the XD fit As a user, I'd like to have the module app specific metrics consumed directly from Boot actuator export API, so I can have insight on how it is performing, being used and that it works etc. ",NULL,"Spike Investigate Boot export metrics and the XD fit As a user, I'd like to have the module app specific metrics consumed directly from Boot actuator export API,","so I can have insight on how it is performing, being used and that it works etc.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26184,"Enable component model for As a developer, I'd like to create an annotation , the application would be responsible for creating the actual channel beans and channel adapters vs. the developer creating concrete channel instance types. The annotations will be used to indicate the input and output channels of the module. ",NULL,"Enable component model for As a developer, I'd like to create an annotation , the application would be responsible for creating the actual channel beans and channel adapters vs. the developer creating concrete channel instance types. The annotations will be used to indicate the input and output channels of the module. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26184,"Enable component model for As a developer, I'd like to create an annotation , the application would be responsible for creating the actual channel beans and channel adapters vs. the developer creating concrete channel instance types. The annotations will be used to indicate the input and output channels of the module. ",NULL,"Enable component model for As a developer, I'd like to create an annotation , the application would be responsible for creating the actual channel beans and channel adapters vs. the developer creating concrete channel instance types. The annotations will be used to indicate the input and output channels of the module. ",NULL,"Enable component model for As a developer, I'd like to create an annotation , the application would be responsible for creating the actual channel beans<span class='highlight-text severity-high'> and </span>channel adapters vs. the developer creating concrete channel instance types. The annotations will be used to indicate the input and output channels of the module. ","atomic","conjunctions","high",False
26184,"Enable component model for As a developer, I'd like to create an annotation , the application would be responsible for creating the actual channel beans and channel adapters vs. the developer creating concrete channel instance types. The annotations will be used to indicate the input and output channels of the module. ",NULL,"Enable component model for As a developer, I'd like to create an annotation , the application would be responsible for creating the actual channel beans and channel adapters vs. the developer creating concrete channel instance types. The annotations will be used to indicate the input and output channels of the module. ",NULL,"Enable component model for As a developer, I'd like to create an annotation , the application would be responsible for creating the actual channel beans and channel adapters vs<span class='highlight-text severity-high'>. the developer creating concrete channel instance types. The annotations will be used to indicate the input and output channels of the module. </span>","minimal","punctuation","high",False
26186,"Complete remaining Kryo optimization changes As a developer, I'd like to complete the remaining Kryo optimization changes, so I can polish and get the guidelines documented appropriately. ",NULL,"Complete remaining Kryo optimization changes As a developer, I'd like to complete the remaining Kryo optimization changes,","so I can polish and get the guidelines documented appropriately.","Add for who this story is","well_formed","no_role","high",False
26186,"Complete remaining Kryo optimization changes As a developer, I'd like to complete the remaining Kryo optimization changes, so I can polish and get the guidelines documented appropriately. ",NULL,"Complete remaining Kryo optimization changes As a developer, I'd like to complete the remaining Kryo optimization changes,","so I can polish and get the guidelines documented appropriately.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26187,"Move 1.2.x branch to EC2 CI infrastructure As a developer, I'd like to move 1.2.x branch to EC2 infrastructure, so I can reliably run CI test suites.",NULL,"Move 1.2.x branch to EC2 CI infrastructure As a developer, I'd like to move 1.2.x branch to EC2 infrastructure,","so I can reliably run CI test suites.","Add for who this story is","well_formed","no_role","high",False
26187,"Move 1.2.x branch to EC2 CI infrastructure As a developer, I'd like to move 1.2.x branch to EC2 infrastructure, so I can reliably run CI test suites.",NULL,"Move 1.2.x branch to EC2 CI infrastructure As a developer, I'd like to move 1.2.x branch to EC2 infrastructure,","so I can reliably run CI test suites.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26188,"Retrieve description of a single module ",NULL,"Retrieve description of a single module ",NULL,"Add for who this story is","well_formed","no_role","high",False
26189,"Add better support for using control file with gpfdist Currently only database connection info can be read from a control file yml format. Should add rest of the missing options to align how native format works.",NULL,"Add better support for using control file with gpfdist Currently only database connection info can be read from a control file yml format. Should add rest of the missing options to align how native format works.",NULL,"Add for who this story is","well_formed","no_role","high",False
26189,"Add better support for using control file with gpfdist Currently only database connection info can be read from a control file yml format. Should add rest of the missing options to align how native format works.",NULL,"Add better support for using control file with gpfdist Currently only database connection info can be read from a control file yml format. Should add rest of the missing options to align how native format works.",NULL,"Add better support for using control file with gpfdist Currently only database connection info can be read from a control file yml format<span class='highlight-text severity-high'>. Should add rest of the missing options to align how native format works.</span>","minimal","punctuation","high",False
26190,"Add support for update in gpfdist sink Currently we can only do plain inserts, should follow same logic from native gpfdist sink and add upserts.",NULL,"Add support for update in gpfdist sink Currently we can only do plain inserts, should follow same logic from native gpfdist sink and add upserts.",NULL,"Add for who this story is","well_formed","no_role","high",False
26190,"Add support for update in gpfdist sink Currently we can only do plain inserts, should follow same logic from native gpfdist sink and add upserts.",NULL,"Add support for update in gpfdist sink Currently we can only do plain inserts, should follow same logic from native gpfdist sink and add upserts.",NULL,"Add support for update in gpfdist sink Currently we can only do plain inserts, should follow same logic from native gpfdist sink<span class='highlight-text severity-high'> and </span>add upserts.","atomic","conjunctions","high",False
26191,"Change module option type from Class to String This better aligns with boot. Moreover, using Class was a bad design choice one can always get a Class from a String , while to converse is not always easy ",NULL,"Change module option type from Class to String This better aligns with boot. Moreover, using Class was a bad design choice one can always get a Class from a String , while to converse is not always easy ",NULL,"Add for who this story is","well_formed","no_role","high",False
26191,"Change module option type from Class to String This better aligns with boot. Moreover, using Class was a bad design choice one can always get a Class from a String , while to converse is not always easy ",NULL,"Change module option type from Class to String This better aligns with boot. Moreover, using Class was a bad design choice one can always get a Class from a String , while to converse is not always easy ",NULL,"Change module option type from Class to String This better aligns with boot<span class='highlight-text severity-high'>. Moreover, using Class was a bad design choice one can always get a Class from a String , while to converse is not always easy </span>","minimal","punctuation","high",False
26192,"Add command to get listing of a module ",NULL,"Add command to get listing of a module ",NULL,"Add for who this story is","well_formed","no_role","high",False
26200,"UI Add Pagination to Containers Page Add Pagination to Containers Page",NULL,"UI Add Pagination to Containers Page Add Pagination to Containers Page",NULL,"Add for who this story is","well_formed","no_role","high",False
26194,"Spike Investigate installation of XD modules from maven repo As a developer, I'd like to brainstorm and investigate various techniques around installation of XD modules from a maven repo, so I could define the module from CLI to have the module downloaded from the repo and installed to a running Spring XD runtime.",NULL,"Spike Investigate installation of XD modules from maven repo As a developer, I'd like to brainstorm and investigate various techniques around installation of XD modules from a maven repo,","so I could define the module from CLI to have the module downloaded from the repo and installed to a running Spring XD runtime.","Add for who this story is","well_formed","no_role","high",False
26194,"Spike Investigate installation of XD modules from maven repo As a developer, I'd like to brainstorm and investigate various techniques around installation of XD modules from a maven repo, so I could define the module from CLI to have the module downloaded from the repo and installed to a running Spring XD runtime.",NULL,"Spike Investigate installation of XD modules from maven repo As a developer, I'd like to brainstorm and investigate various techniques around installation of XD modules from a maven repo,","so I could define the module from CLI to have the module downloaded from the repo and installed to a running Spring XD runtime.","Spike Investigate installation of XD modules from maven repo As a developer, I'd like to brainstorm<span class='highlight-text severity-high'> and </span>investigate various techniques around installation of XD modules from a maven repo, so I could define the module from CLI to have the module downloaded from the repo and installed to a running Spring XD runtime.","atomic","conjunctions","high",False
26194,"Spike Investigate installation of XD modules from maven repo As a developer, I'd like to brainstorm and investigate various techniques around installation of XD modules from a maven repo, so I could define the module from CLI to have the module downloaded from the repo and installed to a running Spring XD runtime.",NULL,"Spike Investigate installation of XD modules from maven repo As a developer, I'd like to brainstorm and investigate various techniques around installation of XD modules from a maven repo,","so I could define the module from CLI to have the module downloaded from the repo and installed to a running Spring XD runtime.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26196,"Rename xd.messagebus binder properties replace with xd.messagebus prefix with ",NULL,"Rename xd.messagebus binder properties replace with xd.messagebus prefix with ",NULL,"Add for who this story is","well_formed","no_role","high",False
26197,"Add command to get listing of all modules ",NULL,"Add command to get listing of all modules ",NULL,"Add for who this story is","well_formed","no_role","high",False
26198,"Move serialization codec from XD to Spring Integration As a developer, I'd like to move serialization codec from Spring XD repo into SI, so I can update Spring XD to inherit the via maven dependency.",NULL,"Move serialization codec from XD to Spring Integration As a developer, I'd like to move serialization codec from Spring XD repo into SI,","so I can update Spring XD to inherit the via maven dependency.","Add for who this story is","well_formed","no_role","high",False
26198,"Move serialization codec from XD to Spring Integration As a developer, I'd like to move serialization codec from Spring XD repo into SI, so I can update Spring XD to inherit the via maven dependency.",NULL,"Move serialization codec from XD to Spring Integration As a developer, I'd like to move serialization codec from Spring XD repo into SI,","so I can update Spring XD to inherit the via maven dependency.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26199,"Update Groovy to 2.4.4 There is a vulnerability in Groovy that is fixed in 2.4.4 CVE 2015 3253 Remote execution of untrusted code See ",NULL,"Update Groovy to 2.4.4 There is a vulnerability in Groovy that is fixed in 2.4.4 CVE 2015 3253 Remote execution of untrusted code See ",NULL,"Add for who this story is","well_formed","no_role","high",False
26231,"Create CI infrastructure for s c d repo As a s c d developer, I'd like to setup CI infrastructure for s c d repo so I can build the project continuously on every commits. ",NULL,"Create CI infrastructure for s c d repo As a s c d developer, I'd like to setup CI infrastructure for s c d repo","so I can build the project continuously on every commits.","Add for who this story is","well_formed","no_role","high",False
26231,"Create CI infrastructure for s c d repo As a s c d developer, I'd like to setup CI infrastructure for s c d repo so I can build the project continuously on every commits. ",NULL,"Create CI infrastructure for s c d repo As a s c d developer, I'd like to setup CI infrastructure for s c d repo","so I can build the project continuously on every commits.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26193,"Refactor s c s samples to use The samples have module options classes copied over from XD. They should use a pure approach, making sure metadata is generated hand written as appropriate. Mixins are still referenced there but obviously can t work, so provide an equivalent",NULL,"Refactor s c s samples to use The samples have module options classes copied over from XD. They should use a pure approach, making sure metadata is generated hand written as appropriate. Mixins are still referenced there but obviously can t work,","so provide an equivalent","Add for who this story is","well_formed","no_role","high",False
26193,"Refactor s c s samples to use The samples have module options classes copied over from XD. They should use a pure approach, making sure metadata is generated hand written as appropriate. Mixins are still referenced there but obviously can t work, so provide an equivalent",NULL,"Refactor s c s samples to use The samples have module options classes copied over from XD. They should use a pure approach, making sure metadata is generated hand written as appropriate. Mixins are still referenced there but obviously can t work,","so provide an equivalent","Refactor s c s samples to use The samples have module options classes copied over from XD<span class='highlight-text severity-high'>. They should use a pure approach, making sure metadata is generated hand written as appropriate. Mixins are still referenced there but obviously can t work, so provide an equivalent</span>","minimal","punctuation","high",False
26193,"Refactor s c s samples to use The samples have module options classes copied over from XD. They should use a pure approach, making sure metadata is generated hand written as appropriate. Mixins are still referenced there but obviously can t work, so provide an equivalent",NULL,"Refactor s c s samples to use The samples have module options classes copied over from XD. They should use a pure approach, making sure metadata is generated hand written as appropriate. Mixins are still referenced there but obviously can t work,","so provide an equivalent","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26182,"Add support to Ambari install multiple XD Admin s As a developer, I'd like to update Ambari installed Spring XD cluster to spin up multiple instances of XD Admin servers, so it is setup for HA. ",NULL,"Add support to Ambari install multiple XD Admin s As a developer, I'd like to update Ambari installed Spring XD cluster to spin up multiple instances of XD Admin servers,","so it is setup for HA.","Add for who this story is","well_formed","no_role","high",False
26182,"Add support to Ambari install multiple XD Admin s As a developer, I'd like to update Ambari installed Spring XD cluster to spin up multiple instances of XD Admin servers, so it is setup for HA. ",NULL,"Add support to Ambari install multiple XD Admin s As a developer, I'd like to update Ambari installed Spring XD cluster to spin up multiple instances of XD Admin servers,","so it is setup for HA.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26183,"Update Spring Integration to 4.2.0.M2 4.1.6 on 1.2.x Also Spring Framework 4.2.0.RC2, Spring AMQP 1.5.0.M1 Also Batch 3.0.4",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26183,"Update Spring Integration to 4.2.0.M2 4.1.6 on 1.2.x Also Spring Framework 4.2.0.RC2, Spring AMQP 1.5.0.M1 Also Batch 3.0.4",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26201,"Spike Investigate distributed implementation of CloudController Admin SPI As a Spring XD user, I'd like to use based implementation of XD Admin SPI based on ModuleLauncher , so I can run data pipeline use cases running on CF. Relevant repos Please refer to XD 3194 or XD 3229 as sample spike deliverables google doc that were completed in the last sprint. ",NULL,"Spike Investigate distributed implementation of CloudController Admin SPI As a Spring XD user, I'd like to use based implementation of XD Admin SPI based on ModuleLauncher ,","so I can run data pipeline use cases running on CF. Relevant repos Please refer to XD 3194 or XD 3229 as sample spike deliverables google doc that were completed in the last sprint.","Add for who this story is","well_formed","no_role","high",False
26201,"Spike Investigate distributed implementation of CloudController Admin SPI As a Spring XD user, I'd like to use based implementation of XD Admin SPI based on ModuleLauncher , so I can run data pipeline use cases running on CF. Relevant repos Please refer to XD 3194 or XD 3229 as sample spike deliverables google doc that were completed in the last sprint. ",NULL,"Spike Investigate distributed implementation of CloudController Admin SPI As a Spring XD user, I'd like to use based implementation of XD Admin SPI based on ModuleLauncher ,","so I can run data pipeline use cases running on CF. Relevant repos Please refer to XD 3194 or XD 3229 as sample spike deliverables google doc that were completed in the last sprint.","Spike Investigate distributed implementation of CloudController Admin SPI As a Spring XD user, I'd like to use based implementation of XD Admin SPI based on ModuleLauncher , so I can run data pipeline use cases running on CF<span class='highlight-text severity-high'>. Relevant repos Please refer to XD 3194 or XD 3229 as sample spike deliverables google doc that were completed in the last sprint. </span>","minimal","punctuation","high",False
26201,"Spike Investigate distributed implementation of CloudController Admin SPI As a Spring XD user, I'd like to use based implementation of XD Admin SPI based on ModuleLauncher , so I can run data pipeline use cases running on CF. Relevant repos Please refer to XD 3194 or XD 3229 as sample spike deliverables google doc that were completed in the last sprint. ",NULL,"Spike Investigate distributed implementation of CloudController Admin SPI As a Spring XD user, I'd like to use based implementation of XD Admin SPI based on ModuleLauncher ,","so I can run data pipeline use cases running on CF. Relevant repos Please refer to XD 3194 or XD 3229 as sample spike deliverables google doc that were completed in the last sprint.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26209,"Add support to store metadata in Eureka As a s c s user, I'd like to store module metadata in , so I can use the repository to determine the current state.",NULL,"Add support to store metadata in Eureka As a s c s user, I'd like to store module metadata in ,","so I can use the repository to determine the current state.","Add for who this story is","well_formed","no_role","high",False
26209,"Add support to store metadata in Eureka As a s c s user, I'd like to store module metadata in , so I can use the repository to determine the current state.",NULL,"Add support to store metadata in Eureka As a s c s user, I'd like to store module metadata in ,","so I can use the repository to determine the current state.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26203,"Find a permanent home for SPI As a Spring XD developer, I'd like to have a permanent location of SPI implementations, so I could use the common repo every time I contribute or enhance the test coverage. ",NULL,"Find a permanent home for SPI As a Spring XD developer, I'd like to have a permanent location of SPI implementations,","so I could use the common repo every time I contribute or enhance the test coverage.","Add for who this story is","well_formed","no_role","high",False
26203,"Find a permanent home for SPI As a Spring XD developer, I'd like to have a permanent location of SPI implementations, so I could use the common repo every time I contribute or enhance the test coverage. ",NULL,"Find a permanent home for SPI As a Spring XD developer, I'd like to have a permanent location of SPI implementations,","so I could use the common repo every time I contribute or enhance the test coverage.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26208,"Make s c s modules searchable by it s name As a s c s user, I'd like to search the modules by it s name aside from the default offered by boot, so I can also fetch modules by it s name.",NULL,"Make s c s modules searchable by it s name As a s c s user, I'd like to search the modules by it s name aside from the default offered by boot,","so I can also fetch modules by it s name.","Add for who this story is","well_formed","no_role","high",False
26208,"Make s c s modules searchable by it s name As a s c s user, I'd like to search the modules by it s name aside from the default offered by boot, so I can also fetch modules by it s name.",NULL,"Make s c s modules searchable by it s name As a s c s user, I'd like to search the modules by it s name aside from the default offered by boot,","so I can also fetch modules by it s name.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26205,"Create module registry abstraction As a Spring XD developer, I'd like to create initial version of the new module registry abstraction, so we could leverage the foundation to make progress and test the respective SPI implementations.",NULL,"Create module registry abstraction As a Spring XD developer, I'd like to create initial version of the new module registry abstraction,","so we could leverage the foundation to make progress and test the respective SPI implementations.","Add for who this story is","well_formed","no_role","high",False
26205,"Create module registry abstraction As a Spring XD developer, I'd like to create initial version of the new module registry abstraction, so we could leverage the foundation to make progress and test the respective SPI implementations.",NULL,"Create module registry abstraction As a Spring XD developer, I'd like to create initial version of the new module registry abstraction,","so we could leverage the foundation to make progress and test the respective SPI implementations.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26207,"Add support for modules to register itself to Eureka As a s c s user, I'd like to have the modules self register itself with whenever they re installed, so I can also discover the same modules using Spring XD Admin SPI and reuse them to create data pipelines. ",NULL,"Add support for modules to register itself to Eureka As a s c s user, I'd like to have the modules self register itself with whenever they re installed,","so I can also discover the same modules using Spring XD Admin SPI and reuse them to create data pipelines.","Add for who this story is","well_formed","no_role","high",False
26207,"Add support for modules to register itself to Eureka As a s c s user, I'd like to have the modules self register itself with whenever they re installed, so I can also discover the same modules using Spring XD Admin SPI and reuse them to create data pipelines. ",NULL,"Add support for modules to register itself to Eureka As a s c s user, I'd like to have the modules self register itself with whenever they re installed,","so I can also discover the same modules using Spring XD Admin SPI and reuse them to create data pipelines.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26206,"Add admin or and the corresponding implementation gets wired in automatically.",NULL,"Add admin or and the corresponding implementation gets wired in automatically.",NULL,"Add for who this story is","well_formed","no_role","high",False
26206,"Add admin or and the corresponding implementation gets wired in automatically.",NULL,"Add admin or and the corresponding implementation gets wired in automatically.",NULL,"Add admin<span class='highlight-text severity-high'> or </span>span class='highlight-text severity-high'> and </span>the corresponding implementation gets wired in automatically.","atomic","conjunctions","high",False
26212,"Retrieve information for a Counter ",NULL,"Retrieve information for a Counter ",NULL,"Add for who this story is","well_formed","no_role","high",False
26213,"Self register xd admin server with Eureka As a Spring XD developer, I'd like to self register , so I could have admin server exposed as discoverable endpoint. ",NULL,"Self register xd admin server with Eureka As a Spring XD developer, I'd like to self register ,","so I could have admin server exposed as discoverable endpoint.","Add for who this story is","well_formed","no_role","high",False
26213,"Self register xd admin server with Eureka As a Spring XD developer, I'd like to self register , so I could have admin server exposed as discoverable endpoint. ",NULL,"Self register xd admin server with Eureka As a Spring XD developer, I'd like to self register ,","so I could have admin server exposed as discoverable endpoint.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26210,"Add state to Eureka when deploying s c s modules As a s c s user, I'd like to have my modules add update it s current state to Eureka, so I can use the repository to discover the current sate of the module as needed. ",NULL,"Add state to Eureka when deploying s c s modules As a s c s user, I'd like to have my modules add update it s current state to Eureka,","so I can use the repository to discover the current sate of the module as needed.","Add for who this story is","well_formed","no_role","high",False
26210,"Add state to Eureka when deploying s c s modules As a s c s user, I'd like to have my modules add update it s current state to Eureka, so I can use the repository to discover the current sate of the module as needed. ",NULL,"Add state to Eureka when deploying s c s modules As a s c s user, I'd like to have my modules add update it s current state to Eureka,","so I can use the repository to discover the current sate of the module as needed.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26232,"Add support to resolve and add JARs to Boot loader As a s c d developer, I'd like to resolve and then add module dependent JAR s to Boot loader, so I have an approach to handle external libraries ex database drivers required by OOTB modules. ",NULL,"Add support to re","solve and add JARs to Boot loader As a s c d developer, I'd like to resolve and then add module dependent JAR s to Boot loader, so I have an approach to handle external libraries ex database drivers required by OOTB modules.","Add for who this story is","well_formed","no_role","high",False
26232,"Add support to resolve and add JARs to Boot loader As a s c d developer, I'd like to resolve and then add module dependent JAR s to Boot loader, so I have an approach to handle external libraries ex database drivers required by OOTB modules. ",NULL,"Add support to re","solve and add JARs to Boot loader As a s c d developer, I'd like to resolve and then add module dependent JAR s to Boot loader, so I have an approach to handle external libraries ex database drivers required by OOTB modules.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26214,"Create CI infrastructure for s c s As a s c s developer, I'd like to setup CI builds for s c s builds, so I can incrementally build and test code commits automatically.",NULL,"Create CI infrastructure for s c s As a s c s developer, I'd like to setup CI builds for s c s builds,","so I can incrementally build and test code commits automatically.","Add for who this story is","well_formed","no_role","high",False
26214,"Create CI infrastructure for s c s As a s c s developer, I'd like to setup CI builds for s c s builds, so I can incrementally build and test code commits automatically.",NULL,"Create CI infrastructure for s c s As a s c s developer, I'd like to setup CI builds for s c s builds,","so I can incrementally build and test code commits automatically.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26215,"Port FTP as s c s source module As a Spring XD developer, I'd like to port modules to build streaming pipeline.",NULL,"Port FTP as s c s source module As a Spring XD developer, I'd like to port modules to build streaming pipeline.",NULL,"Add for who this story is","well_formed","no_role","high",False
26202,"Add support for Receptor SPI to query module status As a Spring XD on CF user, I'd like to use Receptor implementation of Admin SPI every time I deploy Spring XD modules, so I can leverage the SPI to query for module status and health metrics. Possible APIs ModuleStatus descriptor ; listModules ; ModuleStatus ",NULL,"Add support for Receptor SPI to query module status As a Spring XD on CF user, I'd like to use Receptor implementation of Admin SPI every time I deploy Spring XD modules,","so I can leverage the SPI to query for module status and health metrics. Possible APIs ModuleStatus descriptor ; listModules ; ModuleStatus","Add for who this story is","well_formed","no_role","high",False
26202,"Add support for Receptor SPI to query module status As a Spring XD on CF user, I'd like to use Receptor implementation of Admin SPI every time I deploy Spring XD modules, so I can leverage the SPI to query for module status and health metrics. Possible APIs ModuleStatus descriptor ; listModules ; ModuleStatus ",NULL,"Add support for Receptor SPI to query module status As a Spring XD on CF user, I'd like to use Receptor implementation of Admin SPI every time I deploy Spring XD modules,","so I can leverage the SPI to query for module status and health metrics. Possible APIs ModuleStatus descriptor ; listModules ; ModuleStatus","Add support for Receptor SPI to query module status As a Spring XD on CF user, I'd like to use Receptor implementation of Admin SPI every time I deploy Spring XD modules, so I can leverage the SPI to query for module status and health metrics<span class='highlight-text severity-high'>. Possible APIs ModuleStatus descriptor ; listModules ; ModuleStatus </span>","minimal","punctuation","high",False
26202,"Add support for Receptor SPI to query module status As a Spring XD on CF user, I'd like to use Receptor implementation of Admin SPI every time I deploy Spring XD modules, so I can leverage the SPI to query for module status and health metrics. Possible APIs ModuleStatus descriptor ; listModules ; ModuleStatus ",NULL,"Add support for Receptor SPI to query module status As a Spring XD on CF user, I'd like to use Receptor implementation of Admin SPI every time I deploy Spring XD modules,","so I can leverage the SPI to query for module status and health metrics. Possible APIs ModuleStatus descriptor ; listModules ; ModuleStatus","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26204,"Retrieve monitoring information for a specfied module For a this would be among other things message rate, number of messages",NULL,"Retrieve monitoring information for a specfied module For a this would be among other things message rate, number of messages",NULL,"Add for who this story is","well_formed","no_role","high",False
26218,"Spike Determine options for configuring shared module dependencies As a developer, I'd like to be able to configure common dependencies for the entire environment. An example could be that I use MySql for my databases. I want to be able to configure the MySql driver once and have all modules use it. ",NULL,"Spike Determine options for configuring shared module dependencies As a developer, I'd like to be able to configure common dependencies for the entire environment. An example could be that I use MySql for my databases. I want to be able to configure the MySql driver once and have all modules use it. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26218,"Spike Determine options for configuring shared module dependencies As a developer, I'd like to be able to configure common dependencies for the entire environment. An example could be that I use MySql for my databases. I want to be able to configure the MySql driver once and have all modules use it. ",NULL,"Spike Determine options for configuring shared module dependencies As a developer, I'd like to be able to configure common dependencies for the entire environment. An example could be that I use MySql for my databases. I want to be able to configure the MySql driver once and have all modules use it. ",NULL,"Spike Determine options for configuring shared module dependencies As a developer, I'd like to be able to configure common dependencies for the entire environment. An example could be that I use MySql for my databases. I want to be able to configure the MySql driver once<span class='highlight-text severity-high'> and </span>have all modules use it. ","atomic","conjunctions","high",False
26218,"Spike Determine options for configuring shared module dependencies As a developer, I'd like to be able to configure common dependencies for the entire environment. An example could be that I use MySql for my databases. I want to be able to configure the MySql driver once and have all modules use it. ",NULL,"Spike Determine options for configuring shared module dependencies As a developer, I'd like to be able to configure common dependencies for the entire environment. An example could be that I use MySql for my databases. I want to be able to configure the MySql driver once and have all modules use it. ",NULL,"Spike Determine options for configuring shared module dependencies As a developer, I'd like to be able to configure common dependencies for the entire environment<span class='highlight-text severity-high'>. An example could be that I use MySql for my databases. I want to be able to configure the MySql driver once and have all modules use it. </span>","minimal","punctuation","high",False
26218,"Spike Determine options for configuring shared module dependencies As a developer, I'd like to be able to configure common dependencies for the entire environment. An example could be that I use MySql for my databases. I want to be able to configure the MySql driver once and have all modules use it. ",NULL,"Spike Determine options for configuring shared module dependencies As a developer, I'd like to be able to configure common dependencies for the entire environment. An example could be that I use MySql for my databases. I want to be able to configure the MySql driver once and have all modules use it. ",NULL,"Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26217,"Retrieve information for a Field Value Counter TODO as part of this see XD 537 Get rid of so called Service layer in analytics project doesn t do much right now, and logic would better live in the Handler IMO Have REST controllers depend on XRepository in all cases",NULL,"Retrieve information for a Field Value Counter TODO as part of this see XD 537 Get rid of","so called Service layer in analytics project doesn t do much right now, and logic would better live in the Handler IMO Have REST controllers depend on XRepository in all cases","Add for who this story is","well_formed","no_role","high",False
26217,"Retrieve information for a Field Value Counter TODO as part of this see XD 537 Get rid of so called Service layer in analytics project doesn t do much right now, and logic would better live in the Handler IMO Have REST controllers depend on XRepository in all cases",NULL,"Retrieve information for a Field Value Counter TODO as part of this see XD 537 Get rid of","so called Service layer in analytics project doesn t do much right now, and logic would better live in the Handler IMO Have REST controllers depend on XRepository in all cases","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26220,"Create basic TaskLauncher files as Diego Tasks. ",NULL,"Create basic TaskLauncher files as Diego Tasks. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26219,"Spike Design a tasks repository as a task on CF and obtain the result reliably. ",NULL,"Spike Design a tasks repository as a task on CF and obtain the result reliably. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26221,"Retrieve information for a Gauge TODO as part of this see XD 537 Get rid of so called Service layer in analytics project doesn t do much right now, and logic would better live in the Handler IMO Have REST controllers depend on XRepository in all cases",NULL,"Retrieve information for a Gauge TODO as part of this see XD 537 Get rid of","so called Service layer in analytics project doesn t do much right now, and logic would better live in the Handler IMO Have REST controllers depend on XRepository in all cases","Add for who this story is","well_formed","no_role","high",False
26221,"Retrieve information for a Gauge TODO as part of this see XD 537 Get rid of so called Service layer in analytics project doesn t do much right now, and logic would better live in the Handler IMO Have REST controllers depend on XRepository in all cases",NULL,"Retrieve information for a Gauge TODO as part of this see XD 537 Get rid of","so called Service layer in analytics project doesn t do much right now, and logic would better live in the Handler IMO Have REST controllers depend on XRepository in all cases","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26222,"Spike Determine best way to centrally configure the job repository for batch jobs. As a developer, I need to be able to run batch jobs that use the centrally configured job repository to store job state. ",NULL,"Spike Determine best way to centrally configure the job repository for batch jobs. As a developer, I need to be able to run batch jobs that use the centrally configured job repository to store job state. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26222,"Spike Determine best way to centrally configure the job repository for batch jobs. As a developer, I need to be able to run batch jobs that use the centrally configured job repository to store job state. ",NULL,"Spike Determine best way to centrally configure the job repository for batch jobs. As a developer, I need to be able to run batch jobs that use the centrally configured job repository to store job state. ",NULL,"Spike Determine best way to centrally configure the job repository for batch jobs<span class='highlight-text severity-high'>. As a developer, I need to be able to run batch jobs that use the centrally configured job repository to store job state. </span>","minimal","punctuation","high",False
26223,"Add direct binding option for s c s modules As a s c s user, I'd like to have the option to direct bind modules , so I don t have to use messaging middleware and I can eliminate latency between them. This is important for high throughput and low latency use cases. ",NULL,"Add direct binding option for s c s modules As a s c s user, I'd like to have the option to direct bind modules ,","so I don t have to use messaging middleware and I can eliminate latency between them. This is important for high throughput and low latency use cases.","Add for who this story is","well_formed","no_role","high",False
26223,"Add direct binding option for s c s modules As a s c s user, I'd like to have the option to direct bind modules , so I don t have to use messaging middleware and I can eliminate latency between them. This is important for high throughput and low latency use cases. ",NULL,"Add direct binding option for s c s modules As a s c s user, I'd like to have the option to direct bind modules ,","so I don t have to use messaging middleware and I can eliminate latency between them. This is important for high throughput and low latency use cases.","Add direct binding option for s c s modules As a s c s user, I'd like to have the option to direct bind modules , so I don t have to use messaging middleware and I can eliminate latency between them<span class='highlight-text severity-high'>. This is important for high throughput and low latency use cases. </span>","minimal","punctuation","high",False
26223,"Add direct binding option for s c s modules As a s c s user, I'd like to have the option to direct bind modules , so I don t have to use messaging middleware and I can eliminate latency between them. This is important for high throughput and low latency use cases. ",NULL,"Add direct binding option for s c s modules As a s c s user, I'd like to have the option to direct bind modules ,","so I don t have to use messaging middleware and I can eliminate latency between them. This is important for high throughput and low latency use cases.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26225,"Add REST support for spring cloud data As a s c d developer, I'd like to establish the foundation to expose REST APIs to interact with the and likewise perform CRUD operations to maneuver streaming and batch pipelines. ",NULL,"Add REST support for spring cloud data As a s c d developer, I'd like to establish the foundation to expose REST APIs to interact with the and likewise perform CRUD operations to maneuver streaming and batch pipelines. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26225,"Add REST support for spring cloud data As a s c d developer, I'd like to establish the foundation to expose REST APIs to interact with the and likewise perform CRUD operations to maneuver streaming and batch pipelines. ",NULL,"Add REST support for spring cloud data As a s c d developer, I'd like to establish the foundation to expose REST APIs to interact with the and likewise perform CRUD operations to maneuver streaming and batch pipelines. ",NULL,"Add REST support for spring cloud data As a s c d developer, I'd like to establish the foundation to expose REST APIs to interact with the<span class='highlight-text severity-high'> and </span>likewise perform CRUD operations to maneuver streaming and batch pipelines. ","atomic","conjunctions","high",False
26230,"Port Redis counter as s c s sink As a s c s developer, I'd like to adapt redis from XD to s c s, so I can build streaming pipes using s c s modules with simple counters to feed dashboards. ",NULL,"Port Redis counter as s c s sink As a s c s developer, I'd like to adapt redis from XD to s c s,","so I can build streaming pipes using s c s modules with simple counters to feed dashboards.","Add for who this story is","well_formed","no_role","high",False
26230,"Port Redis counter as s c s sink As a s c s developer, I'd like to adapt redis from XD to s c s, so I can build streaming pipes using s c s modules with simple counters to feed dashboards. ",NULL,"Port Redis counter as s c s sink As a s c s developer, I'd like to adapt redis from XD to s c s,","so I can build streaming pipes using s c s modules with simple counters to feed dashboards.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26226,"Create ModuleRegistry stubs As a s c d developer, I'd like to create stubs, so I can create mock streams by interacting with the registry APIs.",NULL,"Create ModuleRegistry stubs As a s c d developer, I'd like to create stubs,","so I can create mock streams by interacting with the registry APIs.","Add for who this story is","well_formed","no_role","high",False
26226,"Create ModuleRegistry stubs As a s c d developer, I'd like to create stubs, so I can create mock streams by interacting with the registry APIs.",NULL,"Create ModuleRegistry stubs As a s c d developer, I'd like to create stubs,","so I can create mock streams by interacting with the registry APIs.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26227,"Move to spring cloud repo As a s c s developer, I'd like to move from s c s to s c repo, so I can cleanup s c s project and at the same time make these modules visible outside of s c s.",NULL,"Move to spring cloud repo As a s c s developer, I'd like to move from s c s to s c repo,","so I can cleanup s c s project and at the same time make these modules visible outside of s c s.","Add for who this story is","well_formed","no_role","high",False
26227,"Move to spring cloud repo As a s c s developer, I'd like to move from s c s to s c repo, so I can cleanup s c s project and at the same time make these modules visible outside of s c s.",NULL,"Move to spring cloud repo As a s c s developer, I'd like to move from s c s to s c repo,","so I can cleanup s c s project and at the same time make these modules visible outside of s c s.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26369,"Port STDOUT as s c s source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.",NULL,NULL,"source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.","Add what you want to achieve","well_formed","no_means","high",False
26369,"Port STDOUT as s c s source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.",NULL,NULL,"source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.","Add for who this story is","well_formed","no_role","high",False
26369,"Port STDOUT as s c s source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.",NULL,NULL,"source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26224,"Retrieve information for a Rich Gauge TODO as part of this see XD 537 Get rid of so called Service layer in analytics project doesn t do much right now, and logic would better live in the Handler IMO Have REST controllers depend on XRepository in all cases",NULL,"Retrieve information for a Rich Gauge TODO as part of this see XD 537 Get rid of","so called Service layer in analytics project doesn t do much right now, and logic would better live in the Handler IMO Have REST controllers depend on XRepository in all cases","Add for who this story is","well_formed","no_role","high",False
26224,"Retrieve information for a Rich Gauge TODO as part of this see XD 537 Get rid of so called Service layer in analytics project doesn t do much right now, and logic would better live in the Handler IMO Have REST controllers depend on XRepository in all cases",NULL,"Retrieve information for a Rich Gauge TODO as part of this see XD 537 Get rid of","so called Service layer in analytics project doesn t do much right now, and logic would better live in the Handler IMO Have REST controllers depend on XRepository in all cases","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26228,"Add in memory stream definition repository As a spring cloud data developer, I'd like to use an in memory stream definition repository, so I don t have to spin up a store; obviously, this will not persist between application executions, but it will be useful for a simplified development experience. ",NULL,"Add in memory stream definition repository As a spring cloud data developer, I'd like to use an in memory stream definition repository,","so I don t have to spin up a store; obviously, this will not persist between application executions, but it will be useful for a simplified development experience.","Add for who this story is","well_formed","no_role","high",False
26228,"Add in memory stream definition repository As a spring cloud data developer, I'd like to use an in memory stream definition repository, so I don t have to spin up a store; obviously, this will not persist between application executions, but it will be useful for a simplified development experience. ",NULL,"Add in memory stream definition repository As a spring cloud data developer, I'd like to use an in memory stream definition repository,","so I don t have to spin up a store; obviously, this will not persist between application executions, but it will be useful for a simplified development experience.","Add in memory stream definition repository As a spring cloud data developer, I'd like to use an in memory stream definition repository, so I don t have to spin up a store<span class='highlight-text severity-high'>; obviously, this will not persist between application executions, but it will be useful for a simplified development experience. </span>","minimal","punctuation","high",False
26228,"Add in memory stream definition repository As a spring cloud data developer, I'd like to use an in memory stream definition repository, so I don t have to spin up a store; obviously, this will not persist between application executions, but it will be useful for a simplified development experience. ",NULL,"Add in memory stream definition repository As a spring cloud data developer, I'd like to use an in memory stream definition repository,","so I don t have to spin up a store; obviously, this will not persist between application executions, but it will be useful for a simplified development experience.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26229,"Validate stream commands from shell As a s c d developer, I'd like to invoke REST APIs via shell, so I can validate operations.",NULL,"Validate stream commands from shell As a s c d developer, I'd like to invoke REST APIs via shell,","so I can validate operations.","Add for who this story is","well_formed","no_role","high",False
26229,"Validate stream commands from shell As a s c d developer, I'd like to invoke REST APIs via shell, so I can validate operations.",NULL,"Validate stream commands from shell As a s c d developer, I'd like to invoke REST APIs via shell,","so I can validate operations.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26233,"Bootify ModuleLauncher As a s c s developer, I'd like to bootify , so I can use Spring Boot s support for property, setting, as well as adding options and new functionality in the future, such as CP augmentation. ",NULL,"Bootify ModuleLauncher As a s c s developer, I'd like to bootify ,","so I can use Spring Boot s support for property, setting, as well as adding options and new functionality in the future, such as CP augmentation.","Add for who this story is","well_formed","no_role","high",False
26233,"Bootify ModuleLauncher As a s c s developer, I'd like to bootify , so I can use Spring Boot s support for property, setting, as well as adding options and new functionality in the future, such as CP augmentation. ",NULL,"Bootify ModuleLauncher As a s c s developer, I'd like to bootify ,","so I can use Spring Boot s support for property, setting, as well as adding options and new functionality in the future, such as CP augmentation.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26236,"Migrate StreamController from XD 1.0 As a s c d user, I'd like to add REST support for stream commands, so I can maneuver streaming pipeline backed by StreamController.",NULL,"Migrate StreamController from XD 1.0 As a s c d user, I'd like to add REST support for stream commands,","so I can maneuver streaming pipeline backed by StreamController.","Add for who this story is","well_formed","no_role","high",False
26236,"Migrate StreamController from XD 1.0 As a s c d user, I'd like to add REST support for stream commands, so I can maneuver streaming pipeline backed by StreamController.",NULL,"Migrate StreamController from XD 1.0 As a s c d user, I'd like to add REST support for stream commands,","so I can maneuver streaming pipeline backed by StreamController.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26234,"Add PHD HDFS as s c s module As a s c s developer, I'd like to investigate the right approach to port module from XD, so I can decide better handling of HDFS dependencies, which needs loaded and available in root CP at the runtime. ",NULL,"Add PHD HDFS as s c s module As a s c s developer, I'd like to investigate the right approach to port module from XD,","so I can decide better handling of HDFS dependencies, which needs loaded and available in root CP at the runtime.","Add for who this story is","well_formed","no_role","high",False
26234,"Add PHD HDFS as s c s module As a s c s developer, I'd like to investigate the right approach to port module from XD, so I can decide better handling of HDFS dependencies, which needs loaded and available in root CP at the runtime. ",NULL,"Add PHD HDFS as s c s module As a s c s developer, I'd like to investigate the right approach to port module from XD,","so I can decide better handling of HDFS dependencies, which needs loaded and available in root CP at the runtime.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26237,"Create CI infrastructure for s c s m repo As a s c s developer, I'd like to setup CI infrastructure for s c s m repo, so I can build the project continuously on every commits. ",NULL,"Create CI infrastructure for s c s m repo As a s c s developer, I'd like to setup CI infrastructure for s c s m repo,","so I can build the project continuously on every commits.","Add for who this story is","well_formed","no_role","high",False
26237,"Create CI infrastructure for s c s m repo As a s c s developer, I'd like to setup CI infrastructure for s c s m repo, so I can build the project continuously on every commits. ",NULL,"Create CI infrastructure for s c s m repo As a s c s developer, I'd like to setup CI infrastructure for s c s m repo,","so I can build the project continuously on every commits.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26238,"Add binding information to application definition ModuleDefinition contains bindings that need to be passed to the ModuleRunner app. It appears these can be included in the application s environment.",NULL,"Add binding information to application definition ModuleDefinition contains bindings that need to be passed to the ModuleRunner app. It appears these can be included in the application s environment.",NULL,"Add for who this story is","well_formed","no_role","high",False
26238,"Add binding information to application definition ModuleDefinition contains bindings that need to be passed to the ModuleRunner app. It appears these can be included in the application s environment.",NULL,"Add binding information to application definition ModuleDefinition contains bindings that need to be passed to the ModuleRunner app. It appears these can be included in the application s environment.",NULL,"Add binding information to application definition ModuleDefinition contains bindings that need to be passed to the ModuleRunner app<span class='highlight-text severity-high'>. It appears these can be included in the application s environment.</span>","minimal","punctuation","high",False
26239,"Add parameter information to application definition A ModuleDefinition contains parameters, which need to be passed to the CloudFoundry application. Currently these are put directly into the application s environment. This issue will verify they are correctly named.",NULL,"Add parameter information to application definition A ModuleDefinition contains parameters, which need to be passed to the CloudFoundry application. Currently these are put directly into the application s environment. This issue will verify they are correctly named.",NULL,"Add for who this story is","well_formed","no_role","high",False
26239,"Add parameter information to application definition A ModuleDefinition contains parameters, which need to be passed to the CloudFoundry application. Currently these are put directly into the application s environment. This issue will verify they are correctly named.",NULL,"Add parameter information to application definition A ModuleDefinition contains parameters, which need to be passed to the CloudFoundry application. Currently these are put directly into the application s environment. This issue will verify they are correctly named.",NULL,"Add parameter information to application definition A ModuleDefinition contains parameters, which need to be passed to the CloudFoundry application<span class='highlight-text severity-high'>. Currently these are put directly into the application s environment. This issue will verify they are correctly named.</span>","minimal","punctuation","high",False
26247,"Spike s, so I can decide the binding selection and fallback mechanism when there is none setup.",NULL,NULL,"so I can decide the binding selection and fallback mechanism when there is none setup.","Add what you want to achieve","well_formed","no_means","high",False
26247,"Spike s, so I can decide the binding selection and fallback mechanism when there is none setup.",NULL,NULL,"so I can decide the binding selection and fallback mechanism when there is none setup.","Add for who this story is","well_formed","no_role","high",False
26247,"Spike s, so I can decide the binding selection and fallback mechanism when there is none setup.",NULL,NULL,"so I can decide the binding selection and fallback mechanism when there is none setup.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26248,"Dependency s ex direct binding of two modules that include different versions of spring data , I have the capability to resolve and include the right bits at runtime.",NULL,"Dependency s ex direct binding of two modules that include different versions of spring data , I have the capability to resolve and include the right bits at runtime.",NULL,"Add for who this story is","well_formed","no_role","high",False
26248,"Dependency s ex direct binding of two modules that include different versions of spring data , I have the capability to resolve and include the right bits at runtime.",NULL,"Dependency s ex direct binding of two modules that include different versions of spring data , I have the capability to resolve and include the right bits at runtime.",NULL,"Dependency s ex direct binding of two modules that include different versions of spring data , I have the capability to resolve<span class='highlight-text severity-high'> and </span>include the right bits at runtime.","atomic","conjunctions","high",False
26242,"Implement undeploy operation for CC SPI Currently undeploy is a no op.",NULL,"Implement undeploy operation for CC SPI Currently undeploy is a no op.",NULL,"Add for who this story is","well_formed","no_role","high",False
26243,"Add real ModuleRunner application The current ModuleRunner is test app used for validation. This should be replaced by a real app.",NULL,"Add real ModuleRunner application The current ModuleRunner is test app used for validation. This should be replaced by a real app.",NULL,"Add for who this story is","well_formed","no_role","high",False
26243,"Add real ModuleRunner application The current ModuleRunner is test app used for validation. This should be replaced by a real app.",NULL,"Add real ModuleRunner application The current ModuleRunner is test app used for validation. This should be replaced by a real app.",NULL,"Add real ModuleRunner application The current ModuleRunner is test app used for validation<span class='highlight-text severity-high'>. This should be replaced by a real app.</span>","minimal","punctuation","high",False
26244,"Obtain username and password credentials for CloudFoundry As part of moving to a bespoke RestOperations application we will need credentials to access CloudFoundry. These will need to be supplied from the new XD Admin app at runtime.",NULL,"Obtain username and password credentials for CloudFoundry As part of moving to a bespoke RestOperations application we will need credentials to access CloudFoundry. These will need to be supplied from the new XD Admin app at runtime.",NULL,"Add for who this story is","well_formed","no_role","high",False
26244,"Obtain username and password credentials for CloudFoundry As part of moving to a bespoke RestOperations application we will need credentials to access CloudFoundry. These will need to be supplied from the new XD Admin app at runtime.",NULL,"Obtain username and password credentials for CloudFoundry As part of moving to a bespoke RestOperations application we will need credentials to access CloudFoundry. These will need to be supplied from the new XD Admin app at runtime.",NULL,"Obtain username<span class='highlight-text severity-high'> and </span>password credentials for CloudFoundry As part of moving to a bespoke RestOperations application we will need credentials to access CloudFoundry. These will need to be supplied from the new XD Admin app at runtime.","atomic","conjunctions","high",False
26244,"Obtain username and password credentials for CloudFoundry As part of moving to a bespoke RestOperations application we will need credentials to access CloudFoundry. These will need to be supplied from the new XD Admin app at runtime.",NULL,"Obtain username and password credentials for CloudFoundry As part of moving to a bespoke RestOperations application we will need credentials to access CloudFoundry. These will need to be supplied from the new XD Admin app at runtime.",NULL,"Obtain username and password credentials for CloudFoundry As part of moving to a bespoke RestOperations application we will need credentials to access CloudFoundry<span class='highlight-text severity-high'>. These will need to be supplied from the new XD Admin app at runtime.</span>","minimal","punctuation","high",False
26245,"Refactor This class should not know what the test app is. This means changing the constructors on ",NULL,"Refactor This class should not know what the test app is. This means changing the constructors on ",NULL,"Add for who this story is","well_formed","no_role","high",False
26245,"Refactor This class should not know what the test app is. This means changing the constructors on ",NULL,"Refactor This class should not know what the test app is. This means changing the constructors on ",NULL,"Refactor This class should not know what the test app is<span class='highlight-text severity-high'>. This means changing the constructors on </span>","minimal","punctuation","high",False
26246,"Refactor to use RestOperations The current implementation makes use of cf java client, which is relatively heavy for our needs. It should be removed in favour of a bespoke RestOperations wrapper. See for sample code.",NULL,"Refactor to use RestOperations The current implementation makes use of cf java client, which is relatively heavy for our needs. It should be removed in favour of a bespoke RestOperations wrapper. See for sample code.",NULL,"Add for who this story is","well_formed","no_role","high",False
26246,"Refactor to use RestOperations The current implementation makes use of cf java client, which is relatively heavy for our needs. It should be removed in favour of a bespoke RestOperations wrapper. See for sample code.",NULL,"Refactor to use RestOperations The current implementation makes use of cf java client, which is relatively heavy for our needs. It should be removed in favour of a bespoke RestOperations wrapper. See for sample code.",NULL,"Refactor to use RestOperations The current implementation makes use of cf java client, which is relatively heavy for our needs<span class='highlight-text severity-high'>. It should be removed in favour of a bespoke RestOperations wrapper. See for sample code.</span>","minimal","punctuation","high",False
26271,"Port Router as s c s sink As a Spring XD developer, I'd like to port module to build streaming pipeline.",NULL,"Port Router as s c s sink As a Spring XD developer, I'd like to port module to build streaming pipeline.",NULL,"Add for who this story is","well_formed","no_role","high",False
26249,"Document the structure of the REST API ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26249,"Document the structure of the REST API ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26250,"Publish s c d image to DockerHub As a s c d developer, I'd like to publish the s c d image to DockerHub, so I can incrementally push the latest commits to the remote location.",NULL,"Publish s c d image to DockerHub As a s c d developer, I'd like to publish the s c d image to DockerHub,","so I can incrementally push the latest commits to the remote location.","Add for who this story is","well_formed","no_role","high",False
26250,"Publish s c d image to DockerHub As a s c d developer, I'd like to publish the s c d image to DockerHub, so I can incrementally push the latest commits to the remote location.",NULL,"Publish s c d image to DockerHub As a s c d developer, I'd like to publish the s c d image to DockerHub,","so I can incrementally push the latest commits to the remote location.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26272,"Port File as s c s sink As a Spring XD developer, I'd like to port module to build streaming pipeline.",NULL,"Port File as s c s sink As a Spring XD developer, I'd like to port module to build streaming pipeline.",NULL,"Add for who this story is","well_formed","no_role","high",False
26241,"Return full information Currently there is no returned. This issue will fill in the details.",NULL,"Return full information Currently there is no returned. This issue will fill in the details.",NULL,"Add for who this story is","well_formed","no_role","high",False
26241,"Return full information Currently there is no returned. This issue will fill in the details.",NULL,"Return full information Currently there is no returned. This issue will fill in the details.",NULL,"Return full information Currently there is no returned<span class='highlight-text severity-high'>. This issue will fill in the details.</span>","minimal","punctuation","high",False
26252,"Run all shell integration tests also with enabled security Apply the same strategy for the Module Command Tests also to all other Shell integration tests.",NULL,"Run all shell integration tests also with enabled security Apply the same strategy for the Module Command Tests also to all other Shell integration tests.",NULL,"Add for who this story is","well_formed","no_role","high",False
26253,"Add profile support for stream repositories As a s c d developer, I'd like to add support for profiles to the core profile would use in memory strategy to store the metadata.",NULL,"Add profile support for stream repositories As a s c d developer, I'd like to add support for profiles to the core profile would use in memory strategy to store the metadata.",NULL,"Add for who this story is","well_formed","no_role","high",False
26255,"Review DSL updated story points to 14 since 5 of us just participated in a 2 hour call, and we still need to discuss topology support after some dev spikes later this week",NULL,"Review DSL updated story points to 14 since 5 of us just participated in a 2 hour call, and we still need to discuss topology support after some dev spikes later this week",NULL,"Add for who this story is","well_formed","no_role","high",False
26255,"Review DSL updated story points to 14 since 5 of us just participated in a 2 hour call, and we still need to discuss topology support after some dev spikes later this week",NULL,"Review DSL updated story points to 14 since 5 of us just participated in a 2 hour call, and we still need to discuss topology support after some dev spikes later this week",NULL,"Review DSL updated story points to 14 since 5 of us just participated in a 2 hour call,<span class='highlight-text severity-high'> and </span>we still need to discuss topology support after some dev spikes later this week","atomic","conjunctions","high",False
26254,"Design the foundation to port XD modules to s c s As an s c s developer, I'd like to brainstorm and design the foundation to port XD modules as s c s modules, so I can use it as the base and start migrating the modules.",NULL,"Design the foundation to port XD modules to s c s As an s c s developer, I'd like to brainstorm and design the foundation to port XD modules as s c s modules,","so I can use it as the base and start migrating the modules.","Add for who this story is","well_formed","no_role","high",False
26254,"Design the foundation to port XD modules to s c s As an s c s developer, I'd like to brainstorm and design the foundation to port XD modules as s c s modules, so I can use it as the base and start migrating the modules.",NULL,"Design the foundation to port XD modules to s c s As an s c s developer, I'd like to brainstorm and design the foundation to port XD modules as s c s modules,","so I can use it as the base and start migrating the modules.","Design the foundation to port XD modules to s c s As an s c s developer, I'd like to brainstorm<span class='highlight-text severity-high'> and </span>design the foundation to port XD modules as s c s modules, so I can use it as the base and start migrating the modules.","atomic","conjunctions","high",False
26254,"Design the foundation to port XD modules to s c s As an s c s developer, I'd like to brainstorm and design the foundation to port XD modules as s c s modules, so I can use it as the base and start migrating the modules.",NULL,"Design the foundation to port XD modules to s c s As an s c s developer, I'd like to brainstorm and design the foundation to port XD modules as s c s modules,","so I can use it as the base and start migrating the modules.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26263,"Document Splunk source sink ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26263,"Document Splunk source sink ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26256,"Add support to expose counter metrics for dashboarding As a s c d developer, I'd like to add support to expose counter metrics endpoints, so I can consume to feed the dashboards to demonstrate pipe.",NULL,"Add support to expose counter metrics for dashboarding As a s c d developer, I'd like to add support to expose counter metrics endpoints,","so I can consume to feed the dashboards to demonstrate pipe.","Add for who this story is","well_formed","no_role","high",False
26256,"Add support to expose counter metrics for dashboarding As a s c d developer, I'd like to add support to expose counter metrics endpoints, so I can consume to feed the dashboards to demonstrate pipe.",NULL,"Add support to expose counter metrics for dashboarding As a s c d developer, I'd like to add support to expose counter metrics endpoints,","so I can consume to feed the dashboards to demonstrate pipe.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26257,"Replace codec impl in with SI Codec ",NULL,"Replace codec impl in with SI Codec ",NULL,"Add for who this story is","well_formed","no_role","high",False
26258,"Replace Binder XML config with Configuration Create Confguration and Configuration must support replacing the default Kryo Codec implementation with something else.",NULL,"Replace Binder XML config with Configuration Create Confguration and Configuration must support replacing the default Kryo Codec implementation with something else.",NULL,"Add for who this story is","well_formed","no_role","high",False
26258,"Replace Binder XML config with Configuration Create Confguration and Configuration must support replacing the default Kryo Codec implementation with something else.",NULL,"Replace Binder XML config with Configuration Create Confguration and Configuration must support replacing the default Kryo Codec implementation with something else.",NULL,"Replace Binder XML config with Configuration Create Confguration<span class='highlight-text severity-high'> and </span>Configuration must support replacing the default Kryo Codec implementation with something else.","atomic","conjunctions","high",False
26259,"Add shell as a rest client to the spring cloud data REST API As a user I would like to have shell interface to the spring cloud data rest API. The scope for this JIRA could be limited to stream commands.",NULL,"Add shell as a rest client to the spring cloud data REST API As a user I would like to have shell interface to the spring cloud data rest API. The scope for this JIRA could be limited to stream commands.",NULL,"Add for who this story is","well_formed","no_role","high",False
26259,"Add shell as a rest client to the spring cloud data REST API As a user I would like to have shell interface to the spring cloud data rest API. The scope for this JIRA could be limited to stream commands.",NULL,"Add shell as a rest client to the spring cloud data REST API As a user I would like to have shell interface to the spring cloud data rest API. The scope for this JIRA could be limited to stream commands.",NULL,"Add shell as a rest client to the spring cloud data REST API As a user I would like to have shell interface to the spring cloud data rest API<span class='highlight-text severity-high'>. The scope for this JIRA could be limited to stream commands.</span>","minimal","punctuation","high",False
26260,"Move shell integration tests to spring cloud data shell This could focus only on the subset Stream operations ",NULL,"Move shell integration tests to spring cloud data shell This could focus only on the subset Stream operations ",NULL,"Add for who this story is","well_formed","no_role","high",False
26261,"Add support for module info to list module properties As a s c d developer, I'd like to derive a strategy for module metadata via command in shell to list all the module properties. ",NULL,"Add support for module info to list module properties As a s c d developer, I'd like to derive a strategy for module metadata via command in shell to list all the module properties. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26264,"Add Spring Cloud Config to SPI Module Parent Enable spring cloud config for all modules Add spring cloud config client to pom dependencies. Add bootstrap.yml to scs project ",NULL,"Add Spring Cloud Config to SPI Module Parent Enable spring cloud config for all modules Add spring cloud config client to pom dependencies. Add bootstrap.yml to scs project ",NULL,"Add for who this story is","well_formed","no_role","high",False
26264,"Add Spring Cloud Config to SPI Module Parent Enable spring cloud config for all modules Add spring cloud config client to pom dependencies. Add bootstrap.yml to scs project ",NULL,"Add Spring Cloud Config to SPI Module Parent Enable spring cloud config for all modules Add spring cloud config client to pom dependencies. Add bootstrap.yml to scs project ",NULL,"Add Spring Cloud Config to SPI Module Parent Enable spring cloud config for all modules Add spring cloud config client to pom dependencies<span class='highlight-text severity-high'>. Add bootstrap.yml to scs project </span>","minimal","punctuation","high",False
26265,"Port HTTP as s c s module As a Spring XD developer, I'd like to port module in streaming pipeline. ",NULL,"Port HTTP as s c s module As a Spring XD developer, I'd like to port module in streaming pipeline. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26266,"Port TCP as s c s module As a Spring XD developer, I'd like to port module to build streaming pipeline. ",NULL,"Port TCP as s c s module As a Spring XD developer, I'd like to port module to build streaming pipeline. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26268,"Port Twittersearch as s c s module As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source modules to build streaming pipeline. ",NULL,"Port Twittersearch as s c s module As a Spring XD developer, I'd like to move module from XD to s c s repo,","so I can use it as source modules to build streaming pipeline.","Add for who this story is","well_formed","no_role","high",False
26268,"Port Twittersearch as s c s module As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source modules to build streaming pipeline. ",NULL,"Port Twittersearch as s c s module As a Spring XD developer, I'd like to move module from XD to s c s repo,","so I can use it as source modules to build streaming pipeline.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26267,"Port Twitterstream as s c s module As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source modules to build streaming pipeline. ",NULL,"Port Twitterstream as s c s module As a Spring XD developer, I'd like to move module from XD to s c s repo,","so I can use it as source modules to build streaming pipeline.","Add for who this story is","well_formed","no_role","high",False
26267,"Port Twitterstream as s c s module As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source modules to build streaming pipeline. ",NULL,"Port Twitterstream as s c s module As a Spring XD developer, I'd like to move module from XD to s c s repo,","so I can use it as source modules to build streaming pipeline.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26269,"Port Filter as s c s module As a Spring XD developer, I'd like to port module to build streaming pipeline.",NULL,"Port Filter as s c s module As a Spring XD developer, I'd like to port module to build streaming pipeline.",NULL,"Add for who this story is","well_formed","no_role","high",False
26262,"Standardize Spring Cloud Data configuration User can configure spring cloud data via via Spring Cloud Config, data admin.yml or Spring Cloud Connector Add bootstrap.yml to spring cloud data create a default data admin.yml and configure spring data to look for this vs application.yml. Spring Cloud Data will have Spring Cloud Config enabled by default User has the ability to disable it via the bootstrap.yml",NULL,"Standardize Spring Cloud Data configuration User can configure spring cloud data via via Spring Cloud Config, data admin.yml or Spring Cloud Connector Add bootstrap.yml to spring cloud data create a default data admin.yml and configure spring data to look for this vs application.yml. Spring Cloud Data will have Spring Cloud Config enabled by default User has the ability to disable it via the bootstrap.yml",NULL,"Add for who this story is","well_formed","no_role","high",False
26262,"Standardize Spring Cloud Data configuration User can configure spring cloud data via via Spring Cloud Config, data admin.yml or Spring Cloud Connector Add bootstrap.yml to spring cloud data create a default data admin.yml and configure spring data to look for this vs application.yml. Spring Cloud Data will have Spring Cloud Config enabled by default User has the ability to disable it via the bootstrap.yml",NULL,"Standardize Spring Cloud Data configuration User can configure spring cloud data via via Spring Cloud Config, data admin.yml or Spring Cloud Connector Add bootstrap.yml to spring cloud data create a default data admin.yml and configure spring data to look for this vs application.yml. Spring Cloud Data will have Spring Cloud Config enabled by default User has the ability to disable it via the bootstrap.yml",NULL,"Standardize Spring Cloud Data configuration User can configure spring cloud data via via Spring Cloud Config, data admin.yml<span class='highlight-text severity-high'> or </span>Spring Cloud Connector Add bootstrap.yml to spring cloud data create a default data admin.yml<span class='highlight-text severity-high'> and </span>configure spring data to look for this vs application.yml. Spring Cloud Data will have Spring Cloud Config enabled by default User has the ability to disable it via the bootstrap.yml","atomic","conjunctions","high",False
26262,"Standardize Spring Cloud Data configuration User can configure spring cloud data via via Spring Cloud Config, data admin.yml or Spring Cloud Connector Add bootstrap.yml to spring cloud data create a default data admin.yml and configure spring data to look for this vs application.yml. Spring Cloud Data will have Spring Cloud Config enabled by default User has the ability to disable it via the bootstrap.yml",NULL,"Standardize Spring Cloud Data configuration User can configure spring cloud data via via Spring Cloud Config, data admin.yml or Spring Cloud Connector Add bootstrap.yml to spring cloud data create a default data admin.yml and configure spring data to look for this vs application.yml. Spring Cloud Data will have Spring Cloud Config enabled by default User has the ability to disable it via the bootstrap.yml",NULL,"Standardize Spring Cloud Data configuration User can configure spring cloud data via via Spring Cloud Config, data admin<span class='highlight-text severity-high'>.yml or Spring Cloud Connector Add bootstrap.yml to spring cloud data create a default data admin.yml and configure spring data to look for this vs application.yml. Spring Cloud Data will have Spring Cloud Config enabled by default User has the ability to disable it via the bootstrap.yml</span>","minimal","punctuation","high",False
26270,"Port Transform as s c s module As a Spring XD developer, I'd like to port module to build streaming pipeline.",NULL,"Port Transform as s c s module As a Spring XD developer, I'd like to port module to build streaming pipeline.",NULL,"Add for who this story is","well_formed","no_role","high",False
26283,"Hide the passwords in custom modules from being displayed. Hi, Passwords are visibly when using custom modules. Attached is example custom module code and xd shell script to reproduce the problem using stream module of type processor on Spring XD 1.2.1.RELEASE. Compile with Maven mvn clean install and run xd shell script xd shell cmdfile . runme.cmd . ",NULL,"Hide the passwords in custom modules from being displayed. Hi, Passwords are visibly when using custom modules. Attached is example custom module code and xd shell script to reproduce the problem using stream module of type processor on Spring XD 1.2.1.RELEASE. Compile with Maven mvn clean install and run xd shell script xd shell cmdfile . runme.cmd . ",NULL,"Add for who this story is","well_formed","no_role","high",False
26283,"Hide the passwords in custom modules from being displayed. Hi, Passwords are visibly when using custom modules. Attached is example custom module code and xd shell script to reproduce the problem using stream module of type processor on Spring XD 1.2.1.RELEASE. Compile with Maven mvn clean install and run xd shell script xd shell cmdfile . runme.cmd . ",NULL,"Hide the passwords in custom modules from being displayed. Hi, Passwords are visibly when using custom modules. Attached is example custom module code and xd shell script to reproduce the problem using stream module of type processor on Spring XD 1.2.1.RELEASE. Compile with Maven mvn clean install and run xd shell script xd shell cmdfile . runme.cmd . ",NULL,"Hide the passwords in custom modules from being displayed. Hi, Passwords are visibly when using custom modules. Attached is example custom module code<span class='highlight-text severity-high'> and </span>xd shell script to reproduce the problem using stream module of type processor on Spring XD 1.2.1.RELEASE. Compile with Maven mvn clean install and run xd shell script xd shell cmdfile . runme.cmd . ","atomic","conjunctions","high",False
26283,"Hide the passwords in custom modules from being displayed. Hi, Passwords are visibly when using custom modules. Attached is example custom module code and xd shell script to reproduce the problem using stream module of type processor on Spring XD 1.2.1.RELEASE. Compile with Maven mvn clean install and run xd shell script xd shell cmdfile . runme.cmd . ",NULL,"Hide the passwords in custom modules from being displayed. Hi, Passwords are visibly when using custom modules. Attached is example custom module code and xd shell script to reproduce the problem using stream module of type processor on Spring XD 1.2.1.RELEASE. Compile with Maven mvn clean install and run xd shell script xd shell cmdfile . runme.cmd . ",NULL,"Hide the passwords in custom modules from being displayed<span class='highlight-text severity-high'>. Hi, Passwords are visibly when using custom modules. Attached is example custom module code and xd shell script to reproduce the problem using stream module of type processor on Spring XD 1.2.1.RELEASE. Compile with Maven mvn clean install and run xd shell script xd shell cmdfile . runme.cmd . </span>","minimal","punctuation","high",False
26282,"Spike Investigate distributed deployment of s c s modules via YARN SPI As an s c d developer, I'd like to investigate the distributed deployment of s c s modules on YARN, so I can experiment the implementation of YARN SPI and derive the strategy for .",NULL,"Spike Investigate distributed deployment of s c s modules via YARN SPI As an s c d developer, I'd like to investigate the distributed deployment of s c s modules on YARN,","so I can experiment the implementation of YARN SPI and derive the strategy for .","Add for who this story is","well_formed","no_role","high",False
26282,"Spike Investigate distributed deployment of s c s modules via YARN SPI As an s c d developer, I'd like to investigate the distributed deployment of s c s modules on YARN, so I can experiment the implementation of YARN SPI and derive the strategy for .",NULL,"Spike Investigate distributed deployment of s c s modules via YARN SPI As an s c d developer, I'd like to investigate the distributed deployment of s c s modules on YARN,","so I can experiment the implementation of YARN SPI and derive the strategy for .","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26284,"Port Trigger as s c s source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline. ",NULL,NULL,"source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.","Add what you want to achieve","well_formed","no_means","high",False
26284,"Port Trigger as s c s source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline. ",NULL,NULL,"source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.","Add for who this story is","well_formed","no_role","high",False
26284,"Port Trigger as s c s source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline. ",NULL,NULL,"source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26289,"Port admin web UI to Spring Cloud Data admin As a user I should be able to use the existing admin UI client for spring cloud data admin with the appropriate server configurations.",NULL,"Port admin web UI to Spring Cloud Data admin As a user I should be able to use the existing admin UI client for spring cloud data admin with the appropriate server configurations.",NULL,"Add for who this story is","well_formed","no_role","high",False
26289,"Port admin web UI to Spring Cloud Data admin As a user I should be able to use the existing admin UI client for spring cloud data admin with the appropriate server configurations.",NULL,"Port admin web UI to Spring Cloud Data admin As a user I should be able to use the existing admin UI client for spring cloud data admin with the appropriate server configurations.",NULL,"Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26285,"Investigate using profiler when doing the performance testing Investigate how efficiently we can integrate profiler into the performance test.",NULL,"Investigate using profiler when doing the performance testing Investigate how efficiently we can integrate profiler into the performance test.",NULL,"Add for who this story is","well_formed","no_role","high",False
26290,"Create auto for Local Binder As a s c s developer, I'd like to create auto configuration for binder so I can automatically configure the Spring application based on the dependencies.",NULL,"Create auto for Local Binder As a s c s developer, I'd like to create auto configuration for binder","so I can automatically configure the Spring application based on the dependencies.","Add for who this story is","well_formed","no_role","high",False
26290,"Create auto for Local Binder As a s c s developer, I'd like to create auto configuration for binder so I can automatically configure the Spring application based on the dependencies.",NULL,"Create auto for Local Binder As a s c s developer, I'd like to create auto configuration for binder","so I can automatically configure the Spring application based on the dependencies.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26286,"Upgrade receptor client to comply with latest Receptor APIs As a s c d developer, I'd like to upgrade API changes, so I can sync up and take advantage of the recent improvements. ",NULL,"Upgrade receptor client to comply with latest Receptor APIs As a s c d developer, I'd like to upgrade API changes,","so I can sync up and take advantage of the recent improvements.","Add for who this story is","well_formed","no_role","high",False
26286,"Upgrade receptor client to comply with latest Receptor APIs As a s c d developer, I'd like to upgrade API changes, so I can sync up and take advantage of the recent improvements. ",NULL,"Upgrade receptor client to comply with latest Receptor APIs As a s c d developer, I'd like to upgrade API changes,","so I can sync up and take advantage of the recent improvements.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26288,"Add cloud connector dependencies for spring cloud data admin Spring cloud data admin requires lattice connector and dependencies so that the admin controllers get access to any services while running on lattice. One example is, CounterContoller using redis service for MetricRepository.",NULL,"Add cloud connector dependencies for spring cloud data admin Spring cloud data admin requires lattice connector and dependencies","so that the admin controllers get access to any services while running on lattice. One example is, CounterContoller using redis service for MetricRepository.","Add for who this story is","well_formed","no_role","high",False
26288,"Add cloud connector dependencies for spring cloud data admin Spring cloud data admin requires lattice connector and dependencies so that the admin controllers get access to any services while running on lattice. One example is, CounterContoller using redis service for MetricRepository.",NULL,"Add cloud connector dependencies for spring cloud data admin Spring cloud data admin requires lattice connector and dependencies","so that the admin controllers get access to any services while running on lattice. One example is, CounterContoller using redis service for MetricRepository.","Add cloud connector dependencies for spring cloud data admin Spring cloud data admin requires lattice connector and dependencies so that the admin controllers get access to any services while running on lattice<span class='highlight-text severity-high'>. One example is, CounterContoller using redis service for MetricRepository.</span>","minimal","punctuation","high",False
26288,"Add cloud connector dependencies for spring cloud data admin Spring cloud data admin requires lattice connector and dependencies so that the admin controllers get access to any services while running on lattice. One example is, CounterContoller using redis service for MetricRepository.",NULL,"Add cloud connector dependencies for spring cloud data admin Spring cloud data admin requires lattice connector and dependencies","so that the admin controllers get access to any services while running on lattice. One example is, CounterContoller using redis service for MetricRepository.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26292,"Create script to extract table data from JSON based on a given HAWQ table structure We should be able to write a script that can examine the table structure for a given HAWQ table and then extract the data from JSON without the custom script we are using now.",NULL,"Create script to extract table data from JSON based on a given HAWQ table structure We should be able to write a script that can examine the table structure for a given HAWQ table and then extract the data from JSON without the custom script we are using now.",NULL,"Add for who this story is","well_formed","no_role","high",False
26292,"Create script to extract table data from JSON based on a given HAWQ table structure We should be able to write a script that can examine the table structure for a given HAWQ table and then extract the data from JSON without the custom script we are using now.",NULL,"Create script to extract table data from JSON based on a given HAWQ table structure We should be able to write a script that can examine the table structure for a given HAWQ table and then extract the data from JSON without the custom script we are using now.",NULL,"Create script to extract table data from JSON based on a given HAWQ table structure We should be able to write a script that can examine the table structure for a given HAWQ table<span class='highlight-text severity-high'> and </span>then extract the data from JSON without the custom script we are using now.","atomic","conjunctions","high",False
26291,"Create CI Builds for SCD and Receptor Client Build SCS and SCD projects upon change in github repo. Push docker image for SCD Admin to docker hub",NULL,"Create CI Builds for SCD and Receptor Client Build SCS and SCD projects upon change in github repo. Push docker image for SCD Admin to docker hub",NULL,"Add for who this story is","well_formed","no_role","high",False
26291,"Create CI Builds for SCD and Receptor Client Build SCS and SCD projects upon change in github repo. Push docker image for SCD Admin to docker hub",NULL,"Create CI Builds for SCD and Receptor Client Build SCS and SCD projects upon change in github repo. Push docker image for SCD Admin to docker hub",NULL,"Create CI Builds for SCD and Receptor Client Build SCS and SCD projects upon change in github repo<span class='highlight-text severity-high'>. Push docker image for SCD Admin to docker hub</span>","minimal","punctuation","high",False
26329,"Create a new banner for As a s c d user, I'd like to create a new banner, so I can embed and display the banner when the shell server boots up. Perhaps use this banner generator ",NULL,"Create a new banner for As a s c d user, I'd like to create a new banner,","so I can embed and display the banner when the shell server boots up. Perhaps use this banner generator","Add for who this story is","well_formed","no_role","high",False
26329,"Create a new banner for As a s c d user, I'd like to create a new banner, so I can embed and display the banner when the shell server boots up. Perhaps use this banner generator ",NULL,"Create a new banner for As a s c d user, I'd like to create a new banner,","so I can embed and display the banner when the shell server boots up. Perhaps use this banner generator","Create a new banner for As a s c d user, I'd like to create a new banner, so I can embed and display the banner when the shell server boots up<span class='highlight-text severity-high'>. Perhaps use this banner generator </span>","minimal","punctuation","high",False
26329,"Create a new banner for As a s c d user, I'd like to create a new banner, so I can embed and display the banner when the shell server boots up. Perhaps use this banner generator ",NULL,"Create a new banner for As a s c d user, I'd like to create a new banner,","so I can embed and display the banner when the shell server boots up. Perhaps use this banner generator","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26294,"Add support for deploying YARN app into HDFS As a s c d developer, I'd like to add support to deploy YARN App into HDFS automatically, so I can have the orchestrate overall deployment by leveraging the manifest to deploy where and with what assets.",NULL,"Add support for deploying YARN app into HDFS As a s c d developer, I'd like to add support to deploy YARN App into HDFS automatically,","so I can have the orchestrate overall deployment by leveraging the manifest to deploy where and with what assets.","Add for who this story is","well_formed","no_role","high",False
26294,"Add support for deploying YARN app into HDFS As a s c d developer, I'd like to add support to deploy YARN App into HDFS automatically, so I can have the orchestrate overall deployment by leveraging the manifest to deploy where and with what assets.",NULL,"Add support for deploying YARN app into HDFS As a s c d developer, I'd like to add support to deploy YARN App into HDFS automatically,","so I can have the orchestrate overall deployment by leveraging the manifest to deploy where and with what assets.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26293,"Add support for passing parameters to YARN container As a s c d user, I'd like to have the option to support passing definition parameters into YARN container, so I can effectively use those params within the module running inside the container.",NULL,"Add support for passing parameters to YARN container As a s c d user, I'd like to have the option to support passing definition parameters into YARN container,","so I can effectively use those params within the module running inside the container.","Add for who this story is","well_formed","no_role","high",False
26293,"Add support for passing parameters to YARN container As a s c d user, I'd like to have the option to support passing definition parameters into YARN container, so I can effectively use those params within the module running inside the container.",NULL,"Add support for passing parameters to YARN container As a s c d user, I'd like to have the option to support passing definition parameters into YARN container,","so I can effectively use those params within the module running inside the container.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26281,"Refactor which itself has the meat of the configuration . This is typically what boot AutoConfiguration is for. Moreover, adding a new binding eg Kafka or a stub for module testing would require to crack open EnableModule",NULL,"Refactor which itself has the meat of the configuration . This is typically what boot AutoConfiguration is for. Moreover, adding a new binding eg Kafka or a stub for module testing would require to crack open EnableModule",NULL,"Add for who this story is","well_formed","no_role","high",False
26344,"Add support to load Hadoop distribution of choice As a s c d user, I'd like to have the option to choose Hadoop distribution of choice, so I can load the right Hadoop libraries in the CP. ",NULL,"Add support to load Hadoop distribution of choice As a s c d user, I'd like to have the option to choose Hadoop distribution of choice,","so I can load the right Hadoop libraries in the CP.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26338,"Port Kafka as s c s source As a s c d developer, I'd like to move to build streaming pipeline.",NULL,"Port Kafka as s c s source As a s c d developer, I'd like to move to build streaming pipeline.",NULL,"Add for who this story is","well_formed","no_role","high",False
26339,"Port Kafka as s c s sink As a s c d developer, I'd like to move to build streaming pipeline.",NULL,"Port Kafka as s c s sink As a s c d developer, I'd like to move to build streaming pipeline.",NULL,"Add for who this story is","well_formed","no_role","high",False
26281,"Refactor which itself has the meat of the configuration . This is typically what boot AutoConfiguration is for. Moreover, adding a new binding eg Kafka or a stub for module testing would require to crack open EnableModule",NULL,"Refactor which itself has the meat of the configuration . This is typically what boot AutoConfiguration is for. Moreover, adding a new binding eg Kafka or a stub for module testing would require to crack open EnableModule",NULL,"Refactor which itself has the meat of the configuration . This is typically what boot AutoConfiguration is for. Moreover, adding a new binding eg Kafka<span class='highlight-text severity-high'> or </span>a stub for module testing would require to crack open EnableModule","atomic","conjunctions","high",False
26281,"Refactor which itself has the meat of the configuration . This is typically what boot AutoConfiguration is for. Moreover, adding a new binding eg Kafka or a stub for module testing would require to crack open EnableModule",NULL,"Refactor which itself has the meat of the configuration . This is typically what boot AutoConfiguration is for. Moreover, adding a new binding eg Kafka or a stub for module testing would require to crack open EnableModule",NULL,"Refactor which itself has the meat of the configuration <span class='highlight-text severity-high'>. This is typically what boot AutoConfiguration is for. Moreover, adding a new binding eg Kafka or a stub for module testing would require to crack open EnableModule</span>","minimal","punctuation","high",False
26287,"Module Launcher properties improvments Improve Spring Cloud Stream module launcher resolver properties 1 Support comma separated remoteRepositories 2 Classify group the properties",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26287,"Module Launcher properties improvments Improve Spring Cloud Stream module launcher resolver properties 1 Support comma separated remoteRepositories 2 Classify group the properties",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26298,"Refactor to use Boot s JarLauncher As a s c s developer, I'd like to refactor the current API, so we don t have to maintain duplicate functionality.",NULL,"Refactor to use Boot s JarLauncher As a s c s developer, I'd like to refactor the current API,","so we don t have to maintain duplicate functionality.","Add for who this story is","well_formed","no_role","high",False
26298,"Refactor to use Boot s JarLauncher As a s c s developer, I'd like to refactor the current API, so we don t have to maintain duplicate functionality.",NULL,"Refactor to use Boot s JarLauncher As a s c s developer, I'd like to refactor the current API,","so we don t have to maintain duplicate functionality.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26296,"Refactor YARN deployer to deploy asycnhrounously As a s c d developer, I'd like to make the deployer work asynchronously, so I can use the shell to return quickly and also queue deploy operations within YARN as tasks.",NULL,"Refactor YARN deployer to deploy asycnhrounously As a s c d developer, I'd like to make the deployer work asynchronously,","so I can use the shell to return quickly and also queue deploy operations within YARN as tasks.","Add for who this story is","well_formed","no_role","high",False
26296,"Refactor YARN deployer to deploy asycnhrounously As a s c d developer, I'd like to make the deployer work asynchronously, so I can use the shell to return quickly and also queue deploy operations within YARN as tasks.",NULL,"Refactor YARN deployer to deploy asycnhrounously As a s c d developer, I'd like to make the deployer work asynchronously,","so I can use the shell to return quickly and also queue deploy operations within YARN as tasks.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26303,"Create foundation to support s c s processor modules As a s c d developer, I'd like to create foundation to support processor as OOTB modules, so I can use the processor modules from repo to build streaming pipeline.",NULL,"Create foundation to support s c s proces","sor modules As a s c d developer, I'd like to create foundation to support processor as OOTB modules, so I can use the processor modules from repo to build streaming pipeline.","Add for who this story is","well_formed","no_role","high",False
26303,"Create foundation to support s c s processor modules As a s c d developer, I'd like to create foundation to support processor as OOTB modules, so I can use the processor modules from repo to build streaming pipeline.",NULL,"Create foundation to support s c s proces","sor modules As a s c d developer, I'd like to create foundation to support processor as OOTB modules, so I can use the processor modules from repo to build streaming pipeline.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26297,"Spike Study how to resolve and add JARs to Boot loader As a s c d developer, I'd like to experiment how do we resolve and then add module dependent JAR s to Boot loader, so I have an approach to handle external libraries required by OOTB modules. ",NULL,"Spike Study how to re","solve and add JARs to Boot loader As a s c d developer, I'd like to experiment how do we resolve and then add module dependent JAR s to Boot loader, so I have an approach to handle external libraries required by OOTB modules.","Add for who this story is","well_formed","no_role","high",False
26297,"Spike Study how to resolve and add JARs to Boot loader As a s c d developer, I'd like to experiment how do we resolve and then add module dependent JAR s to Boot loader, so I have an approach to handle external libraries required by OOTB modules. ",NULL,"Spike Study how to re","solve and add JARs to Boot loader As a s c d developer, I'd like to experiment how do we resolve and then add module dependent JAR s to Boot loader, so I have an approach to handle external libraries required by OOTB modules.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26300,"Move external library resolver to its own project As a s c d developer, I'd like to move the external library to its own project, so we have a clear separation of functionalities in s c d repo.",NULL,"Move external library re","solver to its own project As a s c d developer, I'd like to move the external library to its own project, so we have a clear separation of functionalities in s c d repo.","Add for who this story is","well_formed","no_role","high",False
26300,"Move external library resolver to its own project As a s c d developer, I'd like to move the external library to its own project, so we have a clear separation of functionalities in s c d repo.",NULL,"Move external library re","solver to its own project As a s c d developer, I'd like to move the external library to its own project, so we have a clear separation of functionalities in s c d repo.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26299,"Document JMX features Document jmx command line options and refer to jolokia",NULL,"Document JMX features Document jmx command line options and refer to jolokia",NULL,"Add for who this story is","well_formed","no_role","high",False
26299,"Document JMX features Document jmx command line options and refer to jolokia",NULL,"Document JMX features Document jmx command line options and refer to jolokia",NULL,"Document JMX features Document jmx command line options<span class='highlight-text severity-high'> and </span>refer to jolokia","atomic","conjunctions","high",False
26301,"Port SFTP as s c s source module As a Spring XD developer, I'd like to port SFTP module from XD to s c s repo, so I can use it as source modules to build streaming pipeline. ",NULL,NULL,"source module As a Spring XD developer, I'd like to port SFTP module from XD to s c s repo, so I can use it as source modules to build streaming pipeline.","Add what you want to achieve","well_formed","no_means","high",False
26301,"Port SFTP as s c s source module As a Spring XD developer, I'd like to port SFTP module from XD to s c s repo, so I can use it as source modules to build streaming pipeline. ",NULL,NULL,"source module As a Spring XD developer, I'd like to port SFTP module from XD to s c s repo, so I can use it as source modules to build streaming pipeline.","Add for who this story is","well_formed","no_role","high",False
26301,"Port SFTP as s c s source module As a Spring XD developer, I'd like to port SFTP module from XD to s c s repo, so I can use it as source modules to build streaming pipeline. ",NULL,NULL,"source module As a Spring XD developer, I'd like to port SFTP module from XD to s c s repo, so I can use it as source modules to build streaming pipeline.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26302,"Create a new project for RedisRule As a s c d developer, I'd like to create a new project to contain all the rules associated contract, so it is isolated from core functionalities and reusable by test coverage as needed. Consider moving this coverage to SI commons or equivalent. ",NULL,"Create a new project for RedisRule As a s c d developer, I'd like to create a new project to contain all the rules as","sociated contract, so it is isolated from core functionalities and reusable by test coverage as needed. Consider moving this coverage to SI commons or equivalent.","Add for who this story is","well_formed","no_role","high",False
26302,"Create a new project for RedisRule As a s c d developer, I'd like to create a new project to contain all the rules associated contract, so it is isolated from core functionalities and reusable by test coverage as needed. Consider moving this coverage to SI commons or equivalent. ",NULL,"Create a new project for RedisRule As a s c d developer, I'd like to create a new project to contain all the rules as","sociated contract, so it is isolated from core functionalities and reusable by test coverage as needed. Consider moving this coverage to SI commons or equivalent.","Create a new project for RedisRule As a s c d developer, I'd like to create a new project to contain all the rules associated contract, so it is isolated from core functionalities and reusable by test coverage as needed<span class='highlight-text severity-high'>. Consider moving this coverage to SI commons or equivalent. </span>","minimal","punctuation","high",False
26302,"Create a new project for RedisRule As a s c d developer, I'd like to create a new project to contain all the rules associated contract, so it is isolated from core functionalities and reusable by test coverage as needed. Consider moving this coverage to SI commons or equivalent. ",NULL,"Create a new project for RedisRule As a s c d developer, I'd like to create a new project to contain all the rules as","sociated contract, so it is isolated from core functionalities and reusable by test coverage as needed. Consider moving this coverage to SI commons or equivalent.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26310,"Support shell commands to interact with module registry As a s c d developer, I'd like to have .",NULL,"Support shell commands to interact with module registry As a s c d developer, I'd like to have .",NULL,"Add for who this story is","well_formed","no_role","high",False
26305,"Enable offline mode for As a s c s developer, I'd like to enable , so I can pull the module artifacts from local instead of remote maven repo.",NULL,"Enable offline mode for As a s c s developer, I'd like to enable ,","so I can pull the module artifacts from local instead of remote maven repo.","Add for who this story is","well_formed","no_role","high",False
26305,"Enable offline mode for As a s c s developer, I'd like to enable , so I can pull the module artifacts from local instead of remote maven repo.",NULL,"Enable offline mode for As a s c s developer, I'd like to enable ,","so I can pull the module artifacts from local instead of remote maven repo.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26307,"Fix s on the claspath that needs cleanup. Building and running with xd singlenode script gave this error Jun 27, 2013 3 18 16 PM process SEVERE Error processing request at at at at at at at at ",NULL,"Fix s on the claspath that needs cleanup. Building and running with xd singlenode script gave this error Jun 27, 2013 3 18 16 PM process SEVERE Error processing request at at at at at at at at ",NULL,"Add for who this story is","well_formed","no_role","high",False
26307,"Fix s on the claspath that needs cleanup. Building and running with xd singlenode script gave this error Jun 27, 2013 3 18 16 PM process SEVERE Error processing request at at at at at at at at ",NULL,"Fix s on the claspath that needs cleanup. Building and running with xd singlenode script gave this error Jun 27, 2013 3 18 16 PM process SEVERE Error processing request at at at at at at at at ",NULL,"Fix s on the claspath that needs cleanup. Building<span class='highlight-text severity-high'> and </span>running with xd singlenode script gave this error Jun 27, 2013 3 18 16 PM process SEVERE Error processing request at at at at at at at at ","atomic","conjunctions","high",False
26307,"Fix s on the claspath that needs cleanup. Building and running with xd singlenode script gave this error Jun 27, 2013 3 18 16 PM process SEVERE Error processing request at at at at at at at at ",NULL,"Fix s on the claspath that needs cleanup. Building and running with xd singlenode script gave this error Jun 27, 2013 3 18 16 PM process SEVERE Error processing request at at at at at at at at ",NULL,"Fix s on the claspath that needs cleanup<span class='highlight-text severity-high'>. Building and running with xd singlenode script gave this error Jun 27, 2013 3 18 16 PM process SEVERE Error processing request at at at at at at at at </span>","minimal","punctuation","high",False
26308,"Create a Rabbit Kafka Available Rule in s c s m Can take from previous implementation in Should have a way to enforce not skipping tests based on an environment variable. Consider moving this coverage to SI commons or equivalent. ",NULL,"Create a Rabbit Kafka Available Rule in s c s m Can take from previous implementation in Should have a way to enforce not skipping tests based on an environment variable. Consider moving this coverage to SI commons or equivalent. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26308,"Create a Rabbit Kafka Available Rule in s c s m Can take from previous implementation in Should have a way to enforce not skipping tests based on an environment variable. Consider moving this coverage to SI commons or equivalent. ",NULL,"Create a Rabbit Kafka Available Rule in s c s m Can take from previous implementation in Should have a way to enforce not skipping tests based on an environment variable. Consider moving this coverage to SI commons or equivalent. ",NULL,"Create a Rabbit Kafka Available Rule in s c s m Can take from previous implementation in Should have a way to enforce not skipping tests based on an environment variable<span class='highlight-text severity-high'>. Consider moving this coverage to SI commons or equivalent. </span>","minimal","punctuation","high",False
26309,"Update Shell to support tasks via the CLI. ",NULL,"Update Shell to support tasks via the CLI. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26311,"Investigate JMX object naming of deployed modules and inbound outbound channel adapters. The object naming is still not ideal for XD since SI conventions add some noise. Likely need to design and implement a custom naming strategy",NULL,"Investigate JMX object naming of deployed modules and inbound outbound channel adapters. The object naming is still not ideal for XD since SI conventions add some noise. Likely need to design and implement a custom naming strategy",NULL,"Add for who this story is","well_formed","no_role","high",False
26311,"Investigate JMX object naming of deployed modules and inbound outbound channel adapters. The object naming is still not ideal for XD since SI conventions add some noise. Likely need to design and implement a custom naming strategy",NULL,"Investigate JMX object naming of deployed modules and inbound outbound channel adapters. The object naming is still not ideal for XD since SI conventions add some noise. Likely need to design and implement a custom naming strategy",NULL,"Investigate JMX object naming of deployed modules<span class='highlight-text severity-high'> and </span>inbound outbound channel adapters. The object naming is still not ideal for XD since SI conventions add some noise. Likely need to design and implement a custom naming strategy","atomic","conjunctions","high",False
26311,"Investigate JMX object naming of deployed modules and inbound outbound channel adapters. The object naming is still not ideal for XD since SI conventions add some noise. Likely need to design and implement a custom naming strategy",NULL,"Investigate JMX object naming of deployed modules and inbound outbound channel adapters. The object naming is still not ideal for XD since SI conventions add some noise. Likely need to design and implement a custom naming strategy",NULL,"Investigate JMX object naming of deployed modules and inbound outbound channel adapters<span class='highlight-text severity-high'>. The object naming is still not ideal for XD since SI conventions add some noise. Likely need to design and implement a custom naming strategy</span>","minimal","punctuation","high",False
26304,"Add SmartLifecycle to Make implement SmartLifecycle so that it gets started with the highest precedence and before any other message producing bean.",NULL,"Add SmartLifecycle to Make implement SmartLifecycle","so that it gets started with the highest precedence and before any other message producing bean.","Add for who this story is","well_formed","no_role","high",False
26304,"Add SmartLifecycle to Make implement SmartLifecycle so that it gets started with the highest precedence and before any other message producing bean.",NULL,"Add SmartLifecycle to Make implement SmartLifecycle","so that it gets started with the highest precedence and before any other message producing bean.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26295,"Add support to start Apps in YARN automatically by type As an s c d developer, I'd like to add support to negotiate with the ResourceManager REST APIs to deploy modules by groups. so I can build instrumentation to start the App instances automatically. Perhaps also take into account of the App specifics such as . ",NULL,"Add support to start Apps in YARN automatically by type As an s c d developer, I'd like to add support to negotiate with the Re","sourceManager REST APIs to deploy modules by groups. so I can build instrumentation to start the App instances automatically. Perhaps also take into account of the App specifics such as .","Add for who this story is","well_formed","no_role","high",False
26295,"Add support to start Apps in YARN automatically by type As an s c d developer, I'd like to add support to negotiate with the ResourceManager REST APIs to deploy modules by groups. so I can build instrumentation to start the App instances automatically. Perhaps also take into account of the App specifics such as . ",NULL,"Add support to start Apps in YARN automatically by type As an s c d developer, I'd like to add support to negotiate with the Re","sourceManager REST APIs to deploy modules by groups. so I can build instrumentation to start the App instances automatically. Perhaps also take into account of the App specifics such as .","Add support to start Apps in YARN automatically by type As an s c d developer, I'd like to add support to negotiate with the ResourceManager REST APIs to deploy modules by groups<span class='highlight-text severity-high'>. so I can build instrumentation to start the App instances automatically. Perhaps also take into account of the App specifics such as . </span>","minimal","punctuation","high",False
26295,"Add support to start Apps in YARN automatically by type As an s c d developer, I'd like to add support to negotiate with the ResourceManager REST APIs to deploy modules by groups. so I can build instrumentation to start the App instances automatically. Perhaps also take into account of the App specifics such as . ",NULL,"Add support to start Apps in YARN automatically by type As an s c d developer, I'd like to add support to negotiate with the Re","sourceManager REST APIs to deploy modules by groups. so I can build instrumentation to start the App instances automatically. Perhaps also take into account of the App specifics such as .","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26319,"Document s c d architecture and deployment variants As a s c d developer, I'd like to produce ref. documentation for s c d architecture, so I could define 1.x and 2.x deployment differences. ",NULL,"Document s c d architecture and deployment variants As a s c d developer, I'd like to produce ref. documentation for s c d architecture,","so I could define 1.x and 2.x deployment differences.","Add for who this story is","well_formed","no_role","high",False
26319,"Document s c d architecture and deployment variants As a s c d developer, I'd like to produce ref. documentation for s c d architecture, so I could define 1.x and 2.x deployment differences. ",NULL,"Document s c d architecture and deployment variants As a s c d developer, I'd like to produce ref. documentation for s c d architecture,","so I could define 1.x and 2.x deployment differences.","Document s c d architecture<span class='highlight-text severity-high'> and </span>deployment variants As a s c d developer, I'd like to produce ref. documentation for s c d architecture, so I could define 1.x and 2.x deployment differences. ","atomic","conjunctions","high",False
26319,"Document s c d architecture and deployment variants As a s c d developer, I'd like to produce ref. documentation for s c d architecture, so I could define 1.x and 2.x deployment differences. ",NULL,"Document s c d architecture and deployment variants As a s c d developer, I'd like to produce ref. documentation for s c d architecture,","so I could define 1.x and 2.x deployment differences.","Document s c d architecture and deployment variants As a s c d developer, I'd like to produce ref<span class='highlight-text severity-high'>. documentation for s c d architecture, so I could define 1.x and 2.x deployment differences. </span>","minimal","punctuation","high",False
26319,"Document s c d architecture and deployment variants As a s c d developer, I'd like to produce ref. documentation for s c d architecture, so I could define 1.x and 2.x deployment differences. ",NULL,"Document s c d architecture and deployment variants As a s c d developer, I'd like to produce ref. documentation for s c d architecture,","so I could define 1.x and 2.x deployment differences.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26313,"Use mocks in shell tests Instead of using real moduleDeployer , try using mocks so that the module deployer downloading the maven co ordinates from repo can be avoided for module deployment case . Since module deployer and controllers are tested individually, it would be good to focus on shell functionality only for the shell tests.",NULL,"Use mocks in shell tests Instead of using real moduleDeployer , try using mocks","so that the module deployer downloading the maven co ordinates from repo can be avoided for module deployment case . Since module deployer and controllers are tested individually, it would be good to focus on shell functionality only for the shell tests.","Add for who this story is","well_formed","no_role","high",False
26340,"Port Rabbit as s c s sink As a s c d developer, I'd like to move to build streaming pipeline.",NULL,"Port Rabbit as s c s sink As a s c d developer, I'd like to move to build streaming pipeline.",NULL,"Add for who this story is","well_formed","no_role","high",False
26313,"Use mocks in shell tests Instead of using real moduleDeployer , try using mocks so that the module deployer downloading the maven co ordinates from repo can be avoided for module deployment case . Since module deployer and controllers are tested individually, it would be good to focus on shell functionality only for the shell tests.",NULL,"Use mocks in shell tests Instead of using real moduleDeployer , try using mocks","so that the module deployer downloading the maven co ordinates from repo can be avoided for module deployment case . Since module deployer and controllers are tested individually, it would be good to focus on shell functionality only for the shell tests.","Use mocks in shell tests Instead of using real moduleDeployer , try using mocks so that the module deployer downloading the maven co ordinates from repo can be avoided for module deployment case <span class='highlight-text severity-high'>. Since module deployer and controllers are tested individually, it would be good to focus on shell functionality only for the shell tests.</span>","minimal","punctuation","high",False
26313,"Use mocks in shell tests Instead of using real moduleDeployer , try using mocks so that the module deployer downloading the maven co ordinates from repo can be avoided for module deployment case . Since module deployer and controllers are tested individually, it would be good to focus on shell functionality only for the shell tests.",NULL,"Use mocks in shell tests Instead of using real moduleDeployer , try using mocks","so that the module deployer downloading the maven co ordinates from repo can be avoided for module deployment case . Since module deployer and controllers are tested individually, it would be good to focus on shell functionality only for the shell tests.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26315,"Create a spring cloud stream timestamp task module Create a timestamp job that will be used a a sample for users to create their own spring boot based jobs. ",NULL,"Create a spring cloud stream timestamp task module Create a timestamp job that will be used a a sample for users to create their own spring boot based jobs. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26326,"Create infrastructure for Spring cloud task modules Create Parent pom file for build Create .settings file Migrate Timestamp task from SCSM to SCTM. ",NULL,"Create infrastructure for Spring cloud task modules Create Parent pom file for build Create .settings file Migrate Timestamp task from SCSM to SCTM. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26317,"Create gh pages for s c d and s c s m repos As a s c d developer, I'd like to setup branch for s c d and s c s m repos, so I can start pushing documentation with PR commits.",NULL,"Create gh pages for s c d and s c s m repos As a s c d developer, I'd like to setup branch for s c d and s c s m repos,","so I can start pushing documentation with PR commits.","Add for who this story is","well_formed","no_role","high",False
26317,"Create gh pages for s c d and s c s m repos As a s c d developer, I'd like to setup branch for s c d and s c s m repos, so I can start pushing documentation with PR commits.",NULL,"Create gh pages for s c d and s c s m repos As a s c d developer, I'd like to setup branch for s c d and s c s m repos,","so I can start pushing documentation with PR commits.","Create gh pages for s c d<span class='highlight-text severity-high'> and </span>s c s m repos As a s c d developer, I'd like to setup branch for s c d and s c s m repos, so I can start pushing documentation with PR commits.","atomic","conjunctions","high",False
26317,"Create gh pages for s c d and s c s m repos As a s c d developer, I'd like to setup branch for s c d and s c s m repos, so I can start pushing documentation with PR commits.",NULL,"Create gh pages for s c d and s c s m repos As a s c d developer, I'd like to setup branch for s c d and s c s m repos,","so I can start pushing documentation with PR commits.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26318,"Fix Kafka Binder for s c s modules As a s c s developer, I'd like to fix the binder, so I can create messaging microservices apps and successfully bind them to an operational Kafka broker. ",NULL,"Fix Kafka Binder for s c s modules As a s c s developer, I'd like to fix the binder,","so I can create messaging microservices apps and successfully bind them to an operational Kafka broker.","Add for who this story is","well_formed","no_role","high",False
26318,"Fix Kafka Binder for s c s modules As a s c s developer, I'd like to fix the binder, so I can create messaging microservices apps and successfully bind them to an operational Kafka broker. ",NULL,"Fix Kafka Binder for s c s modules As a s c s developer, I'd like to fix the binder,","so I can create messaging microservices apps and successfully bind them to an operational Kafka broker.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26321,"Deploy multiple instances of a module Currently we deploy a single instance, and ignore the instances setting. It is easy to change this in the ModuleDeployer, but there is no guarantee this will work in the ModuleLauncher, so we hold off until that can be verified.",NULL,"Deploy multiple instances of a module Currently we deploy a single instance, and ignore the instances setting. It is easy to change this in the ModuleDeployer, but there is no guarantee this will work in the ModuleLauncher,","so we hold off until that can be verified.","Add for who this story is","well_formed","no_role","high",False
26321,"Deploy multiple instances of a module Currently we deploy a single instance, and ignore the instances setting. It is easy to change this in the ModuleDeployer, but there is no guarantee this will work in the ModuleLauncher, so we hold off until that can be verified.",NULL,"Deploy multiple instances of a module Currently we deploy a single instance, and ignore the instances setting. It is easy to change this in the ModuleDeployer, but there is no guarantee this will work in the ModuleLauncher,","so we hold off until that can be verified.","Deploy multiple instances of a module Currently we deploy a single instance,<span class='highlight-text severity-high'> and </span>ignore the instances setting. It is easy to change this in the ModuleDeployer, but there is no guarantee this will work in the ModuleLauncher, so we hold off until that can be verified.","atomic","conjunctions","high",False
26321,"Deploy multiple instances of a module Currently we deploy a single instance, and ignore the instances setting. It is easy to change this in the ModuleDeployer, but there is no guarantee this will work in the ModuleLauncher, so we hold off until that can be verified.",NULL,"Deploy multiple instances of a module Currently we deploy a single instance, and ignore the instances setting. It is easy to change this in the ModuleDeployer, but there is no guarantee this will work in the ModuleLauncher,","so we hold off until that can be verified.","Deploy multiple instances of a module Currently we deploy a single instance, and ignore the instances setting<span class='highlight-text severity-high'>. It is easy to change this in the ModuleDeployer, but there is no guarantee this will work in the ModuleLauncher, so we hold off until that can be verified.</span>","minimal","punctuation","high",False
26321,"Deploy multiple instances of a module Currently we deploy a single instance, and ignore the instances setting. It is easy to change this in the ModuleDeployer, but there is no guarantee this will work in the ModuleLauncher, so we hold off until that can be verified.",NULL,"Deploy multiple instances of a module Currently we deploy a single instance, and ignore the instances setting. It is easy to change this in the ModuleDeployer, but there is no guarantee this will work in the ModuleLauncher,","so we hold off until that can be verified.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26322,"Correctly report state of module instances Currently only the STARTED application and application instance status is recognised. This issue will look at the other possible states and report them as module instance states. This would be trivial if we knew what the possible states might be and how we should interpret them for module instance state.",NULL,"Correctly report state of module instances Currently only the STARTED application and application instance status is recognised. This issue will look at the other possible states and report them as module instance states. This would be trivial if we knew what the possible states might be and how we should interpret them for module instance state.",NULL,"Add for who this story is","well_formed","no_role","high",False
26322,"Correctly report state of module instances Currently only the STARTED application and application instance status is recognised. This issue will look at the other possible states and report them as module instance states. This would be trivial if we knew what the possible states might be and how we should interpret them for module instance state.",NULL,"Correctly report state of module instances Currently only the STARTED application and application instance status is recognised. This issue will look at the other possible states and report them as module instance states. This would be trivial if we knew what the possible states might be and how we should interpret them for module instance state.",NULL,"Correctly report state of module instances Currently only the STARTED application<span class='highlight-text severity-high'> and </span>application instance status is recognised. This issue will look at the other possible states and report them as module instance states. This would be trivial if we knew what the possible states might be and how we should interpret them for module instance state.","atomic","conjunctions","high",False
26322,"Correctly report state of module instances Currently only the STARTED application and application instance status is recognised. This issue will look at the other possible states and report them as module instance states. This would be trivial if we knew what the possible states might be and how we should interpret them for module instance state.",NULL,"Correctly report state of module instances Currently only the STARTED application and application instance status is recognised. This issue will look at the other possible states and report them as module instance states. This would be trivial if we knew what the possible states might be and how we should interpret them for module instance state.",NULL,"Correctly report state of module instances Currently only the STARTED application and application instance status is recognised<span class='highlight-text severity-high'>. This issue will look at the other possible states and report them as module instance states. This would be trivial if we knew what the possible states might be and how we should interpret them for module instance state.</span>","minimal","punctuation","high",False
26323,"Handle paginated responses Currently we handle only a single page response from CC SPI list requests, but potentially there could be multiple ones.",NULL,"Handle paginated responses Currently we handle only a single page response from CC SPI list requests, but potentially there could be multiple ones.",NULL,"Add for who this story is","well_formed","no_role","high",False
26324,"Speed Upload of module launcher bits is slow because we do not take into account the CC cache. To fix this we need to use an async upload, and to somehow generate the SHA, etc, for the Module Launcher so that CC can pre empt uploading all the bits every time.",NULL,"Speed Upload of module launcher bits is slow because we do not take into account the CC cache. To fix this we need to use an async upload, and to somehow generate the SHA, etc, for the Module Launcher","so that CC can pre empt uploading all the bits every time.","Add for who this story is","well_formed","no_role","high",False
26324,"Speed Upload of module launcher bits is slow because we do not take into account the CC cache. To fix this we need to use an async upload, and to somehow generate the SHA, etc, for the Module Launcher so that CC can pre empt uploading all the bits every time.",NULL,"Speed Upload of module launcher bits is slow because we do not take into account the CC cache. To fix this we need to use an async upload, and to somehow generate the SHA, etc, for the Module Launcher","so that CC can pre empt uploading all the bits every time.","Speed Upload of module launcher bits is slow because we do not take into account the CC cache. To fix this we need to use an async upload,<span class='highlight-text severity-high'> and </span>to somehow generate the SHA, etc, for the Module Launcher so that CC can pre empt uploading all the bits every time.","atomic","conjunctions","high",False
26324,"Speed Upload of module launcher bits is slow because we do not take into account the CC cache. To fix this we need to use an async upload, and to somehow generate the SHA, etc, for the Module Launcher so that CC can pre empt uploading all the bits every time.",NULL,"Speed Upload of module launcher bits is slow because we do not take into account the CC cache. To fix this we need to use an async upload, and to somehow generate the SHA, etc, for the Module Launcher","so that CC can pre empt uploading all the bits every time.","Speed Upload of module launcher bits is slow because we do not take into account the CC cache<span class='highlight-text severity-high'>. To fix this we need to use an async upload, and to somehow generate the SHA, etc, for the Module Launcher so that CC can pre empt uploading all the bits every time.</span>","minimal","punctuation","high",False
26324,"Speed Upload of module launcher bits is slow because we do not take into account the CC cache. To fix this we need to use an async upload, and to somehow generate the SHA, etc, for the Module Launcher so that CC can pre empt uploading all the bits every time.",NULL,"Speed Upload of module launcher bits is slow because we do not take into account the CC cache. To fix this we need to use an async upload, and to somehow generate the SHA, etc, for the Module Launcher","so that CC can pre empt uploading all the bits every time.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26325,"Add RxJava processor module As a module author, I would like to apply RxJava processor module with spring cloud stream. ",NULL,"Add RxJava processor module As a module author, I would like to apply RxJava processor module with spring cloud stream. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26328,"Remove in yml files. Need to make define version during a build and allow to override location of those files.",NULL,"Remove in yml files. Need to make define version during a build and allow to override location of those files.",NULL,"Add for who this story is","well_formed","no_role","high",False
26328,"Remove in yml files. Need to make define version during a build and allow to override location of those files.",NULL,"Remove in yml files. Need to make define version during a build and allow to override location of those files.",NULL,"Remove in yml files. Need to make define version during a build<span class='highlight-text severity-high'> and </span>allow to override location of those files.","atomic","conjunctions","high",False
26328,"Remove in yml files. Need to make define version during a build and allow to override location of those files.",NULL,"Remove in yml files. Need to make define version during a build and allow to override location of those files.",NULL,"Remove in yml files<span class='highlight-text severity-high'>. Need to make define version during a build and allow to override location of those files.</span>","minimal","punctuation","high",False
26327,"Create CI Build for SCTM ",NULL,"Create CI Build for SCTM ",NULL,"Add for who this story is","well_formed","no_role","high",False
26452,"Create bridge processor See This is needed to support channel channel type constructs",NULL,"Create bridge processor See This is needed to support channel channel type constructs",NULL,"Add for who this story is","well_formed","no_role","high",False
26451,"Upgrade to SI 4.2.1 As a developer, I'd like to upgrade to SI 4.2.1 release, so I can take advantage of the latest improvements.",NULL,"Upgrade to SI 4.2.1 As a developer, I'd like to upgrade to SI 4.2.1 release,","so I can take advantage of the latest improvements.","Add for who this story is","well_formed","no_role","high",False
26451,"Upgrade to SI 4.2.1 As a developer, I'd like to upgrade to SI 4.2.1 release, so I can take advantage of the latest improvements.",NULL,"Upgrade to SI 4.2.1 As a developer, I'd like to upgrade to SI 4.2.1 release,","so I can take advantage of the latest improvements.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26316,"Add BatchMbeanExporter for batch modules ",NULL,"Add BatchMbeanExporter for batch modules ",NULL,"Add for who this story is","well_formed","no_role","high",False
26320,"Replace gardenhose doc with new twitterstream ",NULL,"Replace gardenhose doc with new twitterstream ",NULL,"Add for who this story is","well_formed","no_role","high",False
26333,"Spike Investigate options for composed jobs repository As a XD developer, I'd like to explore repository options for composed jobs , so I have the leverage to read write composed job definitions.",NULL,"Spike Investigate options for composed jobs repository As a XD developer, I'd like to explore repository options for composed jobs ,","so I have the leverage to read write composed job definitions.","Add for who this story is","well_formed","no_role","high",False
26333,"Spike Investigate options for composed jobs repository As a XD developer, I'd like to explore repository options for composed jobs , so I have the leverage to read write composed job definitions.",NULL,"Spike Investigate options for composed jobs repository As a XD developer, I'd like to explore repository options for composed jobs ,","so I have the leverage to read write composed job definitions.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26331,"Add hdfs sink to module registry As a s c d developer, I'd like to add hdfs sink to module registry, so I can use this module to build streaming pipeline and write to Hadoop.",NULL,"Add hdfs sink to module registry As a s c d developer, I'd like to add hdfs sink to module registry,","so I can use this module to build streaming pipeline and write to Hadoop.","Add for who this story is","well_formed","no_role","high",False
26331,"Add hdfs sink to module registry As a s c d developer, I'd like to add hdfs sink to module registry, so I can use this module to build streaming pipeline and write to Hadoop.",NULL,"Add hdfs sink to module registry As a s c d developer, I'd like to add hdfs sink to module registry,","so I can use this module to build streaming pipeline and write to Hadoop.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26334,"Orchestrate job composition As a XD user, I'd like to orchestrate composed jobs, so I can bring multiple jobs into single workflow and operationalize.",NULL,"Orchestrate job composition As a XD user, I'd like to orchestrate composed jobs,","so I can bring multiple jobs into single workflow and operationalize.","Add for who this story is","well_formed","no_role","high",False
26334,"Orchestrate job composition As a XD user, I'd like to orchestrate composed jobs, so I can bring multiple jobs into single workflow and operationalize.",NULL,"Orchestrate job composition As a XD user, I'd like to orchestrate composed jobs,","so I can bring multiple jobs into single workflow and operationalize.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26341,"Spike Study support for different binder types for module channels As a s c d developer, I'd like to add support for having different binder types for module s channels, so I can plug as the source or sink to read and write respectively.",NULL,"Spike Study support for different binder types for module channels As a s c d developer, I'd like to add support for having different binder types for module s channels,","so I can plug as the source or sink to read and write respectively.","Add for who this story is","well_formed","no_role","high",False
26341,"Spike Study support for different binder types for module channels As a s c d developer, I'd like to add support for having different binder types for module s channels, so I can plug as the source or sink to read and write respectively.",NULL,"Spike Study support for different binder types for module channels As a s c d developer, I'd like to add support for having different binder types for module s channels,","so I can plug as the source or sink to read and write respectively.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26335,"Trigger Add support for fixed delay interval",NULL,"Trigger Add support for fixed delay interval",NULL,"Add for who this story is","well_formed","no_role","high",False
26337,"Port JDBC as s c s sink As a s c s m developer, I'd like to move to build streaming pipeline. See also XD 2250",NULL,"Port JDBC as s c s sink As a s c s m developer, I'd like to move to build streaming pipeline. See also XD 2250",NULL,"Add for who this story is","well_formed","no_role","high",False
26337,"Port JDBC as s c s sink As a s c s m developer, I'd like to move to build streaming pipeline. See also XD 2250",NULL,"Port JDBC as s c s sink As a s c s m developer, I'd like to move to build streaming pipeline. See also XD 2250",NULL,"Port JDBC as s c s sink As a s c s m developer, I'd like to move to build streaming pipeline<span class='highlight-text severity-high'>. See also XD 2250</span>","minimal","punctuation","high",False
26336,"Bind message properties to modules As a s c s developer, I'd like to support XD like features where modules bind to incoming messages via expressions or other mechanism, so I can bind message properties to every microservice modules. ",NULL,"Bind message properties to modules As a s c s developer, I'd like to support XD like features where modules bind to incoming messages via expressions or other mechanism,","so I can bind message properties to every microservice modules.","Add for who this story is","well_formed","no_role","high",False
26336,"Bind message properties to modules As a s c s developer, I'd like to support XD like features where modules bind to incoming messages via expressions or other mechanism, so I can bind message properties to every microservice modules. ",NULL,"Bind message properties to modules As a s c s developer, I'd like to support XD like features where modules bind to incoming messages via expressions or other mechanism,","so I can bind message properties to every microservice modules.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26344,"Add support to load Hadoop distribution of choice As a s c d user, I'd like to have the option to choose Hadoop distribution of choice, so I can load the right Hadoop libraries in the CP. ",NULL,"Add support to load Hadoop distribution of choice As a s c d user, I'd like to have the option to choose Hadoop distribution of choice,","so I can load the right Hadoop libraries in the CP.","Add for who this story is","well_formed","no_role","high",False
26342,"Add property override support for modules via external config file As a s c d developer, I'd like to pass any overrides via external config file, so I can influence and override the default module configurations. ex module resolution from a different maven coordinate . ",NULL,"Add property override support for modules via external config file As a s c d developer, I'd like to pass any overrides via external config file,","so I can influence and override the default module configurations. ex module resolution from a different maven coordinate .","Add for who this story is","well_formed","no_role","high",False
26342,"Add property override support for modules via external config file As a s c d developer, I'd like to pass any overrides via external config file, so I can influence and override the default module configurations. ex module resolution from a different maven coordinate . ",NULL,"Add property override support for modules via external config file As a s c d developer, I'd like to pass any overrides via external config file,","so I can influence and override the default module configurations. ex module resolution from a different maven coordinate .","Add property override support for modules via external config file As a s c d developer, I'd like to pass any overrides via external config file, so I can influence and override the default module configurations<span class='highlight-text severity-high'>. ex module resolution from a different maven coordinate . </span>","minimal","punctuation","high",False
26342,"Add property override support for modules via external config file As a s c d developer, I'd like to pass any overrides via external config file, so I can influence and override the default module configurations. ex module resolution from a different maven coordinate . ",NULL,"Add property override support for modules via external config file As a s c d developer, I'd like to pass any overrides via external config file,","so I can influence and override the default module configurations. ex module resolution from a different maven coordinate .","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26343,"Refactor CF SPI with CF java client library As a s c d developer, I'd like to refactor CC SPI deployer with CF java client, so I can improve the overall design and performance. ",NULL,"Refactor CF SPI with CF java client library As a s c d developer, I'd like to refactor CC SPI deployer with CF java client,","so I can improve the overall design and performance.","Add for who this story is","well_formed","no_role","high",False
26343,"Refactor CF SPI with CF java client library As a s c d developer, I'd like to refactor CC SPI deployer with CF java client, so I can improve the overall design and performance. ",NULL,"Refactor CF SPI with CF java client library As a s c d developer, I'd like to refactor CC SPI deployer with CF java client,","so I can improve the overall design and performance.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26345,"Trigger Add support for date based one time execution Currently Jobs can be either executed using cron expression or immediately at once. We should also support the one time scheduling of jobs in the future. Would this possibly require us to implement That could severely impact story points.",NULL,"Trigger Add support for date based one time execution Currently Jobs can be either executed using cron expression or immediately at once. We should also support the one time scheduling of jobs in the future. Would this possibly require us to implement That could severely impact story points.",NULL,"Add for who this story is","well_formed","no_role","high",False
26345,"Trigger Add support for date based one time execution Currently Jobs can be either executed using cron expression or immediately at once. We should also support the one time scheduling of jobs in the future. Would this possibly require us to implement That could severely impact story points.",NULL,"Trigger Add support for date based one time execution Currently Jobs can be either executed using cron expression or immediately at once. We should also support the one time scheduling of jobs in the future. Would this possibly require us to implement That could severely impact story points.",NULL,"Trigger Add support for date based one time execution Currently Jobs can be either executed using cron expression or immediately at once<span class='highlight-text severity-high'>. We should also support the one time scheduling of jobs in the future. Would this possibly require us to implement That could severely impact story points.</span>","minimal","punctuation","high",False
26347,"Move header enricher to XD proper As a XD developer, I'd like to move header enricher from modules repo to XD proper. ",NULL,"Move header enricher to XD proper As a XD developer, I'd like to move header enricher from modules repo to XD proper. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26348,"Update SI, Spring, and AMQP dependencies As a XD developer, I'd like to upgrade to SI 4.2, Spring 4.2.1, and AMQP 1.5 dependencies, so I can take advantage of the latest improvements. ",NULL,"Update SI, Spring, and AMQP dependencies As a XD developer, I'd like to upgrade to SI 4.2, Spring 4.2.1, and AMQP 1.5 dependencies,","so I can take advantage of the latest improvements.","Add for who this story is","well_formed","no_role","high",False
26348,"Update SI, Spring, and AMQP dependencies As a XD developer, I'd like to upgrade to SI 4.2, Spring 4.2.1, and AMQP 1.5 dependencies, so I can take advantage of the latest improvements. ",NULL,"Update SI, Spring, and AMQP dependencies As a XD developer, I'd like to upgrade to SI 4.2, Spring 4.2.1, and AMQP 1.5 dependencies,","so I can take advantage of the latest improvements.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26453,"Create TriggerDefinition Repository Redis based.",NULL,"Create TriggerDefinition Repository Redis based.",NULL,"Add for who this story is","well_formed","no_role","high",False
26330,"Complete Running on Cloud Foundry section in README As a s c d developer, I'd like to document Running on Cloud Foundry section in README, so it can be publicly available as deployment guideline.",NULL,"Complete Running on Cloud Foundry section in README As a s c d developer, I'd like to document Running on Cloud Foundry section in README,","so it can be publicly available as deployment guideline.","Add for who this story is","well_formed","no_role","high",False
26330,"Complete Running on Cloud Foundry section in README As a s c d developer, I'd like to document Running on Cloud Foundry section in README, so it can be publicly available as deployment guideline.",NULL,"Complete Running on Cloud Foundry section in README As a s c d developer, I'd like to document Running on Cloud Foundry section in README,","so it can be publicly available as deployment guideline.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26351,"Support hourly resolution in redis aggregate counter ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26351,"Support hourly resolution in redis aggregate counter ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26352,"Admin UI container shutdown not working As a user, I m not able to shutdown from Admin UI with the following stream definition deployed. stream create swagataTestIssue definition jdbc query select employee id, employee name, employer from EMPLOYEE password xdpwd hdfs deploy More details here ",NULL,"Admin UI container shutdown not working As a user, I m not able to shutdown from Admin UI with the following stream definition deployed. stream create swagataTestIssue definition jdbc query select employee id, employee name, employer from EMPLOYEE password xdpwd hdfs deploy More details here ",NULL,"Add for who this story is","well_formed","no_role","high",False
26352,"Admin UI container shutdown not working As a user, I m not able to shutdown from Admin UI with the following stream definition deployed. stream create swagataTestIssue definition jdbc query select employee id, employee name, employer from EMPLOYEE password xdpwd hdfs deploy More details here ",NULL,"Admin UI container shutdown not working As a user, I m not able to shutdown from Admin UI with the following stream definition deployed. stream create swagataTestIssue definition jdbc query select employee id, employee name, employer from EMPLOYEE password xdpwd hdfs deploy More details here ",NULL,"Admin UI container shutdown not working As a user, I m not able to shutdown from Admin UI with the following stream definition deployed<span class='highlight-text severity-high'>. stream create swagataTestIssue definition jdbc query select employee id, employee name, employer from EMPLOYEE password xdpwd hdfs deploy More details here </span>","minimal","punctuation","high",False
26353,"Upgrade SCSM hdfs sink to SHDP 2.3.0.M3 ",NULL,"Upgrade SCSM hdfs sink to SHDP 2.3.0.M3 ",NULL,"Add for who this story is","well_formed","no_role","high",False
26354,"Document application.yml ... xd data home file data config home file config module home file modules customModule home file custom modules ui home file allow origin ... We need to document how this property can be used to allow for external services to use the XD Rest API and how you can customize it using servers.yml ",NULL,"Document application.yml ... xd data home file data config home file config module home file modules customModule home file custom modules ui home file allow origin ... We need to document how this property can be used to allow for external services to use the XD Rest API and how you can customize it using servers.yml ",NULL,"Add for who this story is","well_formed","no_role","high",False
26354,"Document application.yml ... xd data home file data config home file config module home file modules customModule home file custom modules ui home file allow origin ... We need to document how this property can be used to allow for external services to use the XD Rest API and how you can customize it using servers.yml ",NULL,"Document application.yml ... xd data home file data config home file config module home file modules customModule home file custom modules ui home file allow origin ... We need to document how this property can be used to allow for external services to use the XD Rest API and how you can customize it using servers.yml ",NULL,"Document application.yml ... xd data home file data config home file config module home file modules customModule home file custom modules ui home file allow origin ... We need to document how this property can be used to allow for external services to use the XD Rest API<span class='highlight-text severity-high'> and </span>how you can customize it using servers.yml ","atomic","conjunctions","high",False
26354,"Document application.yml ... xd data home file data config home file config module home file modules customModule home file custom modules ui home file allow origin ... We need to document how this property can be used to allow for external services to use the XD Rest API and how you can customize it using servers.yml ",NULL,"Document application.yml ... xd data home file data config home file config module home file modules customModule home file custom modules ui home file allow origin ... We need to document how this property can be used to allow for external services to use the XD Rest API and how you can customize it using servers.yml ",NULL,"Document application<span class='highlight-text severity-high'>.yml ... xd data home file data config home file config module home file modules customModule home file custom modules ui home file allow origin ... We need to document how this property can be used to allow for external services to use the XD Rest API and how you can customize it using servers.yml </span>","minimal","punctuation","high",False
26362,"Add support to upload custom modules As an s c d user, I'd like to upload custom modules using shell rest api, so I can contribute modules and create streaming batch pipelines. ",NULL,"Add support to upload custom modules As an s c d user, I'd like to upload custom modules using shell rest api,","so I can contribute modules and create streaming batch pipelines.","Add for who this story is","well_formed","no_role","high",False
26362,"Add support to upload custom modules As an s c d user, I'd like to upload custom modules using shell rest api, so I can contribute modules and create streaming batch pipelines. ",NULL,"Add support to upload custom modules As an s c d user, I'd like to upload custom modules using shell rest api,","so I can contribute modules and create streaming batch pipelines.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26355,"Support for multiple connections to the same binder implementation As a s c s user, I'd like to have the option to use more than one binder connection factory, so I can mix and match where I consume and publish data. More details here ",NULL,"Support for multiple connections to the same binder implementation As a s c s user, I'd like to have the option to use more than one binder connection factory,","so I can mix and match where I consume and publish data. More details here","Add for who this story is","well_formed","no_role","high",False
26355,"Support for multiple connections to the same binder implementation As a s c s user, I'd like to have the option to use more than one binder connection factory, so I can mix and match where I consume and publish data. More details here ",NULL,"Support for multiple connections to the same binder implementation As a s c s user, I'd like to have the option to use more than one binder connection factory,","so I can mix and match where I consume and publish data. More details here","Support for multiple connections to the same binder implementation As a s c s user, I'd like to have the option to use more than one binder connection factory, so I can mix and match where I consume and publish data<span class='highlight-text severity-high'>. More details here </span>","minimal","punctuation","high",False
26355,"Support for multiple connections to the same binder implementation As a s c s user, I'd like to have the option to use more than one binder connection factory, so I can mix and match where I consume and publish data. More details here ",NULL,"Support for multiple connections to the same binder implementation As a s c s user, I'd like to have the option to use more than one binder connection factory,","so I can mix and match where I consume and publish data. More details here","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26357,"Implement Gemfire message channel binder As a s c s user, I'd like to have as the messaging middleware for low latency use cases. ",NULL,"Implement Gemfire message channel binder As a s c s user, I'd like to have as the messaging middleware for low latency use cases. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26360,"Add TAP support for Rabbit binder As an s c d user, I'd like to the primary pipeline, so I can fork the same data and do some ad hoc analysis without impacting the original stream.",NULL,"Add TAP support for Rabbit binder As an s c d user, I'd like to the primary pipeline,","so I can fork the same data and do some ad hoc analysis without impacting the original stream.","Add for who this story is","well_formed","no_role","high",False
26360,"Add TAP support for Rabbit binder As an s c d user, I'd like to the primary pipeline, so I can fork the same data and do some ad hoc analysis without impacting the original stream.",NULL,"Add TAP support for Rabbit binder As an s c d user, I'd like to the primary pipeline,","so I can fork the same data and do some ad hoc analysis without impacting the original stream.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26358,"Document partitioning through deployment properties As an s c d user, I'd like to have documentation on deployment manifest, so I could refer to the relevant bits on . I'd like to understand how streams withe ",NULL,"Document partitioning through deployment properties As an s c d user, I'd like to have documentation on deployment manifest,","so I could refer to the relevant bits on . I'd like to understand how streams withe","Add for who this story is","well_formed","no_role","high",False
26358,"Document partitioning through deployment properties As an s c d user, I'd like to have documentation on deployment manifest, so I could refer to the relevant bits on . I'd like to understand how streams withe ",NULL,"Document partitioning through deployment properties As an s c d user, I'd like to have documentation on deployment manifest,","so I could refer to the relevant bits on . I'd like to understand how streams withe","Document partitioning through deployment properties As an s c d user, I'd like to have documentation on deployment manifest, so I could refer to the relevant bits on <span class='highlight-text severity-high'>. I'd like to understand how streams withe </span>","minimal","punctuation","high",False
26358,"Document partitioning through deployment properties As an s c d user, I'd like to have documentation on deployment manifest, so I could refer to the relevant bits on . I'd like to understand how streams withe ",NULL,"Document partitioning through deployment properties As an s c d user, I'd like to have documentation on deployment manifest,","so I could refer to the relevant bits on . I'd like to understand how streams withe","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26359,"Document direct binding As an s c d user, I'd like to refer to documentation on direct binding , so I can use it as a reference to deploy a stream that includes directly bound modules. Example aggregate true ",NULL,"Document direct binding As an s c d user, I'd like to refer to documentation on direct binding ,","so I can use it as a reference to deploy a stream that includes directly bound modules. Example aggregate true","Add for who this story is","well_formed","no_role","high",False
26359,"Document direct binding As an s c d user, I'd like to refer to documentation on direct binding , so I can use it as a reference to deploy a stream that includes directly bound modules. Example aggregate true ",NULL,"Document direct binding As an s c d user, I'd like to refer to documentation on direct binding ,","so I can use it as a reference to deploy a stream that includes directly bound modules. Example aggregate true","Document direct binding As an s c d user, I'd like to refer to documentation on direct binding , so I can use it as a reference to deploy a stream that includes directly bound modules<span class='highlight-text severity-high'>. Example aggregate true </span>","minimal","punctuation","high",False
26359,"Document direct binding As an s c d user, I'd like to refer to documentation on direct binding , so I can use it as a reference to deploy a stream that includes directly bound modules. Example aggregate true ",NULL,"Document direct binding As an s c d user, I'd like to refer to documentation on direct binding ,","so I can use it as a reference to deploy a stream that includes directly bound modules. Example aggregate true","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26365,"Port Mail as s c s source As a Spring XD developer, I'd like to move module from XD to s c s m repo, so I can use it as source to build streaming pipeline. ",NULL,NULL,"source As a Spring XD developer, I'd like to move module from XD to s c s m repo, so I can use it as source to build streaming pipeline.","Add what you want to achieve","well_formed","no_means","high",False
26365,"Port Mail as s c s source As a Spring XD developer, I'd like to move module from XD to s c s m repo, so I can use it as source to build streaming pipeline. ",NULL,NULL,"source As a Spring XD developer, I'd like to move module from XD to s c s m repo, so I can use it as source to build streaming pipeline.","Add for who this story is","well_formed","no_role","high",False
26365,"Port Mail as s c s source As a Spring XD developer, I'd like to move module from XD to s c s m repo, so I can use it as source to build streaming pipeline. ",NULL,NULL,"source As a Spring XD developer, I'd like to move module from XD to s c s m repo, so I can use it as source to build streaming pipeline.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26367,"Port MQTT as s c s source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline. ",NULL,NULL,"source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.","Add what you want to achieve","well_formed","no_means","high",False
26367,"Port MQTT as s c s source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline. ",NULL,NULL,"source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.","Add for who this story is","well_formed","no_role","high",False
26367,"Port MQTT as s c s source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline. ",NULL,NULL,"source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26363,"Add dynamic addition to module registry As an s c d user, I'd like to contribute modules that immediately reflects in module registry, so I can create stream or task definitions using the shell rest api s. Currently the registry isn t flexible, as it is pretty much hard coded at registry bootstrap level ",NULL,"Add dynamic addition to module registry As an s c d user, I'd like to contribute modules that immediately reflects in module registry,","so I can create stream or task definitions using the shell rest api s. Currently the registry isn t flexible, as it is pretty much hard coded at registry bootstrap level","Add for who this story is","well_formed","no_role","high",False
26363,"Add dynamic addition to module registry As an s c d user, I'd like to contribute modules that immediately reflects in module registry, so I can create stream or task definitions using the shell rest api s. Currently the registry isn t flexible, as it is pretty much hard coded at registry bootstrap level ",NULL,"Add dynamic addition to module registry As an s c d user, I'd like to contribute modules that immediately reflects in module registry,","so I can create stream or task definitions using the shell rest api s. Currently the registry isn t flexible, as it is pretty much hard coded at registry bootstrap level","Add dynamic addition to module registry As an s c d user, I'd like to contribute modules that immediately reflects in module registry, so I can create stream or task definitions using the shell rest api s<span class='highlight-text severity-high'>. Currently the registry isn t flexible, as it is pretty much hard coded at registry bootstrap level </span>","minimal","punctuation","high",False
26363,"Add dynamic addition to module registry As an s c d user, I'd like to contribute modules that immediately reflects in module registry, so I can create stream or task definitions using the shell rest api s. Currently the registry isn t flexible, as it is pretty much hard coded at registry bootstrap level ",NULL,"Add dynamic addition to module registry As an s c d user, I'd like to contribute modules that immediately reflects in module registry,","so I can create stream or task definitions using the shell rest api s. Currently the registry isn t flexible, as it is pretty much hard coded at registry bootstrap level","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26368,"Port ReactorIP as s c s source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.",NULL,NULL,"source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.","Add what you want to achieve","well_formed","no_means","high",False
26368,"Port ReactorIP as s c s source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.",NULL,NULL,"source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.","Add for who this story is","well_formed","no_role","high",False
26368,"Port ReactorIP as s c s source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.",NULL,NULL,"source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26356,"Support daily query resolution in redis aggregate counter ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26356,"Support daily query resolution in redis aggregate counter ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26349,"Document how to use to BOM template As a s c d developer, I'd like to document the use of BOM templates, so the general audience can use it as a reference to include external libraries dynamically.",NULL,"Document how to use to BOM template As a s c d developer, I'd like to document the use of BOM templates,","so the general audience can use it as a reference to include external libraries dynamically.","Add for who this story is","well_formed","no_role","high",False
26349,"Document how to use to BOM template As a s c d developer, I'd like to document the use of BOM templates, so the general audience can use it as a reference to include external libraries dynamically.",NULL,"Document how to use to BOM template As a s c d developer, I'd like to document the use of BOM templates,","so the general audience can use it as a reference to include external libraries dynamically.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26361,"In memory implementation of aggregate counter ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26361,"In memory implementation of aggregate counter ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26366,"Port MongoDB as s c s source As a Spring XD developer, I'd like to move module from XD to s c s m repo, so I can use it as source to build streaming pipeline. ",NULL,NULL,"source As a Spring XD developer, I'd like to move module from XD to s c s m repo, so I can use it as source to build streaming pipeline.","Add what you want to achieve","well_formed","no_means","high",False
26366,"Port MongoDB as s c s source As a Spring XD developer, I'd like to move module from XD to s c s m repo, so I can use it as source to build streaming pipeline. ",NULL,NULL,"source As a Spring XD developer, I'd like to move module from XD to s c s m repo, so I can use it as source to build streaming pipeline.","Add for who this story is","well_formed","no_role","high",False
26366,"Port MongoDB as s c s source As a Spring XD developer, I'd like to move module from XD to s c s m repo, so I can use it as source to build streaming pipeline. ",NULL,NULL,"source As a Spring XD developer, I'd like to move module from XD to s c s m repo, so I can use it as source to build streaming pipeline.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26372,"Port TCP as s c s source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.",NULL,NULL,"source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.","Add what you want to achieve","well_formed","no_means","high",False
26372,"Port TCP as s c s source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.",NULL,NULL,"source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.","Add for who this story is","well_formed","no_role","high",False
26372,"Port TCP as s c s source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.",NULL,NULL,"source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26373,"Port TCP Client as s c s source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline. ",NULL,NULL,"source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.","Add what you want to achieve","well_formed","no_means","high",False
26373,"Port TCP Client as s c s source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline. ",NULL,NULL,"source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.","Add for who this story is","well_formed","no_role","high",False
26373,"Port TCP Client as s c s source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline. ",NULL,NULL,"source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26374,"Port GPFDIST as s c s sink As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as sink to build streaming pipeline. ",NULL,"Port GPFDIST as s c s sink As a Spring XD developer, I'd like to move module from XD to s c s repo,","so I can use it as sink to build streaming pipeline.","Add for who this story is","well_formed","no_role","high",False
26374,"Port GPFDIST as s c s sink As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as sink to build streaming pipeline. ",NULL,"Port GPFDIST as s c s sink As a Spring XD developer, I'd like to move module from XD to s c s repo,","so I can use it as sink to build streaming pipeline.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26376,"Port Mail as s c s sink As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as sink to build streaming pipeline. ",NULL,"Port Mail as s c s sink As a Spring XD developer, I'd like to move module from XD to s c s repo,","so I can use it as sink to build streaming pipeline.","Add for who this story is","well_formed","no_role","high",False
26376,"Port Mail as s c s sink As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as sink to build streaming pipeline. ",NULL,"Port Mail as s c s sink As a Spring XD developer, I'd like to move module from XD to s c s repo,","so I can use it as sink to build streaming pipeline.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26375,"Port HDFS DataSet as s c s sink As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as sink to build streaming pipeline. ",NULL,"Port HDFS DataSet as s c s sink As a Spring XD developer, I'd like to move module from XD to s c s repo,","so I can use it as sink to build streaming pipeline.","Add for who this story is","well_formed","no_role","high",False
26375,"Port HDFS DataSet as s c s sink As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as sink to build streaming pipeline. ",NULL,"Port HDFS DataSet as s c s sink As a Spring XD developer, I'd like to move module from XD to s c s repo,","so I can use it as sink to build streaming pipeline.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26380,"Port Shell as s c s sink As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as sink to build streaming pipeline. ",NULL,"Port Shell as s c s sink As a Spring XD developer, I'd like to move module from XD to s c s repo,","so I can use it as sink to build streaming pipeline.","Add for who this story is","well_formed","no_role","high",False
26380,"Port Shell as s c s sink As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as sink to build streaming pipeline. ",NULL,"Port Shell as s c s sink As a Spring XD developer, I'd like to move module from XD to s c s repo,","so I can use it as sink to build streaming pipeline.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26378,"Port MQTT as s c s sink As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as sink to build streaming pipeline. ",NULL,"Port MQTT as s c s sink As a Spring XD developer, I'd like to move module from XD to s c s repo,","so I can use it as sink to build streaming pipeline.","Add for who this story is","well_formed","no_role","high",False
26378,"Port MQTT as s c s sink As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as sink to build streaming pipeline. ",NULL,"Port MQTT as s c s sink As a Spring XD developer, I'd like to move module from XD to s c s repo,","so I can use it as sink to build streaming pipeline.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26377,"Port MongoDB as s c s sink As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as sink to build streaming pipeline. ",NULL,"Port MongoDB as s c s sink As a Spring XD developer, I'd like to move module from XD to s c s repo,","so I can use it as sink to build streaming pipeline.","Add for who this story is","well_formed","no_role","high",False
26377,"Port MongoDB as s c s sink As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as sink to build streaming pipeline. ",NULL,"Port MongoDB as s c s sink As a Spring XD developer, I'd like to move module from XD to s c s repo,","so I can use it as sink to build streaming pipeline.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26381,"Investigate Reactor based Dispatchers in the common ApplicationContext that can be used by Modules ",NULL,"Investigate Reactor based Dispatchers in the common ApplicationContext that can be used by Modules ",NULL,"Add for who this story is","well_formed","no_role","high",False
26379,"Port NULL as s c s sink As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as sink to build streaming pipeline. ",NULL,"Port NULL as s c s sink As a Spring XD developer, I'd like to move module from XD to s c s repo,","so I can use it as sink to build streaming pipeline.","Add for who this story is","well_formed","no_role","high",False
26379,"Port NULL as s c s sink As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as sink to build streaming pipeline. ",NULL,"Port NULL as s c s sink As a Spring XD developer, I'd like to move module from XD to s c s repo,","so I can use it as sink to build streaming pipeline.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26382,"Port Splunk as s c s sink As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as sink to build streaming pipeline. ",NULL,"Port Splunk as s c s sink As a Spring XD developer, I'd like to move module from XD to s c s repo,","so I can use it as sink to build streaming pipeline.","Add for who this story is","well_formed","no_role","high",False
26382,"Port Splunk as s c s sink As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as sink to build streaming pipeline. ",NULL,"Port Splunk as s c s sink As a Spring XD developer, I'd like to move module from XD to s c s repo,","so I can use it as sink to build streaming pipeline.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26388,"Port Object to JSON as s c s processor As a Spring XD developer, I'd like to port module to build streaming pipeline.",NULL,"Port Object to JSON as s c s processor As a Spring XD developer, I'd like to port module to build streaming pipeline.",NULL,"Add for who this story is","well_formed","no_role","high",False
26383,"Port TCP as s c s sink As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as sink to build streaming pipeline. ",NULL,"Port TCP as s c s sink As a Spring XD developer, I'd like to move module from XD to s c s repo,","so I can use it as sink to build streaming pipeline.","Add for who this story is","well_formed","no_role","high",False
26383,"Port TCP as s c s sink As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as sink to build streaming pipeline. ",NULL,"Port TCP as s c s sink As a Spring XD developer, I'd like to move module from XD to s c s repo,","so I can use it as sink to build streaming pipeline.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26386,"Port HTTP Client as s c s processor As a Spring XD developer, I'd like to port module to build streaming pipeline.",NULL,"Port HTTP Client as s c s processor As a Spring XD developer, I'd like to port module to build streaming pipeline.",NULL,"Add for who this story is","well_formed","no_role","high",False
26384,"Port JDBC as s c s source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline. ",NULL,NULL,"source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.","Add what you want to achieve","well_formed","no_means","high",False
26384,"Port JDBC as s c s source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline. ",NULL,NULL,"source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.","Add for who this story is","well_formed","no_role","high",False
26384,"Port JDBC as s c s source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline. ",NULL,NULL,"source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26387,"Port JSON to Tuple as s c s processor As a Spring XD developer, I'd like to port module to build streaming pipeline.",NULL,"Port JSON to Tuple as s c s processor As a Spring XD developer, I'd like to port module to build streaming pipeline.",NULL,"Add for who this story is","well_formed","no_role","high",False
26389,"Port Script as s c s processor As a Spring XD developer, I'd like to port module to build streaming pipeline.",NULL,"Port Script as s c s processor As a Spring XD developer, I'd like to port module to build streaming pipeline.",NULL,"Add for who this story is","well_formed","no_role","high",False
26390,"Port Shell as s c s processor As a Spring XD developer, I'd like to port module to build streaming pipeline.",NULL,"Port Shell as s c s processor As a Spring XD developer, I'd like to port module to build streaming pipeline.",NULL,"Add for who this story is","well_formed","no_role","high",False
26391,"Port Splitter as s c s processor As a Spring XD developer, I'd like to port module to build streaming pipeline.",NULL,"Port Splitter as s c s processor As a Spring XD developer, I'd like to port module to build streaming pipeline.",NULL,"Add for who this story is","well_formed","no_role","high",False
26454,"Job composition improvements As a developer, I'd like to review and refactor , so I can improve performance characteristics. ",NULL,"Job composition improvements As a developer, I'd like to review and refactor ,","so I can improve performance characteristics.","Add for who this story is","well_formed","no_role","high",False
26454,"Job composition improvements As a developer, I'd like to review and refactor , so I can improve performance characteristics. ",NULL,"Job composition improvements As a developer, I'd like to review and refactor ,","so I can improve performance characteristics.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26371,"Port Tail as s c s source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.",NULL,NULL,"source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.","Add what you want to achieve","well_formed","no_means","high",False
26371,"Port Tail as s c s source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.",NULL,NULL,"source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.","Add for who this story is","well_formed","no_role","high",False
26371,"Port Tail as s c s source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.",NULL,NULL,"source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26385,"Port aggregator as s c s processor As a Spring XD developer, I'd like to port module to build streaming pipeline.",NULL,"Port aggregator as s c s processor As a Spring XD developer, I'd like to port module to build streaming pipeline.",NULL,"Add for who this story is","well_formed","no_role","high",False
26394,"Spike Create composed job module As an XD developer, I'd like to explore options to represent composed job, so I can create a workflow to orchestrate multiple jobs. ",NULL,"Spike Create composed job module As an XD developer, I'd like to explore options to represent composed job,","so I can create a workflow to orchestrate multiple jobs.","Add for who this story is","well_formed","no_role","high",False
26394,"Spike Create composed job module As an XD developer, I'd like to explore options to represent composed job, so I can create a workflow to orchestrate multiple jobs. ",NULL,"Spike Create composed job module As an XD developer, I'd like to explore options to represent composed job,","so I can create a workflow to orchestrate multiple jobs.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26395,"Spike Destroy composed job As an XD developer, I'd like to explore options to remove composed job, so I can clean up unused resources and memory footprints. ",NULL,"Spike Destroy composed job As an XD developer, I'd like to explore options to remove composed job,","so I can clean up unused resources and memory footprints.","Add for who this story is","well_formed","no_role","high",False
26395,"Spike Destroy composed job As an XD developer, I'd like to explore options to remove composed job, so I can clean up unused resources and memory footprints. ",NULL,"Spike Destroy composed job As an XD developer, I'd like to explore options to remove composed job,","so I can clean up unused resources and memory footprints.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26396,"Develop tasklet to execute a Job As the system, I would like a way to launch a previously deployed job module from another job module. ",NULL,"Develop tasklet to execute a Job As the system, I would like a way to launch a previously deployed job module from another job module. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26397,"Add ability to launch job composition Verify that the job launch works as we expect for the composed job. ",NULL,"Add ability to launch job composition Verify that the job launch works as we expect for the composed job. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26398,"Add support to restart job composition As a XD user, I'd like to restart the composed job workflow from Shell UI. ",NULL,"Add support to restart job composition As a XD user, I'd like to restart the composed job workflow from Shell UI. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26399,"Test startup scripts on windows startup scripts on windows should be tested, xd admin, xd container, xd shell.",NULL,"Test startup scripts on windows startup scripts on windows should be tested, xd admin, xd container, xd shell.",NULL,"Add for who this story is","well_formed","no_role","high",False
26400,"Better printing of array default valuesin documentation When a default value is an array, the current behavior using toString not only produces useless results like but also constantly changing results.",NULL,"Better printing of array default valuesin documentation When a default value is an array, the current behavior using toString not only produces useless results like but also constantly changing results.",NULL,"Add for who this story is","well_formed","no_role","high",False
26402,"Add support for multiple binders per binder type As a developer, I want to be able to connect to multiple external systems for the same binding type, so that I can read data from a system and write it to another.",NULL,"Add support for multiple binders per binder type As a developer, I want to be able to connect to multiple external systems for the same binding type,","so that I can read data from a system and write it to another.","Add for who this story is","well_formed","no_role","high",False
26402,"Add support for multiple binders per binder type As a developer, I want to be able to connect to multiple external systems for the same binding type, so that I can read data from a system and write it to another.",NULL,"Add support for multiple binders per binder type As a developer, I want to be able to connect to multiple external systems for the same binding type,","so that I can read data from a system and write it to another.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26401,"Create BinderFactory abstraction As a developer, I want to have a abstraction, so that I can support multiple binder types in the future.",NULL,"Create BinderFactory abstraction As a developer, I want to have a abstraction,","so that I can support multiple binder types in the future.","Add for who this story is","well_formed","no_role","high",False
26401,"Create BinderFactory abstraction As a developer, I want to have a abstraction, so that I can support multiple binder types in the future.",NULL,"Create BinderFactory abstraction As a developer, I want to have a abstraction,","so that I can support multiple binder types in the future.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26404,"doesn t support HA namenode for hdfs custom module location As an XD module developer I would like to use HDFS for my custom module location even when my namenode is configured for HA. We had an issue filed in the spring xd ambari project It seems like custom module doesn t pickup namenode HA? and still use see ",NULL,"doesn t support HA namenode for hdfs custom module location As an XD module developer I would like to use HDFS for my custom module location even when my namenode is configured for HA. We had an issue filed in the spring xd ambari project It seems like custom module doesn t pickup namenode HA? and still use see ",NULL,"Add for who this story is","well_formed","no_role","high",False
26404,"doesn t support HA namenode for hdfs custom module location As an XD module developer I would like to use HDFS for my custom module location even when my namenode is configured for HA. We had an issue filed in the spring xd ambari project It seems like custom module doesn t pickup namenode HA? and still use see ",NULL,"doesn t support HA namenode for hdfs custom module location As an XD module developer I would like to use HDFS for my custom module location even when my namenode is configured for HA. We had an issue filed in the spring xd ambari project It seems like custom module doesn t pickup namenode HA? and still use see ",NULL,"doesn t support HA namenode for hdfs custom module location As an XD module developer I would like to use HDFS for my custom module location even when my namenode is configured for HA. We had an issue filed in the spring xd ambari project It seems like custom module doesn t pickup namenode HA?<span class='highlight-text severity-high'> and </span>still use see ","atomic","conjunctions","high",False
26409,"Include job composition flag in REST endpoint As an XD user, I'd like to have a REST endpoint that returns job composition , so I can use it to differentiate visual representation between parent child relationship and standalone jobs. ",NULL,"Include job composition flag in REST endpoint As an XD user, I'd like to have a REST endpoint that returns job composition ,","so I can use it to differentiate visual representation between parent child relationship and standalone jobs.","Add for who this story is","well_formed","no_role","high",False
26409,"Include job composition flag in REST endpoint As an XD user, I'd like to have a REST endpoint that returns job composition , so I can use it to differentiate visual representation between parent child relationship and standalone jobs. ",NULL,"Include job composition flag in REST endpoint As an XD user, I'd like to have a REST endpoint that returns job composition ,","so I can use it to differentiate visual representation between parent child relationship and standalone jobs.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26430,"Add support for creating a spring batch job that references a named trigger ",NULL,"Add support for creating a spring batch job that references a named trigger ",NULL,"Add for who this story is","well_formed","no_role","high",False
26404,"doesn t support HA namenode for hdfs custom module location As an XD module developer I would like to use HDFS for my custom module location even when my namenode is configured for HA. We had an issue filed in the spring xd ambari project It seems like custom module doesn t pickup namenode HA? and still use see ",NULL,"doesn t support HA namenode for hdfs custom module location As an XD module developer I would like to use HDFS for my custom module location even when my namenode is configured for HA. We had an issue filed in the spring xd ambari project It seems like custom module doesn t pickup namenode HA? and still use see ",NULL,"doesn t support HA namenode for hdfs custom module location As an XD module developer I would like to use HDFS for my custom module location even when my namenode is configured for HA<span class='highlight-text severity-high'>. We had an issue filed in the spring xd ambari project It seems like custom module doesn t pickup namenode HA? and still use see </span>","minimal","punctuation","high",False
26405,"Creating a base class for Plugins It might be worth creating a base class for Plugins that combines common concerns across plugins. E.g. That would allow us to hide the and for common cases, instead exposing a simple addBeanDefinition method to sub classes. ",NULL,"Creating a base class for Plugins It might be worth creating a base class for Plugins that combines common concerns across plugins. E.g. That would allow us to hide the and for common cases, instead exposing a simple addBeanDefinition method to sub classes. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26405,"Creating a base class for Plugins It might be worth creating a base class for Plugins that combines common concerns across plugins. E.g. That would allow us to hide the and for common cases, instead exposing a simple addBeanDefinition method to sub classes. ",NULL,"Creating a base class for Plugins It might be worth creating a base class for Plugins that combines common concerns across plugins. E.g. That would allow us to hide the and for common cases, instead exposing a simple addBeanDefinition method to sub classes. ",NULL,"Creating a base class for Plugins It might be worth creating a base class for Plugins that combines common concerns across plugins. E.g. That would allow us to hide the<span class='highlight-text severity-high'> and </span>for common cases, instead exposing a simple addBeanDefinition method to sub classes. ","atomic","conjunctions","high",False
26405,"Creating a base class for Plugins It might be worth creating a base class for Plugins that combines common concerns across plugins. E.g. That would allow us to hide the and for common cases, instead exposing a simple addBeanDefinition method to sub classes. ",NULL,"Creating a base class for Plugins It might be worth creating a base class for Plugins that combines common concerns across plugins. E.g. That would allow us to hide the and for common cases, instead exposing a simple addBeanDefinition method to sub classes. ",NULL,"Creating a base class for Plugins It might be worth creating a base class for Plugins that combines common concerns across plugins<span class='highlight-text severity-high'>. E.g. That would allow us to hide the and for common cases, instead exposing a simple addBeanDefinition method to sub classes. </span>","minimal","punctuation","high",False
26406,"Readme has conflicting CF information In the section starting Now we can configure the app needs to be revised the information is both out of date and, even if up to date, misleading it includes some values as if they are universal, when they are really just examples .",NULL,"Readme has conflicting CF information In the section starting Now we can configure the app needs to be revised the information is both out of date and, even if up to date, misleading it includes some values as if they are universal, when they are really just examples .",NULL,"Add for who this story is","well_formed","no_role","high",False
26407,"Port Cassandra as s c s sink As a Spring XD developer, I'd like to move to build streaming pipeline.",NULL,"Port Cassandra as s c s sink As a Spring XD developer, I'd like to move to build streaming pipeline.",NULL,"Add for who this story is","well_formed","no_role","high",False
26408,"Port analytic pmml as s c s processor As a Spring XD developer, I'd like to port module to build streaming pipeline.",NULL,"Port analytic pmml as s c s processor As a Spring XD developer, I'd like to port module to build streaming pipeline.",NULL,"Add for who this story is","well_formed","no_role","high",False
26455,"Add test coverage for batch DSL and XML generation variants As a developer, I'd like to enhance test coverage to capture DSL and XML generation variants. ",NULL,"Add test coverage for batch DSL and XML generation variants As a developer, I'd like to enhance test coverage to capture DSL and XML generation variants. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26455,"Add test coverage for batch DSL and XML generation variants As a developer, I'd like to enhance test coverage to capture DSL and XML generation variants. ",NULL,"Add test coverage for batch DSL and XML generation variants As a developer, I'd like to enhance test coverage to capture DSL and XML generation variants. ",NULL,"Add test coverage for batch DSL<span class='highlight-text severity-high'> and </span>XML generation variants As a developer, I'd like to enhance test coverage to capture DSL and XML generation variants. ","atomic","conjunctions","high",False
26403,"TwitterStream test must use unique name to prevent test collision XD Developer does not want the the twitter stream acceptance tests to interfere with other tests.",NULL,"TwitterStream test must use unique name to prevent test collision XD Developer does not want the the twitter stream acceptance tests to interfere with other tests.",NULL,"Add for who this story is","well_formed","no_role","high",False
26392,"Enable configuration of Executors in source and sink modules, by default using Dispatchers in parent context Need to understand how individual modules may or may not share Dispatchers that are part of the parent context. If modules have their own dispatchers, those also need to be configurable.",NULL,"Enable configuration of Executors in source and sink modules, by default using Dispatchers in parent context Need to understand how individual modules may or may not share Dispatchers that are part of the parent context. If modules have their own dispatchers, those also need to be configurable.",NULL,"Add for who this story is","well_formed","no_role","high",False
26392,"Enable configuration of Executors in source and sink modules, by default using Dispatchers in parent context Need to understand how individual modules may or may not share Dispatchers that are part of the parent context. If modules have their own dispatchers, those also need to be configurable.",NULL,"Enable configuration of Executors in source and sink modules, by default using Dispatchers in parent context Need to understand how individual modules may or may not share Dispatchers that are part of the parent context. If modules have their own dispatchers, those also need to be configurable.",NULL,"Enable configuration of Executors in source<span class='highlight-text severity-high'> and </span>sink modules, by default using Dispatchers in parent context Need to understand how individual modules may<span class='highlight-text severity-high'> or </span>may not share Dispatchers that are part of the parent context. If modules have their own dispatchers, those also need to be configurable.","atomic","conjunctions","high",False
26392,"Enable configuration of Executors in source and sink modules, by default using Dispatchers in parent context Need to understand how individual modules may or may not share Dispatchers that are part of the parent context. If modules have their own dispatchers, those also need to be configurable.",NULL,"Enable configuration of Executors in source and sink modules, by default using Dispatchers in parent context Need to understand how individual modules may or may not share Dispatchers that are part of the parent context. If modules have their own dispatchers, those also need to be configurable.",NULL,"Enable configuration of Executors in source and sink modules, by default using Dispatchers in parent context Need to understand how individual modules may or may not share Dispatchers that are part of the parent context<span class='highlight-text severity-high'>. If modules have their own dispatchers, those also need to be configurable.</span>","minimal","punctuation","high",False
26411,"Add visual representation of job workflow in executions list page As an XD user, I'd like to be able to visually differentiate between job composition workflow and single job.",NULL,"Add visual representation of job workflow in executions list page As an XD user, I'd like to be able to visually differentiate between job composition workflow and single job.",NULL,"Add for who this story is","well_formed","no_role","high",False
26410,"Include job composition graph in REST endpoint As an XD user, I'd like to have a REST endpoint that returns job composition graph, so I can use it to build visual representation of parent child relationship. ",NULL,"Include job composition graph in REST endpoint As an XD user, I'd like to have a REST endpoint that returns job composition graph,","so I can use it to build visual representation of parent child relationship.","Add for who this story is","well_formed","no_role","high",False
26410,"Include job composition graph in REST endpoint As an XD user, I'd like to have a REST endpoint that returns job composition graph, so I can use it to build visual representation of parent child relationship. ",NULL,"Include job composition graph in REST endpoint As an XD user, I'd like to have a REST endpoint that returns job composition graph,","so I can use it to build visual representation of parent child relationship.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26413,"Add support to restart job composition As an XD user, I'd like have support restart an existing composed job, so I could re launch it at will.",NULL,"Add support to restart job composition As an XD user, I'd like have support restart an existing composed job,","so I could re launch it at will.","Add for who this story is","well_formed","no_role","high",False
26413,"Add support to restart job composition As an XD user, I'd like have support restart an existing composed job, so I could re launch it at will.",NULL,"Add support to restart job composition As an XD user, I'd like have support restart an existing composed job,","so I could re launch it at will.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26412,"Add support to retrieve job details As an XD user, I'd like to click to go the detail page of the job page whether or not the selected entity is singular or part of a composed job.",NULL,"Add support to retrieve job details As an XD user, I'd like to click to go the detail page of the job page whether or not the selected entity is singular or part of a composed job.",NULL,"Add for who this story is","well_formed","no_role","high",False
26412,"Add support to retrieve job details As an XD user, I'd like to click to go the detail page of the job page whether or not the selected entity is singular or part of a composed job.",NULL,"Add support to retrieve job details As an XD user, I'd like to click to go the detail page of the job page whether or not the selected entity is singular or part of a composed job.",NULL,"Add support to retrieve job details As an XD user, I'd like to click to go the detail page of the job page whether<span class='highlight-text severity-high'> or </span>not the selected entity is singular or part of a composed job.","atomic","conjunctions","high",False
26415,"Spike Explore options to setup bare metal deployment of s c d using Lattice As a s c d developer, I'd like to explore options to bootstrap and setup Lattice based infrastructure for s c d s bare metal deployment.",NULL,"Spike Explore options to setup bare metal deployment of s c d using Lattice As a s c d developer, I'd like to explore options to bootstrap and setup Lattice based infrastructure for s c d s bare metal deployment.",NULL,"Add for who this story is","well_formed","no_role","high",False
26415,"Spike Explore options to setup bare metal deployment of s c d using Lattice As a s c d developer, I'd like to explore options to bootstrap and setup Lattice based infrastructure for s c d s bare metal deployment.",NULL,"Spike Explore options to setup bare metal deployment of s c d using Lattice As a s c d developer, I'd like to explore options to bootstrap and setup Lattice based infrastructure for s c d s bare metal deployment.",NULL,"Spike Explore options to setup bare metal deployment of s c d using Lattice As a s c d developer, I'd like to explore options to bootstrap<span class='highlight-text severity-high'> and </span>setup Lattice based infrastructure for s c d s bare metal deployment.","atomic","conjunctions","high",False
26414,"Add support for creating named cron triggers Simple cron based triggers",NULL,"Add support for creating named cron triggers Simple cron based triggers",NULL,"Add for who this story is","well_formed","no_role","high",False
26418,"Implement Mesos SPI As an s c d user, I'd like to deploy s c d on Mesos.",NULL,"Implement Mesos SPI As an s c d user, I'd like to deploy s c d on Mesos.",NULL,"Add for who this story is","well_formed","no_role","high",False
26416,"Add support for Tuple and JSON SpEL property accessors in As a user, I'd like to build stream definitions using dot delimited syntax for resolving properties for Tuple and JSON.",NULL,"Add support for Tuple and JSON SpEL property accessors in As a user, I'd like to build stream definitions using dot delimited syntax for resolving properties for Tuple and JSON.",NULL,"Add for who this story is","well_formed","no_role","high",False
26416,"Add support for Tuple and JSON SpEL property accessors in As a user, I'd like to build stream definitions using dot delimited syntax for resolving properties for Tuple and JSON.",NULL,"Add support for Tuple and JSON SpEL property accessors in As a user, I'd like to build stream definitions using dot delimited syntax for resolving properties for Tuple and JSON.",NULL,"Add support for Tuple<span class='highlight-text severity-high'> and </span>JSON SpEL property accessors in As a user, I'd like to build stream definitions using dot delimited syntax for resolving properties for Tuple and JSON.","atomic","conjunctions","high",False
26423,"Harmonize REST features between deployment profiles As an s c d user, I'd like to take advantage of admin running on variety of platforms such as Lattice, YARN or CF. I'd like to access REST APIs consistently across these platforms.",NULL,"Harmonize REST features between deployment profiles As an s c d user, I'd like to take advantage of admin running on variety of platforms such as Lattice, YARN or CF. I'd like to access REST APIs consistently across these platforms.",NULL,"Add for who this story is","well_formed","no_role","high",False
26423,"Harmonize REST features between deployment profiles As an s c d user, I'd like to take advantage of admin running on variety of platforms such as Lattice, YARN or CF. I'd like to access REST APIs consistently across these platforms.",NULL,"Harmonize REST features between deployment profiles As an s c d user, I'd like to take advantage of admin running on variety of platforms such as Lattice, YARN or CF. I'd like to access REST APIs consistently across these platforms.",NULL,"Harmonize REST features between deployment profiles As an s c d user, I'd like to take advantage of admin running on variety of platforms such as Lattice, YARN<span class='highlight-text severity-high'> or </span>CF. I'd like to access REST APIs consistently across these platforms.","atomic","conjunctions","high",False
26423,"Harmonize REST features between deployment profiles As an s c d user, I'd like to take advantage of admin running on variety of platforms such as Lattice, YARN or CF. I'd like to access REST APIs consistently across these platforms.",NULL,"Harmonize REST features between deployment profiles As an s c d user, I'd like to take advantage of admin running on variety of platforms such as Lattice, YARN or CF. I'd like to access REST APIs consistently across these platforms.",NULL,"Harmonize REST features between deployment profiles As an s c d user, I'd like to take advantage of admin running on variety of platforms such as Lattice, YARN or CF<span class='highlight-text severity-high'>. I'd like to access REST APIs consistently across these platforms.</span>","minimal","punctuation","high",False
26417,"Add support for tab completion in shell As an s c d user, I'd like to have tab completion on shell, so I can interact with the modules and its available options.",NULL,"Add support for tab completion in shell As an s c d user, I'd like to have tab completion on shell,","so I can interact with the modules and its available options.","Add for who this story is","well_formed","no_role","high",False
26417,"Add support for tab completion in shell As an s c d user, I'd like to have tab completion on shell, so I can interact with the modules and its available options.",NULL,"Add support for tab completion in shell As an s c d user, I'd like to have tab completion on shell,","so I can interact with the modules and its available options.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26422,"Add support for creating a spring batch job that has an embedded trigger expression Add support for creating a spring batch job that has an embedded trigger expression ",NULL,"Add support for creating a spring batch job that has an embedded trigger expression Add support for creating a spring batch job that has an embedded trigger expression ",NULL,"Add for who this story is","well_formed","no_role","high",False
26420,"Move Kafka Rule to a separate repo As an s c d developer, I'd like to move kafka to a separate repo, so I can consume the test fixtures in different projects.",NULL,"Move Kafka Rule to a separate repo As an s c d developer, I'd like to move kafka to a separate repo,","so I can consume the test fixtures in different projects.","Add for who this story is","well_formed","no_role","high",False
26420,"Move Kafka Rule to a separate repo As an s c d developer, I'd like to move kafka to a separate repo, so I can consume the test fixtures in different projects.",NULL,"Move Kafka Rule to a separate repo As an s c d developer, I'd like to move kafka to a separate repo,","so I can consume the test fixtures in different projects.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26427,"Prevent streams with duplicate name As a s c d user, I should be prevented from creating streams with duplicate name. I d expect streams to have unique names all the time. ",NULL,"Prevent streams with duplicate name As a s c d user, I should be prevented from creating streams with duplicate name. I d expect streams to have unique names all the time. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26427,"Prevent streams with duplicate name As a s c d user, I should be prevented from creating streams with duplicate name. I d expect streams to have unique names all the time. ",NULL,"Prevent streams with duplicate name As a s c d user, I should be prevented from creating streams with duplicate name. I d expect streams to have unique names all the time. ",NULL,"Prevent streams with duplicate name As a s c d user, I should be prevented from creating streams with duplicate name<span class='highlight-text severity-high'>. I d expect streams to have unique names all the time. </span>","minimal","punctuation","high",False
26421,"Move Rabbit Rule to a separate repo As an s c d developer, I'd like to move rabbit to a separate repo, so I can consume the test fixtures in different projects.",NULL,"Move Rabbit Rule to a separate repo As an s c d developer, I'd like to move rabbit to a separate repo,","so I can consume the test fixtures in different projects.","Add for who this story is","well_formed","no_role","high",False
26421,"Move Rabbit Rule to a separate repo As an s c d developer, I'd like to move rabbit to a separate repo, so I can consume the test fixtures in different projects.",NULL,"Move Rabbit Rule to a separate repo As an s c d developer, I'd like to move rabbit to a separate repo,","so I can consume the test fixtures in different projects.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26425,"Add support for named channels As an s c d user, I'd like to have the option to use named channels , so I can create streaming pipelines without source or sink modules. ",NULL,"Add support for named channels As an s c d user, I'd like to have the option to use named channels ,","so I can create streaming pipelines without source or sink modules.","Add for who this story is","well_formed","no_role","high",False
26425,"Add support for named channels As an s c d user, I'd like to have the option to use named channels , so I can create streaming pipelines without source or sink modules. ",NULL,"Add support for named channels As an s c d user, I'd like to have the option to use named channels ,","so I can create streaming pipelines without source or sink modules.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26424,"Add support to register artifacts as libraries As a SCDF user, I want to be able to register artifacts as libraries, so that I can reference them in include and exclude statements.",NULL,"Add support to register artifacts as libraries As a SCDF user, I want to be able to register artifacts as libraries,","so that I can reference them in include and exclude statements.","Add for who this story is","well_formed","no_role","high",False
26424,"Add support to register artifacts as libraries As a SCDF user, I want to be able to register artifacts as libraries, so that I can reference them in include and exclude statements.",NULL,"Add support to register artifacts as libraries As a SCDF user, I want to be able to register artifacts as libraries,","so that I can reference them in include and exclude statements.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26426,"Add test coverage for StreamController As a s c d developer, I'd like to add test coverage for , so I can verify API contracts at build time. ",NULL,"Add test coverage for StreamController As a s c d developer, I'd like to add test coverage for ,","so I can verify API contracts at build time.","Add for who this story is","well_formed","no_role","high",False
26426,"Add test coverage for StreamController As a s c d developer, I'd like to add test coverage for , so I can verify API contracts at build time. ",NULL,"Add test coverage for StreamController As a s c d developer, I'd like to add test coverage for ,","so I can verify API contracts at build time.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26434,"Port as s c s sink As a developer, I'd like to port module to build streaming pipeline.",NULL,"Port as s c s sink As a developer, I'd like to port module to build streaming pipeline.",NULL,"Add for who this story is","well_formed","no_role","high",False
26433,"Implement parser for Job DSL As a XD user, I'd like to have job DSL as an option, so I can leverage the DSL to create comprehensive workflows and orchestrate jobs. ",NULL,"Implement parser for Job DSL As a XD user, I'd like to have job DSL as an option,","so I can leverage the DSL to create comprehensive workflows and orchestrate jobs.","Add for who this story is","well_formed","no_role","high",False
26433,"Implement parser for Job DSL As a XD user, I'd like to have job DSL as an option, so I can leverage the DSL to create comprehensive workflows and orchestrate jobs. ",NULL,"Implement parser for Job DSL As a XD user, I'd like to have job DSL as an option,","so I can leverage the DSL to create comprehensive workflows and orchestrate jobs.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26442,"Study YARN SPI gaps As a s c d user, I'd like to deploy data flow on YARN, so I can reuse the existing Hadoop cluster and leverage data flow features to build streaming or batch pipelines.",NULL,"Study YARN SPI gaps As a s c d user, I'd like to deploy data flow on YARN,","so I can reuse the existing Hadoop cluster and leverage data flow features to build streaming or batch pipelines.","Add for who this story is","well_formed","no_role","high",False
26442,"Study YARN SPI gaps As a s c d user, I'd like to deploy data flow on YARN, so I can reuse the existing Hadoop cluster and leverage data flow features to build streaming or batch pipelines.",NULL,"Study YARN SPI gaps As a s c d user, I'd like to deploy data flow on YARN,","so I can reuse the existing Hadoop cluster and leverage data flow features to build streaming or batch pipelines.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26435,"Port aggregate counter as s c s sink As a developer, I'd like to port module to build streaming pipeline.",NULL,"Port aggregate counter as s c s sink As a developer, I'd like to port module to build streaming pipeline.",NULL,"Add for who this story is","well_formed","no_role","high",False
26436,"Port Gauge as s c s sink As a developer, I'd like to port module to build streaming pipeline.",NULL,"Port Gauge as s c s sink As a developer, I'd like to port module to build streaming pipeline.",NULL,"Add for who this story is","well_formed","no_role","high",False
26437,"Port rich gauge as s c s sink As a developer, I'd like to port module to build streaming pipeline.",NULL,"Port rich gauge as s c s sink As a developer, I'd like to port module to build streaming pipeline.",NULL,"Add for who this story is","well_formed","no_role","high",False
26438,"Create a trigger from Shell Create a trigger from Shell ",NULL,"Create a trigger from Shell Create a trigger from Shell ",NULL,"Add for who this story is","well_formed","no_role","high",False
26439,"Add standardized way to pass props from Deployers Admin to ModuleLauncher There is a need to customize the ModuleLauncher behavior itself, NOT pass options to modules that are launched, which is already supported for example to set the location of the maven repository. ",NULL,"Add standardized way to pass props from Deployers Admin to ModuleLauncher There is a need to customize the ModuleLauncher behavior itself, NOT pass options to modules that are launched, which is already supported for example to set the location of the maven repository. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26440,"Update build to use SHDP 2.3.0.RC1 ",NULL,"Update build to use SHDP 2.3.0.RC1 ",NULL,"Add for who this story is","well_formed","no_role","high",False
26443,"Port File as s c s source As a developer, I'd like to port module to build streaming pipeline.",NULL,"Port File as s c s source As a developer, I'd like to port module to build streaming pipeline.",NULL,"Add for who this story is","well_formed","no_role","high",False
26445,"Get rid of XDRuntimeException As a developer, I'd like to get rid off from XD.",NULL,"Get rid of XDRuntimeException As a developer, I'd like to get rid off from XD.",NULL,"Add for who this story is","well_formed","no_role","high",False
26448,"Add SFTP source to default registry As a user, I'd like to use SFTP source module, so I can create streaming pipeline with it. However, I cannot see SFTP as OOTB module listed on and as well as the module bits are not available in maven repo ",NULL,"Add SFTP","source to default registry As a user, I'd like to use SFTP source module, so I can create streaming pipeline with it. However, I cannot see SFTP as OOTB module listed on and as well as the module bits are not available in maven repo","Add for who this story is","well_formed","no_role","high",False
26448,"Add SFTP source to default registry As a user, I'd like to use SFTP source module, so I can create streaming pipeline with it. However, I cannot see SFTP as OOTB module listed on and as well as the module bits are not available in maven repo ",NULL,"Add SFTP","source to default registry As a user, I'd like to use SFTP source module, so I can create streaming pipeline with it. However, I cannot see SFTP as OOTB module listed on and as well as the module bits are not available in maven repo","Add SFTP source to default registry As a user, I'd like to use SFTP source module, so I can create streaming pipeline with it<span class='highlight-text severity-high'>. However, I cannot see SFTP as OOTB module listed on and as well as the module bits are not available in maven repo </span>","minimal","punctuation","high",False
26448,"Add SFTP source to default registry As a user, I'd like to use SFTP source module, so I can create streaming pipeline with it. However, I cannot see SFTP as OOTB module listed on and as well as the module bits are not available in maven repo ",NULL,"Add SFTP","source to default registry As a user, I'd like to use SFTP source module, so I can create streaming pipeline with it. However, I cannot see SFTP as OOTB module listed on and as well as the module bits are not available in maven repo","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26444,"Add support to build Admin with individual SPI deployers As a s c d developer, I'd like to break the build lifecycle to bundle SPI deployers individually, so I don t have to build with all the deployer variations as one whole thing.",NULL,"Add support to build Admin with individual SPI deployers As a s c d developer, I'd like to break the build lifecycle to bundle SPI deployers individually,","so I don t have to build with all the deployer variations as one whole thing.","Add for who this story is","well_formed","no_role","high",False
26444,"Add support to build Admin with individual SPI deployers As a s c d developer, I'd like to break the build lifecycle to bundle SPI deployers individually, so I don t have to build with all the deployer variations as one whole thing.",NULL,"Add support to build Admin with individual SPI deployers As a s c d developer, I'd like to break the build lifecycle to bundle SPI deployers individually,","so I don t have to build with all the deployer variations as one whole thing.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26447,"Upgrade GF sink to 8.2 As a user, I'd like to use the latest release of sink, so I can create a streaming pipeline to land data in gemfire. ",NULL,"Upgrade GF sink to 8.2 As a user, I'd like to use the latest release of sink,","so I can create a streaming pipeline to land data in gemfire.","Add for who this story is","well_formed","no_role","high",False
26447,"Upgrade GF sink to 8.2 As a user, I'd like to use the latest release of sink, so I can create a streaming pipeline to land data in gemfire. ",NULL,"Upgrade GF sink to 8.2 As a user, I'd like to use the latest release of sink,","so I can create a streaming pipeline to land data in gemfire.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26446,"Add support for creating fixed delay fixed rate triggers Add support for creating fixed delay fixed rate triggers ",NULL,"Add support for creating fixed delay fixed rate triggers Add support for creating fixed delay fixed rate triggers ",NULL,"Add for who this story is","well_formed","no_role","high",False
26449,"Resolve remaining gaps with CI As a developer, I'd like to resolve remaining gaps wrt CI pipelines for Data Flow and the family, so I can continuously evaluate functionalities on every commit.",NULL,NULL,"solve remaining gaps with CI As a developer, I'd like to resolve remaining gaps wrt CI pipelines for Data Flow and the family, so I can continuously evaluate functionalities on every commit.","Add what you want to achieve","well_formed","no_means","high",False
26449,"Resolve remaining gaps with CI As a developer, I'd like to resolve remaining gaps wrt CI pipelines for Data Flow and the family, so I can continuously evaluate functionalities on every commit.",NULL,NULL,"solve remaining gaps with CI As a developer, I'd like to resolve remaining gaps wrt CI pipelines for Data Flow and the family, so I can continuously evaluate functionalities on every commit.","Add for who this story is","well_formed","no_role","high",False
26449,"Resolve remaining gaps with CI As a developer, I'd like to resolve remaining gaps wrt CI pipelines for Data Flow and the family, so I can continuously evaluate functionalities on every commit.",NULL,NULL,"solve remaining gaps with CI As a developer, I'd like to resolve remaining gaps wrt CI pipelines for Data Flow and the family, so I can continuously evaluate functionalities on every commit.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26450,"Add support for global options in DSL As a Flo user, I'd like to have as global options at the DSL level, so I can override the defaults at will. ",NULL,"Add support for global options in DSL As a Flo user, I'd like to have as global options at the DSL level,","so I can override the defaults at will.","Add for who this story is","well_formed","no_role","high",False
26450,"Add support for global options in DSL As a Flo user, I'd like to have as global options at the DSL level, so I can override the defaults at will. ",NULL,"Add support for global options in DSL As a Flo user, I'd like to have as global options at the DSL level,","so I can override the defaults at will.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26432,"Port Log as s c s sink As a developer, I'd like to port modules to build streaming pipeline.",NULL,"Port Log as s c s sink As a developer, I'd like to port modules to build streaming pipeline.",NULL,"Add for who this story is","well_formed","no_role","high",False
26428,"Separate Lifecycle of Input and Output adapter endpoints Described in As a developer, I want Input enpoints to be started after all the beans in the context, so that received messages can be delivered to components. ",NULL,"Separate Lifecycle of Input and Output adapter endpoints Described in As a developer, I want Input enpoints to be started after all the beans in the context,","so that received messages can be delivered to components.","Add for who this story is","well_formed","no_role","high",False
26428,"Separate Lifecycle of Input and Output adapter endpoints Described in As a developer, I want Input enpoints to be started after all the beans in the context, so that received messages can be delivered to components. ",NULL,"Separate Lifecycle of Input and Output adapter endpoints Described in As a developer, I want Input enpoints to be started after all the beans in the context,","so that received messages can be delivered to components.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26441,"Add runtime info shell command As a s c d user, I'd like to have and the like.",NULL,"Add runtime info shell command As a s c d user, I'd like to have and the like.",NULL,"Add for who this story is","well_formed","no_role","high",False
26459,"Add undeployed status for YARN SPI As a developer, I'd like to add state.",NULL,"Add undeployed status for YARN SPI As a developer, I'd like to add state.",NULL,"Add for who this story is","well_formed","no_role","high",False
26457,"Support having multiple property placeholders defined in different modules Right now the PPC for jolokia mgmt is conflicting with the PPC used to resolve redis properties. Need to determine a strategy such that multiple PPCs can be used.",NULL,"Support having multiple property placeholders defined in different modules Right now the PPC for jolokia mgmt is conflicting with the PPC used to resolve redis properties. Need to determine a strategy such that multiple PPCs can be used.",NULL,"Add for who this story is","well_formed","no_role","high",False
26457,"Support having multiple property placeholders defined in different modules Right now the PPC for jolokia mgmt is conflicting with the PPC used to resolve redis properties. Need to determine a strategy such that multiple PPCs can be used.",NULL,"Support having multiple property placeholders defined in different modules Right now the PPC for jolokia mgmt is conflicting with the PPC used to resolve redis properties. Need to determine a strategy such that multiple PPCs can be used.",NULL,"Support having multiple property placeholders defined in different modules Right now the PPC for jolokia mgmt is conflicting with the PPC used to resolve redis properties<span class='highlight-text severity-high'>. Need to determine a strategy such that multiple PPCs can be used.</span>","minimal","punctuation","high",False
26470,"Move Mesos SPI to a separate repo As a developer, I'd like to submit a PR for existing work on Mesos SPI. ",NULL,"Move Mesos SPI to a separate repo As a developer, I'd like to submit a PR for existing work on Mesos SPI. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26458,"Documentation Flo for XD Batch As a user, I'd like to refer to job orchestration documentation, so I can use it as guideline for building batch workflows. ",NULL,"Documentation Flo for XD Batch As a user, I'd like to refer to job orchestration documentation,","so I can use it as guideline for building batch workflows.","Add for who this story is","well_formed","no_role","high",False
26458,"Documentation Flo for XD Batch As a user, I'd like to refer to job orchestration documentation, so I can use it as guideline for building batch workflows. ",NULL,"Documentation Flo for XD Batch As a user, I'd like to refer to job orchestration documentation,","so I can use it as guideline for building batch workflows.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26460,"Create admin artifact for each Hadoop distro As a developer, I'd like to split artifact packaged with hadoop distro specific libraries, so I could avoid adding all variations of hadoop libraries under one project. ",NULL,"Create admin artifact for each Hadoop distro As a developer, I'd like to split artifact packaged with hadoop distro specific libraries,","so I could avoid adding all variations of hadoop libraries under one project.","Add for who this story is","well_formed","no_role","high",False
26460,"Create admin artifact for each Hadoop distro As a developer, I'd like to split artifact packaged with hadoop distro specific libraries, so I could avoid adding all variations of hadoop libraries under one project. ",NULL,"Create admin artifact for each Hadoop distro As a developer, I'd like to split artifact packaged with hadoop distro specific libraries,","so I could avoid adding all variations of hadoop libraries under one project.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26461,"Create a XD job definition when posting the DSL to create a spring batch job e.g. trigger job.xml option1 foo it should be stored in redis so that a listing of XD job definitions can be retrieved.",NULL,"Create a XD job definition when posting the DSL to create a spring batch job e.g. trigger job.xml option1 foo it should be stored in redis","so that a listing of XD job definitions can be retrieved.","Add for who this story is","well_formed","no_role","high",False
26461,"Create a XD job definition when posting the DSL to create a spring batch job e.g. trigger job.xml option1 foo it should be stored in redis so that a listing of XD job definitions can be retrieved.",NULL,"Create a XD job definition when posting the DSL to create a spring batch job e.g. trigger job.xml option1 foo it should be stored in redis","so that a listing of XD job definitions can be retrieved.","Create a XD job definition when posting the DSL to create a spring batch job e<span class='highlight-text severity-high'>.g. trigger job.xml option1 foo it should be stored in redis so that a listing of XD job definitions can be retrieved.</span>","minimal","punctuation","high",False
26461,"Create a XD job definition when posting the DSL to create a spring batch job e.g. trigger job.xml option1 foo it should be stored in redis so that a listing of XD job definitions can be retrieved.",NULL,"Create a XD job definition when posting the DSL to create a spring batch job e.g. trigger job.xml option1 foo it should be stored in redis","so that a listing of XD job definitions can be retrieved.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26462,"UI Replace XD with Data Flow As a developer, I'd like to replace all references of Spring XD with Spring Cloud Data Flow. ",NULL,"UI Replace XD with Data Flow As a developer, I'd like to replace all references of Spring XD with Spring Cloud Data Flow. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26463,"UI Replace Job references with Task As a developer, I'd like to replace all . ",NULL,"UI Replace Job references with Task As a developer, I'd like to replace all . ",NULL,"Add for who this story is","well_formed","no_role","high",False
26464,"UI Study PUI theming scope As a user, I'd like to use the admin ui and flo with consistent look and feel. ",NULL,"UI Study PUI theming scope As a user, I'd like to use the admin ui and flo with consistent look and feel. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26464,"UI Study PUI theming scope As a user, I'd like to use the admin ui and flo with consistent look and feel. ",NULL,"UI Study PUI theming scope As a user, I'd like to use the admin ui and flo with consistent look and feel. ",NULL,"UI Study PUI theming scope As a user, I'd like to use the admin ui<span class='highlight-text severity-high'> and </span>flo with consistent look and feel. ","atomic","conjunctions","high",False
26468,"Spike Revisit the core design and document gaps As a developer, I'd like to revisit the existing design and identify known limitations and or the gaps. ",NULL,"Spike Revisit the core design and document gaps As a developer, I'd like to revisit the existing design and identify known limitations and or the gaps. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26468,"Spike Revisit the core design and document gaps As a developer, I'd like to revisit the existing design and identify known limitations and or the gaps. ",NULL,"Spike Revisit the core design and document gaps As a developer, I'd like to revisit the existing design and identify known limitations and or the gaps. ",NULL,"Spike Revisit the core design<span class='highlight-text severity-high'> and </span>document gaps As a developer, I'd like to revisit the existing design and identify known limitations and<span class='highlight-text severity-high'> or </span>the gaps. ","atomic","conjunctions","high",False
26465,"UI Add SPI type and version to about section As a user, I'd like to see the version and SPI type in the about section, so I can confirm which build of I m currently using. ",NULL,"UI Add SPI type and version to about section As a user, I'd like to see the version and SPI type in the about section,","so I can confirm which build of I m currently using.","Add for who this story is","well_formed","no_role","high",False
26465,"UI Add SPI type and version to about section As a user, I'd like to see the version and SPI type in the about section, so I can confirm which build of I m currently using. ",NULL,"UI Add SPI type and version to about section As a user, I'd like to see the version and SPI type in the about section,","so I can confirm which build of I m currently using.","UI Add SPI type<span class='highlight-text severity-high'> and </span>version to about section As a user, I'd like to see the version and SPI type in the about section, so I can confirm which build of I m currently using. ","atomic","conjunctions","high",False
26465,"UI Add SPI type and version to about section As a user, I'd like to see the version and SPI type in the about section, so I can confirm which build of I m currently using. ",NULL,"UI Add SPI type and version to about section As a user, I'd like to see the version and SPI type in the about section,","so I can confirm which build of I m currently using.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26467,"Final review of REST API structure document for streams, taps and jobs Final review of REST API structure document for streams, taps and jobs Get closure on open discussion points for REST API wrt to streams, taps and jobs. Get closure on open discussion points for REST API wrt to streams, taps and jobs. ",NULL,"Final review of REST API structure document for streams, taps and jobs Final review of REST API structure document for streams, taps and jobs Get closure on open discussion points for REST API wrt to streams, taps and jobs. Get closure on open discussion points for REST API wrt to streams, taps and jobs. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26467,"Final review of REST API structure document for streams, taps and jobs Final review of REST API structure document for streams, taps and jobs Get closure on open discussion points for REST API wrt to streams, taps and jobs. Get closure on open discussion points for REST API wrt to streams, taps and jobs. ",NULL,"Final review of REST API structure document for streams, taps and jobs Final review of REST API structure document for streams, taps and jobs Get closure on open discussion points for REST API wrt to streams, taps and jobs. Get closure on open discussion points for REST API wrt to streams, taps and jobs. ",NULL,"Final review of REST API structure document for streams, taps and jobs Final review of REST API structure document for streams, taps and jobs Get closure on open discussion points for REST API wrt to streams, taps and jobs<span class='highlight-text severity-high'>. Get closure on open discussion points for REST API wrt to streams, taps and jobs. </span>","minimal","punctuation","high",False
26469,"Spike Explore options to scale modules from shell As a user, I'd like to have direct shell commands to scale up down a given module instance, so I can avoid SPI specific CLI commands that needs run outside of data flow.",NULL,"Spike Explore options to scale modules from shell As a user, I'd like to have direct shell commands to scale up down a given module instance,","so I can avoid SPI specific CLI commands that needs run outside of data flow.","Add for who this story is","well_formed","no_role","high",False
26469,"Spike Explore options to scale modules from shell As a user, I'd like to have direct shell commands to scale up down a given module instance, so I can avoid SPI specific CLI commands that needs run outside of data flow.",NULL,"Spike Explore options to scale modules from shell As a user, I'd like to have direct shell commands to scale up down a given module instance,","so I can avoid SPI specific CLI commands that needs run outside of data flow.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26473,"Add undeployed status for Lattice SPI As a developer, I'd like to add state.",NULL,"Add undeployed status for Lattice SPI As a developer, I'd like to add state.",NULL,"Add for who this story is","well_formed","no_role","high",False
26471,"Create admin artifact and CI build for Lattice As a developer, I'd like to create separate repo for Lattice SPI, so I don t have to bundle all SPI variants under one admin project.",NULL,"Create admin artifact and CI build for Lattice As a developer, I'd like to create separate repo for Lattice SPI,","so I don t have to bundle all SPI variants under one admin project.","Add for who this story is","well_formed","no_role","high",False
26471,"Create admin artifact and CI build for Lattice As a developer, I'd like to create separate repo for Lattice SPI, so I don t have to bundle all SPI variants under one admin project.",NULL,"Create admin artifact and CI build for Lattice As a developer, I'd like to create separate repo for Lattice SPI,","so I don t have to bundle all SPI variants under one admin project.","Create admin artifact<span class='highlight-text severity-high'> and </span>CI build for Lattice As a developer, I'd like to create separate repo for Lattice SPI, so I don t have to bundle all SPI variants under one admin project.","atomic","conjunctions","high",False
26471,"Create admin artifact and CI build for Lattice As a developer, I'd like to create separate repo for Lattice SPI, so I don t have to bundle all SPI variants under one admin project.",NULL,"Create admin artifact and CI build for Lattice As a developer, I'd like to create separate repo for Lattice SPI,","so I don t have to bundle all SPI variants under one admin project.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26472,"Add undeployed status for CF SPI As a developer, I'd like to add state.",NULL,"Add undeployed status for CF SPI As a developer, I'd like to add state.",NULL,"Add for who this story is","well_formed","no_role","high",False
26474,"Improve connection handling in This is currently too chatty. It should be possible to use a single connection for each increment operation.",NULL,"Improve connection handling in This is currently too chatty. It should be possible to use a single connection for each increment operation.",NULL,"Add for who this story is","well_formed","no_role","high",False
26474,"Improve connection handling in This is currently too chatty. It should be possible to use a single connection for each increment operation.",NULL,"Improve connection handling in This is currently too chatty. It should be possible to use a single connection for each increment operation.",NULL,"Improve connection handling in This is currently too chatty<span class='highlight-text severity-high'>. It should be possible to use a single connection for each increment operation.</span>","minimal","punctuation","high",False
26475,"Add consistent support for undeployed state across the deployers As a developer, I'd like to add support for . This is applicable for existing streams without any deployment context associated with it. ",NULL,"Add consistent support for undeployed state across the deployers As a developer, I'd like to add support for . This is applicable for existing streams without any deployment context associated with it. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26475,"Add consistent support for undeployed state across the deployers As a developer, I'd like to add support for . This is applicable for existing streams without any deployment context associated with it. ",NULL,"Add consistent support for undeployed state across the deployers As a developer, I'd like to add support for . This is applicable for existing streams without any deployment context associated with it. ",NULL,"Add consistent support for undeployed state across the deployers As a developer, I'd like to add support for <span class='highlight-text severity-high'>. This is applicable for existing streams without any deployment context associated with it. </span>","minimal","punctuation","high",False
26466,"Add Flo screenshots to Batch DSL section As a user, I'd like Flo Graphs as screenshots while referring to the batch DSL, so it will be easy for me to relate to concepts. ",NULL,"Add Flo screenshots to Batch DSL section As a user, I'd like Flo Graphs as screenshots while referring to the batch DSL,","so it will be easy for me to relate to concepts.","Add for who this story is","well_formed","no_role","high",False
26466,"Add Flo screenshots to Batch DSL section As a user, I'd like Flo Graphs as screenshots while referring to the batch DSL, so it will be easy for me to relate to concepts. ",NULL,"Add Flo screenshots to Batch DSL section As a user, I'd like Flo Graphs as screenshots while referring to the batch DSL,","so it will be easy for me to relate to concepts.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26486,"Support partitioning for Kafka even if count 1 As a developer, I want to be able to set a partitioning key for the Kafka bus even when there is a single downstream module, so that I can take advantage of the native Kafka partitioning and message ordering support.",NULL,"Support partitioning for Kafka even if count 1 As a developer, I want to be able to set a partitioning key for the Kafka bus even when there is a single downstream module,","so that I can take advantage of the native Kafka partitioning and message ordering support.","Add for who this story is","well_formed","no_role","high",False
26486,"Support partitioning for Kafka even if count 1 As a developer, I want to be able to set a partitioning key for the Kafka bus even when there is a single downstream module, so that I can take advantage of the native Kafka partitioning and message ordering support.",NULL,"Support partitioning for Kafka even if count 1 As a developer, I want to be able to set a partitioning key for the Kafka bus even when there is a single downstream module,","so that I can take advantage of the native Kafka partitioning and message ordering support.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26488,"Document limitations with HSQL when using composed jobs As a developer, I'd want to document the limitations of HSQL DB when using composed jobs. ",NULL,"Document limitations with HSQL when using composed jobs As a developer, I'd want to document the limitations of HSQL DB when using composed jobs. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26487,"Bump Boot and spring cloud build Versions As a developer, I'd like to upgrade Boot and Spring Cloud Build revisions, so I can leverage the latest updates.",NULL,"Bump Boot and spring cloud build Versions As a developer, I'd like to upgrade Boot and Spring Cloud Build revisions,","so I can leverage the latest updates.","Add for who this story is","well_formed","no_role","high",False
26487,"Bump Boot and spring cloud build Versions As a developer, I'd like to upgrade Boot and Spring Cloud Build revisions, so I can leverage the latest updates.",NULL,"Bump Boot and spring cloud build Versions As a developer, I'd like to upgrade Boot and Spring Cloud Build revisions,","so I can leverage the latest updates.","Bump Boot<span class='highlight-text severity-high'> and </span>spring cloud build Versions As a developer, I'd like to upgrade Boot and Spring Cloud Build revisions, so I can leverage the latest updates.","atomic","conjunctions","high",False
26487,"Bump Boot and spring cloud build Versions As a developer, I'd like to upgrade Boot and Spring Cloud Build revisions, so I can leverage the latest updates.",NULL,"Bump Boot and spring cloud build Versions As a developer, I'd like to upgrade Boot and Spring Cloud Build revisions,","so I can leverage the latest updates.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26490,"Upgrade XD Ambari release to 1.3 As a developer, I'd like to upgrade Spring XD s ambari plugin to 1.3 release.",NULL,"Upgrade XD Ambari release to 1.3 As a developer, I'd like to upgrade Spring XD s ambari plugin to 1.3 release.",NULL,"Add for who this story is","well_formed","no_role","high",False
26489,"Command for creating a job Command for creating a job Command for creating a job optional autostart switch to also deploy the job optional autostart switch to also deploy the job optional autostart switch to also deploy the job",NULL,"Command for creating a job Command for creating a job Command for creating a job optional autostart switch to also deploy the job optional autostart switch to also deploy the job optional autostart switch to also deploy the job",NULL,"Add for who this story is","well_formed","no_role","high",False
26492,"Command to deploy a job Command to deploy a job Command to deploy a job Deploy an existing job. Must exist in the JobsRepository Deploy an existing job. Must exist in the JobsRepository Deploy an existing job. Must exist in the JobsRepository",NULL,"Command to deploy a job Command to deploy a job Command to deploy a job Deploy an existing job. Must exist in the JobsRepository Deploy an existing job. Must exist in the JobsRepository Deploy an existing job. Must exist in the JobsRepository",NULL,"Add for who this story is","well_formed","no_role","high",False
26492,"Command to deploy a job Command to deploy a job Command to deploy a job Deploy an existing job. Must exist in the JobsRepository Deploy an existing job. Must exist in the JobsRepository Deploy an existing job. Must exist in the JobsRepository",NULL,"Command to deploy a job Command to deploy a job Command to deploy a job Deploy an existing job. Must exist in the JobsRepository Deploy an existing job. Must exist in the JobsRepository Deploy an existing job. Must exist in the JobsRepository",NULL,"Command to deploy a job Command to deploy a job Command to deploy a job Deploy an existing job<span class='highlight-text severity-high'>. Must exist in the JobsRepository Deploy an existing job. Must exist in the JobsRepository Deploy an existing job. Must exist in the JobsRepository</span>","minimal","punctuation","high",False
26491,"Move k8s SPI to a separate repo As a developer, I'd like to move k8s SPI to it s own repo.",NULL,"Move k8s SPI to a separate repo As a developer, I'd like to move k8s SPI to it s own repo.",NULL,"Add for who this story is","well_formed","no_role","high",False
26496,"add create and deploy methods to JobsController add create and deploy methods to JobsController see Create the controller if it doesn t exist. Test with MvcTest see Create the controller if it doesn t exist. Test with MvcTest",NULL,"add create and deploy methods to JobsController add create and deploy methods to JobsController see Create the controller if it doesn t exist. Test with MvcTest see Create the controller if it doesn t exist. Test with MvcTest",NULL,"Add for who this story is","well_formed","no_role","high",False
26496,"add create and deploy methods to JobsController add create and deploy methods to JobsController see Create the controller if it doesn t exist. Test with MvcTest see Create the controller if it doesn t exist. Test with MvcTest",NULL,"add create and deploy methods to JobsController add create and deploy methods to JobsController see Create the controller if it doesn t exist. Test with MvcTest see Create the controller if it doesn t exist. Test with MvcTest",NULL,"add create<span class='highlight-text severity-high'> and </span>deploy methods to JobsController add create and deploy methods to JobsController see Create the controller if it doesn t exist. Test with MvcTest see Create the controller if it doesn t exist. Test with MvcTest","atomic","conjunctions","high",False
26496,"add create and deploy methods to JobsController add create and deploy methods to JobsController see Create the controller if it doesn t exist. Test with MvcTest see Create the controller if it doesn t exist. Test with MvcTest",NULL,"add create and deploy methods to JobsController add create and deploy methods to JobsController see Create the controller if it doesn t exist. Test with MvcTest see Create the controller if it doesn t exist. Test with MvcTest",NULL,"add create and deploy methods to JobsController add create and deploy methods to JobsController see Create the controller if it doesn t exist<span class='highlight-text severity-high'>. Test with MvcTest see Create the controller if it doesn t exist. Test with MvcTest</span>","minimal","punctuation","high",False
26493,"Command to create a tap Command to create a tap To store it s definition and optionally deploy with autostart flag To store it s definition and optionally deploy with autostart flag",NULL,"Command to create a tap Command to create a tap To store it s definition and optionally deploy with autostart flag To store it s definition and optionally deploy with autostart flag",NULL,"Add for who this story is","well_formed","no_role","high",False
26493,"Command to create a tap Command to create a tap To store it s definition and optionally deploy with autostart flag To store it s definition and optionally deploy with autostart flag",NULL,"Command to create a tap Command to create a tap To store it s definition and optionally deploy with autostart flag To store it s definition and optionally deploy with autostart flag",NULL,"Command to create a tap Command to create a tap To store it s definition<span class='highlight-text severity-high'> and </span>optionally deploy with autostart flag To store it s definition and optionally deploy with autostart flag","atomic","conjunctions","high",False
26495,"Command to delete tap Command to delete tap Command to delete tap ",NULL,"Command to delete tap Command to delete tap Command to delete tap ",NULL,"Add for who this story is","well_formed","no_role","high",False
26499,"add create and deploy methods to StreamDeployer see Refactor current ",NULL,"add create and deploy methods to StreamDeployer see Refactor current ",NULL,"Add for who this story is","well_formed","no_role","high",False
26499,"add create and deploy methods to StreamDeployer see Refactor current ",NULL,"add create and deploy methods to StreamDeployer see Refactor current ",NULL,"add create<span class='highlight-text severity-high'> and </span>deploy methods to StreamDeployer see Refactor current ","atomic","conjunctions","high",False
26497,"add create and deploy methods to JobDeployer add create and deploy methods to JobDeployer see Create the deployer if it doesn t exist. see Create the deployer if it doesn t exist.",NULL,"add create and deploy methods to JobDeployer add create and deploy methods to JobDeployer see Create the deployer if it doesn t exist. see Create the deployer if it doesn t exist.",NULL,"Add for who this story is","well_formed","no_role","high",False
26497,"add create and deploy methods to JobDeployer add create and deploy methods to JobDeployer see Create the deployer if it doesn t exist. see Create the deployer if it doesn t exist.",NULL,"add create and deploy methods to JobDeployer add create and deploy methods to JobDeployer see Create the deployer if it doesn t exist. see Create the deployer if it doesn t exist.",NULL,"add create<span class='highlight-text severity-high'> and </span>deploy methods to JobDeployer add create and deploy methods to JobDeployer see Create the deployer if it doesn t exist. see Create the deployer if it doesn t exist.","atomic","conjunctions","high",False
26497,"add create and deploy methods to JobDeployer add create and deploy methods to JobDeployer see Create the deployer if it doesn t exist. see Create the deployer if it doesn t exist.",NULL,"add create and deploy methods to JobDeployer add create and deploy methods to JobDeployer see Create the deployer if it doesn t exist. see Create the deployer if it doesn t exist.",NULL,"add create and deploy methods to JobDeployer add create and deploy methods to JobDeployer see Create the deployer if it doesn t exist<span class='highlight-text severity-high'>. see Create the deployer if it doesn t exist.</span>","minimal","punctuation","high",False
26501,"add create and deploy methods to TapsController see create TapsController if necessary",NULL,"add create and deploy methods to TapsController see create TapsController if necessary",NULL,"Add for who this story is","well_formed","no_role","high",False
26501,"add create and deploy methods to TapsController see create TapsController if necessary",NULL,"add create and deploy methods to TapsController see create TapsController if necessary",NULL,"add create<span class='highlight-text severity-high'> and </span>deploy methods to TapsController see create TapsController if necessary","atomic","conjunctions","high",False
26500,"Support in HDFS writing features for compression and popular serialization formats TODO break out into sub task or other stories.",NULL,"Support in HDFS writing features for compression and popular serialization formats TODO break out into sub task or other stories.",NULL,"Add for who this story is","well_formed","no_role","high",False
26500,"Support in HDFS writing features for compression and popular serialization formats TODO break out into sub task or other stories.",NULL,"Support in HDFS writing features for compression and popular serialization formats TODO break out into sub task or other stories.",NULL,"Support in HDFS writing features for compression<span class='highlight-text severity-high'> and </span>popular serialization formats TODO break out into sub task<span class='highlight-text severity-high'> or </span>other stories.","atomic","conjunctions","high",False
26503,"Create TapRepository see StreamsRepository as an example. This includes in memory and Redis implementations",NULL,"Create TapRepository see StreamsRepository as an example. This includes in memory and Redis implementations",NULL,"Add for who this story is","well_formed","no_role","high",False
26503,"Create TapRepository see StreamsRepository as an example. This includes in memory and Redis implementations",NULL,"Create TapRepository see StreamsRepository as an example. This includes in memory and Redis implementations",NULL,"Create TapRepository see StreamsRepository as an example<span class='highlight-text severity-high'>. This includes in memory and Redis implementations</span>","minimal","punctuation","high",False
26502,"add create and deploy methods to TapDeployer see ",NULL,"add create and deploy methods to TapDeployer see ",NULL,"Add for who this story is","well_formed","no_role","high",False
26502,"add create and deploy methods to TapDeployer see ",NULL,"add create and deploy methods to TapDeployer see ",NULL,"add create<span class='highlight-text severity-high'> and </span>deploy methods to TapDeployer see ","atomic","conjunctions","high",False
26504,"Implement list method on TapController Implement list method on TapController ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26504,"Implement list method on TapController Implement list method on TapController ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26506,"Error handling on Streams Have proper exceptions for common error cases on Stream and propagate those to clients correctly.",NULL,"Error handling on Streams Have proper exceptions for common error cases on Stream and propagate those to clients correctly.",NULL,"Add for who this story is","well_formed","no_role","high",False
26506,"Error handling on Streams Have proper exceptions for common error cases on Stream and propagate those to clients correctly.",NULL,"Error handling on Streams Have proper exceptions for common error cases on Stream and propagate those to clients correctly.",NULL,"Error handling on Streams Have proper exceptions for common error cases on Stream<span class='highlight-text severity-high'> and </span>propagate those to clients correctly.","atomic","conjunctions","high",False
26508,"Create a stubbed out job controller ",NULL,"Create a stubbed out job controller ",NULL,"Add for who this story is","well_formed","no_role","high",False
26509,"Add section to documentation that shows command line options available for each server This should likely be in the start the runtime section of Getting Started section.",NULL,"Add section to documentation that shows command line options available for each server This should likely be in the start the runtime section of Getting Started section.",NULL,"Add for who this story is","well_formed","no_role","high",False
26498,"add create and deploy methods to StreamsController see create optionally deploys",NULL,"add create and deploy methods to StreamsController see create optionally deploys",NULL,"Add for who this story is","well_formed","no_role","high",False
26498,"add create and deploy methods to StreamsController see create optionally deploys",NULL,"add create and deploy methods to StreamsController see create optionally deploys",NULL,"add create<span class='highlight-text severity-high'> and </span>deploy methods to StreamsController see create optionally deploys","atomic","conjunctions","high",False
26494,"Command to list taps Command to list taps ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26494,"Command to list taps Command to list taps ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26505,"Implement list method on TapDeployer Implement list method on TapDeployer ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26505,"Implement list method on TapDeployer Implement list method on TapDeployer ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26584,"StreamDeployer to implement ResourceDeployer StreamController to not access the repository instance directly, all access to go through StreamDeployer ",NULL,"StreamDeployer to implement ResourceDeployer StreamController to not access the repository instance directly, all access to go through StreamDeployer ",NULL,"Add for who this story is","well_formed","no_role","high",False
26507,"Refactor exception classes NAME?",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26507,"Refactor exception classes NAME?",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26513,"Build script that creates an executable server as an artifact Gradle application plugin is a good starting point. this should be the main server that would host SI based modules to do syslog file ingestion as an example ",NULL,"Build script that creates an executable server as an artifact Gradle application plugin is a good starting point. this should be the main server that would host SI based modules to do syslog file ingestion as an example ",NULL,"Add for who this story is","well_formed","no_role","high",False
26513,"Build script that creates an executable server as an artifact Gradle application plugin is a good starting point. this should be the main server that would host SI based modules to do syslog file ingestion as an example ",NULL,"Build script that creates an executable server as an artifact Gradle application plugin is a good starting point. this should be the main server that would host SI based modules to do syslog file ingestion as an example ",NULL,"Build script that creates an executable server as an artifact Gradle application plugin is a good starting point<span class='highlight-text severity-high'>. this should be the main server that would host SI based modules to do syslog file ingestion as an example </span>","minimal","punctuation","high",False
26512,"Update Getting Started chapter to include a section on starting the shell. The chapter on how to start up the shell should ocme right after start the runtime and before create the stream ",NULL,"Update Getting Started chapter to include a section on starting the shell. The chapter on how to start up the shell should ocme right after start the runtime and before create the stream ",NULL,"Add for who this story is","well_formed","no_role","high",False
26512,"Update Getting Started chapter to include a section on starting the shell. The chapter on how to start up the shell should ocme right after start the runtime and before create the stream ",NULL,"Update Getting Started chapter to include a section on starting the shell. The chapter on how to start up the shell should ocme right after start the runtime and before create the stream ",NULL,"Update Getting Started chapter to include a section on starting the shell. The chapter on how to start up the shell should ocme right after start the runtime<span class='highlight-text severity-high'> and </span>before create the stream ","atomic","conjunctions","high",False
26512,"Update Getting Started chapter to include a section on starting the shell. The chapter on how to start up the shell should ocme right after start the runtime and before create the stream ",NULL,"Update Getting Started chapter to include a section on starting the shell. The chapter on how to start up the shell should ocme right after start the runtime and before create the stream ",NULL,"Update Getting Started chapter to include a section on starting the shell<span class='highlight-text severity-high'>. The chapter on how to start up the shell should ocme right after start the runtime and before create the stream </span>","minimal","punctuation","high",False
26523,"Update Processors Filter JSon Filed Value Filter section to use Shell commands instead of curl See ",NULL,"Update Processors Filter JSon Filed Value Filter section to use Shell commands instead of curl See ",NULL,"Add for who this story is","well_formed","no_role","high",False
26514,"Update Streams Chapter to use shell commands instead of curl the current streams chapter shows creation and deleting streams using CURL switch to use shell. Also add listing of a stream. there is also an example of creating a stream, this should be replaced as well. ",NULL,"Update Streams Chapter to use shell commands instead of curl the current streams chapter shows creation and deleting streams using CURL switch to use shell. Also add listing of a stream. there is also an example of creating a stream, this should be replaced as well. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26514,"Update Streams Chapter to use shell commands instead of curl the current streams chapter shows creation and deleting streams using CURL switch to use shell. Also add listing of a stream. there is also an example of creating a stream, this should be replaced as well. ",NULL,"Update Streams Chapter to use shell commands instead of curl the current streams chapter shows creation and deleting streams using CURL switch to use shell. Also add listing of a stream. there is also an example of creating a stream, this should be replaced as well. ",NULL,"Update Streams Chapter to use shell commands instead of curl the current streams chapter shows creation<span class='highlight-text severity-high'> and </span>deleting streams using CURL switch to use shell. Also add listing of a stream. there is also an example of creating a stream, this should be replaced as well. ","atomic","conjunctions","high",False
26514,"Update Streams Chapter to use shell commands instead of curl the current streams chapter shows creation and deleting streams using CURL switch to use shell. Also add listing of a stream. there is also an example of creating a stream, this should be replaced as well. ",NULL,"Update Streams Chapter to use shell commands instead of curl the current streams chapter shows creation and deleting streams using CURL switch to use shell. Also add listing of a stream. there is also an example of creating a stream, this should be replaced as well. ",NULL,"Update Streams Chapter to use shell commands instead of curl the current streams chapter shows creation and deleting streams using CURL switch to use shell<span class='highlight-text severity-high'>. Also add listing of a stream. there is also an example of creating a stream, this should be replaced as well. </span>","minimal","punctuation","high",False
26521,"Update Source Syslog section to use Shell commands instead of curl See ",NULL,"Update Source Syslog section to use Shell commands instead of curl See ",NULL,"Add for who this story is","well_formed","no_role","high",False
26515,"Create a shell command to post data to an http port for use with the http source module the current streams chapter shows using curl to post some data to a http source module, curl d hello create a shell command so curl doesn t have to be used. has a command already developed for this.",NULL,"Create a shell command to post data to an http port for use with the http","source module the current streams chapter shows using curl to post some data to a http source module, curl d hello create a shell command so curl doesn t have to be used. has a command already developed for this.","Add for who this story is","well_formed","no_role","high",False
26515,"Create a shell command to post data to an http port for use with the http source module the current streams chapter shows using curl to post some data to a http source module, curl d hello create a shell command so curl doesn t have to be used. has a command already developed for this.",NULL,"Create a shell command to post data to an http port for use with the http","source module the current streams chapter shows using curl to post some data to a http source module, curl d hello create a shell command so curl doesn t have to be used. has a command already developed for this.","Create a shell command to post data to an http port for use with the http source module the current streams chapter shows using curl to post some data to a http source module, curl d hello create a shell command so curl doesn t have to be used<span class='highlight-text severity-high'>. has a command already developed for this.</span>","minimal","punctuation","high",False
26515,"Create a shell command to post data to an http port for use with the http source module the current streams chapter shows using curl to post some data to a http source module, curl d hello create a shell command so curl doesn t have to be used. has a command already developed for this.",NULL,"Create a shell command to post data to an http port for use with the http","source module the current streams chapter shows using curl to post some data to a http source module, curl d hello create a shell command so curl doesn t have to be used. has a command already developed for this.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26517,"Update Sources section to use Shell commands instead of curl See ",NULL,"Update Sources section to use Shell commands instead of curl See ",NULL,"Add for who this story is","well_formed","no_role","high",False
26519,"Update Sources twitter search section to use Shell commands instead of curl See ",NULL,"Update Sources twitter search section to use Shell commands instead of curl See ",NULL,"Add for who this story is","well_formed","no_role","high",False
26528,"Update Sink s File section to use Shell commands instead of curl See ",NULL,"Update Sink s File section to use Shell commands instead of curl See ",NULL,"Add for who this story is","well_formed","no_role","high",False
26520,"Update Sources Gemfire CQ section to use Shell commands instead of curl See ",NULL,"Update Sources Gemfire CQ section to use Shell commands instead of curl See ",NULL,"Add for who this story is","well_formed","no_role","high",False
26522,"Update Sources TCP section to use Shell commands instead of curl See ",NULL,"Update Sources TCP section to use Shell commands instead of curl See ",NULL,"Add for who this story is","well_formed","no_role","high",False
26524,"Update Processors Transform section to use Shell commands instead of curl See ",NULL,"Update Processors Transform section to use Shell commands instead of curl See ",NULL,"Add for who this story is","well_formed","no_role","high",False
26530,"Update Sink s TCP section to use Shell commands instead of curl See ",NULL,"Update Sink s TCP section to use Shell commands instead of curl See ",NULL,"Add for who this story is","well_formed","no_role","high",False
26525,"Update Processors JSON Field Extractor section to use Shell commands instead of curl See ",NULL,"Update Processors JSON Field Extractor section to use Shell commands instead of curl See ",NULL,"Add for who this story is","well_formed","no_role","high",False
26526,"Update Processors Script section to use Shell commands instead of curl See ",NULL,"Update Processors Script section to use Shell commands instead of curl See ",NULL,"Add for who this story is","well_formed","no_role","high",False
26527,"Update Sink s Log section to use Shell commands instead of curl See ",NULL,"Update Sink s Log section to use Shell commands instead of curl See ",NULL,"Add for who this story is","well_formed","no_role","high",False
26529,"Update Sink s HDFS section to use Shell commands instead of curl See ",NULL,"Update Sink s HDFS section to use Shell commands instead of curl See ",NULL,"Add for who this story is","well_formed","no_role","high",False
26569,"Add JSON conversion to tuple Support toString to emit JSON by default. Should be backed by a simple strategy to allow the possibility of other representations. Also provide toTuple String json . This supports seamless mapping JSON Tuple in XD",NULL,"Add JSON conversion to tuple Support toString to emit JSON by default. Should be backed by a simple strategy to allow the possibility of other representations. Also provide toTuple String json . This supports seamless mapping JSON Tuple in XD",NULL,"Add for who this story is","well_formed","no_role","high",False
26569,"Add JSON conversion to tuple Support toString to emit JSON by default. Should be backed by a simple strategy to allow the possibility of other representations. Also provide toTuple String json . This supports seamless mapping JSON Tuple in XD",NULL,"Add JSON conversion to tuple Support toString to emit JSON by default. Should be backed by a simple strategy to allow the possibility of other representations. Also provide toTuple String json . This supports seamless mapping JSON Tuple in XD",NULL,"Add JSON conversion to tuple Support toString to emit JSON by default<span class='highlight-text severity-high'>. Should be backed by a simple strategy to allow the possibility of other representations. Also provide toTuple String json . This supports seamless mapping JSON Tuple in XD</span>","minimal","punctuation","high",False
26531,"Update Sink s GemFire section to use Shell commands instead of curl See ",NULL,"Update Sink s GemFire section to use Shell commands instead of curl See ",NULL,"Add for who this story is","well_formed","no_role","high",False
26510,"Document Monitoring Management Features This section should discuss what is exposed via JMX, how you can view it in JConsole, and how you can view it over http via Jolikia. in particular showing how some existing metrics for inbound message channel adapters or the inbound channel of the stream, that indicate the number of messages processed per section. ",NULL,"Document Monitoring Management Features This section should discuss what is exposed via JMX, how you can view it in JConsole, and how you can view it over http via Jolikia. in particular showing how some existing metrics for inbound message channel adapters or the inbound channel of the stream, that indicate the number of messages processed per section. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26510,"Document Monitoring Management Features This section should discuss what is exposed via JMX, how you can view it in JConsole, and how you can view it over http via Jolikia. in particular showing how some existing metrics for inbound message channel adapters or the inbound channel of the stream, that indicate the number of messages processed per section. ",NULL,"Document Monitoring Management Features This section should discuss what is exposed via JMX, how you can view it in JConsole, and how you can view it over http via Jolikia. in particular showing how some existing metrics for inbound message channel adapters or the inbound channel of the stream, that indicate the number of messages processed per section. ",NULL,"Document Monitoring Management Features This section should discuss what is exposed via JMX, how you can view it in JConsole,<span class='highlight-text severity-high'> and </span>how you can view it over http via Jolikia. in particular showing how some existing metrics for inbound message channel adapters<span class='highlight-text severity-high'> or </span>the inbound channel of the stream, that indicate the number of messages processed per section. ","atomic","conjunctions","high",False
26510,"Document Monitoring Management Features This section should discuss what is exposed via JMX, how you can view it in JConsole, and how you can view it over http via Jolikia. in particular showing how some existing metrics for inbound message channel adapters or the inbound channel of the stream, that indicate the number of messages processed per section. ",NULL,"Document Monitoring Management Features This section should discuss what is exposed via JMX, how you can view it in JConsole, and how you can view it over http via Jolikia. in particular showing how some existing metrics for inbound message channel adapters or the inbound channel of the stream, that indicate the number of messages processed per section. ",NULL,"Document Monitoring Management Features This section should discuss what is exposed via JMX, how you can view it in JConsole, and how you can view it over http via Jolikia<span class='highlight-text severity-high'>. in particular showing how some existing metrics for inbound message channel adapters or the inbound channel of the stream, that indicate the number of messages processed per section. </span>","minimal","punctuation","high",False
26518,"Update Sources tail section to use Shell commands instead of curl ",NULL,"Update Sources tail section to use Shell commands instead of curl ",NULL,"Add for who this story is","well_formed","no_role","high",False
26533,"Documentation for AggregateCounter Add section to Analytics chapter on use of AggregateCounter. The example should show the use of the shell to create the tap that uses the AggregateCounter.",NULL,"Documentation for AggregateCounter Add section to Analytics chapter on use of AggregateCounter. The example should show the use of the shell to create the tap that uses the AggregateCounter.",NULL,"Add for who this story is","well_formed","no_role","high",False
26533,"Documentation for AggregateCounter Add section to Analytics chapter on use of AggregateCounter. The example should show the use of the shell to create the tap that uses the AggregateCounter.",NULL,"Documentation for AggregateCounter Add section to Analytics chapter on use of AggregateCounter. The example should show the use of the shell to create the tap that uses the AggregateCounter.",NULL,"Documentation for AggregateCounter Add section to Analytics chapter on use of AggregateCounter<span class='highlight-text severity-high'>. The example should show the use of the shell to create the tap that uses the AggregateCounter.</span>","minimal","punctuation","high",False
26534,"Update Analytics Counter section to use Shell commands instead of curl ",NULL,"Update Analytics Counter section to use Shell commands instead of curl ",NULL,"Add for who this story is","well_formed","no_role","high",False
26535,"Update Analytics Field Value Counter section to use Shell commands instead of curl ",NULL,"Update Analytics Field Value Counter section to use Shell commands instead of curl ",NULL,"Add for who this story is","well_formed","no_role","high",False
26536,"Update Analytics Gauge section to use Shell commands instead of curl ",NULL,"Update Analytics Gauge section to use Shell commands instead of curl ",NULL,"Add for who this story is","well_formed","no_role","high",False
26537,"Update Analytics Rich Gauge section to use Shell commands instead of curl ",NULL,"Update Analytics Rich Gauge section to use Shell commands instead of curl ",NULL,"Add for who this story is","well_formed","no_role","high",False
26538,"Update Samples syslog ingestion section to use Shell commands instead of curl ",NULL,"Update Samples syslog ingestion section to use Shell commands instead of curl ",NULL,"Add for who this story is","well_formed","no_role","high",False
26539,"Update Creating a Processor Module section to use Shell commands instead of curl test the deployed module sub section uses curl.",NULL,"Update Creating a Processor Module section to use Shell commands instead of curl test the deployed module sub section uses curl.",NULL,"Add for who this story is","well_formed","no_role","high",False
26540,"Update Creating a Source Module section to use Shell commands instead of curl See ",NULL,"Update Creating a Source Module section to use Shell commands instead of curl See ",NULL,"Add for who this story is","well_formed","no_role","high",False
26541,"Update Creating a Sink Module section to use Shell commands instead of curl See ",NULL,"Update Creating a Sink Module section to use Shell commands instead of curl See ",NULL,"Add for who this story is","well_formed","no_role","high",False
26542,"Metric repositories should support Spring Data CrudRepository interface This provides common CRUD behavior and a shared interface that can be useful in testing scenarios. ",NULL,"Metric repositories should support Spring Data CrudRepository interface This provides common CRUD behavior and a shared interface that can be useful in testing scenarios. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26542,"Metric repositories should support Spring Data CrudRepository interface This provides common CRUD behavior and a shared interface that can be useful in testing scenarios. ",NULL,"Metric repositories should support Spring Data CrudRepository interface This provides common CRUD behavior and a shared interface that can be useful in testing scenarios. ",NULL,"Metric repositories should support Spring Data CrudRepository interface This provides common CRUD behavior<span class='highlight-text severity-high'> and </span>a shared interface that can be useful in testing scenarios. ","atomic","conjunctions","high",False
26543,"Use a Different Default Jolokia Port for Admin Vs. Container Avoid the need for on the same server",NULL,"Use a Different Default Jolokia Port for Admin Vs. Container Avoid the need for on the same server",NULL,"Add for who this story is","well_formed","no_role","high",False
26543,"Use a Different Default Jolokia Port for Admin Vs. Container Avoid the need for on the same server",NULL,"Use a Different Default Jolokia Port for Admin Vs. Container Avoid the need for on the same server",NULL,"Use a Different Default Jolokia Port for Admin Vs<span class='highlight-text severity-high'>. Container Avoid the need for on the same server</span>","minimal","punctuation","high",False
26544,"Make String conversion optional with local transport ",NULL,"Make String conversion optional with local transport ",NULL,"Add for who this story is","well_formed","no_role","high",False
26545,"User wants to configure MessageBus XD 162 requires registering message converters with the ChannelRegistry. End user needs to configure this statically as the Spring configuration is not exposed.",NULL,"User wants to configure MessageBus XD 162 requires registering message converters with the ChannelRegistry. End user needs to configure this statically as the Spring configuration is not exposed.",NULL,"Add for who this story is","well_formed","no_role","high",False
26545,"User wants to configure MessageBus XD 162 requires registering message converters with the ChannelRegistry. End user needs to configure this statically as the Spring configuration is not exposed.",NULL,"User wants to configure MessageBus XD 162 requires registering message converters with the ChannelRegistry. End user needs to configure this statically as the Spring configuration is not exposed.",NULL,"User wants to configure MessageBus XD 162 requires registering message converters with the ChannelRegistry<span class='highlight-text severity-high'>. End user needs to configure this statically as the Spring configuration is not exposed.</span>","minimal","punctuation","high",False
26546,"Homogenize Container Initialization Failures If Redis is not running, the container fails to initialize in because the connection factory attempts to eagerly connect. If RabbitMQ is not running, the container fails to initialize in . Make the failure behavior consistent from a user perspective and add a spring retry to retry container startup.",NULL,"Homogenize Container Initialization Failures If Redis is not running, the container fails to initialize in because the connection factory attempts to eagerly connect. If RabbitMQ is not running, the container fails to initialize in . Make the failure behavior consistent from a user perspective and add a spring retry to retry container startup.",NULL,"Add for who this story is","well_formed","no_role","high",False
26546,"Homogenize Container Initialization Failures If Redis is not running, the container fails to initialize in because the connection factory attempts to eagerly connect. If RabbitMQ is not running, the container fails to initialize in . Make the failure behavior consistent from a user perspective and add a spring retry to retry container startup.",NULL,"Homogenize Container Initialization Failures If Redis is not running, the container fails to initialize in because the connection factory attempts to eagerly connect. If RabbitMQ is not running, the container fails to initialize in . Make the failure behavior consistent from a user perspective and add a spring retry to retry container startup.",NULL,"Homogenize Container Initialization Failures If Redis is not running, the container fails to initialize in because the connection factory attempts to eagerly connect. If RabbitMQ is not running, the container fails to initialize in . Make the failure behavior consistent from a user perspective<span class='highlight-text severity-high'> and </span>add a spring retry to retry container startup.","atomic","conjunctions","high",False
26546,"Homogenize Container Initialization Failures If Redis is not running, the container fails to initialize in because the connection factory attempts to eagerly connect. If RabbitMQ is not running, the container fails to initialize in . Make the failure behavior consistent from a user perspective and add a spring retry to retry container startup.",NULL,"Homogenize Container Initialization Failures If Redis is not running, the container fails to initialize in because the connection factory attempts to eagerly connect. If RabbitMQ is not running, the container fails to initialize in . Make the failure behavior consistent from a user perspective and add a spring retry to retry container startup.",NULL,"Homogenize Container Initialization Failures If Redis is not running, the container fails to initialize in because the connection factory attempts to eagerly connect<span class='highlight-text severity-high'>. If RabbitMQ is not running, the container fails to initialize in . Make the failure behavior consistent from a user perspective and add a spring retry to retry container startup.</span>","minimal","punctuation","high",False
26547,"Create tests to load the standard runtime app context configurations The basic launch configurations should be tested automatically to ensure that startup scripts and launch aren t broken by changes.",NULL,"Create tests to load the standard runtime app context configurations The basic launch configurations should be tested automatically to ensure that startup scripts and launch aren t broken by changes.",NULL,"Add for who this story is","well_formed","no_role","high",False
26547,"Create tests to load the standard runtime app context configurations The basic launch configurations should be tested automatically to ensure that startup scripts and launch aren t broken by changes.",NULL,"Create tests to load the standard runtime app context configurations The basic launch configurations should be tested automatically to ensure that startup scripts and launch aren t broken by changes.",NULL,"Create tests to load the standard runtime app context configurations The basic launch configurations should be tested automatically to ensure that startup scripts<span class='highlight-text severity-high'> and </span>launch aren t broken by changes.","atomic","conjunctions","high",False
26548,"Decouple s with runtime dependencies",NULL,"Decouple s with runtime dependencies",NULL,"Add for who this story is","well_formed","no_role","high",False
26549,"Fix Package Tangles Looking at the latest Sonar run we have 3 package tangles in Spring XD ",NULL,"Fix Package Tangles Looking at the latest Sonar run we have 3 package tangles in Spring XD ",NULL,"Add for who this story is","well_formed","no_role","high",False
26550,"Redis based repositories should use a NamingStrategy class to calculate the name of the key to use for persistence and have duplicated code that needs to be factored out into a one place. One such duplication is the determination of the key name to use for persistence. This should be abstracted out into a strategy helper class.",NULL,"Redis based repositories should use a NamingStrategy class to calculate the name of the key to use for persistence and have duplicated code that needs to be factored out into a one place. One such duplication is the determination of the key name to use for persistence. This should be abstracted out into a strategy helper class.",NULL,"Add for who this story is","well_formed","no_role","high",False
26550,"Redis based repositories should use a NamingStrategy class to calculate the name of the key to use for persistence and have duplicated code that needs to be factored out into a one place. One such duplication is the determination of the key name to use for persistence. This should be abstracted out into a strategy helper class.",NULL,"Redis based repositories should use a NamingStrategy class to calculate the name of the key to use for persistence and have duplicated code that needs to be factored out into a one place. One such duplication is the determination of the key name to use for persistence. This should be abstracted out into a strategy helper class.",NULL,"Redis based repositories should use a NamingStrategy class to calculate the name of the key to use for persistence<span class='highlight-text severity-high'> and </span>have duplicated code that needs to be factored out into a one place. One such duplication is the determination of the key name to use for persistence. This should be abstracted out into a strategy helper class.","atomic","conjunctions","high",False
26550,"Redis based repositories should use a NamingStrategy class to calculate the name of the key to use for persistence and have duplicated code that needs to be factored out into a one place. One such duplication is the determination of the key name to use for persistence. This should be abstracted out into a strategy helper class.",NULL,"Redis based repositories should use a NamingStrategy class to calculate the name of the key to use for persistence and have duplicated code that needs to be factored out into a one place. One such duplication is the determination of the key name to use for persistence. This should be abstracted out into a strategy helper class.",NULL,"Redis based repositories should use a NamingStrategy class to calculate the name of the key to use for persistence and have duplicated code that needs to be factored out into a one place<span class='highlight-text severity-high'>. One such duplication is the determination of the key name to use for persistence. This should be abstracted out into a strategy helper class.</span>","minimal","punctuation","high",False
26551,"More DSL work Documentation updates for new format Once issues like XD 438 have been completed the wiki doc will need updates to reflect the current behaviour and syntax options.",NULL,"More DSL work Documentation updates for new format Once issues like XD 438 have been completed the wiki doc will need updates to reflect the current behaviour and syntax options.",NULL,"Add for who this story is","well_formed","no_role","high",False
26552,"Make Redis Rabbit Rules Conditional Dependent servers should be required on the CI server, but optional on developer systems.",NULL,"Make Redis Rabbit Rules Conditional Dependent servers should be required on the CI server, but optional on developer systems.",NULL,"Add for who this story is","well_formed","no_role","high",False
26553,"Add support to set the read timeout for http request We need to have the ability to set read timeout for http request. This is already implemented here ",NULL,"Add support to set the read timeout for http request We need to have the ability to set read timeout for http request. This is already implemented here ",NULL,"Add for who this story is","well_formed","no_role","high",False
26553,"Add support to set the read timeout for http request We need to have the ability to set read timeout for http request. This is already implemented here ",NULL,"Add support to set the read timeout for http request We need to have the ability to set read timeout for http request. This is already implemented here ",NULL,"Add support to set the read timeout for http request We need to have the ability to set read timeout for http request<span class='highlight-text severity-high'>. This is already implemented here </span>","minimal","punctuation","high",False
26574,"Modify startup script of to allow specifying hadoop distro to use we need to modify startup script to use hadoop 1.1.2 as default or phd1 when specified with hadoopDistro phd1",NULL,"Modify startup script of to allow specifying hadoop distro to use we need to modify startup script to use hadoop 1.1.2 as default or phd1 when specified with hadoopDistro phd1",NULL,"Add for who this story is","well_formed","no_role","high",False
26574,"Modify startup script of to allow specifying hadoop distro to use we need to modify startup script to use hadoop 1.1.2 as default or phd1 when specified with hadoopDistro phd1",NULL,"Modify startup script of to allow specifying hadoop distro to use we need to modify startup script to use hadoop 1.1.2 as default or phd1 when specified with hadoopDistro phd1",NULL,"Modify startup script of to allow specifying hadoop distro to use we need to modify startup script to use hadoop 1.1.2 as default<span class='highlight-text severity-high'> or </span>phd1 when specified with hadoopDistro phd1","atomic","conjunctions","high",False
26575,"Create JSON to tab delimited text transformer script We need a generic script that can do JSON to tab delimited text transformation for data written to HDFS HAWQ external tables. Users should be able to specify columns fields to be included.",NULL,"Create JSON to tab delimited text transformer script We need a generic script that can do JSON to tab delimited text transformation for data written to HDFS HAWQ external tables. Users should be able to specify columns fields to be included.",NULL,"Add for who this story is","well_formed","no_role","high",False
26575,"Create JSON to tab delimited text transformer script We need a generic script that can do JSON to tab delimited text transformation for data written to HDFS HAWQ external tables. Users should be able to specify columns fields to be included.",NULL,"Create JSON to tab delimited text transformer script We need a generic script that can do JSON to tab delimited text transformation for data written to HDFS HAWQ external tables. Users should be able to specify columns fields to be included.",NULL,"Create JSON to tab delimited text transformer script We need a generic script that can do JSON to tab delimited text transformation for data written to HDFS HAWQ external tables<span class='highlight-text severity-high'>. Users should be able to specify columns fields to be included.</span>","minimal","punctuation","high",False
26576,"Support pagination in list command for streams Spring HATEOAS is here to help. Nonetheless, there are currently a number of outstanding issues, namely Creating a issue here for future reference",NULL,"Support pagination in list command for streams Spring HATEOAS is here to help. Nonetheless, there are currently a number of outstanding issues, namely Creating a issue here for future reference",NULL,"Add for who this story is","well_formed","no_role","high",False
26576,"Support pagination in list command for streams Spring HATEOAS is here to help. Nonetheless, there are currently a number of outstanding issues, namely Creating a issue here for future reference",NULL,"Support pagination in list command for streams Spring HATEOAS is here to help. Nonetheless, there are currently a number of outstanding issues, namely Creating a issue here for future reference",NULL,"Support pagination in list command for streams Spring HATEOAS is here to help<span class='highlight-text severity-high'>. Nonetheless, there are currently a number of outstanding issues, namely Creating a issue here for future reference</span>","minimal","punctuation","high",False
26577,"Add conversion support to ChannelRegistrar and ChannelRegistry Implements automatic conversion. Provide APIs to channel registry to register Payload conversion. Includes Redis and Rabbit transport.",NULL,"Add conversion support to ChannelRegistrar and ChannelRegistry Implements automatic conversion. Provide APIs to channel registry to register Payload conversion. Includes Redis and Rabbit transport.",NULL,"Add for who this story is","well_formed","no_role","high",False
26577,"Add conversion support to ChannelRegistrar and ChannelRegistry Implements automatic conversion. Provide APIs to channel registry to register Payload conversion. Includes Redis and Rabbit transport.",NULL,"Add conversion support to ChannelRegistrar and ChannelRegistry Implements automatic conversion. Provide APIs to channel registry to register Payload conversion. Includes Redis and Rabbit transport.",NULL,"Add conversion support to ChannelRegistrar<span class='highlight-text severity-high'> and </span>ChannelRegistry Implements automatic conversion. Provide APIs to channel registry to register Payload conversion. Includes Redis and Rabbit transport.","atomic","conjunctions","high",False
26577,"Add conversion support to ChannelRegistrar and ChannelRegistry Implements automatic conversion. Provide APIs to channel registry to register Payload conversion. Includes Redis and Rabbit transport.",NULL,"Add conversion support to ChannelRegistrar and ChannelRegistry Implements automatic conversion. Provide APIs to channel registry to register Payload conversion. Includes Redis and Rabbit transport.",NULL,"Add conversion support to ChannelRegistrar and ChannelRegistry Implements automatic conversion<span class='highlight-text severity-high'>. Provide APIs to channel registry to register Payload conversion. Includes Redis and Rabbit transport.</span>","minimal","punctuation","high",False
26578,"Job Delete Destroy Command for shell ",NULL,"Job Delete Destroy Command for shell ",NULL,"Add for who this story is","well_formed","no_role","high",False
26579,"All controllers to return XYZResource objects not the raw domain objects. Resource objects should be returned from all controller methods. MVC Tests should be added to check returned values.",NULL,"All controllers to return XYZResource objects not the raw domain objects. Resource objects should be returned from all controller methods. MVC Tests should be added to check returned values.",NULL,"Add for who this story is","well_formed","no_role","high",False
26579,"All controllers to return XYZResource objects not the raw domain objects. Resource objects should be returned from all controller methods. MVC Tests should be added to check returned values.",NULL,"All controllers to return XYZResource objects not the raw domain objects. Resource objects should be returned from all controller methods. MVC Tests should be added to check returned values.",NULL,"All controllers to return XYZResource objects not the raw domain objects<span class='highlight-text severity-high'>. Resource objects should be returned from all controller methods. MVC Tests should be added to check returned values.</span>","minimal","punctuation","high",False
26580,"StreamsController to return paged results for list See implementation used for Steams and apply to jobs, taps, triggers.",NULL,"StreamsController to return paged results for list See implementation used for Steams and apply to jobs, taps, triggers.",NULL,"Add for who this story is","well_formed","no_role","high",False
26580,"StreamsController to return paged results for list See implementation used for Steams and apply to jobs, taps, triggers.",NULL,"StreamsController to return paged results for list See implementation used for Steams and apply to jobs, taps, triggers.",NULL,"StreamsController to return paged results for list See implementation used for Steams<span class='highlight-text severity-high'> and </span>apply to jobs, taps, triggers.","atomic","conjunctions","high",False
26581,"Rename controllers to have pluralized named e.g. JobsController See implementation used for Steams and apply to jobs, taps, triggers.",NULL,"Rename controllers to have pluralized named e.g. JobsController See implementation used for Steams and apply to jobs, taps, triggers.",NULL,"Add for who this story is","well_formed","no_role","high",False
26581,"Rename controllers to have pluralized named e.g. JobsController See implementation used for Steams and apply to jobs, taps, triggers.",NULL,"Rename controllers to have pluralized named e.g. JobsController See implementation used for Steams and apply to jobs, taps, triggers.",NULL,"Rename controllers to have pluralized named e.g. JobsController See implementation used for Steams<span class='highlight-text severity-high'> and </span>apply to jobs, taps, triggers.","atomic","conjunctions","high",False
26581,"Rename controllers to have pluralized named e.g. JobsController See implementation used for Steams and apply to jobs, taps, triggers.",NULL,"Rename controllers to have pluralized named e.g. JobsController See implementation used for Steams and apply to jobs, taps, triggers.",NULL,"Rename controllers to have pluralized named e<span class='highlight-text severity-high'>.g. JobsController See implementation used for Steams and apply to jobs, taps, triggers.</span>","minimal","punctuation","high",False
26582,"Introduce distinction between TapDefinition and Tap the instance Rename existing Tap class to something else.",NULL,"Introduce distinction between TapDefinition and Tap the instance Rename existing Tap class to something else.",NULL,"Add for who this story is","well_formed","no_role","high",False
26582,"Introduce distinction between TapDefinition and Tap the instance Rename existing Tap class to something else.",NULL,"Introduce distinction between TapDefinition and Tap the instance Rename existing Tap class to something else.",NULL,"Introduce distinction between TapDefinition<span class='highlight-text severity-high'> and </span>Tap the instance Rename existing Tap class to something else.","atomic","conjunctions","high",False
26585,"Exception Consistency Favor using custom exceptions instead of using Assert.notNull, review usage and make changes. Eg. if a stream can t be found or another definition a instead of Assert.Null on the return value of a findOne method ",NULL,"Exception Consistency Favor using custom exceptions instead of using Assert.notNull, review usage and make changes. Eg. if a stream can t be found or another definition a instead of Assert.Null on the return value of a findOne method ",NULL,"Add for who this story is","well_formed","no_role","high",False
26585,"Exception Consistency Favor using custom exceptions instead of using Assert.notNull, review usage and make changes. Eg. if a stream can t be found or another definition a instead of Assert.Null on the return value of a findOne method ",NULL,"Exception Consistency Favor using custom exceptions instead of using Assert.notNull, review usage and make changes. Eg. if a stream can t be found or another definition a instead of Assert.Null on the return value of a findOne method ",NULL,"Exception Consistency Favor using custom exceptions instead of using Assert.notNull, review usage<span class='highlight-text severity-high'> and </span>make changes. Eg. if a stream can t be found<span class='highlight-text severity-high'> or </span>another definition a instead of Assert.Null on the return value of a findOne method ","atomic","conjunctions","high",False
26585,"Exception Consistency Favor using custom exceptions instead of using Assert.notNull, review usage and make changes. Eg. if a stream can t be found or another definition a instead of Assert.Null on the return value of a findOne method ",NULL,"Exception Consistency Favor using custom exceptions instead of using Assert.notNull, review usage and make changes. Eg. if a stream can t be found or another definition a instead of Assert.Null on the return value of a findOne method ",NULL,"Exception Consistency Favor using custom exceptions instead of using Assert<span class='highlight-text severity-high'>.notNull, review usage and make changes. Eg. if a stream can t be found or another definition a instead of Assert.Null on the return value of a findOne method </span>","minimal","punctuation","high",False
26583,"Move Redis Queue Channel Adapters into Currently these implementations are in the spring xd dirt module, but they should be moved into We are already depending upon Spring Integration 3.0 snapshots since the ChannelRegistry implementation is not yet at a milestone, so this should be okay for the Redis Channel Adapters also until Spring Integration M2 is released.",NULL,"Move Redis Queue Channel Adapters into Currently these implementations are in the spring xd dirt module, but they should be moved into We are already depending upon Spring Integration 3.0 snapshots since the ChannelRegistry implementation is not yet at a milestone,","so this should be okay for the Redis Channel Adapters also until Spring Integration M2 is released.","Add for who this story is","well_formed","no_role","high",False
26583,"Move Redis Queue Channel Adapters into Currently these implementations are in the spring xd dirt module, but they should be moved into We are already depending upon Spring Integration 3.0 snapshots since the ChannelRegistry implementation is not yet at a milestone, so this should be okay for the Redis Channel Adapters also until Spring Integration M2 is released.",NULL,"Move Redis Queue Channel Adapters into Currently these implementations are in the spring xd dirt module, but they should be moved into We are already depending upon Spring Integration 3.0 snapshots since the ChannelRegistry implementation is not yet at a milestone,","so this should be okay for the Redis Channel Adapters also until Spring Integration M2 is released.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26587,"Remove duplicate code in ResourceDeployer implementations, create abstract base class. Only create in TapDeployer has some additional code to check if the stream exists, could take place in another location.",NULL,"Remove duplicate code in ResourceDeployer implementations, create abstract base class. Only create in TapDeployer has some additional code to check if the stream exists, could take place in another location.",NULL,"Add for who this story is","well_formed","no_role","high",False
26587,"Remove duplicate code in ResourceDeployer implementations, create abstract base class. Only create in TapDeployer has some additional code to check if the stream exists, could take place in another location.",NULL,"Remove duplicate code in ResourceDeployer implementations, create abstract base class. Only create in TapDeployer has some additional code to check if the stream exists, could take place in another location.",NULL,"Remove duplicate code in ResourceDeployer implementations, create abstract base class<span class='highlight-text severity-high'>. Only create in TapDeployer has some additional code to check if the stream exists, could take place in another location.</span>","minimal","punctuation","high",False
26586,"Rename create to save in ResourceDeployer To be consistent with Spring Data Repository method names.",NULL,"Rename create to save in ResourceDeployer To be consistent with Spring Data Repository method names.",NULL,"Add for who this story is","well_formed","no_role","high",False
26589,"Document MQTT Source and Sink ",NULL,"Document MQTT Source and Sink ",NULL,"Add for who this story is","well_formed","no_role","high",False
26588,"Implement common set of controller methods Save Save a XYZDefinition method used to be create Delete Delete a XYZDefinition method used to be called destroy Deploy Deploy a XYZDefinition Undeploy Undeploy a XYZDefinition List List a XYZDefinition Returns Display Get specific information about a XYZDefinition Create other stories for each Controller and include in this weeks sprint ",NULL,"Implement common set of controller methods Save Save a XYZDefinition method used to be create Delete Delete a XYZDefinition method used to be called destroy Deploy Deploy a XYZDefinition Undeploy Undeploy a XYZDefinition List List a XYZDefinition Returns Display Get specific information about a XYZDefinition Create other stories for each Controller and include in this weeks sprint ",NULL,"Add for who this story is","well_formed","no_role","high",False
26588,"Implement common set of controller methods Save Save a XYZDefinition method used to be create Delete Delete a XYZDefinition method used to be called destroy Deploy Deploy a XYZDefinition Undeploy Undeploy a XYZDefinition List List a XYZDefinition Returns Display Get specific information about a XYZDefinition Create other stories for each Controller and include in this weeks sprint ",NULL,"Implement common set of controller methods Save Save a XYZDefinition method used to be create Delete Delete a XYZDefinition method used to be called destroy Deploy Deploy a XYZDefinition Undeploy Undeploy a XYZDefinition List List a XYZDefinition Returns Display Get specific information about a XYZDefinition Create other stories for each Controller and include in this weeks sprint ",NULL,"Implement common set of controller methods Save Save a XYZDefinition method used to be create Delete Delete a XYZDefinition method used to be called destroy Deploy Deploy a XYZDefinition Undeploy Undeploy a XYZDefinition List List a XYZDefinition Returns Display Get specific information about a XYZDefinition Create other stories for each Controller<span class='highlight-text severity-high'> and </span>include in this weeks sprint ","atomic","conjunctions","high",False
26573,"Add spring xd hadoop distro specific sub projects we need to modify build adding two sub projects for spring xd hadoop one for hadoop 1.1.2 and one for phd1 Pivotal HD to pull in transitive dependencies for correct Hadoop distro",NULL,"Add spring xd hadoop distro specific sub projects we need to modify build adding two sub projects for spring xd hadoop one for hadoop 1.1.2 and one for phd1 Pivotal HD to pull in transitive dependencies for correct Hadoop distro",NULL,"Add for who this story is","well_formed","no_role","high",False
26573,"Add spring xd hadoop distro specific sub projects we need to modify build adding two sub projects for spring xd hadoop one for hadoop 1.1.2 and one for phd1 Pivotal HD to pull in transitive dependencies for correct Hadoop distro",NULL,"Add spring xd hadoop distro specific sub projects we need to modify build adding two sub projects for spring xd hadoop one for hadoop 1.1.2 and one for phd1 Pivotal HD to pull in transitive dependencies for correct Hadoop distro",NULL,"Add spring xd hadoop distro specific sub projects we need to modify build adding two sub projects for spring xd hadoop one for hadoop 1.1.2<span class='highlight-text severity-high'> and </span>one for phd1 Pivotal HD to pull in transitive dependencies for correct Hadoop distro","atomic","conjunctions","high",False
26591,"Fix Sonar build! Caused by that weird annotation dependency problem that I worked around for compile. But Sonar complains. One solution would be to add Jackson 2 to the Sonar classpath , but I did not manage to do that. ",NULL,"Fix Sonar build! Caused by that weird annotation dependency problem that I worked around for compile. But Sonar complains. One solution would be to add Jackson 2 to the Sonar classpath , but I did not manage to do that. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26591,"Fix Sonar build! Caused by that weird annotation dependency problem that I worked around for compile. But Sonar complains. One solution would be to add Jackson 2 to the Sonar classpath , but I did not manage to do that. ",NULL,"Fix Sonar build! Caused by that weird annotation dependency problem that I worked around for compile. But Sonar complains. One solution would be to add Jackson 2 to the Sonar classpath , but I did not manage to do that. ",NULL,"Fix Sonar build! Caused by that weird annotation dependency problem that I worked around for compile<span class='highlight-text severity-high'>. But Sonar complains. One solution would be to add Jackson 2 to the Sonar classpath , but I did not manage to do that. </span>","minimal","punctuation","high",False
26592,"Better UX when admin is not running Current behavior is to just have a prompt of unknown I think any return value of a CliCommand method is not shown b c the whole infrastructure is not up at that time",NULL,"Better UX when admin is not running Current behavior is to just have a prompt of unknown I think any return value of a CliCommand method is not shown b c the whole infrastructure is not up at that time",NULL,"Add for who this story is","well_formed","no_role","high",False
26593,"Add tap support to DIRT syntax tap somechannel key value somecounter ",NULL,"Add tap support to DIRT syntax tap somechannel key value somecounter ",NULL,"Add for who this story is","well_formed","no_role","high",False
26594,"Stream Plugin cleanup public StreamPlugin CHANNEL REGISTRY; Subclasses should not directly update superclass fields.",NULL,"Stream Plugin cleanup public StreamPlugin CHANNEL REGISTRY; Subclasses should not directly update superclass fields.",NULL,"Add for who this story is","well_formed","no_role","high",False
26594,"Stream Plugin cleanup public StreamPlugin CHANNEL REGISTRY; Subclasses should not directly update superclass fields.",NULL,"Stream Plugin cleanup public StreamPlugin CHANNEL REGISTRY; Subclasses should not directly update superclass fields.",NULL,"Stream Plugin cleanup public StreamPlugin CHANNEL REGISTRY<span class='highlight-text severity-high'>; Subclasses should not directly update superclass fields.</span>","minimal","punctuation","high",False
26595,"Delete a trigger from Shell Shell command to delete a trigger. Note this command will only remove the trigger definition not modifying the jobs that use the trigger.",NULL,"Delete a trigger from Shell Shell command to delete a trigger. Note this command will only remove the trigger definition not modifying the jobs that use the trigger.",NULL,"Add for who this story is","well_formed","no_role","high",False
26595,"Delete a trigger from Shell Shell command to delete a trigger. Note this command will only remove the trigger definition not modifying the jobs that use the trigger.",NULL,"Delete a trigger from Shell Shell command to delete a trigger. Note this command will only remove the trigger definition not modifying the jobs that use the trigger.",NULL,"Delete a trigger from Shell Shell command to delete a trigger<span class='highlight-text severity-high'>. Note this command will only remove the trigger definition not modifying the jobs that use the trigger.</span>","minimal","punctuation","high",False
26596,"Add How to Build Spring XD instructions to the documentation We need to determine where this information could fit in. It can be either in README at the project home page or Getting started wiki page.",NULL,"Add How to Build Spring XD instructions to the documentation We need to determine where this information could fit in. It can be either in README at the project home page or Getting started wiki page.",NULL,"Add for who this story is","well_formed","no_role","high",False
26596,"Add How to Build Spring XD instructions to the documentation We need to determine where this information could fit in. It can be either in README at the project home page or Getting started wiki page.",NULL,"Add How to Build Spring XD instructions to the documentation We need to determine where this information could fit in. It can be either in README at the project home page or Getting started wiki page.",NULL,"Add How to Build Spring XD instructions to the documentation We need to determine where this information could fit in. It can be either in README at the project home page<span class='highlight-text severity-high'> or </span>Getting started wiki page.","atomic","conjunctions","high",False
26596,"Add How to Build Spring XD instructions to the documentation We need to determine where this information could fit in. It can be either in README at the project home page or Getting started wiki page.",NULL,"Add How to Build Spring XD instructions to the documentation We need to determine where this information could fit in. It can be either in README at the project home page or Getting started wiki page.",NULL,"Add How to Build Spring XD instructions to the documentation We need to determine where this information could fit in<span class='highlight-text severity-high'>. It can be either in README at the project home page or Getting started wiki page.</span>","minimal","punctuation","high",False
26597,"Fix XD modules parameters with to use camel case XD 482 addresses the use of camel case in fixed delay job module parameter name. and, we need to fix the same for other module parameters wherever is being used. ",NULL,"Fix XD modules parameters with to use camel case XD 482 addresses the use of camel case in fixed delay job module parameter name. and, we need to fix the same for other module parameters wherever is being used. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26597,"Fix XD modules parameters with to use camel case XD 482 addresses the use of camel case in fixed delay job module parameter name. and, we need to fix the same for other module parameters wherever is being used. ",NULL,"Fix XD modules parameters with to use camel case XD 482 addresses the use of camel case in fixed delay job module parameter name. and, we need to fix the same for other module parameters wherever is being used. ",NULL,"Fix XD modules parameters with to use camel case XD 482 addresses the use of camel case in fixed delay job module parameter name<span class='highlight-text severity-high'>. and, we need to fix the same for other module parameters wherever is being used. </span>","minimal","punctuation","high",False
26598,"Support pagination in list command for jobs See XD 477",NULL,"Support pagination in list command for jobs See XD 477",NULL,"Add for who this story is","well_formed","no_role","high",False
26603,"Create XD integration test framework Add top level utility methods to manage XD runtime deploy, start and stop . These methods will be used by underlying integration tests to control runtime test environment. ",NULL,"Create XD integration test framework Add top level utility methods to manage XD runtime deploy, start and stop . These methods will be used by underlying integration tests to control runtime test environment. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26603,"Create XD integration test framework Add top level utility methods to manage XD runtime deploy, start and stop . These methods will be used by underlying integration tests to control runtime test environment. ",NULL,"Create XD integration test framework Add top level utility methods to manage XD runtime deploy, start and stop . These methods will be used by underlying integration tests to control runtime test environment. ",NULL,"Create XD integration test framework Add top level utility methods to manage XD runtime deploy, start and stop <span class='highlight-text severity-high'>. These methods will be used by underlying integration tests to control runtime test environment. </span>","minimal","punctuation","high",False
26604,"Add CI job in bamboo to run XD integration tests CI job will run integration tests that are tagged for CI build.",NULL,"Add CI job in bamboo to run XD integration tests CI job will run integration tests that are tagged for CI build.",NULL,"Add for who this story is","well_formed","no_role","high",False
26602,"Ensure that each controller s list returns PagedResources ",NULL,"Ensure that each controller s list returns PagedResources ",NULL,"Add for who this story is","well_formed","no_role","high",False
26605,"Create proper test coverage for Controllers",NULL,"Create proper test coverage for Controllers",NULL,"Add for who this story is","well_formed","no_role","high",False
26611,"Provide .settings formatting rules so that they re shared Thinking about using the official SpringSource rules as a template",NULL,"Provide .settings formatting rules","so that they re shared Thinking about using the official SpringSource rules as a template","Add for who this story is","well_formed","no_role","high",False
26611,"Provide .settings formatting rules so that they re shared Thinking about using the official SpringSource rules as a template",NULL,"Provide .settings formatting rules","so that they re shared Thinking about using the official SpringSource rules as a template","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26613,"Create SI components that wrap Reactor s TCP server ",NULL,"Create SI components that wrap Reactor s TCP server ",NULL,"Add for who this story is","well_formed","no_role","high",False
26606,"Upgrade to Jackson 2.2.2 ",NULL,"Upgrade to Jackson 2.2.2 ",NULL,"Add for who this story is","well_formed","no_role","high",False
26607,"Modules need to validate their parameters at create time. We need to fail fast.",NULL,"Modules need to validate their parameters at create time. We need to fail fast.",NULL,"Add for who this story is","well_formed","no_role","high",False
26694,"x xd Transport Content Type Leakage The in the Rabbit transport exposes the internal transport content type, if none existed on the original transported message.",NULL,"x xd Transport Content Type Leakage The in the Rabbit transport exposes the internal transport content type, if none existed on the original transported message.",NULL,"Add for who this story is","well_formed","no_role","high",False
26607,"Modules need to validate their parameters at create time. We need to fail fast.",NULL,"Modules need to validate their parameters at create time. We need to fail fast.",NULL,"Modules need to validate their parameters at create time<span class='highlight-text severity-high'>. We need to fail fast.</span>","minimal","punctuation","high",False
26608,"add twitter search source module ",NULL,"add twitter search source module ",NULL,"Add for who this story is","well_formed","no_role","high",False
26609,"All parameters for modules need to use hump case formerly camel hump ",NULL,"All parameters for modules need to use hump case formerly camel hump ",NULL,"Add for who this story is","well_formed","no_role","high",False
26610,"Update jobs section to use shell ",NULL,"Update jobs section to use shell ",NULL,"Add for who this story is","well_formed","no_role","high",False
26612,"Make module files classpath aware Currently, living at the root of the project, those files don t benefit from IDE SI awareness. s used. Has impact on the build.gradle file",NULL,"Make module files classpath aware Currently, living at the root of the project, those files don t benefit from IDE SI awareness. s used. Has impact on the build.gradle file",NULL,"Add for who this story is","well_formed","no_role","high",False
26612,"Make module files classpath aware Currently, living at the root of the project, those files don t benefit from IDE SI awareness. s used. Has impact on the build.gradle file",NULL,"Make module files classpath aware Currently, living at the root of the project, those files don t benefit from IDE SI awareness. s used. Has impact on the build.gradle file",NULL,"Make module files classpath aware Currently, living at the root of the project, those files don t benefit from IDE SI awareness<span class='highlight-text severity-high'>. s used. Has impact on the build.gradle file</span>","minimal","punctuation","high",False
26614,"Review existing Reactor syslog codec implementation ",NULL,"Review existing Reactor syslog codec implementation ",NULL,"Add for who this story is","well_formed","no_role","high",False
26615,"Design and document desired high level DSL for configuring data processing in XD Start to explore how the DSL can cover both advanced non linear spring integration flows as well as spring batch jobs.",NULL,"Design and document desired high level DSL for configuring data processing in XD Start to explore how the DSL can cover both advanced non linear spring integration flows as well as spring batch jobs.",NULL,"Add for who this story is","well_formed","no_role","high",False
26601,"Add xd.stream.name property in StreamPlugin ",NULL,"Add xd.stream.name property in StreamPlugin ",NULL,"Add for who this story is","well_formed","no_role","high",False
26600,"Support pagination in list command for triggers See XD 477",NULL,"Support pagination in list command for triggers See XD 477",NULL,"Add for who this story is","well_formed","no_role","high",False
26599,"Support pagination in list command for taps See XD 477",NULL,"Support pagination in list command for taps See XD 477",NULL,"Add for who this story is","well_formed","no_role","high",False
26626,"Broadcast Undeploy Requests Use an undeploy topic to broadcast undeploy requests to all containers. Applies to Redis and Rabbit transports, not local. Also, rename .",NULL,"Broadcast Undeploy Requests Use an undeploy topic to broadcast undeploy requests to all containers. Applies to Redis and Rabbit transports, not local. Also, rename .",NULL,"Add for who this story is","well_formed","no_role","high",False
26626,"Broadcast Undeploy Requests Use an undeploy topic to broadcast undeploy requests to all containers. Applies to Redis and Rabbit transports, not local. Also, rename .",NULL,"Broadcast Undeploy Requests Use an undeploy topic to broadcast undeploy requests to all containers. Applies to Redis and Rabbit transports, not local. Also, rename .",NULL,"Broadcast Undeploy Requests Use an undeploy topic to broadcast undeploy requests to all containers<span class='highlight-text severity-high'>. Applies to Redis and Rabbit transports, not local. Also, rename .</span>","minimal","punctuation","high",False
26625,"XD Metrics backed Message Counter A Spring Integration based ServiceActivator that counts the number of messages using the Spring XD metrics support",NULL,"XD Metrics backed Message Counter A Spring Integration based ServiceActivator that counts the number of messages using the Spring XD metrics support",NULL,"Add for who this story is","well_formed","no_role","high",False
26629,"Handle Pagination in Spring XD Shell ",NULL,"Handle Pagination in Spring XD Shell ",NULL,"Add for who this story is","well_formed","no_role","high",False
26627,"Add Message Source for error messages returned to users ",NULL,"Add Message Source for error messages returned to users ",NULL,"Add for who this story is","well_formed","no_role","high",False
26637,"Separate Module Context Refresh from Context Start Split plugin module processing into pre and post processing where preprocessing is done before the context is refreshed and post processing is done after the refresh, but before the start. In the Stream plugin, wire the module into the .",NULL,"Separate Module Context Refresh from Context Start Split plugin module processing into pre and post processing where preprocessing is done before the context is refreshed and post processing is done after the refresh, but before the start. In the Stream plugin, wire the module into the .",NULL,"Add for who this story is","well_formed","no_role","high",False
26637,"Separate Module Context Refresh from Context Start Split plugin module processing into pre and post processing where preprocessing is done before the context is refreshed and post processing is done after the refresh, but before the start. In the Stream plugin, wire the module into the .",NULL,"Separate Module Context Refresh from Context Start Split plugin module processing into pre and post processing where preprocessing is done before the context is refreshed and post processing is done after the refresh, but before the start. In the Stream plugin, wire the module into the .",NULL,"Separate Module Context Refresh from Context Start Split plugin module processing into pre<span class='highlight-text severity-high'> and </span>post processing where preprocessing is done before the context is refreshed and post processing is done after the refresh, but before the start. In the Stream plugin, wire the module into the .","atomic","conjunctions","high",False
26637,"Separate Module Context Refresh from Context Start Split plugin module processing into pre and post processing where preprocessing is done before the context is refreshed and post processing is done after the refresh, but before the start. In the Stream plugin, wire the module into the .",NULL,"Separate Module Context Refresh from Context Start Split plugin module processing into pre and post processing where preprocessing is done before the context is refreshed and post processing is done after the refresh, but before the start. In the Stream plugin, wire the module into the .",NULL,"Separate Module Context Refresh from Context Start Split plugin module processing into pre and post processing where preprocessing is done before the context is refreshed and post processing is done after the refresh, but before the start<span class='highlight-text severity-high'>. In the Stream plugin, wire the module into the .</span>","minimal","punctuation","high",False
26628,"Refactor Module to Encapsulate Group and Index Currently many methods take module, group, index defining a module instance; group and index can be encapsulated in so one arg can be passed around.",NULL,"Refactor Module to Encapsulate Group and Index Currently many methods take module, group, index defining a module instance; group and index can be encapsulated in","so one arg can be passed around.","Add for who this story is","well_formed","no_role","high",False
26628,"Refactor Module to Encapsulate Group and Index Currently many methods take module, group, index defining a module instance; group and index can be encapsulated in so one arg can be passed around.",NULL,"Refactor Module to Encapsulate Group and Index Currently many methods take module, group, index defining a module instance; group and index can be encapsulated in","so one arg can be passed around.","Refactor Module to Encapsulate Group<span class='highlight-text severity-high'> and </span>Index Currently many methods take module, group, index defining a module instance; group and index can be encapsulated in so one arg can be passed around.","atomic","conjunctions","high",False
26628,"Refactor Module to Encapsulate Group and Index Currently many methods take module, group, index defining a module instance; group and index can be encapsulated in so one arg can be passed around.",NULL,"Refactor Module to Encapsulate Group and Index Currently many methods take module, group, index defining a module instance; group and index can be encapsulated in","so one arg can be passed around.","Refactor Module to Encapsulate Group and Index Currently many methods take module, group, index defining a module instance<span class='highlight-text severity-high'>; group and index can be encapsulated in so one arg can be passed around.</span>","minimal","punctuation","high",False
26628,"Refactor Module to Encapsulate Group and Index Currently many methods take module, group, index defining a module instance; group and index can be encapsulated in so one arg can be passed around.",NULL,"Refactor Module to Encapsulate Group and Index Currently many methods take module, group, index defining a module instance; group and index can be encapsulated in","so one arg can be passed around.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26631,"Display an Aggregate Counter ",NULL,"Display an Aggregate Counter ",NULL,"Add for who this story is","well_formed","no_role","high",False
26630,"Display a Field Value Counter ",NULL,"Display a Field Value Counter ",NULL,"Add for who this story is","well_formed","no_role","high",False
26633,"SI ServiceActivator for an XD Metrics backed Field Value Counter A Spring Integration based ServiceActivator that counts the occurrence of field names, from either a tuple data structure or a POJO, using the Spring XD metrics support.",NULL,"SI ServiceActivator for an XD Metrics backed Field Value Counter A Spring Integration based ServiceActivator that counts the occurrence of field names, from either a tuple data structure or a POJO, using the Spring XD metrics support.",NULL,"Add for who this story is","well_formed","no_role","high",False
26633,"SI ServiceActivator for an XD Metrics backed Field Value Counter A Spring Integration based ServiceActivator that counts the occurrence of field names, from either a tuple data structure or a POJO, using the Spring XD metrics support.",NULL,"SI ServiceActivator for an XD Metrics backed Field Value Counter A Spring Integration based ServiceActivator that counts the occurrence of field names, from either a tuple data structure or a POJO, using the Spring XD metrics support.",NULL,"SI ServiceActivator for an XD Metrics backed Field Value Counter A Spring Integration based ServiceActivator that counts the occurrence of field names, from either a tuple data structure<span class='highlight-text severity-high'> or </span>a POJO, using the Spring XD metrics support.","atomic","conjunctions","high",False
26632,"Display a Rich Gauge ",NULL,"Display a Rich Gauge ",NULL,"Add for who this story is","well_formed","no_role","high",False
26635,"Add trigger list support to Spring XD Shell ",NULL,"Add trigger list support to Spring XD Shell ",NULL,"Add for who this story is","well_formed","no_role","high",False
26634,"Leverage in was first written to support setting several fields at once, but the current constructor does not use it. Either leverage that feature or simplify code",NULL,"Leverage in was first written to support setting several fields at once, but the current constructor does not use it. Either leverage that feature or simplify code",NULL,"Add for who this story is","well_formed","no_role","high",False
26634,"Leverage in was first written to support setting several fields at once, but the current constructor does not use it. Either leverage that feature or simplify code",NULL,"Leverage in was first written to support setting several fields at once, but the current constructor does not use it. Either leverage that feature or simplify code",NULL,"Leverage in was first written to support setting several fields at once, but the current constructor does not use it. Either leverage that feature<span class='highlight-text severity-high'> or </span>simplify code","atomic","conjunctions","high",False
26634,"Leverage in was first written to support setting several fields at once, but the current constructor does not use it. Either leverage that feature or simplify code",NULL,"Leverage in was first written to support setting several fields at once, but the current constructor does not use it. Either leverage that feature or simplify code",NULL,"Leverage in was first written to support setting several fields at once, but the current constructor does not use it<span class='highlight-text severity-high'>. Either leverage that feature or simplify code</span>","minimal","punctuation","high",False
26638,"make application json the default output type for the REST API? the top level URL works via simple curl without an Accept header or the browser curl However, trying any of those links then fails, e.g. curl ?xml version 1.0 encoding UTF 8 xmlns ns2 not marshal null; nested exception is with linked exception unable to marshal type as an element because it is not known to this ",NULL,"make application json the default output type for the REST API? the top level URL works via simple curl without an Accept header or the browser curl However, trying any of those links then fails, e.g. curl ?xml version 1.0 encoding UTF 8 xmlns ns2 not marshal null; nested exception is with linked exception unable to marshal type as an element because it is not known to this ",NULL,"Add for who this story is","well_formed","no_role","high",False
26638,"make application json the default output type for the REST API? the top level URL works via simple curl without an Accept header or the browser curl However, trying any of those links then fails, e.g. curl ?xml version 1.0 encoding UTF 8 xmlns ns2 not marshal null; nested exception is with linked exception unable to marshal type as an element because it is not known to this ",NULL,"make application json the default output type for the REST API? the top level URL works via simple curl without an Accept header or the browser curl However, trying any of those links then fails, e.g. curl ?xml version 1.0 encoding UTF 8 xmlns ns2 not marshal null; nested exception is with linked exception unable to marshal type as an element because it is not known to this ",NULL,"make application json the default output type for the REST API? the top level URL works via simple curl without an Accept header<span class='highlight-text severity-high'> or </span>the browser curl However, trying any of those links then fails, e.g. curl ?xml version 1.0 encoding UTF 8 xmlns ns2 not marshal null; nested exception is with linked exception unable to marshal type as an element because it is not known to this ","atomic","conjunctions","high",False
26638,"make application json the default output type for the REST API? the top level URL works via simple curl without an Accept header or the browser curl However, trying any of those links then fails, e.g. curl ?xml version 1.0 encoding UTF 8 xmlns ns2 not marshal null; nested exception is with linked exception unable to marshal type as an element because it is not known to this ",NULL,"make application json the default output type for the REST API? the top level URL works via simple curl without an Accept header or the browser curl However, trying any of those links then fails, e.g. curl ?xml version 1.0 encoding UTF 8 xmlns ns2 not marshal null; nested exception is with linked exception unable to marshal type as an element because it is not known to this ",NULL,"make application json the default output type for the REST API<span class='highlight-text severity-high'>? the top level URL works via simple curl without an Accept header or the browser curl However, trying any of those links then fails, e.g. curl ?xml version 1.0 encoding UTF 8 xmlns ns2 not marshal null; nested exception is with linked exception unable to marshal type as an element because it is not known to this </span>","minimal","punctuation","high",False
26636,"Add additional options to File source Seems like the current file source results from an initial POC. Very few things can be parameterized, including the polled directory that needs to be in tmp xxx To be useful in production, we might want to revisit",NULL,"Add additional options to File source Seems like the current file source results from an initial POC. Very few things can be parameterized, including the polled directory that needs to be in tmp xxx To be useful in production, we might want to revisit",NULL,"Add for who this story is","well_formed","no_role","high",False
26636,"Add additional options to File source Seems like the current file source results from an initial POC. Very few things can be parameterized, including the polled directory that needs to be in tmp xxx To be useful in production, we might want to revisit",NULL,"Add additional options to File source Seems like the current file source results from an initial POC. Very few things can be parameterized, including the polled directory that needs to be in tmp xxx To be useful in production, we might want to revisit",NULL,"Add additional options to File source Seems like the current file source results from an initial POC<span class='highlight-text severity-high'>. Very few things can be parameterized, including the polled directory that needs to be in tmp xxx To be useful in production, we might want to revisit</span>","minimal","punctuation","high",False
26640,"Create IntegralMetric and IntegralResource types There is some overlap between the gauge and counter repository types and also between the domain resources used by the REST controllers CounterResource, GaugeResource . The aggregate counter may wish to return a simple count value for the counter too, which would also be a simple integral value.",NULL,"Create IntegralMetric and IntegralResource types There is some overlap between the gauge and counter repository types and also between the domain resources used by the REST controllers CounterResource, GaugeResource . The aggregate counter may wish to return a simple count value for the counter too, which would also be a simple integral value.",NULL,"Add for who this story is","well_formed","no_role","high",False
26640,"Create IntegralMetric and IntegralResource types There is some overlap between the gauge and counter repository types and also between the domain resources used by the REST controllers CounterResource, GaugeResource . The aggregate counter may wish to return a simple count value for the counter too, which would also be a simple integral value.",NULL,"Create IntegralMetric and IntegralResource types There is some overlap between the gauge and counter repository types and also between the domain resources used by the REST controllers CounterResource, GaugeResource . The aggregate counter may wish to return a simple count value for the counter too, which would also be a simple integral value.",NULL,"Create IntegralMetric<span class='highlight-text severity-high'> and </span>IntegralResource types There is some overlap between the gauge and counter repository types and also between the domain resources used by the REST controllers CounterResource, GaugeResource . The aggregate counter may wish to return a simple count value for the counter too, which would also be a simple integral value.","atomic","conjunctions","high",False
26696,"Update architecture diagram to show rabbit in addition to redis to communicate between admin and containers Figure 1 here should also show Rabbit as an option, since otherwise people will think we are tied to redis.",NULL,"Update architecture diagram to show rabbit in addition to redis to communicate between admin and containers Figure 1 here should also show Rabbit as an option, since otherwise people will think we are tied to redis.",NULL,"Add for who this story is","well_formed","no_role","high",False
26640,"Create IntegralMetric and IntegralResource types There is some overlap between the gauge and counter repository types and also between the domain resources used by the REST controllers CounterResource, GaugeResource . The aggregate counter may wish to return a simple count value for the counter too, which would also be a simple integral value.",NULL,"Create IntegralMetric and IntegralResource types There is some overlap between the gauge and counter repository types and also between the domain resources used by the REST controllers CounterResource, GaugeResource . The aggregate counter may wish to return a simple count value for the counter too, which would also be a simple integral value.",NULL,"Create IntegralMetric and IntegralResource types There is some overlap between the gauge and counter repository types and also between the domain resources used by the REST controllers CounterResource, GaugeResource <span class='highlight-text severity-high'>. The aggregate counter may wish to return a simple count value for the counter too, which would also be a simple integral value.</span>","minimal","punctuation","high",False
26639,"HTML Doco has font issues for It seems the html rendering of documentation is using a variable width font for some of the code esp. apparently rendering. Weird thing though is that when mouse hovering over some of them, they went back to fixed width. See screenshot. ",NULL,"HTML Doco has font issues for It seems the html rendering of documentation is using a variable width font for some of the code esp. apparently rendering. Weird thing though is that when mouse hovering over some of them, they went back to fixed width. See screenshot. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26639,"HTML Doco has font issues for It seems the html rendering of documentation is using a variable width font for some of the code esp. apparently rendering. Weird thing though is that when mouse hovering over some of them, they went back to fixed width. See screenshot. ",NULL,"HTML Doco has font issues for It seems the html rendering of documentation is using a variable width font for some of the code esp. apparently rendering. Weird thing though is that when mouse hovering over some of them, they went back to fixed width. See screenshot. ",NULL,"HTML Doco has font issues for It seems the html rendering of documentation is using a variable width font for some of the code esp<span class='highlight-text severity-high'>. apparently rendering. Weird thing though is that when mouse hovering over some of them, they went back to fixed width. See screenshot. </span>","minimal","punctuation","high",False
26641,"Send failing sonar build message to spring xd mailing list. ",NULL,"Send failing sonar build message to spring xd mailing list. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26623,"Develop infrastructure to enable testability of commands This requires to boostrap the singlenode admin server in process, submit commands to the shell programmatically, and assert on the results of executing the command.",NULL,"Develop infrastructure to enable testability of commands This requires to boostrap the singlenode admin server in process, submit commands to the shell programmatically, and assert on the results of executing the command.",NULL,"Add for who this story is","well_formed","no_role","high",False
26623,"Develop infrastructure to enable testability of commands This requires to boostrap the singlenode admin server in process, submit commands to the shell programmatically, and assert on the results of executing the command.",NULL,"Develop infrastructure to enable testability of commands This requires to boostrap the singlenode admin server in process, submit commands to the shell programmatically, and assert on the results of executing the command.",NULL,"Develop infrastructure to enable testability of commands This requires to boostrap the singlenode admin server in process, submit commands to the shell programmatically,<span class='highlight-text severity-high'> and </span>assert on the results of executing the command.","atomic","conjunctions","high",False
26644,"Documentation for use of conversion service and creating custom processing modules that use the Tuple data structure. ",NULL,"Documentation for use of conversion service and creating custom processing modules that use the Tuple data structure. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26645,"Regression test existing functionality of stream taps based on introduction of new conversion functionality make sure nothing is broken spot check using. 1 ticktock 2 twitter 3 gemfire ",NULL,"Regression test existing functionality of stream taps based on introduction of new conversion functionality make sure nothing is broken spot check using. 1 ticktock 2 twitter 3 gemfire ",NULL,"Add for who this story is","well_formed","no_role","high",False
26645,"Regression test existing functionality of stream taps based on introduction of new conversion functionality make sure nothing is broken spot check using. 1 ticktock 2 twitter 3 gemfire ",NULL,"Regression test existing functionality of stream taps based on introduction of new conversion functionality make sure nothing is broken spot check using. 1 ticktock 2 twitter 3 gemfire ",NULL,"Regression test existing functionality of stream taps based on introduction of new conversion functionality make sure nothing is broken spot check using<span class='highlight-text severity-high'>. 1 ticktock 2 twitter 3 gemfire </span>","minimal","punctuation","high",False
26646,"Upgrade sink and processor modules to use new conversion service ",NULL,"Upgrade sink and processor modules to use new conversion service ",NULL,"Add for who this story is","well_formed","no_role","high",False
26646,"Upgrade sink and processor modules to use new conversion service ",NULL,"Upgrade sink and processor modules to use new conversion service ",NULL,"Upgrade sink<span class='highlight-text severity-high'> and </span>processor modules to use new conversion service ","atomic","conjunctions","high",False
26647,"Documentation for using a specific Hadoop distribution Show how to select a specific hadoop distribution when starting XDContainer.",NULL,"Documentation for using a specific Hadoop distribution Show how to select a specific hadoop distribution when starting XDContainer.",NULL,"Add for who this story is","well_formed","no_role","high",False
26649,"Documentation for deleting triggers ",NULL,"Documentation for deleting triggers ",NULL,"Add for who this story is","well_formed","no_role","high",False
26650,"Investigate failures to start a stream when using named channels. Create a reproducible series of steps or shell integration test. ",NULL,"Investigate failures to start a stream when using named channels. Create a reproducible series of steps or shell integration test. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26650,"Investigate failures to start a stream when using named channels. Create a reproducible series of steps or shell integration test. ",NULL,"Investigate failures to start a stream when using named channels. Create a reproducible series of steps or shell integration test. ",NULL,"Investigate failures to start a stream when using named channels<span class='highlight-text severity-high'>. Create a reproducible series of steps or shell integration test. </span>","minimal","punctuation","high",False
26654,"Replace usage of raw curl with shell command to post http data in documentation e.g. httpsource target data 10 I believe this will also help to avoid ugly syntax to escaping quotes for json as in the gemfire example.",NULL,"Replace usage of raw curl with shell command to post http data in documentation e.g. httpsource target data 10 I believe this will also help to avoid ugly syntax to escaping quotes for json as in the gemfire example.",NULL,"Add for who this story is","well_formed","no_role","high",False
26654,"Replace usage of raw curl with shell command to post http data in documentation e.g. httpsource target data 10 I believe this will also help to avoid ugly syntax to escaping quotes for json as in the gemfire example.",NULL,"Replace usage of raw curl with shell command to post http data in documentation e.g. httpsource target data 10 I believe this will also help to avoid ugly syntax to escaping quotes for json as in the gemfire example.",NULL,"Replace usage of raw curl with shell command to post http data in documentation e<span class='highlight-text severity-high'>.g. httpsource target data 10 I believe this will also help to avoid ugly syntax to escaping quotes for json as in the gemfire example.</span>","minimal","punctuation","high",False
26658,"Modify startup script of xd shell to allow specifying hadoop distro to use ",NULL,"Modify startup script of xd shell to allow specifying hadoop distro to use ",NULL,"Add for who this story is","well_formed","no_role","high",False
26655,"Change banner of shell to say only xd ",NULL,"Change banner of shell to say only xd ",NULL,"Add for who this story is","well_formed","no_role","high",False
26657,"Can t access HDFS using webhdfs protocol config fs namenode fs ls Hadoop configuration changed, re initializing shell... run HDFS shell failed. Message is This was on a hadoop 1.0.1 install The hdfs http interface was available curl i HTTP 1.1 200 OK Content Type application json Transfer Encoding chunked Server Jetty 6.1.26 ",NULL,"Can t access HDFS using webhdfs protocol config fs namenode fs ls Hadoop configuration changed, re initializing shell... run HDFS shell failed. Message is This was on a hadoop 1.0.1 install The hdfs http interface was available curl i HTTP 1.1 200 OK Content Type application json Transfer Encoding chunked Server Jetty 6.1.26 ",NULL,"Add for who this story is","well_formed","no_role","high",False
26657,"Can t access HDFS using webhdfs protocol config fs namenode fs ls Hadoop configuration changed, re initializing shell... run HDFS shell failed. Message is This was on a hadoop 1.0.1 install The hdfs http interface was available curl i HTTP 1.1 200 OK Content Type application json Transfer Encoding chunked Server Jetty 6.1.26 ",NULL,"Can t access HDFS using webhdfs protocol config fs namenode fs ls Hadoop configuration changed, re initializing shell... run HDFS shell failed. Message is This was on a hadoop 1.0.1 install The hdfs http interface was available curl i HTTP 1.1 200 OK Content Type application json Transfer Encoding chunked Server Jetty 6.1.26 ",NULL,"Can t access HDFS using webhdfs protocol config fs namenode fs ls Hadoop configuration changed, re initializing shell<span class='highlight-text severity-high'>... run HDFS shell failed. Message is This was on a hadoop 1.0.1 install The hdfs http interface was available curl i HTTP 1.1 200 OK Content Type application json Transfer Encoding chunked Server Jetty 6.1.26 </span>","minimal","punctuation","high",False
26656,"In documentation, replace usage of raw hadoop command with shell hadoop commands ",NULL,"In documentation, replace usage of raw hadoop command with shell hadoop commands ",NULL,"Add for who this story is","well_formed","no_role","high",False
26661,"Support named channels when using local transport Sending data to an incomplete stream which is created using a named sink channel only works when using Redis or Rabbit?, not tested . Since the in memory version doesn t use a queue, it will fail if you are using xd singlenode. We should use a queue channel with unlimited capacity to allow messages to be sent before the full stream is created.",NULL,"Support named channels when using local transport Sending data to an incomplete stream which is created using a named sink channel only works when using Redis or Rabbit?, not tested . Since the in memory version doesn t use a queue, it will fail if you are using xd singlenode. We should use a queue channel with unlimited capacity to allow messages to be sent before the full stream is created.",NULL,"Add for who this story is","well_formed","no_role","high",False
26661,"Support named channels when using local transport Sending data to an incomplete stream which is created using a named sink channel only works when using Redis or Rabbit?, not tested . Since the in memory version doesn t use a queue, it will fail if you are using xd singlenode. We should use a queue channel with unlimited capacity to allow messages to be sent before the full stream is created.",NULL,"Support named channels when using local transport Sending data to an incomplete stream which is created using a named sink channel only works when using Redis or Rabbit?, not tested . Since the in memory version doesn t use a queue, it will fail if you are using xd singlenode. We should use a queue channel with unlimited capacity to allow messages to be sent before the full stream is created.",NULL,"Support named channels when using local transport Sending data to an incomplete stream which is created using a named sink channel only works when using Redis or Rabbit?, not tested <span class='highlight-text severity-high'>. Since the in memory version doesn t use a queue, it will fail if you are using xd singlenode. We should use a queue channel with unlimited capacity to allow messages to be sent before the full stream is created.</span>","minimal","punctuation","high",False
26660,"configuration conflict when using transport , local , store , redis , disableJmx , true , analytics , redis results in both in memory and redis based definitions of RichGaugeService can t satisfy autowiring because there are two candidates. Had to change analytics memory to get the application context to load.",NULL,"configuration conflict when using transport , local , store , redis , disableJmx , true , analytics , redis results in both in memory and redis based definitions of RichGaugeService can t satisfy autowiring because there are two candidates. Had to change analytics memory to get the application context to load.",NULL,"Add for who this story is","well_formed","no_role","high",False
26660,"configuration conflict when using transport , local , store , redis , disableJmx , true , analytics , redis results in both in memory and redis based definitions of RichGaugeService can t satisfy autowiring because there are two candidates. Had to change analytics memory to get the application context to load.",NULL,"configuration conflict when using transport , local , store , redis , disableJmx , true , analytics , redis results in both in memory and redis based definitions of RichGaugeService can t satisfy autowiring because there are two candidates. Had to change analytics memory to get the application context to load.",NULL,"configuration conflict when using transport , local , store , redis , disableJmx , true , analytics , redis results in both in memory<span class='highlight-text severity-high'> and </span>redis based definitions of RichGaugeService can t satisfy autowiring because there are two candidates. Had to change analytics memory to get the application context to load.","atomic","conjunctions","high",False
26660,"configuration conflict when using transport , local , store , redis , disableJmx , true , analytics , redis results in both in memory and redis based definitions of RichGaugeService can t satisfy autowiring because there are two candidates. Had to change analytics memory to get the application context to load.",NULL,"configuration conflict when using transport , local , store , redis , disableJmx , true , analytics , redis results in both in memory and redis based definitions of RichGaugeService can t satisfy autowiring because there are two candidates. Had to change analytics memory to get the application context to load.",NULL,"configuration conflict when using transport , local , store , redis , disableJmx , true , analytics , redis results in both in memory and redis based definitions of RichGaugeService can t satisfy autowiring because there are two candidates<span class='highlight-text severity-high'>. Had to change analytics memory to get the application context to load.</span>","minimal","punctuation","high",False
26659,"XD Shell needs to support multiple Hadoop distros From The command shell needs to also support different hadoop distribution options. Perhaps the shell just uses a relative path to the location of ",NULL,"XD Shell needs to support multiple Hadoop distros From The command shell needs to also support different hadoop distribution options. Perhaps the shell just uses a relative path to the location of ",NULL,"Add for who this story is","well_formed","no_role","high",False
26659,"XD Shell needs to support multiple Hadoop distros From The command shell needs to also support different hadoop distribution options. Perhaps the shell just uses a relative path to the location of ",NULL,"XD Shell needs to support multiple Hadoop distros From The command shell needs to also support different hadoop distribution options. Perhaps the shell just uses a relative path to the location of ",NULL,"XD Shell needs to support multiple Hadoop distros From The command shell needs to also support different hadoop distribution options<span class='highlight-text severity-high'>. Perhaps the shell just uses a relative path to the location of </span>","minimal","punctuation","high",False
26652,"Create shell integration test for named chanels Expected usage ATM would be sink channel called foo http transform foo source channel called foo foo count file",NULL,"Create shell integration test for named chanels Expected usage ATM would be sink channel called foo http transform foo source channel called foo foo count file",NULL,"Add for who this story is","well_formed","no_role","high",False
26643,"Failure when creating deploying stream leaves invalid stream in the Repository implementations. reproduce 1 Create a bad stream definition name bad Try to recreate with the same name, but correct stream definitions. The system will report that the stream already exists. ",NULL,"Failure when creating deploying stream leaves invalid stream in the Repository implementations. reproduce 1 Create a bad stream definition name bad Try to recreate with the same name, but correct stream definitions. The system will report that the stream already exists. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26643,"Failure when creating deploying stream leaves invalid stream in the Repository implementations. reproduce 1 Create a bad stream definition name bad Try to recreate with the same name, but correct stream definitions. The system will report that the stream already exists. ",NULL,"Failure when creating deploying stream leaves invalid stream in the Repository implementations. reproduce 1 Create a bad stream definition name bad Try to recreate with the same name, but correct stream definitions. The system will report that the stream already exists. ",NULL,"Failure when creating deploying stream leaves invalid stream in the Repository implementations<span class='highlight-text severity-high'>. reproduce 1 Create a bad stream definition name bad Try to recreate with the same name, but correct stream definitions. The system will report that the stream already exists. </span>","minimal","punctuation","high",False
26648,"Documentation for fixed rate triggers ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26648,"Documentation for fixed rate triggers ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26653,"Prepare Blog post for XD M2 ",NULL,"Prepare Blog post for XD M2 ",NULL,"Add for who this story is","well_formed","no_role","high",False
26664,"doesn t give proper results back Both Luke s original code and my refactored PR which uses same code snippet seem to behave strangely. Stored values seem fine, but the getCounts method seems phony. To test 1 stream create foo definition time log 2 tap create bar definition tap foo aggregatecounter 3 curl H application json this gives default bucketing hourly but chances are that they are empty. ",NULL,"doesn t give proper results back Both Luke s original code and my refactored PR which uses same code snippet seem to behave strangely. Stored values seem fine, but the getCounts method seems phony. To test 1 stream create foo definition time log 2 tap create bar definition tap foo aggregatecounter 3 curl H application json this gives default bucketing hourly but chances are that they are empty. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26664,"doesn t give proper results back Both Luke s original code and my refactored PR which uses same code snippet seem to behave strangely. Stored values seem fine, but the getCounts method seems phony. To test 1 stream create foo definition time log 2 tap create bar definition tap foo aggregatecounter 3 curl H application json this gives default bucketing hourly but chances are that they are empty. ",NULL,"doesn t give proper results back Both Luke s original code and my refactored PR which uses same code snippet seem to behave strangely. Stored values seem fine, but the getCounts method seems phony. To test 1 stream create foo definition time log 2 tap create bar definition tap foo aggregatecounter 3 curl H application json this gives default bucketing hourly but chances are that they are empty. ",NULL,"doesn t give proper results back Both Luke s original code<span class='highlight-text severity-high'> and </span>my refactored PR which uses same code snippet seem to behave strangely. Stored values seem fine, but the getCounts method seems phony. To test 1 stream create foo definition time log 2 tap create bar definition tap foo aggregatecounter 3 curl H application json this gives default bucketing hourly but chances are that they are empty. ","atomic","conjunctions","high",False
26664,"doesn t give proper results back Both Luke s original code and my refactored PR which uses same code snippet seem to behave strangely. Stored values seem fine, but the getCounts method seems phony. To test 1 stream create foo definition time log 2 tap create bar definition tap foo aggregatecounter 3 curl H application json this gives default bucketing hourly but chances are that they are empty. ",NULL,"doesn t give proper results back Both Luke s original code and my refactored PR which uses same code snippet seem to behave strangely. Stored values seem fine, but the getCounts method seems phony. To test 1 stream create foo definition time log 2 tap create bar definition tap foo aggregatecounter 3 curl H application json this gives default bucketing hourly but chances are that they are empty. ",NULL,"doesn t give proper results back Both Luke s original code and my refactored PR which uses same code snippet seem to behave strangely<span class='highlight-text severity-high'>. Stored values seem fine, but the getCounts method seems phony. To test 1 stream create foo definition time log 2 tap create bar definition tap foo aggregatecounter 3 curl H application json this gives default bucketing hourly but chances are that they are empty. </span>","minimal","punctuation","high",False
26667,"Improve build file distribution tasks The current flow of gradle tasks is confusing. Suggest the following changes to simplify the flow. 1. Move the current task logic in zipXD to distZip 2. Have distZip depend on dist 3. Update the how to build docs on the wiki 4. Make sure that the distZip task only shows up once in the list of gradle target. ",NULL,"Improve build file distribution tasks The current flow of gradle tasks is confusing. Suggest the following changes to simplify the flow. 1. Move the current task logic in zipXD to distZip 2. Have distZip depend on dist 3. Update the how to build docs on the wiki 4. Make sure that the distZip task only shows up once in the list of gradle target. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26667,"Improve build file distribution tasks The current flow of gradle tasks is confusing. Suggest the following changes to simplify the flow. 1. Move the current task logic in zipXD to distZip 2. Have distZip depend on dist 3. Update the how to build docs on the wiki 4. Make sure that the distZip task only shows up once in the list of gradle target. ",NULL,"Improve build file distribution tasks The current flow of gradle tasks is confusing. Suggest the following changes to simplify the flow. 1. Move the current task logic in zipXD to distZip 2. Have distZip depend on dist 3. Update the how to build docs on the wiki 4. Make sure that the distZip task only shows up once in the list of gradle target. ",NULL,"Improve build file distribution tasks The current flow of gradle tasks is confusing<span class='highlight-text severity-high'>. Suggest the following changes to simplify the flow. 1. Move the current task logic in zipXD to distZip 2. Have distZip depend on dist 3. Update the how to build docs on the wiki 4. Make sure that the distZip task only shows up once in the list of gradle target. </span>","minimal","punctuation","high",False
26666,"Tuple should support storing nested tuples Nested tuple structures shoudl be supported, getTuple int index , getTuple String name ",NULL,"Tuple should support storing nested tuples Nested tuple structures shoudl be supported, getTuple int index , getTuple String name ",NULL,"Add for who this story is","well_formed","no_role","high",False
26669,"Create list delete commands for all the metrics We need to add list delete commands for the metrics FieldValueCounter Gauge RichGauge Currently, the class has the delete method to delete the metric from the repository. We can probably use the same for all the metrics.",NULL,"Create list delete commands for all the metrics We need to add list delete commands for the metrics FieldValueCounter Gauge RichGauge Currently, the class has the delete method to delete the metric from the repository. We can probably use the same for all the metrics.",NULL,"Add for who this story is","well_formed","no_role","high",False
26669,"Create list delete commands for all the metrics We need to add list delete commands for the metrics FieldValueCounter Gauge RichGauge Currently, the class has the delete method to delete the metric from the repository. We can probably use the same for all the metrics.",NULL,"Create list delete commands for all the metrics We need to add list delete commands for the metrics FieldValueCounter Gauge RichGauge Currently, the class has the delete method to delete the metric from the repository. We can probably use the same for all the metrics.",NULL,"Create list delete commands for all the metrics We need to add list delete commands for the metrics FieldValueCounter Gauge RichGauge Currently, the class has the delete method to delete the metric from the repository<span class='highlight-text severity-high'>. We can probably use the same for all the metrics.</span>","minimal","punctuation","high",False
26668,"Add counter delete shell command Add counter delete shell command. This also requires implementation of DELETE rest end point at CountersController.",NULL,"Add counter delete shell command Add counter delete shell command. This also requires implementation of DELETE rest end point at CountersController.",NULL,"Add for who this story is","well_formed","no_role","high",False
26668,"Add counter delete shell command Add counter delete shell command. This also requires implementation of DELETE rest end point at CountersController.",NULL,"Add counter delete shell command Add counter delete shell command. This also requires implementation of DELETE rest end point at CountersController.",NULL,"Add counter delete shell command Add counter delete shell command<span class='highlight-text severity-high'>. This also requires implementation of DELETE rest end point at CountersController.</span>","minimal","punctuation","high",False
26671,"Add CONTRIBUTING.md file Add CONTRIBUTING.md file, use the Spring Integration file as the basis.",NULL,"Add CONTRIBUTING.md file Add CONTRIBUTING.md file, use the Spring Integration file as the basis.",NULL,"Add for who this story is","well_formed","no_role","high",False
26670,"Fix wiki documentation to use xd shell command prompt to read xd We need to fix the github wiki to use the xd shell command prompt xd .",NULL,"Fix wiki documentation to use xd shell command prompt to read xd We need to fix the github wiki to use the xd shell command prompt xd .",NULL,"Add for who this story is","well_formed","no_role","high",False
26673,"Gemfire cache closed when a gemfire module is undeployed Need to investigate why this is happening, normally setting gfe client cache close false prevents the singleton cache from closing when the application context is closed. ",NULL,"Gemfire cache closed when a gemfire module is undeployed Need to investigate why this is happening, normally setting gfe client cache close false prevents the singleton cache from closing when the application context is closed. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26672,"Ad Hoc Job needs to have option for launch and forget When running an ad hoc job without the use of a trigger adhoc or named . The user has to wait for job to complete before receiving a success. We need to launch a job and get a success back to the user letting them know the job has been launched. for example immediate",NULL,"Ad Hoc Job needs to have option for launch and forget When running an ad hoc job without the use of a trigger adhoc or named . The user has to wait for job to complete before receiving a success. We need to launch a job and get a success back to the user letting them know the job has been launched. for example immediate",NULL,"Add for who this story is","well_formed","no_role","high",False
26672,"Ad Hoc Job needs to have option for launch and forget When running an ad hoc job without the use of a trigger adhoc or named . The user has to wait for job to complete before receiving a success. We need to launch a job and get a success back to the user letting them know the job has been launched. for example immediate",NULL,"Ad Hoc Job needs to have option for launch and forget When running an ad hoc job without the use of a trigger adhoc or named . The user has to wait for job to complete before receiving a success. We need to launch a job and get a success back to the user letting them know the job has been launched. for example immediate",NULL,"Ad Hoc Job needs to have option for launch<span class='highlight-text severity-high'> and </span>forget When running an ad hoc job without the use of a trigger adhoc<span class='highlight-text severity-high'> or </span>named . The user has to wait for job to complete before receiving a success. We need to launch a job and get a success back to the user letting them know the job has been launched. for example immediate","atomic","conjunctions","high",False
26672,"Ad Hoc Job needs to have option for launch and forget When running an ad hoc job without the use of a trigger adhoc or named . The user has to wait for job to complete before receiving a success. We need to launch a job and get a success back to the user letting them know the job has been launched. for example immediate",NULL,"Ad Hoc Job needs to have option for launch and forget When running an ad hoc job without the use of a trigger adhoc or named . The user has to wait for job to complete before receiving a success. We need to launch a job and get a success back to the user letting them know the job has been launched. for example immediate",NULL,"Ad Hoc Job needs to have option for launch and forget When running an ad hoc job without the use of a trigger adhoc or named <span class='highlight-text severity-high'>. The user has to wait for job to complete before receiving a success. We need to launch a job and get a success back to the user letting them know the job has been launched. for example immediate</span>","minimal","punctuation","high",False
26675,"Rich Gauge doco is outdated The RichGauge section does not mention the alpha parameter in redis output, nor does it explain its meaning.",NULL,"Rich Gauge doco is outdated The RichGauge section does not mention the alpha parameter in redis output, nor does it explain its meaning.",NULL,"Add for who this story is","well_formed","no_role","high",False
26674,"Saving a metric Counter, Gauge.. with an existing name should throw an exception The difference between saving a new metric and updating an existing one needs to be defined. Suggest that if we try to save when an existing counter is already in the database to throw exception, such as ",NULL,"Saving a metric Counter, Gauge.. with an existing name should throw an exception The difference between saving a new metric and updating an existing one needs to be defined. Suggest that if we try to save when an existing counter is already in the database to throw exception, such as ",NULL,"Add for who this story is","well_formed","no_role","high",False
26674,"Saving a metric Counter, Gauge.. with an existing name should throw an exception The difference between saving a new metric and updating an existing one needs to be defined. Suggest that if we try to save when an existing counter is already in the database to throw exception, such as ",NULL,"Saving a metric Counter, Gauge.. with an existing name should throw an exception The difference between saving a new metric and updating an existing one needs to be defined. Suggest that if we try to save when an existing counter is already in the database to throw exception, such as ",NULL,"Saving a metric Counter, Gauge.. with an existing name should throw an exception The difference between saving a new metric<span class='highlight-text severity-high'> and </span>updating an existing one needs to be defined. Suggest that if we try to save when an existing counter is already in the database to throw exception, such as ","atomic","conjunctions","high",False
26674,"Saving a metric Counter, Gauge.. with an existing name should throw an exception The difference between saving a new metric and updating an existing one needs to be defined. Suggest that if we try to save when an existing counter is already in the database to throw exception, such as ",NULL,"Saving a metric Counter, Gauge.. with an existing name should throw an exception The difference between saving a new metric and updating an existing one needs to be defined. Suggest that if we try to save when an existing counter is already in the database to throw exception, such as ",NULL,"Saving a metric Counter, Gauge<span class='highlight-text severity-high'>.. with an existing name should throw an exception The difference between saving a new metric and updating an existing one needs to be defined. Suggest that if we try to save when an existing counter is already in the database to throw exception, such as </span>","minimal","punctuation","high",False
26679,"Documentation for jms source should have jms added to the list and also the corresponding section that shows some basic usage.",NULL,"Documentation for jms source should have jms added to the list and also the corresponding section that shows some basic usage.",NULL,"Add for who this story is","well_formed","no_role","high",False
26679,"Documentation for jms source should have jms added to the list and also the corresponding section that shows some basic usage.",NULL,"Documentation for jms source should have jms added to the list and also the corresponding section that shows some basic usage.",NULL,"Documentation for jms source should have jms added to the list<span class='highlight-text severity-high'> and </span>also the corresponding section that shows some basic usage.","atomic","conjunctions","high",False
26676,"Document JSON quoting behavior in shell This may be an issue following the search replace from curl to Shell, but for example, this documentation line does not work http post target data The backslash prior to quote is left in the payload and hence Jackson chokes on it We need clear rules about quoting at the shell level",NULL,"Document JSON quoting behavior in shell This may be an issue following the search replace from curl to Shell, but for example, this documentation line does not work http post target data The backslash prior to quote is left in the payload and hence Jackson chokes on it We need clear rules about quoting at the shell level",NULL,"Add for who this story is","well_formed","no_role","high",False
26676,"Document JSON quoting behavior in shell This may be an issue following the search replace from curl to Shell, but for example, this documentation line does not work http post target data The backslash prior to quote is left in the payload and hence Jackson chokes on it We need clear rules about quoting at the shell level",NULL,"Document JSON quoting behavior in shell This may be an issue following the search replace from curl to Shell, but for example, this documentation line does not work http post target data The backslash prior to quote is left in the payload and hence Jackson chokes on it We need clear rules about quoting at the shell level",NULL,"Document JSON quoting behavior in shell This may be an issue following the search replace from curl to Shell, but for example, this documentation line does not work http post target data The backslash prior to quote is left in the payload<span class='highlight-text severity-high'> and </span>hence Jackson chokes on it We need clear rules about quoting at the shell level","atomic","conjunctions","high",False
26678,"Documentation for rabbit source should have rabbit added to the list and also the corresponding section that shows some basic usage.",NULL,"Documentation for rabbit source should have rabbit added to the list and also the corresponding section that shows some basic usage.",NULL,"Add for who this story is","well_formed","no_role","high",False
26678,"Documentation for rabbit source should have rabbit added to the list and also the corresponding section that shows some basic usage.",NULL,"Documentation for rabbit source should have rabbit added to the list and also the corresponding section that shows some basic usage.",NULL,"Documentation for rabbit source should have rabbit added to the list<span class='highlight-text severity-high'> and </span>also the corresponding section that shows some basic usage.","atomic","conjunctions","high",False
26677,"Integration tests for DSL Reference examples ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26677,"Integration tests for DSL Reference examples ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26689,"Pluralize test classes in package The classes under test are pluralized. Therefore, the test classes themselves should reflect that. E.g. rename JobCommandTests to JobCommandsTests as it tests class JobCommands . Please check all tests in that package for correct naming.",NULL,"Pluralize test classes in package The classes under test are pluralized. Therefore, the test classes themselves should reflect that. E.g. rename JobCommandTests to JobCommandsTests as it tests class JobCommands . Please check all tests in that package for correct naming.",NULL,"Add for who this story is","well_formed","no_role","high",False
26689,"Pluralize test classes in package The classes under test are pluralized. Therefore, the test classes themselves should reflect that. E.g. rename JobCommandTests to JobCommandsTests as it tests class JobCommands . Please check all tests in that package for correct naming.",NULL,"Pluralize test classes in package The classes under test are pluralized. Therefore, the test classes themselves should reflect that. E.g. rename JobCommandTests to JobCommandsTests as it tests class JobCommands . Please check all tests in that package for correct naming.",NULL,"Pluralize test classes in package The classes under test are pluralized<span class='highlight-text severity-high'>. Therefore, the test classes themselves should reflect that. E.g. rename JobCommandTests to JobCommandsTests as it tests class JobCommands . Please check all tests in that package for correct naming.</span>","minimal","punctuation","high",False
26690,"Shell HTTP Post Allow posting of local file contents E.g. allow for posting of JSON data stored in local files. Allow users to specify the content type . Ensure that Unicode data UTF posts correctly.",NULL,"Shell HTTP Post Allow posting of local file contents E.g. allow for posting of JSON data stored in local files. Allow users to specify the content type . Ensure that Unicode data UTF posts correctly.",NULL,"Add for who this story is","well_formed","no_role","high",False
26690,"Shell HTTP Post Allow posting of local file contents E.g. allow for posting of JSON data stored in local files. Allow users to specify the content type . Ensure that Unicode data UTF posts correctly.",NULL,"Shell HTTP Post Allow posting of local file contents E.g. allow for posting of JSON data stored in local files. Allow users to specify the content type . Ensure that Unicode data UTF posts correctly.",NULL,"Shell HTTP Post Allow posting of local file contents E<span class='highlight-text severity-high'>.g. allow for posting of JSON data stored in local files. Allow users to specify the content type . Ensure that Unicode data UTF posts correctly.</span>","minimal","punctuation","high",False
26691,"Rabbit Source Make Default QueueName Stream Name Consistency with JMS Source.",NULL,"Rabbit Source Make Default QueueName Stream Name Consistency with JMS Source.",NULL,"Add for who this story is","well_formed","no_role","high",False
26692,"Fix guava dependency for hadoop20 and phd1 Spring Xd currently ships with Guava 12.0 while Hadoop 2.0.5 and Pivotal HD 1.0 depends on 11.0.2 this could lead to classpath problems if we include both.",NULL,"Fix guava dependency for hadoop20 and phd1 Spring Xd currently ships with Guava 12.0 while Hadoop 2.0.5 and Pivotal HD 1.0 depends on 11.0.2 this could lead to classpath problems if we include both.",NULL,"Add for who this story is","well_formed","no_role","high",False
26692,"Fix guava dependency for hadoop20 and phd1 Spring Xd currently ships with Guava 12.0 while Hadoop 2.0.5 and Pivotal HD 1.0 depends on 11.0.2 this could lead to classpath problems if we include both.",NULL,"Fix guava dependency for hadoop20 and phd1 Spring Xd currently ships with Guava 12.0 while Hadoop 2.0.5 and Pivotal HD 1.0 depends on 11.0.2 this could lead to classpath problems if we include both.",NULL,"Fix guava dependency for hadoop20<span class='highlight-text severity-high'> and </span>phd1 Spring Xd currently ships with Guava 12.0 while Hadoop 2.0.5 and Pivotal HD 1.0 depends on 11.0.2 this could lead to classpath problems if we include both.","atomic","conjunctions","high",False
26693,"OOTB source modules with poller should use fixed delay pollers should standardize on fixed delay vs fixed rate. The value should accept a property with a standard name like interval ",NULL,"OOTB source modules with poller should use fixed delay pollers should standardize on fixed delay vs fixed rate. The value should accept a property with a standard name like interval ",NULL,"Add for who this story is","well_formed","no_role","high",False
26693,"OOTB source modules with poller should use fixed delay pollers should standardize on fixed delay vs fixed rate. The value should accept a property with a standard name like interval ",NULL,"OOTB source modules with poller should use fixed delay pollers should standardize on fixed delay vs fixed rate. The value should accept a property with a standard name like interval ",NULL,"OOTB source modules with poller should use fixed delay pollers should standardize on fixed delay vs fixed rate<span class='highlight-text severity-high'>. The value should accept a property with a standard name like interval </span>","minimal","punctuation","high",False
26696,"Update architecture diagram to show rabbit in addition to redis to communicate between admin and containers Figure 1 here should also show Rabbit as an option, since otherwise people will think we are tied to redis.",NULL,"Update architecture diagram to show rabbit in addition to redis to communicate between admin and containers Figure 1 here should also show Rabbit as an option, since otherwise people will think we are tied to redis.",NULL,"Update architecture diagram to show rabbit in addition to redis to communicate between admin<span class='highlight-text severity-high'> and </span>containers Figure 1 here should also show Rabbit as an option, since otherwise people will think we are tied to redis.","atomic","conjunctions","high",False
26697,"Map column names with underscore to camelCase style keys for JDBC sink We need to add support for matching column names with underscores like user name and map them to camel case style keys like userName in the ",NULL,"Map column names with underscore to camelCase style keys for JDBC sink We need to add support for matching column names with underscores like user name and map them to camel case style keys like userName in the ",NULL,"Add for who this story is","well_formed","no_role","high",False
26697,"Map column names with underscore to camelCase style keys for JDBC sink We need to add support for matching column names with underscores like user name and map them to camel case style keys like userName in the ",NULL,"Map column names with underscore to camelCase style keys for JDBC sink We need to add support for matching column names with underscores like user name and map them to camel case style keys like userName in the ",NULL,"Map column names with underscore to camelCase style keys for JDBC sink We need to add support for matching column names with underscores like user name<span class='highlight-text severity-high'> and </span>map them to camel case style keys like userName in the ","atomic","conjunctions","high",False
26698,"Split RichGauge in 2 support of the alpha parameter is awkward and can confuse people who are expecting a simple average mean. Consider splitting RichGauge in two flavors arithmetic and exponential. Involves quite some work at the repository, handler and REST level though... ",NULL,"Split RichGauge in 2 support of the alpha parameter is awkward and can confuse people who are expecting a simple average mean. Consider splitting RichGauge in two flavors arithmetic and exponential. Involves quite some work at the repository, handler and REST level though... ",NULL,"Add for who this story is","well_formed","no_role","high",False
26698,"Split RichGauge in 2 support of the alpha parameter is awkward and can confuse people who are expecting a simple average mean. Consider splitting RichGauge in two flavors arithmetic and exponential. Involves quite some work at the repository, handler and REST level though... ",NULL,"Split RichGauge in 2 support of the alpha parameter is awkward and can confuse people who are expecting a simple average mean. Consider splitting RichGauge in two flavors arithmetic and exponential. Involves quite some work at the repository, handler and REST level though... ",NULL,"Split RichGauge in 2 support of the alpha parameter is awkward<span class='highlight-text severity-high'> and </span>can confuse people who are expecting a simple average mean. Consider splitting RichGauge in two flavors arithmetic and exponential. Involves quite some work at the repository, handler and REST level though... ","atomic","conjunctions","high",False
26698,"Split RichGauge in 2 support of the alpha parameter is awkward and can confuse people who are expecting a simple average mean. Consider splitting RichGauge in two flavors arithmetic and exponential. Involves quite some work at the repository, handler and REST level though... ",NULL,"Split RichGauge in 2 support of the alpha parameter is awkward and can confuse people who are expecting a simple average mean. Consider splitting RichGauge in two flavors arithmetic and exponential. Involves quite some work at the repository, handler and REST level though... ",NULL,"Split RichGauge in 2 support of the alpha parameter is awkward and can confuse people who are expecting a simple average mean<span class='highlight-text severity-high'>. Consider splitting RichGauge in two flavors arithmetic and exponential. Involves quite some work at the repository, handler and REST level though... </span>","minimal","punctuation","high",False
26701,"Remove substream from the documentation This will come back in M3 once we iron out the issues.",NULL,"Remove substream from the documentation This will come back in M3 once we iron out the issues.",NULL,"Add for who this story is","well_formed","no_role","high",False
26703,"Eclipse build path error after running gradle refresh source folders in Eclipse After running gradle refresh source folders on the spring xd module project in Eclipse, there is an error because the folder is missing. Solution is to add a placeholder file.",NULL,"Eclipse build path error after running gradle refresh source folders in Eclipse After running gradle refresh source folders on the spring xd module project in Eclipse, there is an error because the folder is missing. Solution is to add a placeholder file.",NULL,"Add for who this story is","well_formed","no_role","high",False
26703,"Eclipse build path error after running gradle refresh source folders in Eclipse After running gradle refresh source folders on the spring xd module project in Eclipse, there is an error because the folder is missing. Solution is to add a placeholder file.",NULL,"Eclipse build path error after running gradle refresh source folders in Eclipse After running gradle refresh source folders on the spring xd module project in Eclipse, there is an error because the folder is missing. Solution is to add a placeholder file.",NULL,"Eclipse build path error after running gradle refresh source folders in Eclipse After running gradle refresh source folders on the spring xd module project in Eclipse, there is an error because the folder is missing<span class='highlight-text severity-high'>. Solution is to add a placeholder file.</span>","minimal","punctuation","high",False
26695,"Channel Registry Refactoring Factor out common Redis Rabbit code. Also, factor out common inbound tap code very similar . Change transport nternals to Use instead of .",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26695,"Channel Registry Refactoring Factor out common Redis Rabbit code. Also, factor out common inbound tap code very similar . Change transport nternals to Use instead of .",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26695,"Channel Registry Refactoring Factor out common Redis Rabbit code. Also, factor out common inbound tap code very similar . Change transport nternals to Use instead of .",NULL,NULL,NULL,"Channel Registry Refactoring Factor out common Redis Rabbit code<span class='highlight-text severity-high'>. Also, factor out common inbound tap code very similar . Change transport nternals to Use instead of .</span>","minimal","punctuation","high",False
26687,"Set Default Hadoop Name Node for Shell Currently, you have to set the default name node every time your start the shell. We should do 2 things Provide a default Name node Set Default Hadoop Name Node for Shell Should we provide some form of persistence? It kind of sucks that you have to re specify the name node every time the shell starts up xd hadoop fs ls You must set fs URL before run fs commands ",NULL,"Set Default Hadoop Name Node for Shell Currently, you have to set the default name node every time your start the shell. We should do 2 things Provide a default Name node Set Default Hadoop Name Node for Shell Should we provide some form of persistence? It kind of sucks that you have to re specify the name node every time the shell starts up xd hadoop fs ls You must set fs URL before run fs commands ",NULL,"Add for who this story is","well_formed","no_role","high",False
26687,"Set Default Hadoop Name Node for Shell Currently, you have to set the default name node every time your start the shell. We should do 2 things Provide a default Name node Set Default Hadoop Name Node for Shell Should we provide some form of persistence? It kind of sucks that you have to re specify the name node every time the shell starts up xd hadoop fs ls You must set fs URL before run fs commands ",NULL,"Set Default Hadoop Name Node for Shell Currently, you have to set the default name node every time your start the shell. We should do 2 things Provide a default Name node Set Default Hadoop Name Node for Shell Should we provide some form of persistence? It kind of sucks that you have to re specify the name node every time the shell starts up xd hadoop fs ls You must set fs URL before run fs commands ",NULL,"Set Default Hadoop Name Node for Shell Currently, you have to set the default name node every time your start the shell<span class='highlight-text severity-high'>. We should do 2 things Provide a default Name node Set Default Hadoop Name Node for Shell Should we provide some form of persistence? It kind of sucks that you have to re specify the name node every time the shell starts up xd hadoop fs ls You must set fs URL before run fs commands </span>","minimal","punctuation","high",False
26688,"Document tuple data structure on XD wiki ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26688,"Document tuple data structure on XD wiki ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26700,"Regression test on file source As we overwrote changes to file source by mistake, let s add some regression tests, esp. to the file location. Plan on extending the utility source and sink functionality",NULL,"Regression test on file source As we overwrote changes to file source by mistake, let s add some regression tests, esp. to the file location. Plan on extending the utility source and sink functionality",NULL,"Add for who this story is","well_formed","no_role","high",False
26700,"Regression test on file source As we overwrote changes to file source by mistake, let s add some regression tests, esp. to the file location. Plan on extending the utility source and sink functionality",NULL,"Regression test on file source As we overwrote changes to file source by mistake, let s add some regression tests, esp. to the file location. Plan on extending the utility source and sink functionality",NULL,"Regression test on file source As we overwrote changes to file source by mistake, let s add some regression tests, esp<span class='highlight-text severity-high'>. to the file location. Plan on extending the utility source and sink functionality</span>","minimal","punctuation","high",False
26702,"Gemfire Sink to update a gemfire cache. Update a gemfire region.",NULL,"Gemfire Sink to update a gemfire cache. Update a gemfire region.",NULL,"Add for who this story is","well_formed","no_role","high",False
26702,"Gemfire Sink to update a gemfire cache. Update a gemfire region.",NULL,"Gemfire Sink to update a gemfire cache. Update a gemfire region.",NULL,"Gemfire Sink to update a gemfire cache<span class='highlight-text severity-high'>. Update a gemfire region.</span>","minimal","punctuation","high",False
26710,"Batch Jobs Add the ability to provide JobParameters ",NULL,"Batch Jobs Add the ability to provide JobParameters ",NULL,"Add for who this story is","well_formed","no_role","high",False
26709,"Rename spring xd shell to xd shell ",NULL,"Rename spring xd shell to xd shell ",NULL,"Add for who this story is","well_formed","no_role","high",False
26712,"File sink filename should default to having a .out suffix. ",NULL,"File sink filename should default to having a .out suffix. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26711,"Use correct constant based on Hadoop version used Keep getting the following warning WARN Spring Shell fs.default.name is deprecated. Instead, use fs.defaultFS Should switch to use the runtime value of the constant based on Hadoop version used.",NULL,"Use correct constant based on Hadoop version used Keep getting the following warning WARN Spring Shell fs.default.name is deprecated. Instead, use fs.defaultFS Should switch to use the runtime value of the constant based on Hadoop version used.",NULL,"Add for who this story is","well_formed","no_role","high",False
26711,"Use correct constant based on Hadoop version used Keep getting the following warning WARN Spring Shell fs.default.name is deprecated. Instead, use fs.defaultFS Should switch to use the runtime value of the constant based on Hadoop version used.",NULL,"Use correct constant based on Hadoop version used Keep getting the following warning WARN Spring Shell fs.default.name is deprecated. Instead, use fs.defaultFS Should switch to use the runtime value of the constant based on Hadoop version used.",NULL,"Use correct constant based on Hadoop version used Keep getting the following warning WARN Spring Shell fs<span class='highlight-text severity-high'>.default.name is deprecated. Instead, use fs.defaultFS Should switch to use the runtime value of the constant based on Hadoop version used.</span>","minimal","punctuation","high",False
26713,"AggregateCounter display command options with lastHours and lastDays It would be nice to have lastHours and lastDays options for aggregatecounter display command.",NULL,"AggregateCounter display command options with lastHours and lastDays It would be nice to have lastHours and lastDays options for aggregatecounter display command.",NULL,"Add for who this story is","well_formed","no_role","high",False
26714,"Remove Redis Transport Headers from Tapped Stream Redis transport headers are not removed in taps.",NULL,"Remove Redis Transport Headers from Tapped Stream Redis transport headers are not removed in taps.",NULL,"Add for who this story is","well_formed","no_role","high",False
26715,"Add Accepted Media Type Support to Tap Currently, the initial tap module accepted media types are not retrieved from the module when creating the tap.",NULL,"Add Accepted Media Type Support to Tap Currently, the initial tap module accepted media types are not retrieved from the module when creating the tap.",NULL,"Add for who this story is","well_formed","no_role","high",False
26716,"Rest Client should not force usage of Joda Time The Rest Client project should not impose Joda to the user.",NULL,"Rest Client should not force usage of Joda Time The Rest Client project should not impose Joda to the user.",NULL,"Add for who this story is","well_formed","no_role","high",False
26717,"should not use Joda Not only should it not use Joda see XD 668 but the passing of dates currently relies on default formatting",NULL,"should not use Joda Not only should it not use Joda see XD 668 but the passing of dates currently relies on default formatting",NULL,"Add for who this story is","well_formed","no_role","high",False
26718,"TAB completion for existing entities Provide Shell TAB completion when referencing an existing entity",NULL,"TAB completion for existing entities Provide Shell TAB completion when referencing an existing entity",NULL,"Add for who this story is","well_formed","no_role","high",False
26719,"Ugly error messages in shell when not connected should go thru the list of all commands available and make sure that a simple not connected message is returned instead of something like this I O error on GET request for end of file from server; nested exception is Unexpected end of file from server at .... ",NULL,"Ugly error messages in shell when not connected should go thru the list of all commands available and make sure that a simple not connected message is returned instead of something like this I O error on GET request for end of file from server; nested exception is Unexpected end of file from server at .... ",NULL,"Add for who this story is","well_formed","no_role","high",False
26719,"Ugly error messages in shell when not connected should go thru the list of all commands available and make sure that a simple not connected message is returned instead of something like this I O error on GET request for end of file from server; nested exception is Unexpected end of file from server at .... ",NULL,"Ugly error messages in shell when not connected should go thru the list of all commands available and make sure that a simple not connected message is returned instead of something like this I O error on GET request for end of file from server; nested exception is Unexpected end of file from server at .... ",NULL,"Ugly error messages in shell when not connected should go thru the list of all commands available<span class='highlight-text severity-high'> and </span>make sure that a simple not connected message is returned instead of something like this I O error on GET request for end of file from server; nested exception is Unexpected end of file from server at .... ","atomic","conjunctions","high",False
26719,"Ugly error messages in shell when not connected should go thru the list of all commands available and make sure that a simple not connected message is returned instead of something like this I O error on GET request for end of file from server; nested exception is Unexpected end of file from server at .... ",NULL,"Ugly error messages in shell when not connected should go thru the list of all commands available and make sure that a simple not connected message is returned instead of something like this I O error on GET request for end of file from server; nested exception is Unexpected end of file from server at .... ",NULL,"Ugly error messages in shell when not connected should go thru the list of all commands available and make sure that a simple not connected message is returned instead of something like this I O error on GET request for end of file from server<span class='highlight-text severity-high'>; nested exception is Unexpected end of file from server at .... </span>","minimal","punctuation","high",False
26720,"http post in shell incorrectly mentions default of target option the value for target is required there is no default , but the hint for that option states otherwise xd http post target http post target required target the location to post to; default if option not present ",NULL,"http post in shell incorrectly mentions default of target option the value for target is required there is no default , but the hint for that option states otherwise xd http post target http post target required target the location to post to; default if option not present ",NULL,"Add for who this story is","well_formed","no_role","high",False
26720,"http post in shell incorrectly mentions default of target option the value for target is required there is no default , but the hint for that option states otherwise xd http post target http post target required target the location to post to; default if option not present ",NULL,"http post in shell incorrectly mentions default of target option the value for target is required there is no default , but the hint for that option states otherwise xd http post target http post target required target the location to post to; default if option not present ",NULL,"http post in shell incorrectly mentions default of target option the value for target is required there is no default , but the hint for that option states otherwise xd http post target http post target required target the location to post to<span class='highlight-text severity-high'>; default if option not present </span>","minimal","punctuation","high",False
26721,"Add Spring Batch word count Sample to Spring XD Samples repo ",NULL,"Add Spring Batch word count Sample to Spring XD Samples repo ",NULL,"Add for who this story is","well_formed","no_role","high",False
26722,"Cannot chain Because expects a String as input, one cannot chain json related processors. A simple solution would be to also accept Jackson IN and forward it directly in that case.",NULL,"Cannot chain Because expects a String as input, one cannot chain json related processors. A simple solution would be to also accept Jackson IN and forward it directly in that case.",NULL,"Add for who this story is","well_formed","no_role","high",False
26722,"Cannot chain Because expects a String as input, one cannot chain json related processors. A simple solution would be to also accept Jackson IN and forward it directly in that case.",NULL,"Cannot chain Because expects a String as input, one cannot chain json related processors. A simple solution would be to also accept Jackson IN and forward it directly in that case.",NULL,"Cannot chain Because expects a String as input, one cannot chain json related processors<span class='highlight-text severity-high'>. A simple solution would be to also accept Jackson IN and forward it directly in that case.</span>","minimal","punctuation","high",False
26723,"add PropertyAccessor for Tuple fields in SpEL Example using name filter Example using index filter This should support nested keys as well filter ",NULL,"add PropertyAccessor for Tuple fields in SpEL Example using name filter Example using index filter This should support nested keys as well filter ",NULL,"Add for who this story is","well_formed","no_role","high",False
26724,"Update settings file and reformat existing codebase. Please put in suggestions for the current .settings file. Maybe one suggestion is to not format on save?",NULL,"Update settings file and reformat existing codebase. Please put in suggestions for the current .settings file. Maybe one suggestion is to not format on save?",NULL,"Add for who this story is","well_formed","no_role","high",False
26724,"Update settings file and reformat existing codebase. Please put in suggestions for the current .settings file. Maybe one suggestion is to not format on save?",NULL,"Update settings file and reformat existing codebase. Please put in suggestions for the current .settings file. Maybe one suggestion is to not format on save?",NULL,"Update settings file and reformat existing codebase<span class='highlight-text severity-high'>. Please put in suggestions for the current .settings file. Maybe one suggestion is to not format on save?</span>","minimal","punctuation","high",False
26725,"Export of data from HDFS to a relational database Based on a single process running a Spring Batch job, support the ETL of data from HDFS to a RDBMS",NULL,"Export of data from HDFS to a relational database Based on a single process running a Spring Batch job, support the ETL of data from HDFS to a RDBMS",NULL,"Add for who this story is","well_formed","no_role","high",False
26707,"Support polling configuration for named channel queues in CLI ",NULL,"Support polling configuration for named channel queues in CLI ",NULL,"Add for who this story is","well_formed","no_role","high",False
26705,"Support explict named channel creation with configurable settings via the REST API and Shell Support pubsub named channels the story could be a bit more general though enable channel creation with configurable settings via the REST API and shell namedchannel create foo domain PUBSUB",NULL,"Support explict named channel creation with configurable settings via the REST API and Shell Support pubsub named channels the story could be a bit more general though enable channel creation with configurable settings via the REST API and shell namedchannel create foo domain PUBSUB",NULL,"Add for who this story is","well_formed","no_role","high",False
26705,"Support explict named channel creation with configurable settings via the REST API and Shell Support pubsub named channels the story could be a bit more general though enable channel creation with configurable settings via the REST API and shell namedchannel create foo domain PUBSUB",NULL,"Support explict named channel creation with configurable settings via the REST API and Shell Support pubsub named channels the story could be a bit more general though enable channel creation with configurable settings via the REST API and shell namedchannel create foo domain PUBSUB",NULL,"Support explict named channel creation with configurable settings via the REST API<span class='highlight-text severity-high'> and </span>Shell Support pubsub named channels the story could be a bit more general though enable channel creation with configurable settings via the REST API and shell namedchannel create foo domain PUBSUB","atomic","conjunctions","high",False
26708,"Update to Spring Data Redis 1.1.0.M2 Remove the and use the non serialization feature of M2.",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26708,"Update to Spring Data Redis 1.1.0.M2 Remove the and use the non serialization feature of M2.",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26731,"Support Named Taps or Similar Support Named Taps or Similar Provide some syntax allowing multiple tap points to be directed to a named channel. e.g. tap foo.4 namedTap tap bar.2 namedTap or tap.foo counter Provide some syntax allowing multiple tap points to be directed to a named channel. e.g. tap foo.4 namedTap tap bar.2 namedTap or tap.foo counter",NULL,"Support Named Taps or Similar Support Named Taps or Similar Provide some syntax allowing multiple tap points to be directed to a named channel. e.g. tap foo.4 namedTap tap bar.2 namedTap or tap.foo counter Provide some syntax allowing multiple tap points to be directed to a named channel. e.g. tap foo.4 namedTap tap bar.2 namedTap or tap.foo counter",NULL,"Add for who this story is","well_formed","no_role","high",False
26731,"Support Named Taps or Similar Support Named Taps or Similar Provide some syntax allowing multiple tap points to be directed to a named channel. e.g. tap foo.4 namedTap tap bar.2 namedTap or tap.foo counter Provide some syntax allowing multiple tap points to be directed to a named channel. e.g. tap foo.4 namedTap tap bar.2 namedTap or tap.foo counter",NULL,"Support Named Taps or Similar Support Named Taps or Similar Provide some syntax allowing multiple tap points to be directed to a named channel. e.g. tap foo.4 namedTap tap bar.2 namedTap or tap.foo counter Provide some syntax allowing multiple tap points to be directed to a named channel. e.g. tap foo.4 namedTap tap bar.2 namedTap or tap.foo counter",NULL,"Support Named Taps<span class='highlight-text severity-high'> or </span>Similar Support Named Taps or Similar Provide some syntax allowing multiple tap points to be directed to a named channel. e.g. tap foo.4 namedTap tap bar.2 namedTap or tap.foo counter Provide some syntax allowing multiple tap points to be directed to a named channel. e.g. tap foo.4 namedTap tap bar.2 namedTap or tap.foo counter","atomic","conjunctions","high",False
26731,"Support Named Taps or Similar Support Named Taps or Similar Provide some syntax allowing multiple tap points to be directed to a named channel. e.g. tap foo.4 namedTap tap bar.2 namedTap or tap.foo counter Provide some syntax allowing multiple tap points to be directed to a named channel. e.g. tap foo.4 namedTap tap bar.2 namedTap or tap.foo counter",NULL,"Support Named Taps or Similar Support Named Taps or Similar Provide some syntax allowing multiple tap points to be directed to a named channel. e.g. tap foo.4 namedTap tap bar.2 namedTap or tap.foo counter Provide some syntax allowing multiple tap points to be directed to a named channel. e.g. tap foo.4 namedTap tap bar.2 namedTap or tap.foo counter",NULL,"Support Named Taps or Similar Support Named Taps or Similar Provide some syntax allowing multiple tap points to be directed to a named channel<span class='highlight-text severity-high'>. e.g. tap foo.4 namedTap tap bar.2 namedTap or tap.foo counter Provide some syntax allowing multiple tap points to be directed to a named channel. e.g. tap foo.4 namedTap tap bar.2 namedTap or tap.foo counter</span>","minimal","punctuation","high",False
26728,"Modify file sink to avoid dot with empty suffix The expression currently appends . where the default suffix is out . If the suffix value were an empty String, this would lead to the file name ending with a dot. We should update the expression so that it only appends the dot if the suffix is not empty. This might be possible with a ternary expression.",NULL,"Modify file sink to avoid dot with empty suffix The expression currently appends . where the default suffix is out . If the suffix value were an empty String, this would lead to the file name ending with a dot. We should update the expression","so that it only appends the dot if the suffix is not empty. This might be possible with a ternary expression.","Add for who this story is","well_formed","no_role","high",False
26728,"Modify file sink to avoid dot with empty suffix The expression currently appends . where the default suffix is out . If the suffix value were an empty String, this would lead to the file name ending with a dot. We should update the expression so that it only appends the dot if the suffix is not empty. This might be possible with a ternary expression.",NULL,"Modify file sink to avoid dot with empty suffix The expression currently appends . where the default suffix is out . If the suffix value were an empty String, this would lead to the file name ending with a dot. We should update the expression","so that it only appends the dot if the suffix is not empty. This might be possible with a ternary expression.","Modify file sink to avoid dot with empty suffix The expression currently appends <span class='highlight-text severity-high'>. where the default suffix is out . If the suffix value were an empty String, this would lead to the file name ending with a dot. We should update the expression so that it only appends the dot if the suffix is not empty. This might be possible with a ternary expression.</span>","minimal","punctuation","high",False
26728,"Modify file sink to avoid dot with empty suffix The expression currently appends . where the default suffix is out . If the suffix value were an empty String, this would lead to the file name ending with a dot. We should update the expression so that it only appends the dot if the suffix is not empty. This might be possible with a ternary expression.",NULL,"Modify file sink to avoid dot with empty suffix The expression currently appends . where the default suffix is out . If the suffix value were an empty String, this would lead to the file name ending with a dot. We should update the expression","so that it only appends the dot if the suffix is not empty. This might be possible with a ternary expression.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26730,"Refactor Taps to Avoid Transport Hop Taps are currently source modules. They could be refactored to simply bridge the tapped module s tap pub sub topic directly with conversion to the first tap module s input channel. Note ensure destroy works. Currently the tap is destroyed by the simple fact it is a module; if it s no longer a module we ll need special handling to stop remove the tap adapter.",NULL,"Refactor Taps to Avoid Transport Hop Taps are currently source modules. They could be refactored to simply bridge the tapped module s tap pub sub topic directly with conversion to the first tap module s input channel. Note ensure destroy works. Currently the tap is destroyed by the simple fact it is a module; if it s no longer a module we ll need special handling to stop remove the tap adapter.",NULL,"Add for who this story is","well_formed","no_role","high",False
26730,"Refactor Taps to Avoid Transport Hop Taps are currently source modules. They could be refactored to simply bridge the tapped module s tap pub sub topic directly with conversion to the first tap module s input channel. Note ensure destroy works. Currently the tap is destroyed by the simple fact it is a module; if it s no longer a module we ll need special handling to stop remove the tap adapter.",NULL,"Refactor Taps to Avoid Transport Hop Taps are currently source modules. They could be refactored to simply bridge the tapped module s tap pub sub topic directly with conversion to the first tap module s input channel. Note ensure destroy works. Currently the tap is destroyed by the simple fact it is a module; if it s no longer a module we ll need special handling to stop remove the tap adapter.",NULL,"Refactor Taps to Avoid Transport Hop Taps are currently source modules<span class='highlight-text severity-high'>. They could be refactored to simply bridge the tapped module s tap pub sub topic directly with conversion to the first tap module s input channel. Note ensure destroy works. Currently the tap is destroyed by the simple fact it is a module; if it s no longer a module we ll need special handling to stop remove the tap adapter.</span>","minimal","punctuation","high",False
26732,"provide user friendly messages when dealing with invalid gemfire sink xd stream create name testgemfire definition http port 8887 gemfire 16 20 28,503 WARN Spring Shell POST request for resulted in 500 Internal Server Error ; invoking error handler Command failed Invalid bean definition with name region defined in null Could not resolve placeholder regionName in string value ",NULL,"provide user friendly messages when dealing with invalid gemfire sink xd stream create name testgemfire definition http port 8887 gemfire 16 20 28,503 WARN Spring Shell POST request for resulted in 500 Internal Server Error ; invoking error handler Command failed Invalid bean definition with name region defined in null Could not resolve placeholder regionName in string value ",NULL,"Add for who this story is","well_formed","no_role","high",False
26732,"provide user friendly messages when dealing with invalid gemfire sink xd stream create name testgemfire definition http port 8887 gemfire 16 20 28,503 WARN Spring Shell POST request for resulted in 500 Internal Server Error ; invoking error handler Command failed Invalid bean definition with name region defined in null Could not resolve placeholder regionName in string value ",NULL,"provide user friendly messages when dealing with invalid gemfire sink xd stream create name testgemfire definition http port 8887 gemfire 16 20 28,503 WARN Spring Shell POST request for resulted in 500 Internal Server Error ; invoking error handler Command failed Invalid bean definition with name region defined in null Could not resolve placeholder regionName in string value ",NULL,"provide user friendly messages when dealing with invalid gemfire sink xd stream create name testgemfire definition http port 8887 gemfire 16 20 28,503 WARN Spring Shell POST request for resulted in 500 Internal Server Error <span class='highlight-text severity-high'>; invoking error handler Command failed Invalid bean definition with name region defined in null Could not resolve placeholder regionName in string value </span>","minimal","punctuation","high",False
26735,"Simplify instance deployment code AbstractDeployer has 4 subclasses, 3 of which override e.g. deploy making the boilerplate factorization ineffective. Introduce an intermediate class for those deployers that support the concept of an instance Stream, Tap, Job to some extent ",NULL,"Simplify instance deployment code AbstractDeployer has 4 subclasses, 3 of which override e.g. deploy making the boilerplate factorization ineffective. Introduce an intermediate class for those deployers that support the concept of an instance Stream, Tap, Job to some extent ",NULL,"Add for who this story is","well_formed","no_role","high",False
26735,"Simplify instance deployment code AbstractDeployer has 4 subclasses, 3 of which override e.g. deploy making the boilerplate factorization ineffective. Introduce an intermediate class for those deployers that support the concept of an instance Stream, Tap, Job to some extent ",NULL,"Simplify instance deployment code AbstractDeployer has 4 subclasses, 3 of which override e.g. deploy making the boilerplate factorization ineffective. Introduce an intermediate class for those deployers that support the concept of an instance Stream, Tap, Job to some extent ",NULL,"Simplify instance deployment code AbstractDeployer has 4 subclasses, 3 of which override e<span class='highlight-text severity-high'>.g. deploy making the boilerplate factorization ineffective. Introduce an intermediate class for those deployers that support the concept of an instance Stream, Tap, Job to some extent </span>","minimal","punctuation","high",False
26733,"Support of Message payloads across JVMs across all transports. String byte byte byte no serialization Pojo configured serialization ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26733,"Support of Message payloads across JVMs across all transports. String byte byte byte no serialization Pojo configured serialization ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26733,"Support of Message payloads across JVMs across all transports. String byte byte byte no serialization Pojo configured serialization ",NULL,NULL,NULL,"Support of Message payloads across JVMs across all transports<span class='highlight-text severity-high'>. String byte byte byte no serialization Pojo configured serialization </span>","minimal","punctuation","high",False
26737,"http source module should copy Content Type header to SI ",NULL,"http source module should copy Content Type header to SI ",NULL,"Add for who this story is","well_formed","no_role","high",False
26740,"Shell integration tests should be able to be run across all transports Automate running integration tests on all supported transports",NULL,"Shell integration tests should be able to be run across all transports Automate running integration tests on all supported transports",NULL,"Add for who this story is","well_formed","no_role","high",False
26739,"Need to check the deployment requests in we should check the actual deployment requests were built correctly for each module in the test. Currently we just use the anyListOf check.",NULL,"Need to check the deployment requests in we should check the actual deployment requests were built correctly for each module in the test. Currently we just use the anyListOf check.",NULL,"Add for who this story is","well_formed","no_role","high",False
26739,"Need to check the deployment requests in we should check the actual deployment requests were built correctly for each module in the test. Currently we just use the anyListOf check.",NULL,"Need to check the deployment requests in we should check the actual deployment requests were built correctly for each module in the test. Currently we just use the anyListOf check.",NULL,"Need to check the deployment requests in we should check the actual deployment requests were built correctly for each module in the test<span class='highlight-text severity-high'>. Currently we just use the anyListOf check.</span>","minimal","punctuation","high",False
26741,"Tuple data structure The tuple data structure should be backward compatible in functionality for use in spring batch. Porting over FieldSet tests in spring batch to use the tuple data structure is one way help ensure that compatibility.",NULL,"Tuple data structure The tuple data structure should be backward compatible in functionality for use in spring batch. Porting over FieldSet tests in spring batch to use the tuple data structure is one way help ensure that compatibility.",NULL,"Add for who this story is","well_formed","no_role","high",False
26741,"Tuple data structure The tuple data structure should be backward compatible in functionality for use in spring batch. Porting over FieldSet tests in spring batch to use the tuple data structure is one way help ensure that compatibility.",NULL,"Tuple data structure The tuple data structure should be backward compatible in functionality for use in spring batch. Porting over FieldSet tests in spring batch to use the tuple data structure is one way help ensure that compatibility.",NULL,"Tuple data structure The tuple data structure should be backward compatible in functionality for use in spring batch<span class='highlight-text severity-high'>. Porting over FieldSet tests in spring batch to use the tuple data structure is one way help ensure that compatibility.</span>","minimal","punctuation","high",False
26742,"Remove XD UUIDGenerator in favor of the new SI provided one Remove bean id idGenerator container.xml Delete remove compile dependency on eaio from build.gradle",NULL,"Remove XD UUIDGenerator in favor of the new SI provided one Remove bean id idGenerator container.xml Delete remove compile dependency on eaio from build.gradle",NULL,"Add for who this story is","well_formed","no_role","high",False
26743,"User should be able to specify Rabbit virtual host Need to support Rabbit virtual host property in properties file and as args to Rabbit source and sink",NULL,"User should be able to specify Rabbit virtual host Need to support Rabbit virtual host property in properties file and as args to Rabbit source and sink",NULL,"Add for who this story is","well_formed","no_role","high",False
26744,"Add SingleNodeMain class SingleNodeMain parent new AC .. This should make startup processing more consistent and symmetrical ",NULL,"Add SingleNodeMain class SingleNodeMain parent new AC .. This should make startup processing more consistent and symmetrical ",NULL,"Add for who this story is","well_formed","no_role","high",False
26744,"Add SingleNodeMain class SingleNodeMain parent new AC .. This should make startup processing more consistent and symmetrical ",NULL,"Add SingleNodeMain class SingleNodeMain parent new AC .. This should make startup processing more consistent and symmetrical ",NULL,"Add SingleNodeMain class SingleNodeMain parent new AC <span class='highlight-text severity-high'>.. This should make startup processing more consistent and symmetrical </span>","minimal","punctuation","high",False
26734,"Export of data from HDFS to MongoDB Based on a single process Spring Batch job, ETL of data from HDFS to MongoDB.",NULL,"Export of data from HDFS to MongoDB Based on a single process Spring Batch job, ETL of data from HDFS to MongoDB.",NULL,"Add for who this story is","well_formed","no_role","high",False
26738,"Add deploy undeploy commands for taps ",NULL,"Add deploy undeploy commands for taps ",NULL,"Add for who this story is","well_formed","no_role","high",False
26748,"MBeanServer should not be declared in module common configuration Register in ",NULL,"MBeanServer should not be declared in module common configuration Register in ",NULL,"Add for who this story is","well_formed","no_role","high",False
26747,"Update JavaDocs in Plugin interface Update JavaDocs in Plugin interface to clearly describe the Plugin contract, i.e., where in the lifecycle each method is invoked",NULL,"Update JavaDocs in Plugin interface Update JavaDocs in Plugin interface to clearly describe the Plugin contract, i.e., where in the lifecycle each method is invoked",NULL,"Add for who this story is","well_formed","no_role","high",False
26749,"Document diagram runtime architecture, container and module lifecycle ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26749,"Document diagram runtime architecture, container and module lifecycle ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26750,"Support for Configuration based module definitions ",NULL,"Support for Configuration based module definitions ",NULL,"Add for who this story is","well_formed","no_role","high",False
26751,"Rename to The above method is invoked before the shared context is refreshed. preProcess... is more accurate",NULL,"Rename to The above method is invoked before the shared context is refreshed. preProcess... is more accurate",NULL,"Add for who this story is","well_formed","no_role","high",False
26751,"Rename to The above method is invoked before the shared context is refreshed. preProcess... is more accurate",NULL,"Rename to The above method is invoked before the shared context is refreshed. preProcess... is more accurate",NULL,"Rename to The above method is invoked before the shared context is refreshed<span class='highlight-text severity-high'>. preProcess... is more accurate</span>","minimal","punctuation","high",False
26752,"Provide a http source stream should be able to ingest data from http ",NULL,"Provide a http source stream should be able to ingest data from http ",NULL,"Add for who this story is","well_formed","no_role","high",False
26754,"Change inconditionnal Thread.sleep calls in tests to smarter incremental pauses There are a lot of Thread.sleep calls with delays chosen in the 1 2 seconds range. Change to a while loop with smaller pauses until a timeout is reached and give up. This applies to verification code e.g. verifying that a counter has expected value as well as File setup, or http being ready to accept requests etc",NULL,"Change inconditionnal Thread.sleep calls in tests to smarter incremental pauses There are a lot of Thread.sleep calls with delays chosen in the 1 2 seconds range. Change to a while loop with smaller pauses until a timeout is reached and give up. This applies to verification code e.g. verifying that a counter has expected value as well as File setup, or http being ready to accept requests etc",NULL,"Add for who this story is","well_formed","no_role","high",False
26754,"Change inconditionnal Thread.sleep calls in tests to smarter incremental pauses There are a lot of Thread.sleep calls with delays chosen in the 1 2 seconds range. Change to a while loop with smaller pauses until a timeout is reached and give up. This applies to verification code e.g. verifying that a counter has expected value as well as File setup, or http being ready to accept requests etc",NULL,"Change inconditionnal Thread.sleep calls in tests to smarter incremental pauses There are a lot of Thread.sleep calls with delays chosen in the 1 2 seconds range. Change to a while loop with smaller pauses until a timeout is reached and give up. This applies to verification code e.g. verifying that a counter has expected value as well as File setup, or http being ready to accept requests etc",NULL,"Change inconditionnal Thread.sleep calls in tests to smarter incremental pauses There are a lot of Thread.sleep calls with delays chosen in the 1 2 seconds range. Change to a while loop with smaller pauses until a timeout is reached<span class='highlight-text severity-high'> and </span>give up. This applies to verification code e.g. verifying that a counter has expected value as well as File setup,<span class='highlight-text severity-high'> or </span>http being ready to accept requests etc","atomic","conjunctions","high",False
26754,"Change inconditionnal Thread.sleep calls in tests to smarter incremental pauses There are a lot of Thread.sleep calls with delays chosen in the 1 2 seconds range. Change to a while loop with smaller pauses until a timeout is reached and give up. This applies to verification code e.g. verifying that a counter has expected value as well as File setup, or http being ready to accept requests etc",NULL,"Change inconditionnal Thread.sleep calls in tests to smarter incremental pauses There are a lot of Thread.sleep calls with delays chosen in the 1 2 seconds range. Change to a while loop with smaller pauses until a timeout is reached and give up. This applies to verification code e.g. verifying that a counter has expected value as well as File setup, or http being ready to accept requests etc",NULL,"Change inconditionnal Thread<span class='highlight-text severity-high'>.sleep calls in tests to smarter incremental pauses There are a lot of Thread.sleep calls with delays chosen in the 1 2 seconds range. Change to a while loop with smaller pauses until a timeout is reached and give up. This applies to verification code e.g. verifying that a counter has expected value as well as File setup, or http being ready to accept requests etc</span>","minimal","punctuation","high",False
26753,"Batch jobs send job and step events on channels This is the other side of launching a job by sending a message. The Job plugin should add listeners at the job step level so that the job step context information can be sent out on a channel. is a suggested channel name that would be created automatically.",NULL,"Batch jobs send job and step events on channels This is the other side of launching a job by sending a message. The Job plugin should add listeners at the job step level","so that the job step context information can be sent out on a channel. is a suggested channel name that would be created automatically.","Add for who this story is","well_formed","no_role","high",False
26753,"Batch jobs send job and step events on channels This is the other side of launching a job by sending a message. The Job plugin should add listeners at the job step level so that the job step context information can be sent out on a channel. is a suggested channel name that would be created automatically.",NULL,"Batch jobs send job and step events on channels This is the other side of launching a job by sending a message. The Job plugin should add listeners at the job step level","so that the job step context information can be sent out on a channel. is a suggested channel name that would be created automatically.","Batch jobs send job<span class='highlight-text severity-high'> and </span>step events on channels This is the other side of launching a job by sending a message. The Job plugin should add listeners at the job step level so that the job step context information can be sent out on a channel. is a suggested channel name that would be created automatically.","atomic","conjunctions","high",False
26753,"Batch jobs send job and step events on channels This is the other side of launching a job by sending a message. The Job plugin should add listeners at the job step level so that the job step context information can be sent out on a channel. is a suggested channel name that would be created automatically.",NULL,"Batch jobs send job and step events on channels This is the other side of launching a job by sending a message. The Job plugin should add listeners at the job step level","so that the job step context information can be sent out on a channel. is a suggested channel name that would be created automatically.","Batch jobs send job and step events on channels This is the other side of launching a job by sending a message<span class='highlight-text severity-high'>. The Job plugin should add listeners at the job step level so that the job step context information can be sent out on a channel. is a suggested channel name that would be created automatically.</span>","minimal","punctuation","high",False
26753,"Batch jobs send job and step events on channels This is the other side of launching a job by sending a message. The Job plugin should add listeners at the job step level so that the job step context information can be sent out on a channel. is a suggested channel name that would be created automatically.",NULL,"Batch jobs send job and step events on channels This is the other side of launching a job by sending a message. The Job plugin should add listeners at the job step level","so that the job step context information can be sent out on a channel. is a suggested channel name that would be created automatically.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26761,"Replace anonymous node in XD module bean names Enhance bean naming strategy or provide a value for the property that binds to this",NULL,"Replace anonymous node in XD module bean names Enhance bean naming strategy or provide a value for the property that binds to this",NULL,"Add for who this story is","well_formed","no_role","high",False
26761,"Replace anonymous node in XD module bean names Enhance bean naming strategy or provide a value for the property that binds to this",NULL,"Replace anonymous node in XD module bean names Enhance bean naming strategy or provide a value for the property that binds to this",NULL,"Replace anonymous node in XD module bean names Enhance bean naming strategy<span class='highlight-text severity-high'> or </span>provide a value for the property that binds to this","atomic","conjunctions","high",False
26755,"Test processor module in isolation Register the module under test and have access to a source channel that drives messages into the processor and a output channel where output messages are sent. Examples Built in Message conversion send JSON to a processor module that accepts Tuples. ",NULL,"Test processor module in isolation Register the module under test and have access to a source channel that drives messages into the processor and a output channel where output messages are sent. Examples Built in Message conversion send JSON to a processor module that accepts Tuples. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26755,"Test processor module in isolation Register the module under test and have access to a source channel that drives messages into the processor and a output channel where output messages are sent. Examples Built in Message conversion send JSON to a processor module that accepts Tuples. ",NULL,"Test processor module in isolation Register the module under test and have access to a source channel that drives messages into the processor and a output channel where output messages are sent. Examples Built in Message conversion send JSON to a processor module that accepts Tuples. ",NULL,"Test processor module in isolation Register the module under test<span class='highlight-text severity-high'> and </span>have access to a source channel that drives messages into the processor and a output channel where output messages are sent. Examples Built in Message conversion send JSON to a processor module that accepts Tuples. ","atomic","conjunctions","high",False
26755,"Test processor module in isolation Register the module under test and have access to a source channel that drives messages into the processor and a output channel where output messages are sent. Examples Built in Message conversion send JSON to a processor module that accepts Tuples. ",NULL,"Test processor module in isolation Register the module under test and have access to a source channel that drives messages into the processor and a output channel where output messages are sent. Examples Built in Message conversion send JSON to a processor module that accepts Tuples. ",NULL,"Test processor module in isolation Register the module under test and have access to a source channel that drives messages into the processor and a output channel where output messages are sent<span class='highlight-text severity-high'>. Examples Built in Message conversion send JSON to a processor module that accepts Tuples. </span>","minimal","punctuation","high",False
26758,"Display the UI from xd admin container when doing development in eclipse The UI code will be sitting in one or more top level directories in the repository This story will address the need to 1 copy over the UI code into a location so that it can be picked up by the embedded servlet container when running inside eclipse",NULL,"Display the UI from xd admin container when doing development in eclipse The UI code will be sitting in one or more top level directories in the repository This story will address the need to 1 copy over the UI code into a location","so that it can be picked up by the embedded servlet container when running inside eclipse","Add for who this story is","well_formed","no_role","high",False
26758,"Display the UI from xd admin container when doing development in eclipse The UI code will be sitting in one or more top level directories in the repository This story will address the need to 1 copy over the UI code into a location so that it can be picked up by the embedded servlet container when running inside eclipse",NULL,"Display the UI from xd admin container when doing development in eclipse The UI code will be sitting in one or more top level directories in the repository This story will address the need to 1 copy over the UI code into a location","so that it can be picked up by the embedded servlet container when running inside eclipse","Display the UI from xd admin container when doing development in eclipse The UI code will be sitting in one<span class='highlight-text severity-high'> or </span>more top level directories in the repository This story will address the need to 1 copy over the UI code into a location so that it can be picked up by the embedded servlet container when running inside eclipse","atomic","conjunctions","high",False
26758,"Display the UI from xd admin container when doing development in eclipse The UI code will be sitting in one or more top level directories in the repository This story will address the need to 1 copy over the UI code into a location so that it can be picked up by the embedded servlet container when running inside eclipse",NULL,"Display the UI from xd admin container when doing development in eclipse The UI code will be sitting in one or more top level directories in the repository This story will address the need to 1 copy over the UI code into a location","so that it can be picked up by the embedded servlet container when running inside eclipse","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26757,"Create directory structures and move existing UI code into Spring XD repository Create a directory structure that best benefits UI development. The copying of the UI files and other gradle build tasks so that the UI can be run inside the embedded servlet container of XD will be a seperate story",NULL,"Create directory structures and move existing UI code into Spring XD repository Create a directory structure that best benefits UI development. The copying of the UI files and other gradle build tasks","so that the UI can be run inside the embedded servlet container of XD will be a seperate story","Add for who this story is","well_formed","no_role","high",False
26757,"Create directory structures and move existing UI code into Spring XD repository Create a directory structure that best benefits UI development. The copying of the UI files and other gradle build tasks so that the UI can be run inside the embedded servlet container of XD will be a seperate story",NULL,"Create directory structures and move existing UI code into Spring XD repository Create a directory structure that best benefits UI development. The copying of the UI files and other gradle build tasks","so that the UI can be run inside the embedded servlet container of XD will be a seperate story","Create directory structures<span class='highlight-text severity-high'> and </span>move existing UI code into Spring XD repository Create a directory structure that best benefits UI development. The copying of the UI files and other gradle build tasks so that the UI can be run inside the embedded servlet container of XD will be a seperate story","atomic","conjunctions","high",False
26757,"Create directory structures and move existing UI code into Spring XD repository Create a directory structure that best benefits UI development. The copying of the UI files and other gradle build tasks so that the UI can be run inside the embedded servlet container of XD will be a seperate story",NULL,"Create directory structures and move existing UI code into Spring XD repository Create a directory structure that best benefits UI development. The copying of the UI files and other gradle build tasks","so that the UI can be run inside the embedded servlet container of XD will be a seperate story","Create directory structures and move existing UI code into Spring XD repository Create a directory structure that best benefits UI development<span class='highlight-text severity-high'>. The copying of the UI files and other gradle build tasks so that the UI can be run inside the embedded servlet container of XD will be a seperate story</span>","minimal","punctuation","high",False
26757,"Create directory structures and move existing UI code into Spring XD repository Create a directory structure that best benefits UI development. The copying of the UI files and other gradle build tasks so that the UI can be run inside the embedded servlet container of XD will be a seperate story",NULL,"Create directory structures and move existing UI code into Spring XD repository Create a directory structure that best benefits UI development. The copying of the UI files and other gradle build tasks","so that the UI can be run inside the embedded servlet container of XD will be a seperate story","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26760,"Add additional embedded servlet container config to load static UI resources Configure embedded servlet container needs to know where to load the UI code.",NULL,"Add additional embedded servlet container config to load static UI resources Configure embedded servlet container needs to know where to load the UI code.",NULL,"Add for who this story is","well_formed","no_role","high",False
26759,"add test to start stop stream server in additional to existing tests that check for redis connection, we need to add tests that start stop stream server. ",NULL,"add test to start stop stream server in additional to existing tests that check for redis connection, we need to add tests that start stop stream server. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26762,"Add PropertyAccessor for JSON fields in SpEL filter Example using index filter This should support nested keys as well filter This is related to and that in turn depends on SI being able to configure SpEL",NULL,"Add PropertyAccessor for JSON fields in SpEL filter Example using index filter This should support nested keys as well filter This is related to and that in turn depends on SI being able to configure SpEL",NULL,"Add for who this story is","well_formed","no_role","high",False
26762,"Add PropertyAccessor for JSON fields in SpEL filter Example using index filter This should support nested keys as well filter This is related to and that in turn depends on SI being able to configure SpEL",NULL,"Add PropertyAccessor for JSON fields in SpEL filter Example using index filter This should support nested keys as well filter This is related to and that in turn depends on SI being able to configure SpEL",NULL,"Add PropertyAccessor for JSON fields in SpEL filter Example using index filter This should support nested keys as well filter This is related to<span class='highlight-text severity-high'> and </span>that in turn depends on SI being able to configure SpEL","atomic","conjunctions","high",False
26745,"Refactor TriggerPlugin Remove unnecessary code that adds beans to shared context after refresh Scheduler should not be in common.xml register it in ",NULL,"Refactor TriggerPlugin Remove unnecessary code that adds beans to shared context after refresh Scheduler should not be in common.xml register it in ",NULL,"Add for who this story is","well_formed","no_role","high",False
26763,"Create JobLaunchRequest Transformer The JobLaunchRequest Transformer shall accept the following payloads File JSON String Properties Map Tuple Use Migrate some of the logic from e.g. using the Special Case File When handling a File , add special JobParameter absoluteFilePath populating it with Add unit tests ",NULL,"Create JobLaunchRequest Transformer The JobLaunchRequest Transformer shall accept the following payloads File JSON String Properties Map Tuple Use Migrate some of the logic from e.g. using the Special Case File When handling a File , add special JobParameter absoluteFilePath populating it with Add unit tests ",NULL,"Add for who this story is","well_formed","no_role","high",False
26763,"Create JobLaunchRequest Transformer The JobLaunchRequest Transformer shall accept the following payloads File JSON String Properties Map Tuple Use Migrate some of the logic from e.g. using the Special Case File When handling a File , add special JobParameter absoluteFilePath populating it with Add unit tests ",NULL,"Create JobLaunchRequest Transformer The JobLaunchRequest Transformer shall accept the following payloads File JSON String Properties Map Tuple Use Migrate some of the logic from e.g. using the Special Case File When handling a File , add special JobParameter absoluteFilePath populating it with Add unit tests ",NULL,"Create JobLaunchRequest Transformer The JobLaunchRequest Transformer shall accept the following payloads File JSON String Properties Map Tuple Use Migrate some of the logic from e<span class='highlight-text severity-high'>.g. using the Special Case File When handling a File , add special JobParameter absoluteFilePath populating it with Add unit tests </span>","minimal","punctuation","high",False
26766,"Rename XDContainer and associated classes to Node Rename XDContainer, ContainerMain, and any variable or methodNames, bean names, etc. that refer to container in favor of the term Node . Eliminate the dirt.container package, and move Node into .server",NULL,"Rename XDContainer and associated classes to Node Rename XDContainer, ContainerMain, and any variable or methodNames, bean names, etc. that refer to container in favor of the term Node . Eliminate the dirt.container package, and move Node into .server",NULL,"Add for who this story is","well_formed","no_role","high",False
26766,"Rename XDContainer and associated classes to Node Rename XDContainer, ContainerMain, and any variable or methodNames, bean names, etc. that refer to container in favor of the term Node . Eliminate the dirt.container package, and move Node into .server",NULL,"Rename XDContainer and associated classes to Node Rename XDContainer, ContainerMain, and any variable or methodNames, bean names, etc. that refer to container in favor of the term Node . Eliminate the dirt.container package, and move Node into .server",NULL,"Rename XDContainer<span class='highlight-text severity-high'> and </span>associated classes to Node Rename XDContainer, ContainerMain, and any variable<span class='highlight-text severity-high'> or </span>methodNames, bean names, etc. that refer to container in favor of the term Node . Eliminate the dirt.container package, and move Node into .server","atomic","conjunctions","high",False
26766,"Rename XDContainer and associated classes to Node Rename XDContainer, ContainerMain, and any variable or methodNames, bean names, etc. that refer to container in favor of the term Node . Eliminate the dirt.container package, and move Node into .server",NULL,"Rename XDContainer and associated classes to Node Rename XDContainer, ContainerMain, and any variable or methodNames, bean names, etc. that refer to container in favor of the term Node . Eliminate the dirt.container package, and move Node into .server",NULL,"Rename XDContainer and associated classes to Node Rename XDContainer, ContainerMain, and any variable or methodNames, bean names, etc<span class='highlight-text severity-high'>. that refer to container in favor of the term Node . Eliminate the dirt.container package, and move Node into .server</span>","minimal","punctuation","high",False
26765,"Trigger can send a message to a named channel Trigger can send a message to a named channel. For example trigger create name mytrigger definition trigger cron 10 message Good Luck, we are all counting on you channel foo Where the message contains the message that will be sent to foo job component.",NULL,"Trigger can send a message to a named channel Trigger can send a message to a named channel. For example trigger create name mytrigger definition trigger cron 10 message Good Luck, we are all counting on you channel foo Where the message contains the message that will be sent to foo job component.",NULL,"Add for who this story is","well_formed","no_role","high",False
26765,"Trigger can send a message to a named channel Trigger can send a message to a named channel. For example trigger create name mytrigger definition trigger cron 10 message Good Luck, we are all counting on you channel foo Where the message contains the message that will be sent to foo job component.",NULL,"Trigger can send a message to a named channel Trigger can send a message to a named channel. For example trigger create name mytrigger definition trigger cron 10 message Good Luck, we are all counting on you channel foo Where the message contains the message that will be sent to foo job component.",NULL,"Trigger can send a message to a named channel Trigger can send a message to a named channel<span class='highlight-text severity-high'>. For example trigger create name mytrigger definition trigger cron 10 message Good Luck, we are all counting on you channel foo Where the message contains the message that will be sent to foo job component.</span>","minimal","punctuation","high",False
26768,"Remove Option parsing code used for tests from Servers Currently Main class provide alternate static methods for parsing CLI options. One used for testing does not call System.exit just throws an exception. This code should be moved to spring xd test to support integration testing.",NULL,"Remove Option parsing code used for tests from Servers Currently Main class provide alternate static methods for parsing CLI options. One used for testing does not call System.exit just throws an exception. This code should be moved to spring xd test to support integration testing.",NULL,"Add for who this story is","well_formed","no_role","high",False
26768,"Remove Option parsing code used for tests from Servers Currently Main class provide alternate static methods for parsing CLI options. One used for testing does not call System.exit just throws an exception. This code should be moved to spring xd test to support integration testing.",NULL,"Remove Option parsing code used for tests from Servers Currently Main class provide alternate static methods for parsing CLI options. One used for testing does not call System.exit just throws an exception. This code should be moved to spring xd test to support integration testing.",NULL,"Remove Option parsing code used for tests from Servers Currently Main class provide alternate static methods for parsing CLI options<span class='highlight-text severity-high'>. One used for testing does not call System.exit just throws an exception. This code should be moved to spring xd test to support integration testing.</span>","minimal","punctuation","high",False
26767,"Create XD module for tail file adapter ",NULL,"Create XD module for tail file adapter ",NULL,"Add for who this story is","well_formed","no_role","high",False
26770,"Gradle Launch needs to use singlenodemain vs. admin main ",NULL,"Gradle Launch needs to use singlenodemain vs. admin main ",NULL,"Add for who this story is","well_formed","no_role","high",False
26770,"Gradle Launch needs to use singlenodemain vs. admin main ",NULL,"Gradle Launch needs to use singlenodemain vs. admin main ",NULL,"Gradle Launch needs to use singlenodemain vs<span class='highlight-text severity-high'>. admin main </span>","minimal","punctuation","high",False
26769,"Add dependency to spring batch admin in spring xd dirt We should depend on dependency version version dependency dependency version version dependency we are using spring batch 2.2.0.RELEASE. We need to depend on spring batch admin version ",NULL,"Add dependency to spring batch admin in spring xd dirt We should depend on dependency version version dependency dependency version version dependency we are using spring batch 2.2.0.RELEASE. We need to depend on spring batch admin version ",NULL,"Add for who this story is","well_formed","no_role","high",False
26769,"Add dependency to spring batch admin in spring xd dirt We should depend on dependency version version dependency dependency version version dependency we are using spring batch 2.2.0.RELEASE. We need to depend on spring batch admin version ",NULL,"Add dependency to spring batch admin in spring xd dirt We should depend on dependency version version dependency dependency version version dependency we are using spring batch 2.2.0.RELEASE. We need to depend on spring batch admin version ",NULL,"Add dependency to spring batch admin in spring xd dirt We should depend on dependency version version dependency dependency version version dependency we are using spring batch 2<span class='highlight-text severity-high'>.2.0.RELEASE. We need to depend on spring batch admin version </span>","minimal","punctuation","high",False
26772,"Comm protocol for appmaster We need to be able to talk to appmaster which will control the whole xd yarn app. 1. Choose the implementation? Thrift? Spring Int? Something else? ",NULL,"Comm protocol for appmaster We need to be able to talk to appmaster which will control the whole xd yarn app. 1. Choose the implementation? Thrift? Spring Int? Something else? ",NULL,"Add for who this story is","well_formed","no_role","high",False
26772,"Comm protocol for appmaster We need to be able to talk to appmaster which will control the whole xd yarn app. 1. Choose the implementation? Thrift? Spring Int? Something else? ",NULL,"Comm protocol for appmaster We need to be able to talk to appmaster which will control the whole xd yarn app. 1. Choose the implementation? Thrift? Spring Int? Something else? ",NULL,"Comm protocol for appmaster We need to be able to talk to appmaster which will control the whole xd yarn app<span class='highlight-text severity-high'>. 1. Choose the implementation? Thrift? Spring Int? Something else? </span>","minimal","punctuation","high",False
26771,"Interacting with XD on Yarn 1. How we talk to the XD instance s on Yarn 2. There is a rest interface which location can be exposed either via resource manager or appmaster 3. Technically appmaster could also expose interface which could eihter be proxy for xd rest or dedicated interface thrift or spring int ",NULL,"Interacting with XD on Yarn 1. How we talk to the XD instance s on Yarn 2. There is a rest interface which location can be exposed either via resource manager or appmaster 3. Technically appmaster could also expose interface which could eihter be proxy for xd rest or dedicated interface thrift or spring int ",NULL,"Add for who this story is","well_formed","no_role","high",False
26771,"Interacting with XD on Yarn 1. How we talk to the XD instance s on Yarn 2. There is a rest interface which location can be exposed either via resource manager or appmaster 3. Technically appmaster could also expose interface which could eihter be proxy for xd rest or dedicated interface thrift or spring int ",NULL,"Interacting with XD on Yarn 1. How we talk to the XD instance s on Yarn 2. There is a rest interface which location can be exposed either via resource manager or appmaster 3. Technically appmaster could also expose interface which could eihter be proxy for xd rest or dedicated interface thrift or spring int ",NULL,"Interacting with XD on Yarn 1<span class='highlight-text severity-high'>. How we talk to the XD instance s on Yarn 2. There is a rest interface which location can be exposed either via resource manager or appmaster 3. Technically appmaster could also expose interface which could eihter be proxy for xd rest or dedicated interface thrift or spring int </span>","minimal","punctuation","high",False
26773,"Container and Grid Control 1. We ll need a system which give better control of what yarn xd containers are out there and what is a status of those containers. 2. We also need grouping of containers order to choose, prioritize and scale tasks. 3. We need heartbeating of the grid nodes. Hadoop Yarn itself doesn t give enough tools to know if container is alive .",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26773,"Container and Grid Control 1. We ll need a system which give better control of what yarn xd containers are out there and what is a status of those containers. 2. We also need grouping of containers order to choose, prioritize and scale tasks. 3. We need heartbeating of the grid nodes. Hadoop Yarn itself doesn t give enough tools to know if container is alive .",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26773,"Container and Grid Control 1. We ll need a system which give better control of what yarn xd containers are out there and what is a status of those containers. 2. We also need grouping of containers order to choose, prioritize and scale tasks. 3. We need heartbeating of the grid nodes. Hadoop Yarn itself doesn t give enough tools to know if container is alive .",NULL,NULL,NULL,"Container and Grid Control 1<span class='highlight-text severity-high'>. We ll need a system which give better control of what yarn xd containers are out there and what is a status of those containers. 2. We also need grouping of containers order to choose, prioritize and scale tasks. 3. We need heartbeating of the grid nodes. Hadoop Yarn itself doesn t give enough tools to know if container is alive .</span>","minimal","punctuation","high",False
26776,"JDBC property settings need to be made externally configurable We need to have a properties section documented as well so that users can setup their jdbc connections for the various components.",NULL,"JDBC property settings need to be made externally configurable We need to have a properties section documented as well","so that users can setup their jdbc connections for the various components.","Add for who this story is","well_formed","no_role","high",False
26776,"JDBC property settings need to be made externally configurable We need to have a properties section documented as well so that users can setup their jdbc connections for the various components.",NULL,"JDBC property settings need to be made externally configurable We need to have a properties section documented as well","so that users can setup their jdbc connections for the various components.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26774,"XD UI on Yarn Technically speaking of we want to integrate XD UI on Hadoop tools we should do it so that the proxy on resource manager works with XD UI. From Hadoop Yarn resource manager point of view this proxied url is the applications tracking url which is registered when application is deployed .",NULL,"XD UI on Yarn Technically speaking of we want to integrate XD UI on Hadoop tools we should do it","so that the proxy on resource manager works with XD UI. From Hadoop Yarn resource manager point of view this proxied url is the applications tracking url which is registered when application is deployed .","Add for who this story is","well_formed","no_role","high",False
26774,"XD UI on Yarn Technically speaking of we want to integrate XD UI on Hadoop tools we should do it so that the proxy on resource manager works with XD UI. From Hadoop Yarn resource manager point of view this proxied url is the applications tracking url which is registered when application is deployed .",NULL,"XD UI on Yarn Technically speaking of we want to integrate XD UI on Hadoop tools we should do it","so that the proxy on resource manager works with XD UI. From Hadoop Yarn resource manager point of view this proxied url is the applications tracking url which is registered when application is deployed .","XD UI on Yarn Technically speaking of we want to integrate XD UI on Hadoop tools we should do it so that the proxy on resource manager works with XD UI<span class='highlight-text severity-high'>. From Hadoop Yarn resource manager point of view this proxied url is the applications tracking url which is registered when application is deployed .</span>","minimal","punctuation","high",False
26774,"XD UI on Yarn Technically speaking of we want to integrate XD UI on Hadoop tools we should do it so that the proxy on resource manager works with XD UI. From Hadoop Yarn resource manager point of view this proxied url is the applications tracking url which is registered when application is deployed .",NULL,"XD UI on Yarn Technically speaking of we want to integrate XD UI on Hadoop tools we should do it","so that the proxy on resource manager works with XD UI. From Hadoop Yarn resource manager point of view this proxied url is the applications tracking url which is registered when application is deployed .","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26775,"Restrict Job launcher with more than one batch job configured in job module Currently the Job launcher launches all the batch jobs configured in the job module. Please refer, executeBatchJob . This makes the JobRegistry registers with multiple batch jobs under the same Spring XD job name group name . Also, it is understood that having multiple jobs configuration under the same config xml is uncommon.",NULL,"Restrict Job launcher with more than one batch job configured in job module Currently the Job launcher launches all the batch jobs configured in the job module. Please refer, executeBatchJob . This makes the JobRegistry registers with multiple batch jobs under the same Spring XD job name group name . Also, it is understood that having multiple jobs configuration under the same config xml is uncommon.",NULL,"Add for who this story is","well_formed","no_role","high",False
26775,"Restrict Job launcher with more than one batch job configured in job module Currently the Job launcher launches all the batch jobs configured in the job module. Please refer, executeBatchJob . This makes the JobRegistry registers with multiple batch jobs under the same Spring XD job name group name . Also, it is understood that having multiple jobs configuration under the same config xml is uncommon.",NULL,"Restrict Job launcher with more than one batch job configured in job module Currently the Job launcher launches all the batch jobs configured in the job module. Please refer, executeBatchJob . This makes the JobRegistry registers with multiple batch jobs under the same Spring XD job name group name . Also, it is understood that having multiple jobs configuration under the same config xml is uncommon.",NULL,"Restrict Job launcher with more than one batch job configured in job module Currently the Job launcher launches all the batch jobs configured in the job module<span class='highlight-text severity-high'>. Please refer, executeBatchJob . This makes the JobRegistry registers with multiple batch jobs under the same Spring XD job name group name . Also, it is understood that having multiple jobs configuration under the same config xml is uncommon.</span>","minimal","punctuation","high",False
26796,"Enable profile selection from module options This came up when working on email source. There is and It would be nice to be able to put those in two profiles and have one of the profile being activated from module options e.g. email Don t know the runtime cost of activating profiles, but we could blindly activate profiles from all options passed explicitly beans Not sure if this is the same as XD 132",NULL,"Enable profile selection from module options This came up when working on email source. There is and It would be nice to be able to put those in two profiles and have one of the profile being activated from module options e.g. email Don t know the runtime cost of activating profiles, but we could blindly activate profiles from all options passed explicitly beans Not sure if this is the same as XD 132",NULL,"Add for who this story is","well_formed","no_role","high",False
26796,"Enable profile selection from module options This came up when working on email source. There is and It would be nice to be able to put those in two profiles and have one of the profile being activated from module options e.g. email Don t know the runtime cost of activating profiles, but we could blindly activate profiles from all options passed explicitly beans Not sure if this is the same as XD 132",NULL,"Enable profile selection from module options This came up when working on email source. There is and It would be nice to be able to put those in two profiles and have one of the profile being activated from module options e.g. email Don t know the runtime cost of activating profiles, but we could blindly activate profiles from all options passed explicitly beans Not sure if this is the same as XD 132",NULL,"Enable profile selection from module options This came up when working on email source. There is<span class='highlight-text severity-high'> and </span>It would be nice to be able to put those in two profiles and have one of the profile being activated from module options e.g. email Don t know the runtime cost of activating profiles, but we could blindly activate profiles from all options passed explicitly beans Not sure if this is the same as XD 132","atomic","conjunctions","high",False
26796,"Enable profile selection from module options This came up when working on email source. There is and It would be nice to be able to put those in two profiles and have one of the profile being activated from module options e.g. email Don t know the runtime cost of activating profiles, but we could blindly activate profiles from all options passed explicitly beans Not sure if this is the same as XD 132",NULL,"Enable profile selection from module options This came up when working on email source. There is and It would be nice to be able to put those in two profiles and have one of the profile being activated from module options e.g. email Don t know the runtime cost of activating profiles, but we could blindly activate profiles from all options passed explicitly beans Not sure if this is the same as XD 132",NULL,"Enable profile selection from module options This came up when working on email source<span class='highlight-text severity-high'>. There is and It would be nice to be able to put those in two profiles and have one of the profile being activated from module options e.g. email Don t know the runtime cost of activating profiles, but we could blindly activate profiles from all options passed explicitly beans Not sure if this is the same as XD 132</span>","minimal","punctuation","high",False
26799,"Add Integration Tests to run JobCommands Tests against all transports similar to ChannelRegistry that has the real tests subclasses for each impl provide the registry to be tested Thus one test can run against multiple transports.",NULL,"Add Integration Tests to run JobCommands Tests against all transports similar to ChannelRegistry that has the real tests subclasses for each impl provide the registry to be tested Thus one test can run against multiple transports.",NULL,"Add for who this story is","well_formed","no_role","high",False
26798,"Add a JobExecution DTO Object related to XD 779. We need the ability to provide JSON serializable JobExecution information. Change from using JavaSerialization back to returning objects ",NULL,"Add a JobExecution DTO Object related to XD 779. We need the ability to provide JSON serializable JobExecution information. Change from using JavaSerialization back to returning objects ",NULL,"Add for who this story is","well_formed","no_role","high",False
26798,"Add a JobExecution DTO Object related to XD 779. We need the ability to provide JSON serializable JobExecution information. Change from using JavaSerialization back to returning objects ",NULL,"Add a JobExecution DTO Object related to XD 779. We need the ability to provide JSON serializable JobExecution information. Change from using JavaSerialization back to returning objects ",NULL,"Add a JobExecution DTO Object related to XD 779<span class='highlight-text severity-high'>. We need the ability to provide JSON serializable JobExecution information. Change from using JavaSerialization back to returning objects </span>","minimal","punctuation","high",False
26801,"End user guide for data streams Put on the guide as a section in an streams wiki page. End user focused, no need to mention spring underpinning, impl details. ",NULL,"End user guide for data streams Put on the guide as a section in an streams wiki page. End user focused, no need to mention spring underpinning, impl details. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26801,"End user guide for data streams Put on the guide as a section in an streams wiki page. End user focused, no need to mention spring underpinning, impl details. ",NULL,"End user guide for data streams Put on the guide as a section in an streams wiki page. End user focused, no need to mention spring underpinning, impl details. ",NULL,"End user guide for data streams Put on the guide as a section in an streams wiki page<span class='highlight-text severity-high'>. End user focused, no need to mention spring underpinning, impl details. </span>","minimal","punctuation","high",False
26800,"Add index based access to ",NULL,"Add index based access to ",NULL,"Add for who this story is","well_formed","no_role","high",False
26803,"Document mail related sources sinks ",NULL,"Document mail related sources sinks ",NULL,"Add for who this story is","well_formed","no_role","high",False
26802,"Cryptic gradle error running tests when XD SingleNode is running calls System.exit causing a gradle buffer underflow. This is called from System.exit should be called from the main method instead. ",NULL,"Cryptic gradle error running tests when XD SingleNode is running calls System.exit causing a gradle buffer underflow. This is called from System.exit should be called from the main method instead. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26802,"Cryptic gradle error running tests when XD SingleNode is running calls System.exit causing a gradle buffer underflow. This is called from System.exit should be called from the main method instead. ",NULL,"Cryptic gradle error running tests when XD SingleNode is running calls System.exit causing a gradle buffer underflow. This is called from System.exit should be called from the main method instead. ",NULL,"Cryptic gradle error running tests when XD SingleNode is running calls System<span class='highlight-text severity-high'>.exit causing a gradle buffer underflow. This is called from System.exit should be called from the main method instead. </span>","minimal","punctuation","high",False
26805,"Upgrade Spring Data Redis to 1.1 RC1 ",NULL,"Upgrade Spring Data Redis to 1.1 RC1 ",NULL,"Add for who this story is","well_formed","no_role","high",False
26804,"Update twittersearch to use Spring Integration support ",NULL,"Update twittersearch to use Spring Integration support ",NULL,"Add for who this story is","well_formed","no_role","high",False
26807,"Refactor mail and imap source into one mail module, leveraging Profiles Once XD 785 is merged",NULL,"Refactor mail and imap source into one mail module, leveraging Profiles Once XD 785 is merged",NULL,"Add for who this story is","well_formed","no_role","high",False
26806,"Add integration tests for SpEL and Groovy based routing ",NULL,"Add integration tests for SpEL and Groovy based routing ",NULL,"Add for who this story is","well_formed","no_role","high",False
26806,"Add integration tests for SpEL and Groovy based routing ",NULL,"Add integration tests for SpEL and Groovy based routing ",NULL,"Add integration tests for SpEL<span class='highlight-text severity-high'> and </span>Groovy based routing ","atomic","conjunctions","high",False
26809,"Add support for grouping in Parser ",NULL,"Add support for grouping in Parser ",NULL,"Add for who this story is","well_formed","no_role","high",False
26808,"Package Tangle Introduced by XD 790 ",NULL,"Package Tangle Introduced by XD 790 ",NULL,"Add for who this story is","well_formed","no_role","high",False
26811,"Documentation for http hdfs processing Put on the guide as a section in an input stream wiki page. ",NULL,"Documentation for http hdfs processing Put on the guide as a section in an input stream wiki page. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26810,"Syslog Ingestion Have a syslog.xml config file that can be added to a module and registered with a module registry.",NULL,"Syslog Ingestion Have a syslog.xml config file that can be added to a module and registered with a module registry.",NULL,"Add for who this story is","well_formed","no_role","high",False
26810,"Syslog Ingestion Have a syslog.xml config file that can be added to a module and registered with a module registry.",NULL,"Syslog Ingestion Have a syslog.xml config file that can be added to a module and registered with a module registry.",NULL,"Syslog Ingestion Have a syslog.xml config file that can be added to a module<span class='highlight-text severity-high'> and </span>registered with a module registry.","atomic","conjunctions","high",False
26812,"Job channels need to denote a namespace Job channels need to have a namespace. i.e. job somejobname. Where the is the delimiter for the namespace. The preference is to use the instead of the . But XD 766 needs to be completed in order to support this.",NULL,"Job channels need to denote a namespace Job channels need to have a namespace. i.e. job somejobname. Where the is the delimiter for the namespace. The preference is to use the instead of the . But XD 766 needs to be completed","in order to support this.","Add for who this story is","well_formed","no_role","high",False
26812,"Job channels need to denote a namespace Job channels need to have a namespace. i.e. job somejobname. Where the is the delimiter for the namespace. The preference is to use the instead of the . But XD 766 needs to be completed in order to support this.",NULL,"Job channels need to denote a namespace Job channels need to have a namespace. i.e. job somejobname. Where the is the delimiter for the namespace. The preference is to use the instead of the . But XD 766 needs to be completed","in order to support this.","Job channels need to denote a namespace Job channels need to have a namespace<span class='highlight-text severity-high'>. i.e. job somejobname. Where the is the delimiter for the namespace. The preference is to use the instead of the . But XD 766 needs to be completed in order to support this.</span>","minimal","punctuation","high",False
26812,"Job channels need to denote a namespace Job channels need to have a namespace. i.e. job somejobname. Where the is the delimiter for the namespace. The preference is to use the instead of the . But XD 766 needs to be completed in order to support this.",NULL,"Job channels need to denote a namespace Job channels need to have a namespace. i.e. job somejobname. Where the is the delimiter for the namespace. The preference is to use the instead of the . But XD 766 needs to be completed","in order to support this.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26813,"Document splitter aggregator processors ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26813,"Document splitter aggregator processors ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26816,"Get notified when created named channel is ready For testing purposes it would be super helpful if there be a hook to get notified when a named channel is up and running. In current tests one may have to resort to Thread.sleep .",NULL,"Get notified when created named channel is ready For testing purposes it would be super helpful if there be a hook to get notified when a named channel is up and running. In current tests one may have to resort to Thread.sleep .",NULL,"Add for who this story is","well_formed","no_role","high",False
26816,"Get notified when created named channel is ready For testing purposes it would be super helpful if there be a hook to get notified when a named channel is up and running. In current tests one may have to resort to Thread.sleep .",NULL,"Get notified when created named channel is ready For testing purposes it would be super helpful if there be a hook to get notified when a named channel is up and running. In current tests one may have to resort to Thread.sleep .",NULL,"Get notified when created named channel is ready For testing purposes it would be super helpful if there be a hook to get notified when a named channel is up<span class='highlight-text severity-high'> and </span>running. In current tests one may have to resort to Thread.sleep .","atomic","conjunctions","high",False
26816,"Get notified when created named channel is ready For testing purposes it would be super helpful if there be a hook to get notified when a named channel is up and running. In current tests one may have to resort to Thread.sleep .",NULL,"Get notified when created named channel is ready For testing purposes it would be super helpful if there be a hook to get notified when a named channel is up and running. In current tests one may have to resort to Thread.sleep .",NULL,"Get notified when created named channel is ready For testing purposes it would be super helpful if there be a hook to get notified when a named channel is up and running<span class='highlight-text severity-high'>. In current tests one may have to resort to Thread.sleep .</span>","minimal","punctuation","high",False
26832,"should not overwrite original id and timestamp fields When converting a JSON string to a tuple the JSON may contain id. This method should handle this. Same with timestamp",NULL,"should not overwrite original id and timestamp fields When converting a JSON string to a tuple the JSON may contain id. This method should handle this. Same with timestamp",NULL,"Add for who this story is","well_formed","no_role","high",False
26832,"should not overwrite original id and timestamp fields When converting a JSON string to a tuple the JSON may contain id. This method should handle this. Same with timestamp",NULL,"should not overwrite original id and timestamp fields When converting a JSON string to a tuple the JSON may contain id. This method should handle this. Same with timestamp",NULL,"should not overwrite original id<span class='highlight-text severity-high'> and </span>timestamp fields When converting a JSON string to a tuple the JSON may contain id. This method should handle this. Same with timestamp","atomic","conjunctions","high",False
26832,"should not overwrite original id and timestamp fields When converting a JSON string to a tuple the JSON may contain id. This method should handle this. Same with timestamp",NULL,"should not overwrite original id and timestamp fields When converting a JSON string to a tuple the JSON may contain id. This method should handle this. Same with timestamp",NULL,"should not overwrite original id and timestamp fields When converting a JSON string to a tuple the JSON may contain id<span class='highlight-text severity-high'>. This method should handle this. Same with timestamp</span>","minimal","punctuation","high",False
26814,"Batch Jobs need container admin profiles This is to set the appropriate data source, so that the container will use admins batch repository.",NULL,"Batch Jobs need container admin profiles This is to set the appropriate data source,","so that the container will use admins batch repository.","Add for who this story is","well_formed","no_role","high",False
26814,"Batch Jobs need container admin profiles This is to set the appropriate data source, so that the container will use admins batch repository.",NULL,"Batch Jobs need container admin profiles This is to set the appropriate data source,","so that the container will use admins batch repository.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26820,"Shell integration with XD on Yarn We should provide a better shell integration when XD is run on Yarn. 1. yarn kill id TAB completion 2. yarn submit, more options like app name 3. yarn list, filter by app states, etc 4. admin config server TAB completion for running xd apps on yarn",NULL,"Shell integration with XD on Yarn We should provide a better shell integration when XD is run on Yarn. 1. yarn kill id TAB completion 2. yarn submit, more options like app name 3. yarn list, filter by app states, etc 4. admin config server TAB completion for running xd apps on yarn",NULL,"Add for who this story is","well_formed","no_role","high",False
26820,"Shell integration with XD on Yarn We should provide a better shell integration when XD is run on Yarn. 1. yarn kill id TAB completion 2. yarn submit, more options like app name 3. yarn list, filter by app states, etc 4. admin config server TAB completion for running xd apps on yarn",NULL,"Shell integration with XD on Yarn We should provide a better shell integration when XD is run on Yarn. 1. yarn kill id TAB completion 2. yarn submit, more options like app name 3. yarn list, filter by app states, etc 4. admin config server TAB completion for running xd apps on yarn",NULL,"Shell integration with XD on Yarn We should provide a better shell integration when XD is run on Yarn<span class='highlight-text severity-high'>. 1. yarn kill id TAB completion 2. yarn submit, more options like app name 3. yarn list, filter by app states, etc 4. admin config server TAB completion for running xd apps on yarn</span>","minimal","punctuation","high",False
26819,"Update to spring data hadoop 1.0.1.RELEASE This might mean we should adjust our hadoopDistro options to the ones supported in the new release hadoop12 default , cdh4, hdp13, phd1 and hadoop21",NULL,"Update to spring data hadoop 1.0.1.RELEASE This might mean we should adjust our hadoopDistro options to the ones supported in the new release hadoop12 default , cdh4, hdp13, phd1 and hadoop21",NULL,"Add for who this story is","well_formed","no_role","high",False
26822,"Add REST endpoint for launching Job We need a REST endpoint to launch a job. Given the constraint on JobRegistry being not persistent and not available outside the container JVM, we can not use the batch job admin controller service to launch the job. One possible way is to use the trigger source to launch the job at XD.",NULL,"Add REST endpoint for launching Job We need a REST endpoint to launch a job. Given the constraint on JobRegistry being not persistent and not available outside the container JVM, we can not use the batch job admin controller service to launch the job. One possible way is to use the trigger source to launch the job at XD.",NULL,"Add for who this story is","well_formed","no_role","high",False
26822,"Add REST endpoint for launching Job We need a REST endpoint to launch a job. Given the constraint on JobRegistry being not persistent and not available outside the container JVM, we can not use the batch job admin controller service to launch the job. One possible way is to use the trigger source to launch the job at XD.",NULL,"Add REST endpoint for launching Job We need a REST endpoint to launch a job. Given the constraint on JobRegistry being not persistent and not available outside the container JVM, we can not use the batch job admin controller service to launch the job. One possible way is to use the trigger source to launch the job at XD.",NULL,"Add REST endpoint for launching Job We need a REST endpoint to launch a job. Given the constraint on JobRegistry being not persistent<span class='highlight-text severity-high'> and </span>not available outside the container JVM, we can not use the batch job admin controller service to launch the job. One possible way is to use the trigger source to launch the job at XD.","atomic","conjunctions","high",False
26822,"Add REST endpoint for launching Job We need a REST endpoint to launch a job. Given the constraint on JobRegistry being not persistent and not available outside the container JVM, we can not use the batch job admin controller service to launch the job. One possible way is to use the trigger source to launch the job at XD.",NULL,"Add REST endpoint for launching Job We need a REST endpoint to launch a job. Given the constraint on JobRegistry being not persistent and not available outside the container JVM, we can not use the batch job admin controller service to launch the job. One possible way is to use the trigger source to launch the job at XD.",NULL,"Add REST endpoint for launching Job We need a REST endpoint to launch a job<span class='highlight-text severity-high'>. Given the constraint on JobRegistry being not persistent and not available outside the container JVM, we can not use the batch job admin controller service to launch the job. One possible way is to use the trigger source to launch the job at XD.</span>","minimal","punctuation","high",False
26821,"Documentation for syslog file processing Put on the guide as a section in an input stream wiki page. ",NULL,"Documentation for syslog file processing Put on the guide as a section in an input stream wiki page. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26824,"Rebase UI on top of new batch admin API Now that the new batch admin api is taking shape, we need to rebase the XD web UI to use this. It s more than just changing the http urls sent to the xd server since the new API is not identical to the old one.",NULL,"Rebase UI on top of new batch admin API Now that the new batch admin api is taking shape, we need to rebase the XD web UI to use this. It s more than just changing the http urls sent to the xd server since the new API is not identical to the old one.",NULL,"Add for who this story is","well_formed","no_role","high",False
26824,"Rebase UI on top of new batch admin API Now that the new batch admin api is taking shape, we need to rebase the XD web UI to use this. It s more than just changing the http urls sent to the xd server since the new API is not identical to the old one.",NULL,"Rebase UI on top of new batch admin API Now that the new batch admin api is taking shape, we need to rebase the XD web UI to use this. It s more than just changing the http urls sent to the xd server since the new API is not identical to the old one.",NULL,"Rebase UI on top of new batch admin API Now that the new batch admin api is taking shape, we need to rebase the XD web UI to use this<span class='highlight-text severity-high'>. It s more than just changing the http urls sent to the xd server since the new API is not identical to the old one.</span>","minimal","punctuation","high",False
26823,"Destroying XD job should remove job s entries at batch job repositories batch job locator When an XD job is destroyed deleted, the batch jobRepository entries for the job associated JobInstances, JobExecutions etc., and the BatchJobLocator entries.",NULL,"Destroying XD job should remove job s entries at batch job repositories batch job locator When an XD job is destroyed deleted, the batch jobRepository entries for the job associated JobInstances, JobExecutions etc., and the BatchJobLocator entries.",NULL,"Add for who this story is","well_formed","no_role","high",False
26826,"Support for composed streams Some recent changes caused this to be turned off. Basically the change was to police whether a stream is well formed at create time, rather than deploy time. By deferring that check we can create composed streams that are not deployable by themselves but that are when used as building blocks in proper streams.",NULL,"Support for composed streams Some recent changes caused this to be turned off. Basically the change was to police whether a stream is well formed at create time, rather than deploy time. By deferring that check we can create composed streams that are not deployable by themselves but that are when used as building blocks in proper streams.",NULL,"Add for who this story is","well_formed","no_role","high",False
26826,"Support for composed streams Some recent changes caused this to be turned off. Basically the change was to police whether a stream is well formed at create time, rather than deploy time. By deferring that check we can create composed streams that are not deployable by themselves but that are when used as building blocks in proper streams.",NULL,"Support for composed streams Some recent changes caused this to be turned off. Basically the change was to police whether a stream is well formed at create time, rather than deploy time. By deferring that check we can create composed streams that are not deployable by themselves but that are when used as building blocks in proper streams.",NULL,"Support for composed streams Some recent changes caused this to be turned off<span class='highlight-text severity-high'>. Basically the change was to police whether a stream is well formed at create time, rather than deploy time. By deferring that check we can create composed streams that are not deployable by themselves but that are when used as building blocks in proper streams.</span>","minimal","punctuation","high",False
26825,"Updgrade to use spring batch admin 1.3.0 M1 when available Once spring batch admin 1.3.0.M1 is available, update the build to use it. Likely to be Sept 7 or 9",NULL,"Updgrade to use spring batch admin 1.3.0 M1 when available Once spring batch admin 1.3.0.M1 is available, update the build to use it. Likely to be Sept 7 or 9",NULL,"Add for who this story is","well_formed","no_role","high",False
26825,"Updgrade to use spring batch admin 1.3.0 M1 when available Once spring batch admin 1.3.0.M1 is available, update the build to use it. Likely to be Sept 7 or 9",NULL,"Updgrade to use spring batch admin 1.3.0 M1 when available Once spring batch admin 1.3.0.M1 is available, update the build to use it. Likely to be Sept 7 or 9",NULL,"Updgrade to use spring batch admin 1<span class='highlight-text severity-high'>.3.0 M1 when available Once spring batch admin 1.3.0.M1 is available, update the build to use it. Likely to be Sept 7 or 9</span>","minimal","punctuation","high",False
26828,"UI should poll server for latest on job info The admin UI should be polling the server to automatically pick up any new jobs, executions, and instances.",NULL,"UI should poll server for latest on job info The admin UI should be polling the server to automatically pick up any new jobs, executions, and instances.",NULL,"Add for who this story is","well_formed","no_role","high",False
26827,"REST API for job listing should provide details on last execution A user should be able to view some important details of the last execution of a job from a job list. The class. At a minimum, I would like to see startTime startDate last job parameters duration last job status",NULL,"REST API for job listing should provide details on last execution A user should be able to view some important details of the last execution of a job from a job list. The class. At a minimum, I would like to see startTime startDate last job parameters duration last job status",NULL,"Add for who this story is","well_formed","no_role","high",False
26827,"REST API for job listing should provide details on last execution A user should be able to view some important details of the last execution of a job from a job list. The class. At a minimum, I would like to see startTime startDate last job parameters duration last job status",NULL,"REST API for job listing should provide details on last execution A user should be able to view some important details of the last execution of a job from a job list. The class. At a minimum, I would like to see startTime startDate last job parameters duration last job status",NULL,"REST API for job listing should provide details on last execution A user should be able to view some important details of the last execution of a job from a job list<span class='highlight-text severity-high'>. The class. At a minimum, I would like to see startTime startDate last job parameters duration last job status</span>","minimal","punctuation","high",False
26830,"Jobs and taps should not require a leading since they have name spaces. ",NULL,"Jobs and taps should not require a leading since they have name spaces. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26829,"Documentation for tail file processing Put on the guide as a section in an input stream wiki page. ",NULL,"Documentation for tail file processing Put on the guide as a section in an input stream wiki page. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26831,"Change url to access UI from browser Currently, the url for accessing the XD UI is This feels messy and dated. We should be able to access the ui without explicitly including the index.html, like this ",NULL,"Change url to access UI from browser Currently, the url for accessing the XD UI is This feels messy and dated. We should be able to access the ui without explicitly including the index.html, like this ",NULL,"Add for who this story is","well_formed","no_role","high",False
26831,"Change url to access UI from browser Currently, the url for accessing the XD UI is This feels messy and dated. We should be able to access the ui without explicitly including the index.html, like this ",NULL,"Change url to access UI from browser Currently, the url for accessing the XD UI is This feels messy and dated. We should be able to access the ui without explicitly including the index.html, like this ",NULL,"Change url to access UI from browser Currently, the url for accessing the XD UI is This feels messy<span class='highlight-text severity-high'> and </span>dated. We should be able to access the ui without explicitly including the index.html, like this ","atomic","conjunctions","high",False
26831,"Change url to access UI from browser Currently, the url for accessing the XD UI is This feels messy and dated. We should be able to access the ui without explicitly including the index.html, like this ",NULL,"Change url to access UI from browser Currently, the url for accessing the XD UI is This feels messy and dated. We should be able to access the ui without explicitly including the index.html, like this ",NULL,"Change url to access UI from browser Currently, the url for accessing the XD UI is This feels messy and dated<span class='highlight-text severity-high'>. We should be able to access the ui without explicitly including the index.html, like this </span>","minimal","punctuation","high",False
26817,"Validate module properties Currently it s possible to do something like http prot 8888 It is possible to validate property names by parsing the module definition file s directly and matching property placeholders or profile declarations that may be mapped to properties, etc . This must account recursively for imports as well. I have some code in a branch that does this . ",NULL,"Validate module properties Currently it s possible to do something like http prot 8888 It is possible to validate property names by parsing the module definition file s directly and matching property placeholders or profile declarations that may be mapped to properties, etc . This must account recursively for imports as well. I have some code in a branch that does this . ",NULL,"Add for who this story is","well_formed","no_role","high",False
26817,"Validate module properties Currently it s possible to do something like http prot 8888 It is possible to validate property names by parsing the module definition file s directly and matching property placeholders or profile declarations that may be mapped to properties, etc . This must account recursively for imports as well. I have some code in a branch that does this . ",NULL,"Validate module properties Currently it s possible to do something like http prot 8888 It is possible to validate property names by parsing the module definition file s directly and matching property placeholders or profile declarations that may be mapped to properties, etc . This must account recursively for imports as well. I have some code in a branch that does this . ",NULL,"Validate module properties Currently it s possible to do something like http prot 8888 It is possible to validate property names by parsing the module definition file s directly<span class='highlight-text severity-high'> and </span>matching property placeholders<span class='highlight-text severity-high'> or </span>profile declarations that may be mapped to properties, etc . This must account recursively for imports as well. I have some code in a branch that does this . ","atomic","conjunctions","high",False
26817,"Validate module properties Currently it s possible to do something like http prot 8888 It is possible to validate property names by parsing the module definition file s directly and matching property placeholders or profile declarations that may be mapped to properties, etc . This must account recursively for imports as well. I have some code in a branch that does this . ",NULL,"Validate module properties Currently it s possible to do something like http prot 8888 It is possible to validate property names by parsing the module definition file s directly and matching property placeholders or profile declarations that may be mapped to properties, etc . This must account recursively for imports as well. I have some code in a branch that does this . ",NULL,"Validate module properties Currently it s possible to do something like http prot 8888 It is possible to validate property names by parsing the module definition file s directly and matching property placeholders or profile declarations that may be mapped to properties, etc <span class='highlight-text severity-high'>. This must account recursively for imports as well. I have some code in a branch that does this . </span>","minimal","punctuation","high",False
26836,"Investigate failing tests in MailCommandTest in spring xd shell project. I get failures relating to invalid username password INFO Stream Name Stream Definition Status mailstream imap port 1044 protocol imap folder INBOX username johndoe password secret file dir tmp suffix txt charset UTF 8 binary false deployed 11 32 11 WARN error occurred in idle task LOGIN failed. Invalid login password at ",NULL,"Investigate failing tests in MailCommandTest in spring xd shell project. I get failures relating to invalid username password INFO Stream Name Stream Definition Status mailstream imap port 1044 protocol imap folder INBOX username johndoe password secret file dir tmp suffix txt charset UTF 8 binary false deployed 11 32 11 WARN error occurred in idle task LOGIN failed. Invalid login password at ",NULL,"Add for who this story is","well_formed","no_role","high",False
26836,"Investigate failing tests in MailCommandTest in spring xd shell project. I get failures relating to invalid username password INFO Stream Name Stream Definition Status mailstream imap port 1044 protocol imap folder INBOX username johndoe password secret file dir tmp suffix txt charset UTF 8 binary false deployed 11 32 11 WARN error occurred in idle task LOGIN failed. Invalid login password at ",NULL,"Investigate failing tests in MailCommandTest in spring xd shell project. I get failures relating to invalid username password INFO Stream Name Stream Definition Status mailstream imap port 1044 protocol imap folder INBOX username johndoe password secret file dir tmp suffix txt charset UTF 8 binary false deployed 11 32 11 WARN error occurred in idle task LOGIN failed. Invalid login password at ",NULL,"Investigate failing tests in MailCommandTest in spring xd shell project<span class='highlight-text severity-high'>. I get failures relating to invalid username password INFO Stream Name Stream Definition Status mailstream imap port 1044 protocol imap folder INBOX username johndoe password secret file dir tmp suffix txt charset UTF 8 binary false deployed 11 32 11 WARN error occurred in idle task LOGIN failed. Invalid login password at </span>","minimal","punctuation","high",False
26837,"provide a property on twittersearch to enable the object to json transformer Twitter search source should produce JSON or Pojo. The Pojo requires a custom wrapper class that is JSON friendly e.g., zero arg constructor . The twittersearch module should have a parameter json true false default true to control the output type.",NULL,"provide a property on twittersearch to enable the object to json transformer Twitter search source should produce JSON or Pojo. The Pojo requires a custom wrapper class that is JSON friendly e.g., zero arg constructor . The twittersearch module should have a parameter json true false default true to control the output type.",NULL,"Add for who this story is","well_formed","no_role","high",False
26837,"provide a property on twittersearch to enable the object to json transformer Twitter search source should produce JSON or Pojo. The Pojo requires a custom wrapper class that is JSON friendly e.g., zero arg constructor . The twittersearch module should have a parameter json true false default true to control the output type.",NULL,"provide a property on twittersearch to enable the object to json transformer Twitter search source should produce JSON or Pojo. The Pojo requires a custom wrapper class that is JSON friendly e.g., zero arg constructor . The twittersearch module should have a parameter json true false default true to control the output type.",NULL,"provide a property on twittersearch to enable the object to json transformer Twitter search source should produce JSON or Pojo<span class='highlight-text severity-high'>. The Pojo requires a custom wrapper class that is JSON friendly e.g., zero arg constructor . The twittersearch module should have a parameter json true false default true to control the output type.</span>","minimal","punctuation","high",False
26838,"rename Bridge to Binding and add direction should now be called Binding we can also move the INBOUND OUTBOUND direction or possibly the CONSUMER PRODUCER role into this class; that should simplify its usage in conditional code within the MessageBus code and also reduce the use of in and out as Strings in that same code",NULL,"rename Bridge to Binding and add direction should now be called Binding we can also move the INBOUND OUTBOUND direction or possibly the CONSUMER PRODUCER role into this class; that should simplify its usage in conditional code within the MessageBus code and also reduce the use of in and out as Strings in that same code",NULL,"Add for who this story is","well_formed","no_role","high",False
26838,"rename Bridge to Binding and add direction should now be called Binding we can also move the INBOUND OUTBOUND direction or possibly the CONSUMER PRODUCER role into this class; that should simplify its usage in conditional code within the MessageBus code and also reduce the use of in and out as Strings in that same code",NULL,"rename Bridge to Binding and add direction should now be called Binding we can also move the INBOUND OUTBOUND direction or possibly the CONSUMER PRODUCER role into this class; that should simplify its usage in conditional code within the MessageBus code and also reduce the use of in and out as Strings in that same code",NULL,"rename Bridge to Binding<span class='highlight-text severity-high'> and </span>add direction should now be called Binding we can also move the INBOUND OUTBOUND direction<span class='highlight-text severity-high'> or </span>possibly the CONSUMER PRODUCER role into this class; that should simplify its usage in conditional code within the MessageBus code and also reduce the use of in and out as Strings in that same code","atomic","conjunctions","high",False
26838,"rename Bridge to Binding and add direction should now be called Binding we can also move the INBOUND OUTBOUND direction or possibly the CONSUMER PRODUCER role into this class; that should simplify its usage in conditional code within the MessageBus code and also reduce the use of in and out as Strings in that same code",NULL,"rename Bridge to Binding and add direction should now be called Binding we can also move the INBOUND OUTBOUND direction or possibly the CONSUMER PRODUCER role into this class; that should simplify its usage in conditional code within the MessageBus code and also reduce the use of in and out as Strings in that same code",NULL,"rename Bridge to Binding and add direction should now be called Binding we can also move the INBOUND OUTBOUND direction or possibly the CONSUMER PRODUCER role into this class<span class='highlight-text severity-high'>; that should simplify its usage in conditional code within the MessageBus code and also reduce the use of in and out as Strings in that same code</span>","minimal","punctuation","high",False
26840,"Documentation for tail hdfs processing Put on the guide as a section in an input stream wiki page. ",NULL,"Documentation for tail hdfs processing Put on the guide as a section in an input stream wiki page. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26839,"Upgrade hsqldb version on XD batch admin to the latest We also would like to upgrade the hsqldb version on spring batch admin so that both are compatible.",NULL,"Upgrade hsqldb version on XD batch admin to the latest We also would like to upgrade the hsqldb version on spring batch admin","so that both are compatible.","Add for who this story is","well_formed","no_role","high",False
26839,"Upgrade hsqldb version on XD batch admin to the latest We also would like to upgrade the hsqldb version on spring batch admin so that both are compatible.",NULL,"Upgrade hsqldb version on XD batch admin to the latest We also would like to upgrade the hsqldb version on spring batch admin","so that both are compatible.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26842,"Update docs for new Tap syntax Now that taps are just channels, we need to update the docs. The preceding colon is no longer needed and will be removed altogether , so all examples should be like this tap foo bar ",NULL,"Update docs for new Tap syntax Now that taps are just channels, we need to update the docs. The preceding colon is no longer needed and will be removed altogether ,","so all examples should be like this tap foo bar","Add for who this story is","well_formed","no_role","high",False
26842,"Update docs for new Tap syntax Now that taps are just channels, we need to update the docs. The preceding colon is no longer needed and will be removed altogether , so all examples should be like this tap foo bar ",NULL,"Update docs for new Tap syntax Now that taps are just channels, we need to update the docs. The preceding colon is no longer needed and will be removed altogether ,","so all examples should be like this tap foo bar","Update docs for new Tap syntax Now that taps are just channels, we need to update the docs. The preceding colon is no longer needed<span class='highlight-text severity-high'> and </span>will be removed altogether , so all examples should be like this tap foo bar ","atomic","conjunctions","high",False
26842,"Update docs for new Tap syntax Now that taps are just channels, we need to update the docs. The preceding colon is no longer needed and will be removed altogether , so all examples should be like this tap foo bar ",NULL,"Update docs for new Tap syntax Now that taps are just channels, we need to update the docs. The preceding colon is no longer needed and will be removed altogether ,","so all examples should be like this tap foo bar","Update docs for new Tap syntax Now that taps are just channels, we need to update the docs<span class='highlight-text severity-high'>. The preceding colon is no longer needed and will be removed altogether , so all examples should be like this tap foo bar </span>","minimal","punctuation","high",False
26842,"Update docs for new Tap syntax Now that taps are just channels, we need to update the docs. The preceding colon is no longer needed and will be removed altogether , so all examples should be like this tap foo bar ",NULL,"Update docs for new Tap syntax Now that taps are just channels, we need to update the docs. The preceding colon is no longer needed and will be removed altogether ,","so all examples should be like this tap foo bar","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26841,"Update docs to cover Module config and lib directory structure ",NULL,"Update docs to cover Module config and lib directory structure ",NULL,"Add for who this story is","well_formed","no_role","high",False
26843,"Handle XD admin server shutdown cleanly There are couple of issues here 1 The admin server destroy close event s listener has stop to stop the admin server s tomcat instance. The stop also calls the destroy which loops again to stop. 2 With HSQLServer or any batch db server in future , the admin server stop also needs to handle the batch db server shutdown.",NULL,"Handle XD admin server shutdown cleanly There are couple of issues here 1 The admin server destroy close event s listener has stop to stop the admin server s tomcat instance. The stop also calls the destroy which loops again to stop. 2 With HSQLServer or any batch db server in future , the admin server stop also needs to handle the batch db server shutdown.",NULL,"Add for who this story is","well_formed","no_role","high",False
26843,"Handle XD admin server shutdown cleanly There are couple of issues here 1 The admin server destroy close event s listener has stop to stop the admin server s tomcat instance. The stop also calls the destroy which loops again to stop. 2 With HSQLServer or any batch db server in future , the admin server stop also needs to handle the batch db server shutdown.",NULL,"Handle XD admin server shutdown cleanly There are couple of issues here 1 The admin server destroy close event s listener has stop to stop the admin server s tomcat instance. The stop also calls the destroy which loops again to stop. 2 With HSQLServer or any batch db server in future , the admin server stop also needs to handle the batch db server shutdown.",NULL,"Handle XD admin server shutdown cleanly There are couple of issues here 1 The admin server destroy close event s listener has stop to stop the admin server s tomcat instance. The stop also calls the destroy which loops again to stop. 2 With HSQLServer<span class='highlight-text severity-high'> or </span>any batch db server in future , the admin server stop also needs to handle the batch db server shutdown.","atomic","conjunctions","high",False
26843,"Handle XD admin server shutdown cleanly There are couple of issues here 1 The admin server destroy close event s listener has stop to stop the admin server s tomcat instance. The stop also calls the destroy which loops again to stop. 2 With HSQLServer or any batch db server in future , the admin server stop also needs to handle the batch db server shutdown.",NULL,"Handle XD admin server shutdown cleanly There are couple of issues here 1 The admin server destroy close event s listener has stop to stop the admin server s tomcat instance. The stop also calls the destroy which loops again to stop. 2 With HSQLServer or any batch db server in future , the admin server stop also needs to handle the batch db server shutdown.",NULL,"Handle XD admin server shutdown cleanly There are couple of issues here 1 The admin server destroy close event s listener has stop to stop the admin server s tomcat instance<span class='highlight-text severity-high'>. The stop also calls the destroy which loops again to stop. 2 With HSQLServer or any batch db server in future , the admin server stop also needs to handle the batch db server shutdown.</span>","minimal","punctuation","high",False
26844,"Tipsy tooltip hovers are not responsive after jobs list is refreshed from server In the XD UI, the list of jobs is refreshed from the server every 5 seconds. There are also tooltips that are activated when hovering over a job execution. These tooltips are no longer responsive ie they remain on the page and don t disappear after the list of jobs is refreshed.",NULL,"Tipsy tooltip hovers are not responsive after jobs list is refreshed from server In the XD UI, the list of jobs is refreshed from the server every 5 seconds. There are also tooltips that are activated when hovering over a job execution. These tooltips are no longer responsive ie they remain on the page and don t disappear after the list of jobs is refreshed.",NULL,"Add for who this story is","well_formed","no_role","high",False
26844,"Tipsy tooltip hovers are not responsive after jobs list is refreshed from server In the XD UI, the list of jobs is refreshed from the server every 5 seconds. There are also tooltips that are activated when hovering over a job execution. These tooltips are no longer responsive ie they remain on the page and don t disappear after the list of jobs is refreshed.",NULL,"Tipsy tooltip hovers are not responsive after jobs list is refreshed from server In the XD UI, the list of jobs is refreshed from the server every 5 seconds. There are also tooltips that are activated when hovering over a job execution. These tooltips are no longer responsive ie they remain on the page and don t disappear after the list of jobs is refreshed.",NULL,"Tipsy tooltip hovers are not responsive after jobs list is refreshed from server In the XD UI, the list of jobs is refreshed from the server every 5 seconds. There are also tooltips that are activated when hovering over a job execution. These tooltips are no longer responsive ie they remain on the page<span class='highlight-text severity-high'> and </span>don t disappear after the list of jobs is refreshed.","atomic","conjunctions","high",False
26844,"Tipsy tooltip hovers are not responsive after jobs list is refreshed from server In the XD UI, the list of jobs is refreshed from the server every 5 seconds. There are also tooltips that are activated when hovering over a job execution. These tooltips are no longer responsive ie they remain on the page and don t disappear after the list of jobs is refreshed.",NULL,"Tipsy tooltip hovers are not responsive after jobs list is refreshed from server In the XD UI, the list of jobs is refreshed from the server every 5 seconds. There are also tooltips that are activated when hovering over a job execution. These tooltips are no longer responsive ie they remain on the page and don t disappear after the list of jobs is refreshed.",NULL,"Tipsy tooltip hovers are not responsive after jobs list is refreshed from server In the XD UI, the list of jobs is refreshed from the server every 5 seconds<span class='highlight-text severity-high'>. There are also tooltips that are activated when hovering over a job execution. These tooltips are no longer responsive ie they remain on the page and don t disappear after the list of jobs is refreshed.</span>","minimal","punctuation","high",False
26847,"Documentation for http gemfire processing Put on the guide as a section in an input stream wiki page. ",NULL,"Documentation for http gemfire processing Put on the guide as a section in an input stream wiki page. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26845,"Refactor out Trigger docs from the Batch Job chapter ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26845,"Refactor out Trigger docs from the Batch Job chapter ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26848,"Add back classifier dist to distZip build target Add back classifier dist to distZip build target it was was accidentally removed.",NULL,"Add back classifier dist to distZip build target Add back classifier dist to distZip build target it was was accidentally removed.",NULL,"Add for who this story is","well_formed","no_role","high",False
26881,"Fix package tangle between and ",NULL,"Fix package tangle between and ",NULL,"Add for who this story is","well_formed","no_role","high",False
26882,"Remove org. in hsqldb dependency ",NULL,"Remove org. in hsqldb dependency ",NULL,"Add for who this story is","well_formed","no_role","high",False
26882,"Remove org. in hsqldb dependency ",NULL,"Remove org. in hsqldb dependency ",NULL,"Remove org<span class='highlight-text severity-high'>. in hsqldb dependency </span>","minimal","punctuation","high",False
26835,"Create object to json transformer processor int channel id input int channel id output ",NULL,"Create object to json transformer processor int channel id input int channel id output ",NULL,"Add for who this story is","well_formed","no_role","high",False
26833,"add discardDeletes property to twitterstream source If true default filter for delete messages in the twitter stream and route to a discard channel. This creates a twitter stream including only new tweets and no references to deleted ones.",NULL,"add discardDeletes property to twitterstream source If true default filter for delete messages in the twitter stream and route to a discard channel. This creates a twitter stream including only new tweets and no references to deleted ones.",NULL,"Add for who this story is","well_formed","no_role","high",False
26833,"add discardDeletes property to twitterstream source If true default filter for delete messages in the twitter stream and route to a discard channel. This creates a twitter stream including only new tweets and no references to deleted ones.",NULL,"add discardDeletes property to twitterstream source If true default filter for delete messages in the twitter stream and route to a discard channel. This creates a twitter stream including only new tweets and no references to deleted ones.",NULL,"add discardDeletes property to twitterstream source If true default filter for delete messages in the twitter stream<span class='highlight-text severity-high'> and </span>route to a discard channel. This creates a twitter stream including only new tweets and no references to deleted ones.","atomic","conjunctions","high",False
26833,"add discardDeletes property to twitterstream source If true default filter for delete messages in the twitter stream and route to a discard channel. This creates a twitter stream including only new tweets and no references to deleted ones.",NULL,"add discardDeletes property to twitterstream source If true default filter for delete messages in the twitter stream and route to a discard channel. This creates a twitter stream including only new tweets and no references to deleted ones.",NULL,"add discardDeletes property to twitterstream source If true default filter for delete messages in the twitter stream and route to a discard channel<span class='highlight-text severity-high'>. This creates a twitter stream including only new tweets and no references to deleted ones.</span>","minimal","punctuation","high",False
26846,"Close parent contexts when shutting down ",NULL,"Close parent contexts when shutting down ",NULL,"Add for who this story is","well_formed","no_role","high",False
26852,"Revise the available hadoopDistro options We should adjust our hadoopDistro options to the ones supported in the new spring data hadoop 1.0.1.RELEASE hadoop12 default , cdh4, hdp13, phd1, hadoop20 This includes updating the wiki pages",NULL,"Revise the available hadoopDistro options We should adjust our hadoopDistro options to the ones supported in the new spring data hadoop 1.0.1.RELEASE hadoop12 default , cdh4, hdp13, phd1, hadoop20 This includes updating the wiki pages",NULL,"Add for who this story is","well_formed","no_role","high",False
26851,"Remove deprecated tap syntax from the parser. Tap and using numbers instead of module names.",NULL,"Remove deprecated tap syntax from the parser. Tap and using numbers instead of module names.",NULL,"Add for who this story is","well_formed","no_role","high",False
26851,"Remove deprecated tap syntax from the parser. Tap and using numbers instead of module names.",NULL,"Remove deprecated tap syntax from the parser. Tap and using numbers instead of module names.",NULL,"Remove deprecated tap syntax from the parser. Tap<span class='highlight-text severity-high'> and </span>using numbers instead of module names.","atomic","conjunctions","high",False
26851,"Remove deprecated tap syntax from the parser. Tap and using numbers instead of module names.",NULL,"Remove deprecated tap syntax from the parser. Tap and using numbers instead of module names.",NULL,"Remove deprecated tap syntax from the parser<span class='highlight-text severity-high'>. Tap and using numbers instead of module names.</span>","minimal","punctuation","high",False
26854,"JAR version mismatches Looks like there are some version mismatch issues with the build packaging of the XD components. Looking in xd lib I see the following which looks suspicious ",NULL,"JAR version mismatches Looks like there are some version mismatch issues with the build packaging of the XD components. Looking in xd lib I see the following which looks suspicious ",NULL,"Add for who this story is","well_formed","no_role","high",False
26854,"JAR version mismatches Looks like there are some version mismatch issues with the build packaging of the XD components. Looking in xd lib I see the following which looks suspicious ",NULL,"JAR version mismatches Looks like there are some version mismatch issues with the build packaging of the XD components. Looking in xd lib I see the following which looks suspicious ",NULL,"JAR version mismatches Looks like there are some version mismatch issues with the build packaging of the XD components<span class='highlight-text severity-high'>. Looking in xd lib I see the following which looks suspicious </span>","minimal","punctuation","high",False
26853,"Documentation for gemfirecq file processing Put on the guide as a section in an input stream wiki page. ",NULL,"Documentation for gemfirecq file processing Put on the guide as a section in an input stream wiki page. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26856,"Add definition of serialVersionUID to Twitter classes Add serialVersionUID to the objects in package XDEntities XDUrlEntity XDHashTagEntity XDMentionEntity XDMediaEntity XDTweet The absence creates warnings during compile time.",NULL,"Add definition of serialVersionUID to Twitter classes Add serialVersionUID to the objects in package XDEntities XDUrlEntity XDHashTagEntity XDMentionEntity XDMediaEntity XDTweet The absence creates warnings during compile time.",NULL,"Add for who this story is","well_formed","no_role","high",False
26855,"DSL needs to have wildcard support for taps Wildcard support for associating inbound and outbound channels with modules. The wild card will be represented by an asterisk . Example myEmailSource tap job send message to all jobs myEmailSource tap send message to all stream job taps myEmailSource foo send message to all channels that contain the channels that contains the word foo tap bar myEmailSource ",NULL,"DSL needs to have wildcard support for taps Wildcard support for associating inbound and outbound channels with modules. The wild card will be represented by an asterisk . Example myEmailSource tap job send message to all jobs myEmailSource tap send message to all stream job taps myEmailSource foo send message to all channels that contain the channels that contains the word foo tap bar myEmailSource ",NULL,"Add for who this story is","well_formed","no_role","high",False
26855,"DSL needs to have wildcard support for taps Wildcard support for associating inbound and outbound channels with modules. The wild card will be represented by an asterisk . Example myEmailSource tap job send message to all jobs myEmailSource tap send message to all stream job taps myEmailSource foo send message to all channels that contain the channels that contains the word foo tap bar myEmailSource ",NULL,"DSL needs to have wildcard support for taps Wildcard support for associating inbound and outbound channels with modules. The wild card will be represented by an asterisk . Example myEmailSource tap job send message to all jobs myEmailSource tap send message to all stream job taps myEmailSource foo send message to all channels that contain the channels that contains the word foo tap bar myEmailSource ",NULL,"DSL needs to have wildcard support for taps Wildcard support for associating inbound and outbound channels with modules<span class='highlight-text severity-high'>. The wild card will be represented by an asterisk . Example myEmailSource tap job send message to all jobs myEmailSource tap send message to all stream job taps myEmailSource foo send message to all channels that contain the channels that contains the word foo tap bar myEmailSource </span>","minimal","punctuation","high",False
26858,"Change metrics assertions in integration tests to use smart Thread.sleep Similar to what has been done for e.g. FileSink, refactor metrics related sinks to use smart Thread.sleep timings",NULL,"Change metrics assertions in integration tests to use smart Thread.sleep Similar to what has been done for e.g. FileSink, refactor metrics related sinks to use smart Thread.sleep timings",NULL,"Add for who this story is","well_formed","no_role","high",False
26858,"Change metrics assertions in integration tests to use smart Thread.sleep Similar to what has been done for e.g. FileSink, refactor metrics related sinks to use smart Thread.sleep timings",NULL,"Change metrics assertions in integration tests to use smart Thread.sleep Similar to what has been done for e.g. FileSink, refactor metrics related sinks to use smart Thread.sleep timings",NULL,"Change metrics assertions in integration tests to use smart Thread<span class='highlight-text severity-high'>.sleep Similar to what has been done for e.g. FileSink, refactor metrics related sinks to use smart Thread.sleep timings</span>","minimal","punctuation","high",False
26857,"Update doc about modules and spring The doc at refers to an old version of the counter sink, when it was still hardwired to use redis. The text next to it that explains placeholders is out of date with respect to the redis placeholders ",NULL,"Update doc about modules and spring The doc at refers to an old version of the counter sink, when it was still hardwired to use redis. The text next to it that explains placeholders is out of date with respect to the redis placeholders ",NULL,"Add for who this story is","well_formed","no_role","high",False
26857,"Update doc about modules and spring The doc at refers to an old version of the counter sink, when it was still hardwired to use redis. The text next to it that explains placeholders is out of date with respect to the redis placeholders ",NULL,"Update doc about modules and spring The doc at refers to an old version of the counter sink, when it was still hardwired to use redis. The text next to it that explains placeholders is out of date with respect to the redis placeholders ",NULL,"Update doc about modules and spring The doc at refers to an old version of the counter sink, when it was still hardwired to use redis<span class='highlight-text severity-high'>. The text next to it that explains placeholders is out of date with respect to the redis placeholders </span>","minimal","punctuation","high",False
26860,"Upgrade to Spring Data Redis 1.1.0.RELEASE ",NULL,"Upgrade to Spring Data Redis 1.1.0.RELEASE ",NULL,"Add for who this story is","well_formed","no_role","high",False
26859,"Refactor FileModuleRegistry as Apart from sanity checks, there is not much that ties FileModuleRegistry to actual java.io.Files. Using the Resource abstraction would work just the same, and would allow loading modules from the classpath in constrained environments or other file systems locations. HDFS HTTP ",NULL,"Refactor FileModuleRegistry as Apart from sanity checks, there is not much that ties FileModuleRegistry to actual java.io.Files. Using the Resource abstraction would work just the same, and would allow loading modules from the classpath in constrained environments or other file systems locations. HDFS HTTP ",NULL,"Add for who this story is","well_formed","no_role","high",False
26859,"Refactor FileModuleRegistry as Apart from sanity checks, there is not much that ties FileModuleRegistry to actual java.io.Files. Using the Resource abstraction would work just the same, and would allow loading modules from the classpath in constrained environments or other file systems locations. HDFS HTTP ",NULL,"Refactor FileModuleRegistry as Apart from sanity checks, there is not much that ties FileModuleRegistry to actual java.io.Files. Using the Resource abstraction would work just the same, and would allow loading modules from the classpath in constrained environments or other file systems locations. HDFS HTTP ",NULL,"Refactor FileModuleRegistry as Apart from sanity checks, there is not much that ties FileModuleRegistry to actual java.io.Files. Using the Resource abstraction would work just the same,<span class='highlight-text severity-high'> and </span>would allow loading modules from the classpath in constrained environments<span class='highlight-text severity-high'> or </span>other file systems locations. HDFS HTTP ","atomic","conjunctions","high",False
26859,"Refactor FileModuleRegistry as Apart from sanity checks, there is not much that ties FileModuleRegistry to actual java.io.Files. Using the Resource abstraction would work just the same, and would allow loading modules from the classpath in constrained environments or other file systems locations. HDFS HTTP ",NULL,"Refactor FileModuleRegistry as Apart from sanity checks, there is not much that ties FileModuleRegistry to actual java.io.Files. Using the Resource abstraction would work just the same, and would allow loading modules from the classpath in constrained environments or other file systems locations. HDFS HTTP ",NULL,"Refactor FileModuleRegistry as Apart from sanity checks, there is not much that ties FileModuleRegistry to actual java<span class='highlight-text severity-high'>.io.Files. Using the Resource abstraction would work just the same, and would allow loading modules from the classpath in constrained environments or other file systems locations. HDFS HTTP </span>","minimal","punctuation","high",False
26862,"Documentation for twittersearch file processing Put on the guide as a section in an input stream wiki page. ",NULL,"Documentation for twittersearch file processing Put on the guide as a section in an input stream wiki page. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26861,"Support for listing of modules in the REST API From the CLI, one should be able to get a listing of modules and be able to specifically ask for jobs, sources, sinks, and processors. A brief description of them would also be nice this might come from adding some metadata into the definition. Finer grained suggestion TBD",NULL,"Support for listing of modules in the REST API From the CLI, one should be able to get a listing of modules and be able to specifically ask for jobs, sources, sinks, and processors. A brief description of them would also be nice this might come from adding some metadata into the definition. Finer grained suggestion TBD",NULL,"Add for who this story is","well_formed","no_role","high",False
26861,"Support for listing of modules in the REST API From the CLI, one should be able to get a listing of modules and be able to specifically ask for jobs, sources, sinks, and processors. A brief description of them would also be nice this might come from adding some metadata into the definition. Finer grained suggestion TBD",NULL,"Support for listing of modules in the REST API From the CLI, one should be able to get a listing of modules and be able to specifically ask for jobs, sources, sinks, and processors. A brief description of them would also be nice this might come from adding some metadata into the definition. Finer grained suggestion TBD",NULL,"Support for listing of modules in the REST API From the CLI, one should be able to get a listing of modules<span class='highlight-text severity-high'> and </span>be able to specifically ask for jobs, sources, sinks, and processors. A brief description of them would also be nice this might come from adding some metadata into the definition. Finer grained suggestion TBD","atomic","conjunctions","high",False
26861,"Support for listing of modules in the REST API From the CLI, one should be able to get a listing of modules and be able to specifically ask for jobs, sources, sinks, and processors. A brief description of them would also be nice this might come from adding some metadata into the definition. Finer grained suggestion TBD",NULL,"Support for listing of modules in the REST API From the CLI, one should be able to get a listing of modules and be able to specifically ask for jobs, sources, sinks, and processors. A brief description of them would also be nice this might come from adding some metadata into the definition. Finer grained suggestion TBD",NULL,"Support for listing of modules in the REST API From the CLI, one should be able to get a listing of modules and be able to specifically ask for jobs, sources, sinks, and processors<span class='highlight-text severity-high'>. A brief description of them would also be nice this might come from adding some metadata into the definition. Finer grained suggestion TBD</span>","minimal","punctuation","high",False
26883,"Change default admin port from 8080 This conflicts with and out of the box hadoop installation that uses 8080 as the map reduce shuffle port . 8088 sound ok? ",NULL,"Change default admin port from 8080 This conflicts with and out of the box hadoop installation that uses 8080 as the map reduce shuffle port . 8088 sound ok? ",NULL,"Add for who this story is","well_formed","no_role","high",False
26883,"Change default admin port from 8080 This conflicts with and out of the box hadoop installation that uses 8080 as the map reduce shuffle port . 8088 sound ok? ",NULL,"Change default admin port from 8080 This conflicts with and out of the box hadoop installation that uses 8080 as the map reduce shuffle port . 8088 sound ok? ",NULL,"Change default admin port from 8080 This conflicts with and out of the box hadoop installation that uses 8080 as the map reduce shuffle port <span class='highlight-text severity-high'>. 8088 sound ok? </span>","minimal","punctuation","high",False
26884,"Documentation for gauge taps Documentation for gauge taps Put on the guide as a section in an input stream wiki page. Put on the guide as a section in an input stream wiki page. ",NULL,"Documentation for gauge taps Documentation for gauge taps Put on the guide as a section in an input stream wiki page. Put on the guide as a section in an input stream wiki page. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26884,"Documentation for gauge taps Documentation for gauge taps Put on the guide as a section in an input stream wiki page. Put on the guide as a section in an input stream wiki page. ",NULL,"Documentation for gauge taps Documentation for gauge taps Put on the guide as a section in an input stream wiki page. Put on the guide as a section in an input stream wiki page. ",NULL,"Documentation for gauge taps Documentation for gauge taps Put on the guide as a section in an input stream wiki page<span class='highlight-text severity-high'>. Put on the guide as a section in an input stream wiki page. </span>","minimal","punctuation","high",False
26849,"Initial XD on CloudFoundry support First take on this involves being able to deploy the two separate applications xd admin xd container being able to CF service provided redis rabbit for internal needs of XD to some extent, make modules smart and CF aware e.g. http source uses correct port ",NULL,"Initial XD on CloudFoundry support First take on this involves being able to deploy the two separate applications xd admin xd container being able to CF service provided redis rabbit for internal needs of XD to some extent, make modules smart and CF aware e.g. http source uses correct port ",NULL,"Add for who this story is","well_formed","no_role","high",False
26908,"Make the parser aware of message conversion configuration Enhance the stream parser to take message conversion into account in order to validate or automatically configure converters. For example ",NULL,"Make the parser aware of message conversion configuration Enhance the stream parser to take message conversion into account","in order to validate or automatically configure converters. For example","Make the parser aware of message conversion configuration Enhance the stream parser to take message conversion into account in order to validate or automatically configure converters<span class='highlight-text severity-high'>. For example </span>","minimal","punctuation","high",False
26849,"Initial XD on CloudFoundry support First take on this involves being able to deploy the two separate applications xd admin xd container being able to CF service provided redis rabbit for internal needs of XD to some extent, make modules smart and CF aware e.g. http source uses correct port ",NULL,"Initial XD on CloudFoundry support First take on this involves being able to deploy the two separate applications xd admin xd container being able to CF service provided redis rabbit for internal needs of XD to some extent, make modules smart and CF aware e.g. http source uses correct port ",NULL,"Initial XD on CloudFoundry support First take on this involves being able to deploy the two separate applications xd admin xd container being able to CF service provided redis rabbit for internal needs of XD to some extent, make modules smart<span class='highlight-text severity-high'> and </span>CF aware e.g. http source uses correct port ","atomic","conjunctions","high",False
26849,"Initial XD on CloudFoundry support First take on this involves being able to deploy the two separate applications xd admin xd container being able to CF service provided redis rabbit for internal needs of XD to some extent, make modules smart and CF aware e.g. http source uses correct port ",NULL,"Initial XD on CloudFoundry support First take on this involves being able to deploy the two separate applications xd admin xd container being able to CF service provided redis rabbit for internal needs of XD to some extent, make modules smart and CF aware e.g. http source uses correct port ",NULL,"Initial XD on CloudFoundry support First take on this involves being able to deploy the two separate applications xd admin xd container being able to CF service provided redis rabbit for internal needs of XD to some extent, make modules smart and CF aware e<span class='highlight-text severity-high'>.g. http source uses correct port </span>","minimal","punctuation","high",False
26867,"Remove remaining Thread.sleeps from the job tests Get rid of all the thread.sleeps and code that supported them.",NULL,"Remove remaining Thread.sleeps from the job tests Get rid of all the thread.sleeps and code that supported them.",NULL,"Add for who this story is","well_formed","no_role","high",False
26867,"Remove remaining Thread.sleeps from the job tests Get rid of all the thread.sleeps and code that supported them.",NULL,"Remove remaining Thread.sleeps from the job tests Get rid of all the thread.sleeps and code that supported them.",NULL,"Remove remaining Thread.sleeps from the job tests Get rid of all the thread.sleeps<span class='highlight-text severity-high'> and </span>code that supported them.","atomic","conjunctions","high",False
26865,"Move to from We need to move the method to as that seems appropriate",NULL,"Move to from We need to move the method to as that seems appropriate",NULL,"Add for who this story is","well_formed","no_role","high",False
26873,"Cleanup hsqldb data directory used by tests after each test completion Currently, the data directory created by the HSQLDB process during the tests run is not cleaned up and may cause issues. We should delete the data directory after each test completion.",NULL,"Cleanup hsqldb data directory used by tests after each test completion Currently, the data directory created by the HSQLDB process during the tests run is not cleaned up and may cause issues. We should delete the data directory after each test completion.",NULL,"Add for who this story is","well_formed","no_role","high",False
26873,"Cleanup hsqldb data directory used by tests after each test completion Currently, the data directory created by the HSQLDB process during the tests run is not cleaned up and may cause issues. We should delete the data directory after each test completion.",NULL,"Cleanup hsqldb data directory used by tests after each test completion Currently, the data directory created by the HSQLDB process during the tests run is not cleaned up and may cause issues. We should delete the data directory after each test completion.",NULL,"Cleanup hsqldb data directory used by tests after each test completion Currently, the data directory created by the HSQLDB process during the tests run is not cleaned up<span class='highlight-text severity-high'> and </span>may cause issues. We should delete the data directory after each test completion.","atomic","conjunctions","high",False
26873,"Cleanup hsqldb data directory used by tests after each test completion Currently, the data directory created by the HSQLDB process during the tests run is not cleaned up and may cause issues. We should delete the data directory after each test completion.",NULL,"Cleanup hsqldb data directory used by tests after each test completion Currently, the data directory created by the HSQLDB process during the tests run is not cleaned up and may cause issues. We should delete the data directory after each test completion.",NULL,"Cleanup hsqldb data directory used by tests after each test completion Currently, the data directory created by the HSQLDB process during the tests run is not cleaned up and may cause issues<span class='highlight-text severity-high'>. We should delete the data directory after each test completion.</span>","minimal","punctuation","high",False
26866,"Add a test suite to the admin ui The admin ui currently has no unit tests. Need to add a test suite and hook it up to the build so that tests are run on every build.",NULL,"Add a test suite to the admin ui The admin ui currently has no unit tests. Need to add a test suite and hook it up to the build","so that tests are run on every build.","Add for who this story is","well_formed","no_role","high",False
26866,"Add a test suite to the admin ui The admin ui currently has no unit tests. Need to add a test suite and hook it up to the build so that tests are run on every build.",NULL,"Add a test suite to the admin ui The admin ui currently has no unit tests. Need to add a test suite and hook it up to the build","so that tests are run on every build.","Add a test suite to the admin ui The admin ui currently has no unit tests. Need to add a test suite<span class='highlight-text severity-high'> and </span>hook it up to the build so that tests are run on every build.","atomic","conjunctions","high",False
26866,"Add a test suite to the admin ui The admin ui currently has no unit tests. Need to add a test suite and hook it up to the build so that tests are run on every build.",NULL,"Add a test suite to the admin ui The admin ui currently has no unit tests. Need to add a test suite and hook it up to the build","so that tests are run on every build.","Add a test suite to the admin ui The admin ui currently has no unit tests<span class='highlight-text severity-high'>. Need to add a test suite and hook it up to the build so that tests are run on every build.</span>","minimal","punctuation","high",False
26866,"Add a test suite to the admin ui The admin ui currently has no unit tests. Need to add a test suite and hook it up to the build so that tests are run on every build.",NULL,"Add a test suite to the admin ui The admin ui currently has no unit tests. Need to add a test suite and hook it up to the build","so that tests are run on every build.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26869,"Colocate Modules using labels. i.e. http group1 filter group1 transform file then specifying anything labelled group1 goes to machineX",NULL,"Colocate Modules using labels. i.e. http group1 filter group1 transform file then specifying anything labelled group1 goes to machineX",NULL,"Add for who this story is","well_formed","no_role","high",False
26869,"Colocate Modules using labels. i.e. http group1 filter group1 transform file then specifying anything labelled group1 goes to machineX",NULL,"Colocate Modules using labels. i.e. http group1 filter group1 transform file then specifying anything labelled group1 goes to machineX",NULL,"Colocate Modules using labels<span class='highlight-text severity-high'>. i.e. http group1 filter group1 transform file then specifying anything labelled group1 goes to machineX</span>","minimal","punctuation","high",False
26868,"Support the ability for a user to create composite modules that can accept parameters Parser creates a module compose command that allows a user to create a module of other modules. This composed module can accept parameters.",NULL,"Support the ability for a user to create composite modules that can accept parameters Parser creates a module compose command that allows a user to create a module of other modules. This composed module can accept parameters.",NULL,"Add for who this story is","well_formed","no_role","high",False
26868,"Support the ability for a user to create composite modules that can accept parameters Parser creates a module compose command that allows a user to create a module of other modules. This composed module can accept parameters.",NULL,"Support the ability for a user to create composite modules that can accept parameters Parser creates a module compose command that allows a user to create a module of other modules. This composed module can accept parameters.",NULL,"Support the ability for a user to create composite modules that can accept parameters Parser creates a module compose command that allows a user to create a module of other modules<span class='highlight-text severity-high'>. This composed module can accept parameters.</span>","minimal","punctuation","high",False
26871,"Support for listing of modules in the Shell Commands that pair up with the functionality described in XD 859 module list would list all modules in a table format module list type source would list only source modules and so on.",NULL,"Support for listing of modules in the Shell Commands that pair up with the functionality described in XD 859 module list would list all modules in a table format module list type","source would list only source modules and so on.","Add for who this story is","well_formed","no_role","high",False
26871,"Support for listing of modules in the Shell Commands that pair up with the functionality described in XD 859 module list would list all modules in a table format module list type source would list only source modules and so on.",NULL,"Support for listing of modules in the Shell Commands that pair up with the functionality described in XD 859 module list would list all modules in a table format module list type","source would list only source modules and so on.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26870,"Documentation that introduces taps Documentation that introduces taps Put on the guide as a section in an input stream wiki page. Put on the guide as a section in an input stream wiki page. ",NULL,"Documentation that introduces taps Documentation that introduces taps Put on the guide as a section in an input stream wiki page. Put on the guide as a section in an input stream wiki page. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26870,"Documentation that introduces taps Documentation that introduces taps Put on the guide as a section in an input stream wiki page. Put on the guide as a section in an input stream wiki page. ",NULL,"Documentation that introduces taps Documentation that introduces taps Put on the guide as a section in an input stream wiki page. Put on the guide as a section in an input stream wiki page. ",NULL,"Documentation that introduces taps Documentation that introduces taps Put on the guide as a section in an input stream wiki page<span class='highlight-text severity-high'>. Put on the guide as a section in an input stream wiki page. </span>","minimal","punctuation","high",False
26874,"Documentation for counter taps Put on the guide as a section in an input stream wiki page. ",NULL,"Documentation for counter taps Put on the guide as a section in an input stream wiki page. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26872,"Handle AdminServer shutdown cleanly The admin Server s tomcat is not shutdown properly. There is an existing method shutdownCleanly on AdminServer but the spring xd shell tests hang when we use this method to shutdown the admin server. ",NULL,"Handle AdminServer shutdown cleanly The admin Server s tomcat is not shutdown properly. There is an existing method shutdownCleanly on AdminServer but the spring xd shell tests hang when we use this method to shutdown the admin server. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26872,"Handle AdminServer shutdown cleanly The admin Server s tomcat is not shutdown properly. There is an existing method shutdownCleanly on AdminServer but the spring xd shell tests hang when we use this method to shutdown the admin server. ",NULL,"Handle AdminServer shutdown cleanly The admin Server s tomcat is not shutdown properly. There is an existing method shutdownCleanly on AdminServer but the spring xd shell tests hang when we use this method to shutdown the admin server. ",NULL,"Handle AdminServer shutdown cleanly The admin Server s tomcat is not shutdown properly<span class='highlight-text severity-high'>. There is an existing method shutdownCleanly on AdminServer but the spring xd shell tests hang when we use this method to shutdown the admin server. </span>","minimal","punctuation","high",False
26875,"Update Java Version to 7 ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26875,"Update Java Version to 7 ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26876,"Introduce wire.js into the XD admin UI We should consider moving to wire.js to encourage dependency injection in the UI Javascript code. See here ",NULL,"Introduce wire.js into the XD admin UI We should consider moving to wire.js to encourage dependency injection in the UI Javascript code. See here ",NULL,"Add for who this story is","well_formed","no_role","high",False
26876,"Introduce wire.js into the XD admin UI We should consider moving to wire.js to encourage dependency injection in the UI Javascript code. See here ",NULL,"Introduce wire.js into the XD admin UI We should consider moving to wire.js to encourage dependency injection in the UI Javascript code. See here ",NULL,"Introduce wire<span class='highlight-text severity-high'>.js into the XD admin UI We should consider moving to wire.js to encourage dependency injection in the UI Javascript code. See here </span>","minimal","punctuation","high",False
26877,"Disable the JMX setting in Set the enableJmx to false because contexts are not getting destroyed properly, and in some cases prevents from running successfully.",NULL,"Disable the JMX setting in Set the enableJmx to false because contexts are not getting destroyed properly, and in some cases prevents from running successfully.",NULL,"Add for who this story is","well_formed","no_role","high",False
26877,"Disable the JMX setting in Set the enableJmx to false because contexts are not getting destroyed properly, and in some cases prevents from running successfully.",NULL,"Disable the JMX setting in Set the enableJmx to false because contexts are not getting destroyed properly, and in some cases prevents from running successfully.",NULL,"Disable the JMX setting in Set the enableJmx to false because contexts are not getting destroyed properly,<span class='highlight-text severity-high'> and </span>in some cases prevents from running successfully.","atomic","conjunctions","high",False
26880,"Add Batch Job Listeners Automatically Add Batch Job Listeners Automatically Each major listener category should send notifications to own channel StepExecution, Chunk, Item etc. Add attribute to disallow automatic adding of listeners",NULL,"Add Batch Job Listeners Automatically Add Batch Job Listeners Automatically Each major listener category should send notifications to own channel StepExecution, Chunk, Item etc. Add attribute to disallow automatic adding of listeners",NULL,"Add for who this story is","well_formed","no_role","high",False
26880,"Add Batch Job Listeners Automatically Add Batch Job Listeners Automatically Each major listener category should send notifications to own channel StepExecution, Chunk, Item etc. Add attribute to disallow automatic adding of listeners",NULL,"Add Batch Job Listeners Automatically Add Batch Job Listeners Automatically Each major listener category should send notifications to own channel StepExecution, Chunk, Item etc. Add attribute to disallow automatic adding of listeners",NULL,"Add Batch Job Listeners Automatically Add Batch Job Listeners Automatically Each major listener category should send notifications to own channel StepExecution, Chunk, Item etc<span class='highlight-text severity-high'>. Add attribute to disallow automatic adding of listeners</span>","minimal","punctuation","high",False
26879,"Do not initialize spring batch schema on each test run If the spring batch database has already been initialized do not re initialize for each test run. ",NULL,"Do not initialize spring batch schema on each test run If the spring batch database has already been initialized do not re initialize for each test run. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26864,"Serialization of Spring Batch Context Objects Needs some investigation on how the update information from Spring Batch listeners can be sent as a message across modules in a single node configuration as well as across JVMs in a distributed node configuration.",NULL,"Serialization of Spring Batch Context Objects Needs some investigation on how the update information from Spring Batch listeners can be sent as a message across modules in a single node configuration as well as across JVMs in a distributed node configuration.",NULL,"Add for who this story is","well_formed","no_role","high",False
26878,"Refactor the tests so that contexts are destroyed properly In our tests the context is destroyed at the end of each module. It should be destroyed at the close of the container.",NULL,NULL,"so that contexts are destroyed properly In our tests the context is destroyed at the end of each module. It should be destroyed at the close of the container.","Add what you want to achieve","well_formed","no_means","high",False
26878,"Refactor the tests so that contexts are destroyed properly In our tests the context is destroyed at the end of each module. It should be destroyed at the close of the container.",NULL,NULL,"so that contexts are destroyed properly In our tests the context is destroyed at the end of each module. It should be destroyed at the close of the container.","Add for who this story is","well_formed","no_role","high",False
26878,"Refactor the tests so that contexts are destroyed properly In our tests the context is destroyed at the end of each module. It should be destroyed at the close of the container.",NULL,NULL,"so that contexts are destroyed properly In our tests the context is destroyed at the end of each module. It should be destroyed at the close of the container.","Refactor the tests so that contexts are destroyed properly In our tests the context is destroyed at the end of each module<span class='highlight-text severity-high'>. It should be destroyed at the close of the container.</span>","minimal","punctuation","high",False
26878,"Refactor the tests so that contexts are destroyed properly In our tests the context is destroyed at the end of each module. It should be destroyed at the close of the container.",NULL,NULL,"so that contexts are destroyed properly In our tests the context is destroyed at the end of each module. It should be destroyed at the close of the container.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26885,"Run JavaScript tests Jasmine as part of the build process We probably need to look into some options to run our JavaScript tests Jasmine as part of the build process some possibilities Jasmine Gradle Plugin Saga Looks like Maven has slightly better support See also XD 865",NULL,"Run JavaScript tests Jasmine as part of the build process We probably need to look into some options to run our JavaScript tests Jasmine as part of the build process some possibilities Jasmine Gradle Plugin Saga Looks like Maven has slightly better support See also XD 865",NULL,"Add for who this story is","well_formed","no_role","high",False
26888,"Create Integration Tests for Batch Notifications ",NULL,"Create Integration Tests for Batch Notifications ",NULL,"Add for who this story is","well_formed","no_role","high",False
26887,"Add inputType and outputType module parameters The ability to configure message conversion via parameters. Consider programatic configuration of data type channels. Values can be media type, e.g., application json or a java class name.",NULL,"Add inputType and outputType module parameters The ability to configure message conversion via parameters. Consider programatic configuration of data type channels. Values can be media type, e.g., application json or a java class name.",NULL,"Add for who this story is","well_formed","no_role","high",False
26908,"Make the parser aware of message conversion configuration Enhance the stream parser to take message conversion into account in order to validate or automatically configure converters. For example ",NULL,"Make the parser aware of message conversion configuration Enhance the stream parser to take message conversion into account","in order to validate or automatically configure converters. For example","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26911,"Add more hands on example to MQTT doco Not everyone may be familiar with MQTT, or esp. with MQTT inside Rabbit",NULL,"Add more hands on example to MQTT doco Not everyone may be familiar with MQTT, or esp. with MQTT inside Rabbit",NULL,"Add for who this story is","well_formed","no_role","high",False
26887,"Add inputType and outputType module parameters The ability to configure message conversion via parameters. Consider programatic configuration of data type channels. Values can be media type, e.g., application json or a java class name.",NULL,"Add inputType and outputType module parameters The ability to configure message conversion via parameters. Consider programatic configuration of data type channels. Values can be media type, e.g., application json or a java class name.",NULL,"Add inputType<span class='highlight-text severity-high'> and </span>outputType module parameters The ability to configure message conversion via parameters. Consider programatic configuration of data type channels. Values can be media type, e.g., application json<span class='highlight-text severity-high'> or </span>a java class name.","atomic","conjunctions","high",False
26887,"Add inputType and outputType module parameters The ability to configure message conversion via parameters. Consider programatic configuration of data type channels. Values can be media type, e.g., application json or a java class name.",NULL,"Add inputType and outputType module parameters The ability to configure message conversion via parameters. Consider programatic configuration of data type channels. Values can be media type, e.g., application json or a java class name.",NULL,"Add inputType and outputType module parameters The ability to configure message conversion via parameters<span class='highlight-text severity-high'>. Consider programatic configuration of data type channels. Values can be media type, e.g., application json or a java class name.</span>","minimal","punctuation","high",False
26894,"Split xd dirt in 3 or 5 The xd dirt project should be split in at least 3 parts Classes and resources pertaining to the admin server Container server Shared classes Additionally, we may consider splitting the first two in half as well, having a separate project for CLI handling and hence introduce 2 other projects for YARN, etc ",NULL,"Split xd dirt in 3 or 5 The xd dirt project should be split in at least 3 parts Classes and resources pertaining to the admin server Container server Shared classes Additionally, we may consider splitting the first two in half as well, having a separate project for CLI handling and hence introduce 2 other projects for YARN, etc ",NULL,"Add for who this story is","well_formed","no_role","high",False
26894,"Split xd dirt in 3 or 5 The xd dirt project should be split in at least 3 parts Classes and resources pertaining to the admin server Container server Shared classes Additionally, we may consider splitting the first two in half as well, having a separate project for CLI handling and hence introduce 2 other projects for YARN, etc ",NULL,"Split xd dirt in 3 or 5 The xd dirt project should be split in at least 3 parts Classes and resources pertaining to the admin server Container server Shared classes Additionally, we may consider splitting the first two in half as well, having a separate project for CLI handling and hence introduce 2 other projects for YARN, etc ",NULL,"Split xd dirt in 3<span class='highlight-text severity-high'> or </span>5 The xd dirt project should be split in at least 3 parts Classes<span class='highlight-text severity-high'> and </span>resources pertaining to the admin server Container server Shared classes Additionally, we may consider splitting the first two in half as well, having a separate project for CLI handling and hence introduce 2 other projects for YARN, etc ","atomic","conjunctions","high",False
26891,"Move SpEL PropertyAccessors to Module Parent Context When INT 3133 is resolved, SpEL s are inherited from parent contexts. Instead of adding the to each module s context, add it to the parent instead.",NULL,"Move SpEL PropertyAccessors to Module Parent Context When INT 3133 is resolved, SpEL s are inherited from parent contexts. Instead of adding the to each module s context, add it to the parent instead.",NULL,"Add for who this story is","well_formed","no_role","high",False
26891,"Move SpEL PropertyAccessors to Module Parent Context When INT 3133 is resolved, SpEL s are inherited from parent contexts. Instead of adding the to each module s context, add it to the parent instead.",NULL,"Move SpEL PropertyAccessors to Module Parent Context When INT 3133 is resolved, SpEL s are inherited from parent contexts. Instead of adding the to each module s context, add it to the parent instead.",NULL,"Move SpEL PropertyAccessors to Module Parent Context When INT 3133 is resolved, SpEL s are inherited from parent contexts<span class='highlight-text severity-high'>. Instead of adding the to each module s context, add it to the parent instead.</span>","minimal","punctuation","high",False
26892,"Wrong Need copy for each distro ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26892,"Wrong Need copy for each distro ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26893,"Properly close Redis Rabbit connection factories in tests Tests that leverage often create another connection factory in the test body but fail to close it. Tests should properly close the resource. As an added benefit, the rule itself can expose the resource that it created for deciding whether to skip the test or not",NULL,"Properly close Redis Rabbit connection factories in tests Tests that leverage often create another connection factory in the test body but fail to close it. Tests should properly close the resource. As an added benefit, the rule itself can expose the resource that it created for deciding whether to skip the test or not",NULL,"Add for who this story is","well_formed","no_role","high",False
26893,"Properly close Redis Rabbit connection factories in tests Tests that leverage often create another connection factory in the test body but fail to close it. Tests should properly close the resource. As an added benefit, the rule itself can expose the resource that it created for deciding whether to skip the test or not",NULL,"Properly close Redis Rabbit connection factories in tests Tests that leverage often create another connection factory in the test body but fail to close it. Tests should properly close the resource. As an added benefit, the rule itself can expose the resource that it created for deciding whether to skip the test or not",NULL,"Properly close Redis Rabbit connection factories in tests Tests that leverage often create another connection factory in the test body but fail to close it<span class='highlight-text severity-high'>. Tests should properly close the resource. As an added benefit, the rule itself can expose the resource that it created for deciding whether to skip the test or not</span>","minimal","punctuation","high",False
26895,"Container start stop publish events are not getting processed It looks like Container s and are published from context whereas the are running in XDContainer s context. This makes the container start stop events not getting processed. ",NULL,"Container start stop publish events are not getting processed It looks like Container s and are published from context whereas the are running in XDContainer s context. This makes the container start stop events not getting processed. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26895,"Container start stop publish events are not getting processed It looks like Container s and are published from context whereas the are running in XDContainer s context. This makes the container start stop events not getting processed. ",NULL,"Container start stop publish events are not getting processed It looks like Container s and are published from context whereas the are running in XDContainer s context. This makes the container start stop events not getting processed. ",NULL,"Container start stop publish events are not getting processed It looks like Container s<span class='highlight-text severity-high'> and </span>are published from context whereas the are running in XDContainer s context. This makes the container start stop events not getting processed. ","atomic","conjunctions","high",False
26895,"Container start stop publish events are not getting processed It looks like Container s and are published from context whereas the are running in XDContainer s context. This makes the container start stop events not getting processed. ",NULL,"Container start stop publish events are not getting processed It looks like Container s and are published from context whereas the are running in XDContainer s context. This makes the container start stop events not getting processed. ",NULL,"Container start stop publish events are not getting processed It looks like Container s and are published from context whereas the are running in XDContainer s context<span class='highlight-text severity-high'>. This makes the container start stop events not getting processed. </span>","minimal","punctuation","high",False
26896,"Add aggregate counter monthly resolution query support ",NULL,"Add aggregate counter monthly resolution query support ",NULL,"Add for who this story is","well_formed","no_role","high",False
26901,"Add a Processor for Restful webservices Offers the functionality to make http request to a web service. i.e. outbound http gateway. Example implementations stream create name foo definition trigger rest reply timeout 1 url stream create name foos definition trigger rest url log ",NULL,"Add a Processor for Restful webservices Offers the functionality to make http request to a web service. i.e. outbound http gateway. Example implementations stream create name foo definition trigger rest reply timeout 1 url stream create name foos definition trigger rest url log ",NULL,"Add for who this story is","well_formed","no_role","high",False
26901,"Add a Processor for Restful webservices Offers the functionality to make http request to a web service. i.e. outbound http gateway. Example implementations stream create name foo definition trigger rest reply timeout 1 url stream create name foos definition trigger rest url log ",NULL,"Add a Processor for Restful webservices Offers the functionality to make http request to a web service. i.e. outbound http gateway. Example implementations stream create name foo definition trigger rest reply timeout 1 url stream create name foos definition trigger rest url log ",NULL,"Add a Processor for Restful webservices Offers the functionality to make http request to a web service<span class='highlight-text severity-high'>. i.e. outbound http gateway. Example implementations stream create name foo definition trigger rest reply timeout 1 url stream create name foos definition trigger rest url log </span>","minimal","punctuation","high",False
26898,"Add aggregate counter query by number of points It should be possible to supply a start or end date or none for the present , plus a count value for the number of points required i.e. after or prior to the given time .",NULL,"Add aggregate counter query by number of points It should be possible to supply a start or end date or none for the present , plus a count value for the number of points required i.e. after or prior to the given time .",NULL,"Add for who this story is","well_formed","no_role","high",False
26898,"Add aggregate counter query by number of points It should be possible to supply a start or end date or none for the present , plus a count value for the number of points required i.e. after or prior to the given time .",NULL,"Add aggregate counter query by number of points It should be possible to supply a start or end date or none for the present , plus a count value for the number of points required i.e. after or prior to the given time .",NULL,"Add aggregate counter query by number of points It should be possible to supply a start<span class='highlight-text severity-high'> or </span>end date or none for the present , plus a count value for the number of points required i.e. after or prior to the given time .","atomic","conjunctions","high",False
26898,"Add aggregate counter query by number of points It should be possible to supply a start or end date or none for the present , plus a count value for the number of points required i.e. after or prior to the given time .",NULL,"Add aggregate counter query by number of points It should be possible to supply a start or end date or none for the present , plus a count value for the number of points required i.e. after or prior to the given time .",NULL,"Add aggregate counter query by number of points It should be possible to supply a start or end date or none for the present , plus a count value for the number of points required i<span class='highlight-text severity-high'>.e. after or prior to the given time .</span>","minimal","punctuation","high",False
26899,"Support additional aggregate counter query options ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26899,"Support additional aggregate counter query options ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26900,"Documentation for field value taps Put on the guide as a section in an input stream wiki page. ",NULL,"Documentation for field value taps Put on the guide as a section in an input stream wiki page. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26902,"Reduce Sonar Critical Errors Should keep the critical error count as close to zero as possible.",NULL,"Reduce Sonar Critical Errors Should keep the critical error count as close to zero as possible.",NULL,"Add for who this story is","well_formed","no_role","high",False
26903,"Support for registering custom message converters Users need to register custom message converters used by modules.",NULL,"Support for registering custom message converters Users need to register custom message converters used by modules.",NULL,"Add for who this story is","well_formed","no_role","high",False
26904,"The XD build breaks with Gradle 1.8 The XD build breaks with Gradle 1.8 due to some changes in dependency resolution.",NULL,"The XD build breaks with Gradle 1.8 The XD build breaks with Gradle 1.8 due to some changes in dependency resolution.",NULL,"Add for who this story is","well_formed","no_role","high",False
26890,"Documentation for rich gauge taps Put on the guide as a section in an input stream wiki page. ",NULL,"Documentation for rich gauge taps Put on the guide as a section in an input stream wiki page. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26889,"Basic implementation of a reactor based tcp server ",NULL,"Basic implementation of a reactor based tcp server ",NULL,"Add for who this story is","well_formed","no_role","high",False
26897,"Add aggregate counter year resolution query support ",NULL,"Add aggregate counter year resolution query support ",NULL,"Add for who this story is","well_formed","no_role","high",False
26909,"Refine project mainly dirt dependencies See also XD 903, XD 915 A lot of dependencies have been added with the compile scope as an oversight over time. Some of them are only required at runtime, some may not be required anymore.",NULL,"Refine project mainly dirt dependencies See also XD 903, XD 915 A lot of dependencies have been added with the compile scope as an oversight over time. Some of them are only required at runtime, some may not be required anymore.",NULL,"Add for who this story is","well_formed","no_role","high",False
26909,"Refine project mainly dirt dependencies See also XD 903, XD 915 A lot of dependencies have been added with the compile scope as an oversight over time. Some of them are only required at runtime, some may not be required anymore.",NULL,"Refine project mainly dirt dependencies See also XD 903, XD 915 A lot of dependencies have been added with the compile scope as an oversight over time. Some of them are only required at runtime, some may not be required anymore.",NULL,"Refine project mainly dirt dependencies See also XD 903, XD 915 A lot of dependencies have been added with the compile scope as an oversight over time<span class='highlight-text severity-high'>. Some of them are only required at runtime, some may not be required anymore.</span>","minimal","punctuation","high",False
26907,"File source should be able to produce file contents or file reference File source should output either the File itself serialized File object or the contents as a byte . This option is configured by a parameter contents true. The byte may be converted to a String using XD Message Conversion, e.g., output ",NULL,"File source should be able to produce file contents or file reference File source should output either the File itself serialized File object or the contents as a byte . This option is configured by a parameter contents true. The byte may be converted to a String using XD Message Conversion, e.g., output ",NULL,"Add for who this story is","well_formed","no_role","high",False
26907,"File source should be able to produce file contents or file reference File source should output either the File itself serialized File object or the contents as a byte . This option is configured by a parameter contents true. The byte may be converted to a String using XD Message Conversion, e.g., output ",NULL,"File source should be able to produce file contents or file reference File source should output either the File itself serialized File object or the contents as a byte . This option is configured by a parameter contents true. The byte may be converted to a String using XD Message Conversion, e.g., output ",NULL,"File source should be able to produce file contents<span class='highlight-text severity-high'> or </span>file reference File source should output either the File itself serialized File object or the contents as a byte . This option is configured by a parameter contents true. The byte may be converted to a String using XD Message Conversion, e.g., output ","atomic","conjunctions","high",False
26907,"File source should be able to produce file contents or file reference File source should output either the File itself serialized File object or the contents as a byte . This option is configured by a parameter contents true. The byte may be converted to a String using XD Message Conversion, e.g., output ",NULL,"File source should be able to produce file contents or file reference File source should output either the File itself serialized File object or the contents as a byte . This option is configured by a parameter contents true. The byte may be converted to a String using XD Message Conversion, e.g., output ",NULL,"File source should be able to produce file contents or file reference File source should output either the File itself serialized File object or the contents as a byte <span class='highlight-text severity-high'>. This option is configured by a parameter contents true. The byte may be converted to a String using XD Message Conversion, e.g., output </span>","minimal","punctuation","high",False
26914,"Split integration.x in dedicated XD projects where appropriate Similar to what is done for e.g. hadoop, reactor, and http, some of the classes in the .x package namely gemfire, splunk, twitter should go in dedicated albeit small projects. This would enable further modularization see XD 915 ",NULL,"Split integration.x in dedicated XD projects where appropriate Similar to what is done for e.g. hadoop, reactor, and http, some of the classes in the .x package namely gemfire, splunk, twitter should go in dedicated albeit small projects. This would enable further modularization see XD 915 ",NULL,"Add for who this story is","well_formed","no_role","high",False
26914,"Split integration.x in dedicated XD projects where appropriate Similar to what is done for e.g. hadoop, reactor, and http, some of the classes in the .x package namely gemfire, splunk, twitter should go in dedicated albeit small projects. This would enable further modularization see XD 915 ",NULL,"Split integration.x in dedicated XD projects where appropriate Similar to what is done for e.g. hadoop, reactor, and http, some of the classes in the .x package namely gemfire, splunk, twitter should go in dedicated albeit small projects. This would enable further modularization see XD 915 ",NULL,"Split integration<span class='highlight-text severity-high'>.x in dedicated XD projects where appropriate Similar to what is done for e.g. hadoop, reactor, and http, some of the classes in the .x package namely gemfire, splunk, twitter should go in dedicated albeit small projects. This would enable further modularization see XD 915 </span>","minimal","punctuation","high",False
26908,"Make the parser aware of message conversion configuration Enhance the stream parser to take message conversion into account in order to validate or automatically configure converters. For example ",NULL,"Make the parser aware of message conversion configuration Enhance the stream parser to take message conversion into account","in order to validate or automatically configure converters. For example","Add for who this story is","well_formed","no_role","high",False
26911,"Add more hands on example to MQTT doco Not everyone may be familiar with MQTT, or esp. with MQTT inside Rabbit",NULL,"Add more hands on example to MQTT doco Not everyone may be familiar with MQTT, or esp. with MQTT inside Rabbit",NULL,"Add more hands on example to MQTT doco Not everyone may be familiar with MQTT, or esp<span class='highlight-text severity-high'>. with MQTT inside Rabbit</span>","minimal","punctuation","high",False
26910,"Remove json parameter from twittersearch source json parameter is no longer required. Use instead",NULL,"Remove json parameter from twittersearch source json parameter is no longer required. Use instead",NULL,"Add for who this story is","well_formed","no_role","high",False
26910,"Remove json parameter from twittersearch source json parameter is no longer required. Use instead",NULL,"Remove json parameter from twittersearch source json parameter is no longer required. Use instead",NULL,"Remove json parameter from twittersearch source json parameter is no longer required<span class='highlight-text severity-high'>. Use instead</span>","minimal","punctuation","high",False
26913,"Error Channel for streams modules that fail to process a message As a user, I'd like to be notified when a exception is thrown in a module so that I can tap into an error channel to receive the failures for each stream module. ",NULL,"Error Channel for streams modules that fail to process a message As a user, I'd like to be notified when a exception is thrown in a module","so that I can tap into an error channel to receive the failures for each stream module.","Add for who this story is","well_formed","no_role","high",False
26913,"Error Channel for streams modules that fail to process a message As a user, I'd like to be notified when a exception is thrown in a module so that I can tap into an error channel to receive the failures for each stream module. ",NULL,"Error Channel for streams modules that fail to process a message As a user, I'd like to be notified when a exception is thrown in a module","so that I can tap into an error channel to receive the failures for each stream module.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26912,"Handle SingleNodeServer s stop method cleanly SingleNode server needs to stop cleanly with stopping both the admin server container server. Also, all the tests that require SingleNode main server needs to handle the server shutdown appropriately.",NULL,"Handle SingleNodeServer s stop method cleanly SingleNode server needs to stop cleanly with stopping both the admin server container server. Also, all the tests that require SingleNode main server needs to handle the server shutdown appropriately.",NULL,"Add for who this story is","well_formed","no_role","high",False
26912,"Handle SingleNodeServer s stop method cleanly SingleNode server needs to stop cleanly with stopping both the admin server container server. Also, all the tests that require SingleNode main server needs to handle the server shutdown appropriately.",NULL,"Handle SingleNodeServer s stop method cleanly SingleNode server needs to stop cleanly with stopping both the admin server container server. Also, all the tests that require SingleNode main server needs to handle the server shutdown appropriately.",NULL,"Handle SingleNodeServer s stop method cleanly SingleNode server needs to stop cleanly with stopping both the admin server container server<span class='highlight-text severity-high'>. Also, all the tests that require SingleNode main server needs to handle the server shutdown appropriately.</span>","minimal","punctuation","high",False
26918,"Refactor in Dirt In the testmodules.source Rename source config to packaged source Rename source config to All xml files should be prefixed with test. i.e. testsource, testsink Make sure all tests pass with new configuration",NULL,"Refactor in Dirt In the testmodules.source Rename source config to packaged source Rename source config to All xml files should be prefixed with test. i.e. testsource, testsink Make sure all tests pass with new configuration",NULL,"Add for who this story is","well_formed","no_role","high",False
26918,"Refactor in Dirt In the testmodules.source Rename source config to packaged source Rename source config to All xml files should be prefixed with test. i.e. testsource, testsink Make sure all tests pass with new configuration",NULL,"Refactor in Dirt In the testmodules.source Rename source config to packaged source Rename source config to All xml files should be prefixed with test. i.e. testsource, testsink Make sure all tests pass with new configuration",NULL,"Refactor in Dirt In the testmodules<span class='highlight-text severity-high'>.source Rename source config to packaged source Rename source config to All xml files should be prefixed with test. i.e. testsource, testsink Make sure all tests pass with new configuration</span>","minimal","punctuation","high",False
26915,"Investigate Swagger to generate REST API Documents Investigate Swagger to generate REST API Documents ",NULL,"Investigate Swagger to generate REST API Documents Investigate Swagger to generate REST API Documents ",NULL,"Add for who this story is","well_formed","no_role","high",False
26919,"Remove the Tabulation characters should not be used from Sonar ",NULL,"Remove the Tabulation characters should not be used from Sonar ",NULL,"Add for who this story is","well_formed","no_role","high",False
26920,"Return rounded interval values from aggregate counter queries The aggregate counter query result currently returns the interval that is passed in, whether it is aligned with the bucket resolution requested or not. It would be more intuitive if the time values returned are rounded down to the resolution of the query i.e. whole minutes, hours, days or whatever .",NULL,"Return rounded interval values from aggregate counter queries The aggregate counter query result currently returns the interval that is passed in, whether it is aligned with the bucket resolution requested or not. It would be more intuitive if the time values returned are rounded down to the resolution of the query i.e. whole minutes, hours, days or whatever .",NULL,"Add for who this story is","well_formed","no_role","high",False
26920,"Return rounded interval values from aggregate counter queries The aggregate counter query result currently returns the interval that is passed in, whether it is aligned with the bucket resolution requested or not. It would be more intuitive if the time values returned are rounded down to the resolution of the query i.e. whole minutes, hours, days or whatever .",NULL,"Return rounded interval values from aggregate counter queries The aggregate counter query result currently returns the interval that is passed in, whether it is aligned with the bucket resolution requested or not. It would be more intuitive if the time values returned are rounded down to the resolution of the query i.e. whole minutes, hours, days or whatever .",NULL,"Return rounded interval values from aggregate counter queries The aggregate counter query result currently returns the interval that is passed in, whether it is aligned with the bucket resolution requested or not<span class='highlight-text severity-high'>. It would be more intuitive if the time values returned are rounded down to the resolution of the query i.e. whole minutes, hours, days or whatever .</span>","minimal","punctuation","high",False
26921,"Format option to display runtime module properties in shell The runtime module properties requires a format option when displayed in the Shell Based on the PR the module properties are stored as String and displayed as is. ",NULL,"Format option to display runtime module properties in shell The runtime module properties requires a format option when displayed in the Shell Based on the PR the module properties are stored as String and displayed as is. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26921,"Format option to display runtime module properties in shell The runtime module properties requires a format option when displayed in the Shell Based on the PR the module properties are stored as String and displayed as is. ",NULL,"Format option to display runtime module properties in shell The runtime module properties requires a format option when displayed in the Shell Based on the PR the module properties are stored as String and displayed as is. ",NULL,"Format option to display runtime module properties in shell The runtime module properties requires a format option when displayed in the Shell Based on the PR the module properties are stored as String<span class='highlight-text severity-high'> and </span>displayed as is. ","atomic","conjunctions","high",False
26916,"Update Core Spring Dependency to 4.0.0.M3 ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26916,"Update Core Spring Dependency to 4.0.0.M3 ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26905,"Add documentation for jsonPath functionality with SpEL based processors See issue The docs should be updated to include examples that show how to use the standard SpEL based splitter, transformer, filters with jsonPath expressions.",NULL,"Add documentation for jsonPath functionality with SpEL based processors See issue The docs should be updated to include examples that show how to use the standard SpEL based splitter, transformer, filters with jsonPath expressions.",NULL,"Add for who this story is","well_formed","no_role","high",False
26917,"ModuleType Refactor Remove All code should use the enum. ",NULL,"ModuleType Refactor Remove All code should use the enum. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26922,"Tests Fail because HSQL not started This is cause generally by someone having port 9100 hsqldb port in use. It is recommended that setup checks to see if port is in use. If it is throw an exception stating that hsqldb port 9100 is in use and suggest options like. Free up the port or change the hsqldb port.",NULL,"Tests Fail because HSQL not started This is cause generally by someone having port 9100 hsqldb port in use. It is recommended that setup checks to see if port is in use. If it is throw an exception stating that hsqldb port 9100 is in use and suggest options like. Free up the port or change the hsqldb port.",NULL,"Add for who this story is","well_formed","no_role","high",False
26922,"Tests Fail because HSQL not started This is cause generally by someone having port 9100 hsqldb port in use. It is recommended that setup checks to see if port is in use. If it is throw an exception stating that hsqldb port 9100 is in use and suggest options like. Free up the port or change the hsqldb port.",NULL,"Tests Fail because HSQL not started This is cause generally by someone having port 9100 hsqldb port in use. It is recommended that setup checks to see if port is in use. If it is throw an exception stating that hsqldb port 9100 is in use and suggest options like. Free up the port or change the hsqldb port.",NULL,"Tests Fail because HSQL not started This is cause generally by someone having port 9100 hsqldb port in use. It is recommended that setup checks to see if port is in use. If it is throw an exception stating that hsqldb port 9100 is in use<span class='highlight-text severity-high'> and </span>suggest options like. Free up the port<span class='highlight-text severity-high'> or </span>change the hsqldb port.","atomic","conjunctions","high",False
26922,"Tests Fail because HSQL not started This is cause generally by someone having port 9100 hsqldb port in use. It is recommended that setup checks to see if port is in use. If it is throw an exception stating that hsqldb port 9100 is in use and suggest options like. Free up the port or change the hsqldb port.",NULL,"Tests Fail because HSQL not started This is cause generally by someone having port 9100 hsqldb port in use. It is recommended that setup checks to see if port is in use. If it is throw an exception stating that hsqldb port 9100 is in use and suggest options like. Free up the port or change the hsqldb port.",NULL,"Tests Fail because HSQL not started This is cause generally by someone having port 9100 hsqldb port in use<span class='highlight-text severity-high'>. It is recommended that setup checks to see if port is in use. If it is throw an exception stating that hsqldb port 9100 is in use and suggest options like. Free up the port or change the hsqldb port.</span>","minimal","punctuation","high",False
26925,"Find runtime modules by type and or name We need a way to find the runtime module info by module type source , sink , processor , job . ",NULL,"Find runtime modules by type and or name We need a way to find the runtime module info by module type source , sink , processor , job . ",NULL,"Add for who this story is","well_formed","no_role","high",False
26925,"Find runtime modules by type and or name We need a way to find the runtime module info by module type source , sink , processor , job . ",NULL,"Find runtime modules by type and or name We need a way to find the runtime module info by module type source , sink , processor , job . ",NULL,"Find runtime modules by type<span class='highlight-text severity-high'> and </span>span class='highlight-text severity-high'> or </span>name We need a way to find the runtime module info by module type source , sink , processor , job . ","atomic","conjunctions","high",False
26924,"Support JSON to Object Register a JSON to Object converter in the Currently we only support Object to JSON but not the other way. This may or may not work for an arbitrary object but is useful in many cases.",NULL,"Support JSON to Object Register a JSON to Object converter in the Currently we only support Object to JSON but not the other way. This may or may not work for an arbitrary object but is useful in many cases.",NULL,"Add for who this story is","well_formed","no_role","high",False
26924,"Support JSON to Object Register a JSON to Object converter in the Currently we only support Object to JSON but not the other way. This may or may not work for an arbitrary object but is useful in many cases.",NULL,"Support JSON to Object Register a JSON to Object converter in the Currently we only support Object to JSON but not the other way. This may or may not work for an arbitrary object but is useful in many cases.",NULL,"Support JSON to Object Register a JSON to Object converter in the Currently we only support Object to JSON but not the other way. This may<span class='highlight-text severity-high'> or </span>may not work for an arbitrary object but is useful in many cases.","atomic","conjunctions","high",False
26924,"Support JSON to Object Register a JSON to Object converter in the Currently we only support Object to JSON but not the other way. This may or may not work for an arbitrary object but is useful in many cases.",NULL,"Support JSON to Object Register a JSON to Object converter in the Currently we only support Object to JSON but not the other way. This may or may not work for an arbitrary object but is useful in many cases.",NULL,"Support JSON to Object Register a JSON to Object converter in the Currently we only support Object to JSON but not the other way<span class='highlight-text severity-high'>. This may or may not work for an arbitrary object but is useful in many cases.</span>","minimal","punctuation","high",False
26927,"List runtime modules by wrong containerId should throw exception With PR 340, listing of runtime modules with a non existent containerId will display empty table. Instead, we can throw exception saying Container doesn t exist.",NULL,"List runtime modules by wrong containerId should throw exception With PR 340, listing of runtime modules with a non existent containerId will display empty table. Instead, we can throw exception saying Container doesn t exist.",NULL,"Add for who this story is","well_formed","no_role","high",False
26927,"List runtime modules by wrong containerId should throw exception With PR 340, listing of runtime modules with a non existent containerId will display empty table. Instead, we can throw exception saying Container doesn t exist.",NULL,"List runtime modules by wrong containerId should throw exception With PR 340, listing of runtime modules with a non existent containerId will display empty table. Instead, we can throw exception saying Container doesn t exist.",NULL,"List runtime modules by wrong containerId should throw exception With PR 340, listing of runtime modules with a non existent containerId will display empty table<span class='highlight-text severity-high'>. Instead, we can throw exception saying Container doesn t exist.</span>","minimal","punctuation","high",False
26926,"Inject into ModulesController Currently, ModulesController creates the instance with ModuleRegistry. Instead, we should inject the into ModulesController directly.",NULL,"Inject into ModulesController Currently, ModulesController creates the instance with ModuleRegistry. Instead, we should inject the into ModulesController directly.",NULL,"Add for who this story is","well_formed","no_role","high",False
26926,"Inject into ModulesController Currently, ModulesController creates the instance with ModuleRegistry. Instead, we should inject the into ModulesController directly.",NULL,"Inject into ModulesController Currently, ModulesController creates the instance with ModuleRegistry. Instead, we should inject the into ModulesController directly.",NULL,"Inject into ModulesController Currently, ModulesController creates the instance with ModuleRegistry<span class='highlight-text severity-high'>. Instead, we should inject the into ModulesController directly.</span>","minimal","punctuation","high",False
26930,"Change repo links in build.gradle repo.spring.io Change repo links in build.gradle repo.spring.io ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26930,"Change repo links in build.gradle repo.spring.io Change repo links in build.gradle repo.spring.io ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26928,"Make Runtime modules listing by ContainerId pageable The from PR 340 returns the list of runtime modules. Instead we need make it pageable.",NULL,"Make Runtime modules listing by ContainerId pageable The from PR 340 returns the list of runtime modules. Instead we need make it pageable.",NULL,"Add for who this story is","well_formed","no_role","high",False
26928,"Make Runtime modules listing by ContainerId pageable The from PR 340 returns the list of runtime modules. Instead we need make it pageable.",NULL,"Make Runtime modules listing by ContainerId pageable The from PR 340 returns the list of runtime modules. Instead we need make it pageable.",NULL,"Make Runtime modules listing by ContainerId pageable The from PR 340 returns the list of runtime modules<span class='highlight-text severity-high'>. Instead we need make it pageable.</span>","minimal","punctuation","high",False
26931,"JobPlugin should not add properties that are not needed If you create a simple http log stream and list the modules, you ll see that JobPlugin adds its numberFormat, makeUnique, etc properties. Even though they do no harm, it s really strange for users. Plus, it could conflict with e.g. activation of profiles given present properties",NULL,"JobPlugin should not add properties that are not needed If you create a simple http log stream and list the modules, you ll see that JobPlugin adds its numberFormat, makeUnique, etc properties. Even though they do no harm, it s really strange for users. Plus, it could conflict with e.g. activation of profiles given present properties",NULL,"Add for who this story is","well_formed","no_role","high",False
26931,"JobPlugin should not add properties that are not needed If you create a simple http log stream and list the modules, you ll see that JobPlugin adds its numberFormat, makeUnique, etc properties. Even though they do no harm, it s really strange for users. Plus, it could conflict with e.g. activation of profiles given present properties",NULL,"JobPlugin should not add properties that are not needed If you create a simple http log stream and list the modules, you ll see that JobPlugin adds its numberFormat, makeUnique, etc properties. Even though they do no harm, it s really strange for users. Plus, it could conflict with e.g. activation of profiles given present properties",NULL,"JobPlugin should not add properties that are not needed If you create a simple http log stream<span class='highlight-text severity-high'> and </span>list the modules, you ll see that JobPlugin adds its numberFormat, makeUnique, etc properties. Even though they do no harm, it s really strange for users. Plus, it could conflict with e.g. activation of profiles given present properties","atomic","conjunctions","high",False
26240,"Return full ModuleStatus information Remove all stubs and check all required information is returned accurately.",NULL,"Return full ModuleStatus information Remove all stubs and check all required information is returned accurately.",NULL,"Return full ModuleStatus information Remove all stubs<span class='highlight-text severity-high'> and </span>check all required information is returned accurately.","atomic","conjunctions","high",False
26931,"JobPlugin should not add properties that are not needed If you create a simple http log stream and list the modules, you ll see that JobPlugin adds its numberFormat, makeUnique, etc properties. Even though they do no harm, it s really strange for users. Plus, it could conflict with e.g. activation of profiles given present properties",NULL,"JobPlugin should not add properties that are not needed If you create a simple http log stream and list the modules, you ll see that JobPlugin adds its numberFormat, makeUnique, etc properties. Even though they do no harm, it s really strange for users. Plus, it could conflict with e.g. activation of profiles given present properties",NULL,"JobPlugin should not add properties that are not needed If you create a simple http log stream and list the modules, you ll see that JobPlugin adds its numberFormat, makeUnique, etc properties<span class='highlight-text severity-high'>. Even though they do no harm, it s really strange for users. Plus, it could conflict with e.g. activation of profiles given present properties</span>","minimal","punctuation","high",False
26932,"Spike for writing to HDFS See Epic ",NULL,"Spike for writing to HDFS See Epic ",NULL,"Add for who this story is","well_formed","no_role","high",False
26936,"Spike for job that exports HDFS CSV data to JDBC ",NULL,"Spike for job that exports HDFS CSV data to JDBC ",NULL,"Add for who this story is","well_formed","no_role","high",False
26938,"Update Jobs documentation to include job launch command This is currently missing and probably supersedes some of the stuff that s in there now.",NULL,"Update Jobs documentation to include job launch command This is currently missing and probably supersedes some of the stuff that s in there now.",NULL,"Add for who this story is","well_formed","no_role","high",False
26938,"Update Jobs documentation to include job launch command This is currently missing and probably supersedes some of the stuff that s in there now.",NULL,"Update Jobs documentation to include job launch command This is currently missing and probably supersedes some of the stuff that s in there now.",NULL,"Update Jobs documentation to include job launch command This is currently missing<span class='highlight-text severity-high'> and </span>probably supersedes some of the stuff that s in there now.","atomic","conjunctions","high",False
26942,"User requires wiki page on how to use the XD EC2 Installer Add instructions to github wiki on the usage of the installer ",NULL,"User requires wiki page on how to use the XD EC2 Installer Add instructions to github wiki on the usage of the installer ",NULL,"Add for who this story is","well_formed","no_role","high",False
26941,"User requests that XD team members are issued EC2 accounts Setup groups for xd user Setup privileges so users can only see their instances Setup user accounts Send created access key to users Send username and passwords to user ",NULL,"User requests that XD team members are issued EC2 accounts Setup groups for xd user Setup privileges","so users can only see their instances Setup user accounts Send created access key to users Send username and passwords to user","Add for who this story is","well_formed","no_role","high",False
26941,"User requests that XD team members are issued EC2 accounts Setup groups for xd user Setup privileges so users can only see their instances Setup user accounts Send created access key to users Send username and passwords to user ",NULL,"User requests that XD team members are issued EC2 accounts Setup groups for xd user Setup privileges","so users can only see their instances Setup user accounts Send created access key to users Send username and passwords to user","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26943,"Create google doc with instructions on managing EC2 Instances Logging into your XD Account For Example Discuss how to terminate running instances. Users can terminate all instances using the UI on the EC2 admin page Usage monitoring via CloudWatch Investigate what metadata in each instance is required so that cloudwatch can track ",NULL,"Create google doc with instructions on managing EC2 Instances Logging into your XD Account For Example Discuss how to terminate running instances. Users can terminate all instances using the UI on the EC2 admin page Usage monitoring via CloudWatch Investigate what metadata in each instance is required","so that cloudwatch can track","Add for who this story is","well_formed","no_role","high",False
26943,"Create google doc with instructions on managing EC2 Instances Logging into your XD Account For Example Discuss how to terminate running instances. Users can terminate all instances using the UI on the EC2 admin page Usage monitoring via CloudWatch Investigate what metadata in each instance is required so that cloudwatch can track ",NULL,"Create google doc with instructions on managing EC2 Instances Logging into your XD Account For Example Discuss how to terminate running instances. Users can terminate all instances using the UI on the EC2 admin page Usage monitoring via CloudWatch Investigate what metadata in each instance is required","so that cloudwatch can track","Create google doc with instructions on managing EC2 Instances Logging into your XD Account For Example Discuss how to terminate running instances<span class='highlight-text severity-high'>. Users can terminate all instances using the UI on the EC2 admin page Usage monitoring via CloudWatch Investigate what metadata in each instance is required so that cloudwatch can track </span>","minimal","punctuation","high",False
26943,"Create google doc with instructions on managing EC2 Instances Logging into your XD Account For Example Discuss how to terminate running instances. Users can terminate all instances using the UI on the EC2 admin page Usage monitoring via CloudWatch Investigate what metadata in each instance is required so that cloudwatch can track ",NULL,"Create google doc with instructions on managing EC2 Instances Logging into your XD Account For Example Discuss how to terminate running instances. Users can terminate all instances using the UI on the EC2 admin page Usage monitoring via CloudWatch Investigate what metadata in each instance is required","so that cloudwatch can track","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26929,"Splunk Pulls in an Old SI Jar into STS ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26929,"Splunk Pulls in an Old SI Jar into STS ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26933,"Spike for EC2 deployments ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26933,"Spike for EC2 deployments ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26934,"Spike for Deployment SPI SPI for deployment on to YARN Local dirt cluster.",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26934,"Spike for Deployment SPI SPI for deployment on to YARN Local dirt cluster.",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26935,"Spike for job that imports data from CSV file to HDFS TBD",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26935,"Spike for job that imports data from CSV file to HDFS TBD",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26940,"fix gradle clean test Currently . gradlew clean test fails since the module dependencies are not packaged before the test task. ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26940,"fix gradle clean test Currently . gradlew clean test fails since the module dependencies are not packaged before the test task. ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26940,"fix gradle clean test Currently . gradlew clean test fails since the module dependencies are not packaged before the test task. ",NULL,NULL,NULL,"fix gradle clean test Currently <span class='highlight-text severity-high'>. gradlew clean test fails since the module dependencies are not packaged before the test task. </span>","minimal","punctuation","high",False
26937,"Spike for advanced Job Orchestration features ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26937,"Spike for advanced Job Orchestration features ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26939,"Update SI Dependency to ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26939,"Update SI Dependency to ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26944,"The HDFS Sink should support compressing files as they are copied Get a java.io.File and copy it into HDFS. Could be text or binary. Write compressed with Hadoop and third party codecs see XD 277, XD 279 should initially support bzip2 LZO ",NULL,"The HDFS Sink should support compressing files as they are copied Get a java.io.File and copy it into HDFS. Could be text or binary. Write compressed with Hadoop and third party codecs see XD 277, XD 279 should initially support bzip2 LZO ",NULL,"Add for who this story is","well_formed","no_role","high",False
26944,"The HDFS Sink should support compressing files as they are copied Get a java.io.File and copy it into HDFS. Could be text or binary. Write compressed with Hadoop and third party codecs see XD 277, XD 279 should initially support bzip2 LZO ",NULL,"The HDFS Sink should support compressing files as they are copied Get a java.io.File and copy it into HDFS. Could be text or binary. Write compressed with Hadoop and third party codecs see XD 277, XD 279 should initially support bzip2 LZO ",NULL,"The HDFS Sink should support compressing files as they are copied Get a java.io.File<span class='highlight-text severity-high'> and </span>copy it into HDFS. Could be text<span class='highlight-text severity-high'> or </span>binary. Write compressed with Hadoop and third party codecs see XD 277, XD 279 should initially support bzip2 LZO ","atomic","conjunctions","high",False
26944,"The HDFS Sink should support compressing files as they are copied Get a java.io.File and copy it into HDFS. Could be text or binary. Write compressed with Hadoop and third party codecs see XD 277, XD 279 should initially support bzip2 LZO ",NULL,"The HDFS Sink should support compressing files as they are copied Get a java.io.File and copy it into HDFS. Could be text or binary. Write compressed with Hadoop and third party codecs see XD 277, XD 279 should initially support bzip2 LZO ",NULL,"The HDFS Sink should support compressing files as they are copied Get a java<span class='highlight-text severity-high'>.io.File and copy it into HDFS. Could be text or binary. Write compressed with Hadoop and third party codecs see XD 277, XD 279 should initially support bzip2 LZO </span>","minimal","punctuation","high",False
26946,"Batch Wordcount Sample to use File Source ",NULL,"Batch Wordcount Sample to use File Source ",NULL,"Add for who this story is","well_formed","no_role","high",False
26947,"Documentation on the module system and how to contribute new modules For people who are familiar with Spring Spring Integration provide documents that show how to add additional input sources sinks.",NULL,"Documentation on the module system and how to contribute new modules For people who are familiar with Spring Spring Integration provide documents that show how to add additional input sources sinks.",NULL,"Add for who this story is","well_formed","no_role","high",False
26951,"Create OOTB batch job for export and processing multiple files from HDFS to JDBC Same setup as XD 987 for ItemReader and ItemProcessor, but should write to HDFS. One can assume that the table structure has been created already external to the batch job execution.",NULL,"Create OOTB batch job for export and processing multiple files from HDFS to JDBC Same setup as XD 987 for ItemReader and ItemProcessor, but should write to HDFS. One can assume that the table structure has been created already external to the batch job execution.",NULL,"Add for who this story is","well_formed","no_role","high",False
26951,"Create OOTB batch job for export and processing multiple files from HDFS to JDBC Same setup as XD 987 for ItemReader and ItemProcessor, but should write to HDFS. One can assume that the table structure has been created already external to the batch job execution.",NULL,"Create OOTB batch job for export and processing multiple files from HDFS to JDBC Same setup as XD 987 for ItemReader and ItemProcessor, but should write to HDFS. One can assume that the table structure has been created already external to the batch job execution.",NULL,"Create OOTB batch job for export<span class='highlight-text severity-high'> and </span>processing multiple files from HDFS to JDBC Same setup as XD 987 for ItemReader and ItemProcessor, but should write to HDFS. One can assume that the table structure has been created already external to the batch job execution.","atomic","conjunctions","high",False
26951,"Create OOTB batch job for export and processing multiple files from HDFS to JDBC Same setup as XD 987 for ItemReader and ItemProcessor, but should write to HDFS. One can assume that the table structure has been created already external to the batch job execution.",NULL,"Create OOTB batch job for export and processing multiple files from HDFS to JDBC Same setup as XD 987 for ItemReader and ItemProcessor, but should write to HDFS. One can assume that the table structure has been created already external to the batch job execution.",NULL,"Create OOTB batch job for export and processing multiple files from HDFS to JDBC Same setup as XD 987 for ItemReader and ItemProcessor, but should write to HDFS<span class='highlight-text severity-high'>. One can assume that the table structure has been created already external to the batch job execution.</span>","minimal","punctuation","high",False
26948,"Missing dependency in the lib dir. That s no longer there so hadoop distros that require this now fail at least any hadoop 2.0.x based ones We should also upgrade to current Hadoop versions Hadoop 2.2 stable ",NULL,"Missing dependency in the lib dir. That s no longer there","so hadoop distros that require this now fail at least any hadoop 2.0.x based ones We should also upgrade to current Hadoop versions Hadoop 2.2 stable","Add for who this story is","well_formed","no_role","high",False
26948,"Missing dependency in the lib dir. That s no longer there so hadoop distros that require this now fail at least any hadoop 2.0.x based ones We should also upgrade to current Hadoop versions Hadoop 2.2 stable ",NULL,"Missing dependency in the lib dir. That s no longer there","so hadoop distros that require this now fail at least any hadoop 2.0.x based ones We should also upgrade to current Hadoop versions Hadoop 2.2 stable","Missing dependency in the lib dir<span class='highlight-text severity-high'>. That s no longer there so hadoop distros that require this now fail at least any hadoop 2.0.x based ones We should also upgrade to current Hadoop versions Hadoop 2.2 stable </span>","minimal","punctuation","high",False
26948,"Missing dependency in the lib dir. That s no longer there so hadoop distros that require this now fail at least any hadoop 2.0.x based ones We should also upgrade to current Hadoop versions Hadoop 2.2 stable ",NULL,"Missing dependency in the lib dir. That s no longer there","so hadoop distros that require this now fail at least any hadoop 2.0.x based ones We should also upgrade to current Hadoop versions Hadoop 2.2 stable","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26950,"Create OOTB batch job for export and processing multiple files from HDFS to MongoDB The ItemReader will read multiple files from HDFS and the data will be converted to a tuple data structure The ItemProcessor will be a no op groovy script. The ItemWriter will write the data to a MongoDB collection A TupleToDBObject converter will need to be developed. the sample job should be documented ",NULL,"Create OOTB batch job for export and processing multiple files from HDFS to MongoDB The ItemReader will read multiple files from HDFS and the data will be converted to a tuple data structure The ItemProcessor will be a no op groovy script. The ItemWriter will write the data to a MongoDB collection A TupleToDBObject converter will need to be developed. the sample job should be documented ",NULL,"Add for who this story is","well_formed","no_role","high",False
26950,"Create OOTB batch job for export and processing multiple files from HDFS to MongoDB The ItemReader will read multiple files from HDFS and the data will be converted to a tuple data structure The ItemProcessor will be a no op groovy script. The ItemWriter will write the data to a MongoDB collection A TupleToDBObject converter will need to be developed. the sample job should be documented ",NULL,"Create OOTB batch job for export and processing multiple files from HDFS to MongoDB The ItemReader will read multiple files from HDFS and the data will be converted to a tuple data structure The ItemProcessor will be a no op groovy script. The ItemWriter will write the data to a MongoDB collection A TupleToDBObject converter will need to be developed. the sample job should be documented ",NULL,"Create OOTB batch job for export<span class='highlight-text severity-high'> and </span>processing multiple files from HDFS to MongoDB The ItemReader will read multiple files from HDFS and the data will be converted to a tuple data structure The ItemProcessor will be a no op groovy script. The ItemWriter will write the data to a MongoDB collection A TupleToDBObject converter will need to be developed. the sample job should be documented ","atomic","conjunctions","high",False
26950,"Create OOTB batch job for export and processing multiple files from HDFS to MongoDB The ItemReader will read multiple files from HDFS and the data will be converted to a tuple data structure The ItemProcessor will be a no op groovy script. The ItemWriter will write the data to a MongoDB collection A TupleToDBObject converter will need to be developed. the sample job should be documented ",NULL,"Create OOTB batch job for export and processing multiple files from HDFS to MongoDB The ItemReader will read multiple files from HDFS and the data will be converted to a tuple data structure The ItemProcessor will be a no op groovy script. The ItemWriter will write the data to a MongoDB collection A TupleToDBObject converter will need to be developed. the sample job should be documented ",NULL,"Create OOTB batch job for export and processing multiple files from HDFS to MongoDB The ItemReader will read multiple files from HDFS and the data will be converted to a tuple data structure The ItemProcessor will be a no op groovy script<span class='highlight-text severity-high'>. The ItemWriter will write the data to a MongoDB collection A TupleToDBObject converter will need to be developed. the sample job should be documented </span>","minimal","punctuation","high",False
26953,"The HDFS Store Library should support writing to Sequence Files Support for writing Sequence Files Without Compression Need a means to specify the key value to be used ",NULL,"The HDFS Store Library should support writing to Sequence Files Support for writing Sequence Files Without Compression Need a means to specify the key value to be used ",NULL,"Add for who this story is","well_formed","no_role","high",False
26956,"Refactor tests with to use eventually matcher Some tests esp. seem to fail because of a race condition. Add a Hamcrest matcher that knows how to read the content of a FileSink Source and refactor those to read like e.g. ",NULL,"Refactor tests with to use eventually matcher Some tests esp. seem to fail because of a race condition. Add a Hamcrest matcher that knows how to read the content of a FileSink Source and refactor those to read like e.g. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26235,"Retrieve information for an aggregate counter TODO as part of this see XD 537 Get rid of so called Service layer in analytics project doesn t do much right now, and logic would better live in the Handler IMO Have REST controllers depend on XRepository in all cases",NULL,"Retrieve information for an aggregate counter TODO as part of this see XD 537 Get rid of","so called Service layer in analytics project doesn t do much right now, and logic would better live in the Handler IMO Have REST controllers depend on XRepository in all cases","Add for who this story is","well_formed","no_role","high",False
26956,"Refactor tests with to use eventually matcher Some tests esp. seem to fail because of a race condition. Add a Hamcrest matcher that knows how to read the content of a FileSink Source and refactor those to read like e.g. ",NULL,"Refactor tests with to use eventually matcher Some tests esp. seem to fail because of a race condition. Add a Hamcrest matcher that knows how to read the content of a FileSink Source and refactor those to read like e.g. ",NULL,"Refactor tests with to use eventually matcher Some tests esp. seem to fail because of a race condition. Add a Hamcrest matcher that knows how to read the content of a FileSink Source<span class='highlight-text severity-high'> and </span>refactor those to read like e.g. ","atomic","conjunctions","high",False
26956,"Refactor tests with to use eventually matcher Some tests esp. seem to fail because of a race condition. Add a Hamcrest matcher that knows how to read the content of a FileSink Source and refactor those to read like e.g. ",NULL,"Refactor tests with to use eventually matcher Some tests esp. seem to fail because of a race condition. Add a Hamcrest matcher that knows how to read the content of a FileSink Source and refactor those to read like e.g. ",NULL,"Refactor tests with to use eventually matcher Some tests esp<span class='highlight-text severity-high'>. seem to fail because of a race condition. Add a Hamcrest matcher that knows how to read the content of a FileSink Source and refactor those to read like e.g. </span>","minimal","punctuation","high",False
26955,"The HDFS Sink should support writing POJOs to HDFS using Parquet Writing POJOs using Kite SDK ",NULL,"The HDFS Sink should support writing POJOs to HDFS using Parquet Writing POJOs using Kite SDK ",NULL,"Add for who this story is","well_formed","no_role","high",False
26959,"Return the step execution information in the current job execution controller Related to overrides and does not include the StepExecution s. This is due to serializion issues with Jackson. In order to fix this, we need to add a Jackson MixIn. ",NULL,"Return the step execution information in the current job execution controller Related to overrides and does not include the StepExecution s. This is due to serializion issues with Jackson.","In order to fix this, we need to add a Jackson MixIn.","Add for who this story is","well_formed","no_role","high",False
26959,"Return the step execution information in the current job execution controller Related to overrides and does not include the StepExecution s. This is due to serializion issues with Jackson. In order to fix this, we need to add a Jackson MixIn. ",NULL,"Return the step execution information in the current job execution controller Related to overrides and does not include the StepExecution s. This is due to serializion issues with Jackson.","In order to fix this, we need to add a Jackson MixIn.","Return the step execution information in the current job execution controller Related to overrides<span class='highlight-text severity-high'> and </span>does not include the StepExecution s. This is due to serializion issues with Jackson. In order to fix this, we need to add a Jackson MixIn. ","atomic","conjunctions","high",False
26959,"Return the step execution information in the current job execution controller Related to overrides and does not include the StepExecution s. This is due to serializion issues with Jackson. In order to fix this, we need to add a Jackson MixIn. ",NULL,"Return the step execution information in the current job execution controller Related to overrides and does not include the StepExecution s. This is due to serializion issues with Jackson.","In order to fix this, we need to add a Jackson MixIn.","Return the step execution information in the current job execution controller Related to overrides and does not include the StepExecution s<span class='highlight-text severity-high'>. This is due to serializion issues with Jackson. In order to fix this, we need to add a Jackson MixIn. </span>","minimal","punctuation","high",False
26959,"Return the step execution information in the current job execution controller Related to overrides and does not include the StepExecution s. This is due to serializion issues with Jackson. In order to fix this, we need to add a Jackson MixIn. ",NULL,"Return the step execution information in the current job execution controller Related to overrides and does not include the StepExecution s. This is due to serializion issues with Jackson.","In order to fix this, we need to add a Jackson MixIn.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26957,"The HDFS Sink should support writing POJOs to HDFS using Avro Kite SDK with support for partitioning The HDFS Sink should support writing POJOs to HDFS using Avro Kite SDK with support for partitioning Support for partitioning on a field, e.g. date. Support for partitioning on a field, e.g. date.",NULL,"The HDFS Sink should support writing POJOs to HDFS using Avro Kite SDK with support for partitioning The HDFS Sink should support writing POJOs to HDFS using Avro Kite SDK with support for partitioning Support for partitioning on a field, e.g. date. Support for partitioning on a field, e.g. date.",NULL,"Add for who this story is","well_formed","no_role","high",False
26957,"The HDFS Sink should support writing POJOs to HDFS using Avro Kite SDK with support for partitioning The HDFS Sink should support writing POJOs to HDFS using Avro Kite SDK with support for partitioning Support for partitioning on a field, e.g. date. Support for partitioning on a field, e.g. date.",NULL,"The HDFS Sink should support writing POJOs to HDFS using Avro Kite SDK with support for partitioning The HDFS Sink should support writing POJOs to HDFS using Avro Kite SDK with support for partitioning Support for partitioning on a field, e.g. date. Support for partitioning on a field, e.g. date.",NULL,"The HDFS Sink should support writing POJOs to HDFS using Avro Kite SDK with support for partitioning The HDFS Sink should support writing POJOs to HDFS using Avro Kite SDK with support for partitioning Support for partitioning on a field, e<span class='highlight-text severity-high'>.g. date. Support for partitioning on a field, e.g. date.</span>","minimal","punctuation","high",False
26958,"Add documentation for gemfire cache listener source Need some sample usage, docs for ",NULL,"Add documentation for gemfire cache listener source Need some sample usage, docs for ",NULL,"Add for who this story is","well_formed","no_role","high",False
25992,"Support writing to HDFS using a SequenceFile using ",NULL,"Support writing to HDFS using a SequenceFile using ",NULL,"Add for who this story is","well_formed","no_role","high",False
26954,"The HDFS Store Library should support compression when writing to Sequence Files Support for using compression when writing Sequence Files Either block or record based compression. ",NULL,"The HDFS Store Library should support compression when writing to Sequence Files Support for using compression when writing Sequence Files Either block or record based compression. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26954,"The HDFS Store Library should support compression when writing to Sequence Files Support for using compression when writing Sequence Files Either block or record based compression. ",NULL,"The HDFS Store Library should support compression when writing to Sequence Files Support for using compression when writing Sequence Files Either block or record based compression. ",NULL,"The HDFS Store Library should support compression when writing to Sequence Files Support for using compression when writing Sequence Files Either block<span class='highlight-text severity-high'> or </span>record based compression. ","atomic","conjunctions","high",False
26945,"Bootstrap Project for XD AWS Installer Create a Spring application context. XML or Java, dealers choice Use XD eclipse code format policy Create Source Package structure Create Test Package Structure Gradle build JClouds and Spring deps ",NULL,"Bootstrap Project for XD AWS Installer Create a Spring application context. XML or Java, dealers choice Use XD eclipse code format policy Create Source Package structure Create Test Package Structure Gradle build JClouds and Spring deps ",NULL,"Add for who this story is","well_formed","no_role","high",False
26945,"Bootstrap Project for XD AWS Installer Create a Spring application context. XML or Java, dealers choice Use XD eclipse code format policy Create Source Package structure Create Test Package Structure Gradle build JClouds and Spring deps ",NULL,"Bootstrap Project for XD AWS Installer Create a Spring application context. XML or Java, dealers choice Use XD eclipse code format policy Create Source Package structure Create Test Package Structure Gradle build JClouds and Spring deps ",NULL,"Bootstrap Project for XD AWS Installer Create a Spring application context. XML<span class='highlight-text severity-high'> or </span>Java, dealers choice Use XD eclipse code format policy Create Source Package structure Create Test Package Structure Gradle build JClouds<span class='highlight-text severity-high'> and </span>Spring deps ","atomic","conjunctions","high",False
26945,"Bootstrap Project for XD AWS Installer Create a Spring application context. XML or Java, dealers choice Use XD eclipse code format policy Create Source Package structure Create Test Package Structure Gradle build JClouds and Spring deps ",NULL,"Bootstrap Project for XD AWS Installer Create a Spring application context. XML or Java, dealers choice Use XD eclipse code format policy Create Source Package structure Create Test Package Structure Gradle build JClouds and Spring deps ",NULL,"Bootstrap Project for XD AWS Installer Create a Spring application context<span class='highlight-text severity-high'>. XML or Java, dealers choice Use XD eclipse code format policy Create Source Package structure Create Test Package Structure Gradle build JClouds and Spring deps </span>","minimal","punctuation","high",False
26952,"Sonar build is failing Caused by at at at ... 94 more",NULL,"Sonar build is failing Caused by at at at ... 94 more",NULL,"Add for who this story is","well_formed","no_role","high",False
26952,"Sonar build is failing Caused by at at at ... 94 more",NULL,"Sonar build is failing Caused by at at at ... 94 more",NULL,"Sonar build is failing Caused by at at at <span class='highlight-text severity-high'>... 94 more</span>","minimal","punctuation","high",False
25715,"Remove logging of password in Shell As a user, I'd like to type the username and password to gain access to Admin server so that I don t have to add it in some file; hence I don t have to worry about having the password getting logged somewhere.",NULL,"Remove logging of password in Shell As a user, I'd like to type the username and password to gain access to Admin server","so that I don t have to add it in some file; hence I don t have to worry about having the password getting logged somewhere.","Add for who this story is","well_formed","no_role","high",False
25715,"Remove logging of password in Shell As a user, I'd like to type the username and password to gain access to Admin server so that I don t have to add it in some file; hence I don t have to worry about having the password getting logged somewhere.",NULL,"Remove logging of password in Shell As a user, I'd like to type the username and password to gain access to Admin server","so that I don t have to add it in some file; hence I don t have to worry about having the password getting logged somewhere.","Remove logging of password in Shell As a user, I'd like to type the username<span class='highlight-text severity-high'> and </span>password to gain access to Admin server so that I don t have to add it in some file; hence I don t have to worry about having the password getting logged somewhere.","atomic","conjunctions","high",False
25715,"Remove logging of password in Shell As a user, I'd like to type the username and password to gain access to Admin server so that I don t have to add it in some file; hence I don t have to worry about having the password getting logged somewhere.",NULL,"Remove logging of password in Shell As a user, I'd like to type the username and password to gain access to Admin server","so that I don t have to add it in some file; hence I don t have to worry about having the password getting logged somewhere.","Remove logging of password in Shell As a user, I'd like to type the username and password to gain access to Admin server so that I don t have to add it in some file<span class='highlight-text severity-high'>; hence I don t have to worry about having the password getting logged somewhere.</span>","minimal","punctuation","high",False
25715,"Remove logging of password in Shell As a user, I'd like to type the username and password to gain access to Admin server so that I don t have to add it in some file; hence I don t have to worry about having the password getting logged somewhere.",NULL,"Remove logging of password in Shell As a user, I'd like to type the username and password to gain access to Admin server","so that I don t have to add it in some file; hence I don t have to worry about having the password getting logged somewhere.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25719,"Baseline tcp measurements DB 1 Using the iperf tool find out the transfer rate in MB sec between three machines in a four machine configuration.",NULL,"Baseline tcp measurements DB 1 Using the iperf tool find out the transfer rate in MB sec between three machines in a four machine configuration.",NULL,"Add for who this story is","well_formed","no_role","high",False
25750,"UI Add support for stoppable notifications Update Angular Growl to v2 Allowing for stoppable notifications in case you want to see it for longer than 5 secs ",NULL,"UI Add support for stoppable notifications Update Angular Growl to v2 Allowing for stoppable notifications in case you want to see it for longer than 5 secs ",NULL,"Add for who this story is","well_formed","no_role","high",False
26121,"Upgrade to 1.2.0 RC1 SIK release ",NULL,"Upgrade to 1.2.0 RC1 SIK release ",NULL,"Add for who this story is","well_formed","no_role","high",False
26126,"Add Logging to Occasional CI test build failures Caused by Container cache not initialized likely as a result of a ZooKeeper connection error at at at e.g. Add logging to to log that the cache was closed; it appears that s the only way the cache not initialized message can be emitted.",NULL,"Add Logging to Occasional CI test build failures Caused by Container cache not initialized likely as a result of a ZooKeeper connection error at at at e.g. Add logging to to log that the cache was closed; it appears that s the only way the cache not initialized message can be emitted.",NULL,"Add for who this story is","well_formed","no_role","high",False
26126,"Add Logging to Occasional CI test build failures Caused by Container cache not initialized likely as a result of a ZooKeeper connection error at at at e.g. Add logging to to log that the cache was closed; it appears that s the only way the cache not initialized message can be emitted.",NULL,"Add Logging to Occasional CI test build failures Caused by Container cache not initialized likely as a result of a ZooKeeper connection error at at at e.g. Add logging to to log that the cache was closed; it appears that s the only way the cache not initialized message can be emitted.",NULL,"Add Logging to Occasional CI test build failures Caused by Container cache not initialized likely as a result of a ZooKeeper connection error at at at e<span class='highlight-text severity-high'>.g. Add logging to to log that the cache was closed; it appears that s the only way the cache not initialized message can be emitted.</span>","minimal","punctuation","high",False
26278,"Refactor Task parsing Currently the DSL parsing for tasks is a copy and paste of what it is for streams minus the ability to parse multiple modules . This results in a lot of duplication. This should be refactored to remove duplication and remove explicit references to either streams or tasks in common code.",NULL,"Refactor Task parsing Currently the DSL parsing for tasks is a copy and paste of what it is for streams minus the ability to parse multiple modules . This results in a lot of duplication. This should be refactored to remove duplication and remove explicit references to either streams or tasks in common code.",NULL,"Add for who this story is","well_formed","no_role","high",False
26278,"Refactor Task parsing Currently the DSL parsing for tasks is a copy and paste of what it is for streams minus the ability to parse multiple modules . This results in a lot of duplication. This should be refactored to remove duplication and remove explicit references to either streams or tasks in common code.",NULL,"Refactor Task parsing Currently the DSL parsing for tasks is a copy and paste of what it is for streams minus the ability to parse multiple modules . This results in a lot of duplication. This should be refactored to remove duplication and remove explicit references to either streams or tasks in common code.",NULL,"Refactor Task parsing Currently the DSL parsing for tasks is a copy<span class='highlight-text severity-high'> and </span>paste of what it is for streams minus the ability to parse multiple modules . This results in a lot of duplication. This should be refactored to remove duplication and remove explicit references to either streams<span class='highlight-text severity-high'> or </span>tasks in common code.","atomic","conjunctions","high",False
26278,"Refactor Task parsing Currently the DSL parsing for tasks is a copy and paste of what it is for streams minus the ability to parse multiple modules . This results in a lot of duplication. This should be refactored to remove duplication and remove explicit references to either streams or tasks in common code.",NULL,"Refactor Task parsing Currently the DSL parsing for tasks is a copy and paste of what it is for streams minus the ability to parse multiple modules . This results in a lot of duplication. This should be refactored to remove duplication and remove explicit references to either streams or tasks in common code.",NULL,"Refactor Task parsing Currently the DSL parsing for tasks is a copy and paste of what it is for streams minus the ability to parse multiple modules <span class='highlight-text severity-high'>. This results in a lot of duplication. This should be refactored to remove duplication and remove explicit references to either streams or tasks in common code.</span>","minimal","punctuation","high",False
25381,"Remove use of application plugin for redis project Currently redis project uses application plugin to bundle distribution. This also includes java plugin which causes java specific build behavior on this project. We should try removing the use of application plugin and use something similar or custom tasks that does the bundling. ",NULL,"Remove use of application plugin for redis project Currently redis project uses application plugin to bundle distribution. This also includes java plugin which causes java specific build behavior on this project. We should try removing the use of application plugin and use something similar or custom tasks that does the bundling. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25381,"Remove use of application plugin for redis project Currently redis project uses application plugin to bundle distribution. This also includes java plugin which causes java specific build behavior on this project. We should try removing the use of application plugin and use something similar or custom tasks that does the bundling. ",NULL,"Remove use of application plugin for redis project Currently redis project uses application plugin to bundle distribution. This also includes java plugin which causes java specific build behavior on this project. We should try removing the use of application plugin and use something similar or custom tasks that does the bundling. ",NULL,"Remove use of application plugin for redis project Currently redis project uses application plugin to bundle distribution. This also includes java plugin which causes java specific build behavior on this project. We should try removing the use of application plugin<span class='highlight-text severity-high'> and </span>use something similar<span class='highlight-text severity-high'> or </span>custom tasks that does the bundling. ","atomic","conjunctions","high",False
25845,"Add support to extend message compression As a user, I'd like to have the option to extend compression support so that I can override the defaults and customize as needed. Follow up from this PR ",NULL,"Add support to extend message compression As a user, I'd like to have the option to extend compression support","so that I can override the defaults and customize as needed. Follow up from this PR","Add support to extend message compression As a user, I'd like to have the option to extend compression support so that I can override the defaults and customize as needed<span class='highlight-text severity-high'>. Follow up from this PR </span>","minimal","punctuation","high",False
25381,"Remove use of application plugin for redis project Currently redis project uses application plugin to bundle distribution. This also includes java plugin which causes java specific build behavior on this project. We should try removing the use of application plugin and use something similar or custom tasks that does the bundling. ",NULL,"Remove use of application plugin for redis project Currently redis project uses application plugin to bundle distribution. This also includes java plugin which causes java specific build behavior on this project. We should try removing the use of application plugin and use something similar or custom tasks that does the bundling. ",NULL,"Remove use of application plugin for redis project Currently redis project uses application plugin to bundle distribution<span class='highlight-text severity-high'>. This also includes java plugin which causes java specific build behavior on this project. We should try removing the use of application plugin and use something similar or custom tasks that does the bundling. </span>","minimal","punctuation","high",False
25520,"Add HdfsMongoDb Acceptance Test. Create Acceptance Test Add Mongo to Ec2 Acceptance Test Environment.",NULL,"Add HdfsMongoDb Acceptance Test. Create Acceptance Test Add Mongo to Ec2 Acceptance Test Environment.",NULL,"Add for who this story is","well_formed","no_role","high",False
25520,"Add HdfsMongoDb Acceptance Test. Create Acceptance Test Add Mongo to Ec2 Acceptance Test Environment.",NULL,"Add HdfsMongoDb Acceptance Test. Create Acceptance Test Add Mongo to Ec2 Acceptance Test Environment.",NULL,"Add HdfsMongoDb Acceptance Test<span class='highlight-text severity-high'>. Create Acceptance Test Add Mongo to Ec2 Acceptance Test Environment.</span>","minimal","punctuation","high",False
25096,"Convert hadoop module to isolated classloader scheme rename to something else, as it seems it is all spring data stuff and is not coupled to xd. But leave it in extensions for now rename and move spring xd hadoop inside extensions maybe to or hdfs make hadoop related modules depend on the latter which itself will depend on the former ",NULL,"Convert hadoop module to isolated classloader scheme rename to something else, as it seems it is all spring data stuff and is not coupled to xd. But leave it in extensions for now rename and move spring xd hadoop inside extensions maybe to or hdfs make hadoop related modules depend on the latter which itself will depend on the former ",NULL,"Add for who this story is","well_formed","no_role","high",False
25096,"Convert hadoop module to isolated classloader scheme rename to something else, as it seems it is all spring data stuff and is not coupled to xd. But leave it in extensions for now rename and move spring xd hadoop inside extensions maybe to or hdfs make hadoop related modules depend on the latter which itself will depend on the former ",NULL,"Convert hadoop module to isolated classloader scheme rename to something else, as it seems it is all spring data stuff and is not coupled to xd. But leave it in extensions for now rename and move spring xd hadoop inside extensions maybe to or hdfs make hadoop related modules depend on the latter which itself will depend on the former ",NULL,"Convert hadoop module to isolated classloader scheme rename to something else, as it seems it is all spring data stuff<span class='highlight-text severity-high'> and </span>is not coupled to xd. But leave it in extensions for now rename and move spring xd hadoop inside extensions maybe to<span class='highlight-text severity-high'> or </span>hdfs make hadoop related modules depend on the latter which itself will depend on the former ","atomic","conjunctions","high",False
25096,"Convert hadoop module to isolated classloader scheme rename to something else, as it seems it is all spring data stuff and is not coupled to xd. But leave it in extensions for now rename and move spring xd hadoop inside extensions maybe to or hdfs make hadoop related modules depend on the latter which itself will depend on the former ",NULL,"Convert hadoop module to isolated classloader scheme rename to something else, as it seems it is all spring data stuff and is not coupled to xd. But leave it in extensions for now rename and move spring xd hadoop inside extensions maybe to or hdfs make hadoop related modules depend on the latter which itself will depend on the former ",NULL,"Convert hadoop module to isolated classloader scheme rename to something else, as it seems it is all spring data stuff and is not coupled to xd<span class='highlight-text severity-high'>. But leave it in extensions for now rename and move spring xd hadoop inside extensions maybe to or hdfs make hadoop related modules depend on the latter which itself will depend on the former </span>","minimal","punctuation","high",False
25125,"Build script should not package spring xd dirt scripts We are packaging separate scripts to start XDAdmin and XDContainer. The Gradle application plugin will generate an unwanted spring xd dirt scripts, this should be removed from the bin directory when creating a distribution zip.",NULL,"Build script should not package spring xd dirt scripts We are packaging separate scripts to start XDAdmin and XDContainer. The Gradle application plugin will generate an unwanted spring xd dirt scripts, this should be removed from the bin directory when creating a distribution zip.",NULL,"Add for who this story is","well_formed","no_role","high",False
25125,"Build script should not package spring xd dirt scripts We are packaging separate scripts to start XDAdmin and XDContainer. The Gradle application plugin will generate an unwanted spring xd dirt scripts, this should be removed from the bin directory when creating a distribution zip.",NULL,"Build script should not package spring xd dirt scripts We are packaging separate scripts to start XDAdmin and XDContainer. The Gradle application plugin will generate an unwanted spring xd dirt scripts, this should be removed from the bin directory when creating a distribution zip.",NULL,"Build script should not package spring xd dirt scripts We are packaging separate scripts to start XDAdmin and XDContainer<span class='highlight-text severity-high'>. The Gradle application plugin will generate an unwanted spring xd dirt scripts, this should be removed from the bin directory when creating a distribution zip.</span>","minimal","punctuation","high",False
26478,"Update default configs to support Composed Jobs Users want the ability to use Composed Jobs specifically parallel Jobs without having to update the configurations for the hsqldb and the Isolation Level for spring batch. These should be set by default. ",NULL,"Update default configs to support Composed Jobs Users want the ability to use Composed Jobs specifically parallel Jobs without having to update the configurations for the hsqldb and the Isolation Level for spring batch. These should be set by default. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26478,"Update default configs to support Composed Jobs Users want the ability to use Composed Jobs specifically parallel Jobs without having to update the configurations for the hsqldb and the Isolation Level for spring batch. These should be set by default. ",NULL,"Update default configs to support Composed Jobs Users want the ability to use Composed Jobs specifically parallel Jobs without having to update the configurations for the hsqldb and the Isolation Level for spring batch. These should be set by default. ",NULL,"Update default configs to support Composed Jobs Users want the ability to use Composed Jobs specifically parallel Jobs without having to update the configurations for the hsqldb and the Isolation Level for spring batch<span class='highlight-text severity-high'>. These should be set by default. </span>","minimal","punctuation","high",False
26555,"The user needs the ability to set up a end time where the trigger should no longer be in effect. ",NULL,"The user needs the ability to set up a end time where the trigger should no longer be in effect. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26557,"Remove the expiry of keys in Redis based repositories There is duplicated code in Redis based repositories that related to expiry behavior, move into a common shared helper class and or base class.",NULL,"Remove the expiry of keys in Redis based repositories There is duplicated code in Redis based repositories that related to expiry behavior, move into a common shared helper class and or base class.",NULL,"Add for who this story is","well_formed","no_role","high",False
26557,"Remove the expiry of keys in Redis based repositories There is duplicated code in Redis based repositories that related to expiry behavior, move into a common shared helper class and or base class.",NULL,"Remove the expiry of keys in Redis based repositories There is duplicated code in Redis based repositories that related to expiry behavior, move into a common shared helper class and or base class.",NULL,"Remove the expiry of keys in Redis based repositories There is duplicated code in Redis based repositories that related to expiry behavior, move into a common shared helper class<span class='highlight-text severity-high'> and </span>span class='highlight-text severity-high'> or </span>base class.","atomic","conjunctions","high",False
26484,"Add command for deploying a Stream Deploy a named stream. The stream must exist in the StreamRepository",NULL,"Add command for deploying a Stream Deploy a named stream. The stream must exist in the StreamRepository",NULL,"Add for who this story is","well_formed","no_role","high",False
26484,"Add command for deploying a Stream Deploy a named stream. The stream must exist in the StreamRepository",NULL,"Add command for deploying a Stream Deploy a named stream. The stream must exist in the StreamRepository",NULL,"Add command for deploying a Stream Deploy a named stream<span class='highlight-text severity-high'>. The stream must exist in the StreamRepository</span>","minimal","punctuation","high",False
26566,"The user needs the ability to pause and resume triggers based on a calendar. ",NULL,"The user needs the ability to pause and resume triggers based on a calendar. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26566,"The user needs the ability to pause and resume triggers based on a calendar. ",NULL,"The user needs the ability to pause and resume triggers based on a calendar. ",NULL,"The user needs the ability to pause<span class='highlight-text severity-high'> and </span>resume triggers based on a calendar. ","atomic","conjunctions","high",False
26778,"Create Syslog Tuple Reactor Codec; Change UDP Syslog Adapter to Emit a Tuple UDP and Legacy syslog sources emit a s.",NULL,"Create Syslog Tuple Reactor Codec; Change UDP Syslog Adapter to Emit a Tuple UDP and Legacy syslog sources emit a s.",NULL,"Add for who this story is","well_formed","no_role","high",False
26778,"Create Syslog Tuple Reactor Codec; Change UDP Syslog Adapter to Emit a Tuple UDP and Legacy syslog sources emit a s.",NULL,"Create Syslog Tuple Reactor Codec; Change UDP Syslog Adapter to Emit a Tuple UDP and Legacy syslog sources emit a s.",NULL,"Create Syslog Tuple Reactor Codec; Change UDP Syslog Adapter to Emit a Tuple UDP<span class='highlight-text severity-high'> and </span>Legacy syslog sources emit a s.","atomic","conjunctions","high",False
26778,"Create Syslog Tuple Reactor Codec; Change UDP Syslog Adapter to Emit a Tuple UDP and Legacy syslog sources emit a s.",NULL,"Create Syslog Tuple Reactor Codec; Change UDP Syslog Adapter to Emit a Tuple UDP and Legacy syslog sources emit a s.",NULL,"Create Syslog Tuple Reactor Codec<span class='highlight-text severity-high'>; Change UDP Syslog Adapter to Emit a Tuple UDP and Legacy syslog sources emit a s.</span>","minimal","punctuation","high",False
26780,"Add gemfire server application to the distribution zip of the project ",NULL,"Add gemfire server application to the distribution zip of the project ",NULL,"Add for who this story is","well_formed","no_role","high",False
26788,"Factor out duplicated SpEL script logic See discussion at ",NULL,"Factor out duplicated SpEL script logic See discussion at ",NULL,"Add for who this story is","well_formed","no_role","high",False
26789,"Need to create a In order to hook up the to get access to all the jobs available the job registry has to be shared. currently the only implmentation is is the MapJobRegistry. Testability. The admin will need to be see all jobs created by its containers.",NULL,"Need to create a","In order to hook up the to get access to all the jobs available the job registry has to be shared. currently the only implmentation is is the MapJobRegistry. Testability. The admin will need to be see all jobs created by its containers.","Add for who this story is","well_formed","no_role","high",False
26789,"Need to create a In order to hook up the to get access to all the jobs available the job registry has to be shared. currently the only implmentation is is the MapJobRegistry. Testability. The admin will need to be see all jobs created by its containers.",NULL,"Need to create a","In order to hook up the to get access to all the jobs available the job registry has to be shared. currently the only implmentation is is the MapJobRegistry. Testability. The admin will need to be see all jobs created by its containers.","Need to create a In order to hook up the to get access to all the jobs available the job registry has to be shared<span class='highlight-text severity-high'>. currently the only implmentation is is the MapJobRegistry. Testability. The admin will need to be see all jobs created by its containers.</span>","minimal","punctuation","high",False
26789,"Need to create a In order to hook up the to get access to all the jobs available the job registry has to be shared. currently the only implmentation is is the MapJobRegistry. Testability. The admin will need to be see all jobs created by its containers.",NULL,"Need to create a","In order to hook up the to get access to all the jobs available the job registry has to be shared. currently the only implmentation is is the MapJobRegistry. Testability. The admin will need to be see all jobs created by its containers.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25127,"Documentation for starting Spring XD servers ",NULL,"Documentation for starting Spring XD servers ",NULL,"Add for who this story is","well_formed","no_role","high",False
25132,"Create microbenchmark for performace of redis and jdbc based aggregators would be good to have a general feel for the general performance of these two options. Redis can run on the same node as the benchmark.",NULL,"Create microbenchmark for performace of redis and jdbc based aggregators would be good to have a general feel for the general performance of these two options. Redis can run on the same node as the benchmark.",NULL,"Add for who this story is","well_formed","no_role","high",False
25132,"Create microbenchmark for performace of redis and jdbc based aggregators would be good to have a general feel for the general performance of these two options. Redis can run on the same node as the benchmark.",NULL,"Create microbenchmark for performace of redis and jdbc based aggregators would be good to have a general feel for the general performance of these two options. Redis can run on the same node as the benchmark.",NULL,"Create microbenchmark for performace of redis<span class='highlight-text severity-high'> and </span>jdbc based aggregators would be good to have a general feel for the general performance of these two options. Redis can run on the same node as the benchmark.","atomic","conjunctions","high",False
25132,"Create microbenchmark for performace of redis and jdbc based aggregators would be good to have a general feel for the general performance of these two options. Redis can run on the same node as the benchmark.",NULL,"Create microbenchmark for performace of redis and jdbc based aggregators would be good to have a general feel for the general performance of these two options. Redis can run on the same node as the benchmark.",NULL,"Create microbenchmark for performace of redis and jdbc based aggregators would be good to have a general feel for the general performance of these two options<span class='highlight-text severity-high'>. Redis can run on the same node as the benchmark.</span>","minimal","punctuation","high",False
25135,"Create Mock on instead of instantiating object Currently, the tests use instantiated object instead of a simple mock. We can just use mock object for the tests.",NULL,"Create Mock on instead of instantiating object Currently, the tests use instantiated object instead of a simple mock. We can just use mock object for the tests.",NULL,"Add for who this story is","well_formed","no_role","high",False
25135,"Create Mock on instead of instantiating object Currently, the tests use instantiated object instead of a simple mock. We can just use mock object for the tests.",NULL,"Create Mock on instead of instantiating object Currently, the tests use instantiated object instead of a simple mock. We can just use mock object for the tests.",NULL,"Create Mock on instead of instantiating object Currently, the tests use instantiated object instead of a simple mock<span class='highlight-text severity-high'>. We can just use mock object for the tests.</span>","minimal","punctuation","high",False
25148,"Better error messages following XD 1109 2 forces at heand here Spring binding validation itself jsr303 for eg NotNull ",NULL,"Better error messages following XD 1109 2 forces at heand here Spring binding validation itself jsr303 for eg NotNull ",NULL,"Add for who this story is","well_formed","no_role","high",False
25228,"Add to Acceptance Test EC2 CI build plan a stage that stops any existing CI EC2 deployments Add a stage to the plan that will stop any instances that the CI process may have started before and relaunch a 2 node install based on rabbit. was created as an empty shell. The running of across different transports will be handled in a separate story along with adding a stage to run a hello world acceptance test. ",NULL,"Add to Acceptance Test EC2 CI build plan a stage that stops any existing CI EC2 deployments Add a stage to the plan that will stop any instances that the CI process may have started before and relaunch a 2 node install based on rabbit. was created as an empty shell. The running of across different transports will be handled in a separate story along with adding a stage to run a hello world acceptance test. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25228,"Add to Acceptance Test EC2 CI build plan a stage that stops any existing CI EC2 deployments Add a stage to the plan that will stop any instances that the CI process may have started before and relaunch a 2 node install based on rabbit. was created as an empty shell. The running of across different transports will be handled in a separate story along with adding a stage to run a hello world acceptance test. ",NULL,"Add to Acceptance Test EC2 CI build plan a stage that stops any existing CI EC2 deployments Add a stage to the plan that will stop any instances that the CI process may have started before and relaunch a 2 node install based on rabbit. was created as an empty shell. The running of across different transports will be handled in a separate story along with adding a stage to run a hello world acceptance test. ",NULL,"Add to Acceptance Test EC2 CI build plan a stage that stops any existing CI EC2 deployments Add a stage to the plan that will stop any instances that the CI process may have started before<span class='highlight-text severity-high'> and </span>relaunch a 2 node install based on rabbit. was created as an empty shell. The running of across different transports will be handled in a separate story along with adding a stage to run a hello world acceptance test. ","atomic","conjunctions","high",False
25845,"Add support to extend message compression As a user, I'd like to have the option to extend compression support so that I can override the defaults and customize as needed. Follow up from this PR ",NULL,"Add support to extend message compression As a user, I'd like to have the option to extend compression support","so that I can override the defaults and customize as needed. Follow up from this PR","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25871,"Create MessageConverter interface to allow user extensions As a user, I'd like to have the option to extend the default message handling behavior for HTTP source module so that I can override the settings via servers.yml to control the default message size. Notes The adapter currently has that hard coded 1MB limit in the We will have to expose this property for overrides. Related PR ",NULL,"Create MessageConverter interface to allow user extensions As a user, I'd like to have the option to extend the default message handling behavior for HTTP source module","so that I can override the settings via servers.yml to control the default message size. Notes The adapter currently has that hard coded 1MB limit in the We will have to expose this property for overrides. Related PR","Add for who this story is","well_formed","no_role","high",False
26235,"Retrieve information for an aggregate counter TODO as part of this see XD 537 Get rid of so called Service layer in analytics project doesn t do much right now, and logic would better live in the Handler IMO Have REST controllers depend on XRepository in all cases",NULL,"Retrieve information for an aggregate counter TODO as part of this see XD 537 Get rid of","so called Service layer in analytics project doesn t do much right now, and logic would better live in the Handler IMO Have REST controllers depend on XRepository in all cases","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25228,"Add to Acceptance Test EC2 CI build plan a stage that stops any existing CI EC2 deployments Add a stage to the plan that will stop any instances that the CI process may have started before and relaunch a 2 node install based on rabbit. was created as an empty shell. The running of across different transports will be handled in a separate story along with adding a stage to run a hello world acceptance test. ",NULL,"Add to Acceptance Test EC2 CI build plan a stage that stops any existing CI EC2 deployments Add a stage to the plan that will stop any instances that the CI process may have started before and relaunch a 2 node install based on rabbit. was created as an empty shell. The running of across different transports will be handled in a separate story along with adding a stage to run a hello world acceptance test. ",NULL,"Add to Acceptance Test EC2 CI build plan a stage that stops any existing CI EC2 deployments Add a stage to the plan that will stop any instances that the CI process may have started before and relaunch a 2 node install based on rabbit<span class='highlight-text severity-high'>. was created as an empty shell. The running of across different transports will be handled in a separate story along with adding a stage to run a hello world acceptance test. </span>","minimal","punctuation","high",False
25250,"Allow for late binding of module options defaults This is about computing the value to support expressions such as as a default. Initial discussion suggested to leverage the work done in XD 1175 by having a custom LateValue or DeployTimeValue, etc be resolved at deployment time",NULL,"Allow for late binding of module options defaults This is about computing the value to support expressions such as as a default. Initial discussion suggested to leverage the work done in XD 1175 by having a custom LateValue or DeployTimeValue, etc be resolved at deployment time",NULL,"Add for who this story is","well_formed","no_role","high",False
25250,"Allow for late binding of module options defaults This is about computing the value to support expressions such as as a default. Initial discussion suggested to leverage the work done in XD 1175 by having a custom LateValue or DeployTimeValue, etc be resolved at deployment time",NULL,"Allow for late binding of module options defaults This is about computing the value to support expressions such as as a default. Initial discussion suggested to leverage the work done in XD 1175 by having a custom LateValue or DeployTimeValue, etc be resolved at deployment time",NULL,"Allow for late binding of module options defaults This is about computing the value to support expressions such as as a default. Initial discussion suggested to leverage the work done in XD 1175 by having a custom LateValue<span class='highlight-text severity-high'> or </span>DeployTimeValue, etc be resolved at deployment time","atomic","conjunctions","high",False
25250,"Allow for late binding of module options defaults This is about computing the value to support expressions such as as a default. Initial discussion suggested to leverage the work done in XD 1175 by having a custom LateValue or DeployTimeValue, etc be resolved at deployment time",NULL,"Allow for late binding of module options defaults This is about computing the value to support expressions such as as a default. Initial discussion suggested to leverage the work done in XD 1175 by having a custom LateValue or DeployTimeValue, etc be resolved at deployment time",NULL,"Allow for late binding of module options defaults This is about computing the value to support expressions such as as a default<span class='highlight-text severity-high'>. Initial discussion suggested to leverage the work done in XD 1175 by having a custom LateValue or DeployTimeValue, etc be resolved at deployment time</span>","minimal","punctuation","high",False
25090,"UI Implement Job Deploy Undeploy from the Job Definitions page From XD 1023, the job is available from JobInstance Repository and a job can be correctly. Implement Job deploy undeploy for a given job from JobDefinitions page and indicate status of the job definition ",NULL,"UI Implement Job Deploy Undeploy from the Job Definitions page From XD 1023, the job is available from JobInstance Repository and a job can be correctly. Implement Job deploy undeploy for a given job from JobDefinitions page and indicate status of the job definition ",NULL,"Add for who this story is","well_formed","no_role","high",False
25090,"UI Implement Job Deploy Undeploy from the Job Definitions page From XD 1023, the job is available from JobInstance Repository and a job can be correctly. Implement Job deploy undeploy for a given job from JobDefinitions page and indicate status of the job definition ",NULL,"UI Implement Job Deploy Undeploy from the Job Definitions page From XD 1023, the job is available from JobInstance Repository and a job can be correctly. Implement Job deploy undeploy for a given job from JobDefinitions page and indicate status of the job definition ",NULL,"UI Implement Job Deploy Undeploy from the Job Definitions page From XD 1023, the job is available from JobInstance Repository<span class='highlight-text severity-high'> and </span>a job can be correctly. Implement Job deploy undeploy for a given job from JobDefinitions page and indicate status of the job definition ","atomic","conjunctions","high",False
25090,"UI Implement Job Deploy Undeploy from the Job Definitions page From XD 1023, the job is available from JobInstance Repository and a job can be correctly. Implement Job deploy undeploy for a given job from JobDefinitions page and indicate status of the job definition ",NULL,"UI Implement Job Deploy Undeploy from the Job Definitions page From XD 1023, the job is available from JobInstance Repository and a job can be correctly. Implement Job deploy undeploy for a given job from JobDefinitions page and indicate status of the job definition ",NULL,"UI Implement Job Deploy Undeploy from the Job Definitions page From XD 1023, the job is available from JobInstance Repository and a job can be correctly<span class='highlight-text severity-high'>. Implement Job deploy undeploy for a given job from JobDefinitions page and indicate status of the job definition </span>","minimal","punctuation","high",False
25706,"Enhance JDBC sink test to include more options To enrich acceptance test, I'd like to add coverage to JDBC sink by including driverclass and url options.",NULL,"Enhance JDBC sink test to include more options To enrich acceptance test, I'd like to add coverage to JDBC sink by including driverclass and url options.",NULL,"Add for who this story is","well_formed","no_role","high",False
25091,"UI Responsive layout for supported user agents Mobile, Tablet and Desktop The current admin UI uses bootstrap 3.0.0 which provides responsive design. We need to expand our scope to support all supported user agents. This requires changes to use user agent specific layout for the UI views.",NULL,"UI Responsive layout for supported user agents Mobile, Tablet and Desktop The current admin UI uses bootstrap 3.0.0 which provides responsive design. We need to expand our scope to support all supported user agents. This requires changes to use user agent specific layout for the UI views.",NULL,"Add for who this story is","well_formed","no_role","high",False
25091,"UI Responsive layout for supported user agents Mobile, Tablet and Desktop The current admin UI uses bootstrap 3.0.0 which provides responsive design. We need to expand our scope to support all supported user agents. This requires changes to use user agent specific layout for the UI views.",NULL,"UI Responsive layout for supported user agents Mobile, Tablet and Desktop The current admin UI uses bootstrap 3.0.0 which provides responsive design. We need to expand our scope to support all supported user agents. This requires changes to use user agent specific layout for the UI views.",NULL,"UI Responsive layout for supported user agents Mobile, Tablet<span class='highlight-text severity-high'> and </span>Desktop The current admin UI uses bootstrap 3.0.0 which provides responsive design. We need to expand our scope to support all supported user agents. This requires changes to use user agent specific layout for the UI views.","atomic","conjunctions","high",False
25091,"UI Responsive layout for supported user agents Mobile, Tablet and Desktop The current admin UI uses bootstrap 3.0.0 which provides responsive design. We need to expand our scope to support all supported user agents. This requires changes to use user agent specific layout for the UI views.",NULL,"UI Responsive layout for supported user agents Mobile, Tablet and Desktop The current admin UI uses bootstrap 3.0.0 which provides responsive design. We need to expand our scope to support all supported user agents. This requires changes to use user agent specific layout for the UI views.",NULL,"UI Responsive layout for supported user agents Mobile, Tablet and Desktop The current admin UI uses bootstrap 3<span class='highlight-text severity-high'>.0.0 which provides responsive design. We need to expand our scope to support all supported user agents. This requires changes to use user agent specific layout for the UI views.</span>","minimal","punctuation","high",False
25086,"Cleanup ModuleDeployer ModuleDeployer has many methods with very similar names that are hard to understand. Moreover, there is a substantial amount of duplicated code that should be extracted in sub methods with descriptive names. One should even consider splitting the class ",NULL,"Cleanup ModuleDeployer ModuleDeployer has many methods with very similar names that are hard to understand. Moreover, there is a substantial amount of duplicated code that should be extracted in sub methods with descriptive names. One should even consider splitting the class ",NULL,"Add for who this story is","well_formed","no_role","high",False
25086,"Cleanup ModuleDeployer ModuleDeployer has many methods with very similar names that are hard to understand. Moreover, there is a substantial amount of duplicated code that should be extracted in sub methods with descriptive names. One should even consider splitting the class ",NULL,"Cleanup ModuleDeployer ModuleDeployer has many methods with very similar names that are hard to understand. Moreover, there is a substantial amount of duplicated code that should be extracted in sub methods with descriptive names. One should even consider splitting the class ",NULL,"Cleanup ModuleDeployer ModuleDeployer has many methods with very similar names that are hard to understand<span class='highlight-text severity-high'>. Moreover, there is a substantial amount of duplicated code that should be extracted in sub methods with descriptive names. One should even consider splitting the class </span>","minimal","punctuation","high",False
25076,"User should be able to view the list of all Deployed Jobs On clicking the Deployed Jobs , we can have a table view of all the deployed jobs. This is again a responsive table layout with all the job definitions with status deployed . The deployed XD job corresponds to a single batch Job Instance. This story addresses the UI layout changes to display existing JobInstance information.",NULL,"User should be able to view the list of all Deployed Jobs On clicking the Deployed Jobs , we can have a table view of all the deployed jobs. This is again a responsive table layout with all the job definitions with status deployed . The deployed XD job corresponds to a single batch Job Instance. This story addresses the UI layout changes to display existing JobInstance information.",NULL,"Add for who this story is","well_formed","no_role","high",False
25076,"User should be able to view the list of all Deployed Jobs On clicking the Deployed Jobs , we can have a table view of all the deployed jobs. This is again a responsive table layout with all the job definitions with status deployed . The deployed XD job corresponds to a single batch Job Instance. This story addresses the UI layout changes to display existing JobInstance information.",NULL,"User should be able to view the list of all Deployed Jobs On clicking the Deployed Jobs , we can have a table view of all the deployed jobs. This is again a responsive table layout with all the job definitions with status deployed . The deployed XD job corresponds to a single batch Job Instance. This story addresses the UI layout changes to display existing JobInstance information.",NULL,"User should be able to view the list of all Deployed Jobs On clicking the Deployed Jobs , we can have a table view of all the deployed jobs<span class='highlight-text severity-high'>. This is again a responsive table layout with all the job definitions with status deployed . The deployed XD job corresponds to a single batch Job Instance. This story addresses the UI layout changes to display existing JobInstance information.</span>","minimal","punctuation","high",False
25097,"Add a tcp client source module Add a module that can act as a tcp client as opposed to our current tcp module, which acts as a server, waiting for an incoming connection Also, the module should allow to send commands to the remote server. The typical minimal case for such a protocol is to send PING messages, but a stateful mechanism should be put in place for more complex cases.",NULL,"Add a tcp client source module Add a module that can act as a tcp client as opposed to our current tcp module, which acts as a server, waiting for an incoming connection Also, the module should allow to send commands to the remote server. The typical minimal case for such a protocol is to send PING messages, but a stateful mechanism should be put in place for more complex cases.",NULL,"Add for who this story is","well_formed","no_role","high",False
25097,"Add a tcp client source module Add a module that can act as a tcp client as opposed to our current tcp module, which acts as a server, waiting for an incoming connection Also, the module should allow to send commands to the remote server. The typical minimal case for such a protocol is to send PING messages, but a stateful mechanism should be put in place for more complex cases.",NULL,"Add a tcp client source module Add a module that can act as a tcp client as opposed to our current tcp module, which acts as a server, waiting for an incoming connection Also, the module should allow to send commands to the remote server. The typical minimal case for such a protocol is to send PING messages, but a stateful mechanism should be put in place for more complex cases.",NULL,"Add a tcp client source module Add a module that can act as a tcp client as opposed to our current tcp module, which acts as a server, waiting for an incoming connection Also, the module should allow to send commands to the remote server<span class='highlight-text severity-high'>. The typical minimal case for such a protocol is to send PING messages, but a stateful mechanism should be put in place for more complex cases.</span>","minimal","punctuation","high",False
25163,"Spike to model the cluster nodes. Each node in the cluster advertises itself and the admin node listens to these ads and creates groups out of them. The deployment of jobs and stream processing can then be deployed onto a specific group and specific nodes within the group. The project is the start of this model.",NULL,"Spike to model the cluster nodes. Each node in the cluster advertises itself and the admin node listens to these ads and creates groups out of them. The deployment of jobs and stream processing can then be deployed onto a specific group and specific nodes within the group. The project is the start of this model.",NULL,"Add for who this story is","well_formed","no_role","high",False
25163,"Spike to model the cluster nodes. Each node in the cluster advertises itself and the admin node listens to these ads and creates groups out of them. The deployment of jobs and stream processing can then be deployed onto a specific group and specific nodes within the group. The project is the start of this model.",NULL,"Spike to model the cluster nodes. Each node in the cluster advertises itself and the admin node listens to these ads and creates groups out of them. The deployment of jobs and stream processing can then be deployed onto a specific group and specific nodes within the group. The project is the start of this model.",NULL,"Spike to model the cluster nodes. Each node in the cluster advertises itself<span class='highlight-text severity-high'> and </span>the admin node listens to these ads and creates groups out of them. The deployment of jobs and stream processing can then be deployed onto a specific group and specific nodes within the group. The project is the start of this model.","atomic","conjunctions","high",False
25163,"Spike to model the cluster nodes. Each node in the cluster advertises itself and the admin node listens to these ads and creates groups out of them. The deployment of jobs and stream processing can then be deployed onto a specific group and specific nodes within the group. The project is the start of this model.",NULL,"Spike to model the cluster nodes. Each node in the cluster advertises itself and the admin node listens to these ads and creates groups out of them. The deployment of jobs and stream processing can then be deployed onto a specific group and specific nodes within the group. The project is the start of this model.",NULL,"Spike to model the cluster nodes<span class='highlight-text severity-high'>. Each node in the cluster advertises itself and the admin node listens to these ads and creates groups out of them. The deployment of jobs and stream processing can then be deployed onto a specific group and specific nodes within the group. The project is the start of this model.</span>","minimal","punctuation","high",False
25173,"Refactor Simplify JobPlugin Currently, the JobPlugin extends AbstractPlugin and the AbstractPlugin has got lots of unused code like it doesn t do anything with in there. ",NULL,"Refactor Simplify JobPlugin Currently, the JobPlugin extends AbstractPlugin and the AbstractPlugin has got lots of unused code like it doesn t do anything with in there. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25173,"Refactor Simplify JobPlugin Currently, the JobPlugin extends AbstractPlugin and the AbstractPlugin has got lots of unused code like it doesn t do anything with in there. ",NULL,"Refactor Simplify JobPlugin Currently, the JobPlugin extends AbstractPlugin and the AbstractPlugin has got lots of unused code like it doesn t do anything with in there. ",NULL,"Refactor Simplify JobPlugin Currently, the JobPlugin extends AbstractPlugin<span class='highlight-text severity-high'> and </span>the AbstractPlugin has got lots of unused code like it doesn t do anything with in there. ","atomic","conjunctions","high",False
25180,"Enhancements to Gemfire CQ Source The Gemfire CQ source needs some enhancements enable locator configuration consider decoupling from JSON. Currently designed to work with to avoid dependence on specific domain objects on the client and server side. So produces json strings from PdxInstance s stored in the cache. ",NULL,NULL,"Source The Gemfire CQ source needs some enhancements enable locator configuration consider decoupling from JSON. Currently designed to work with to avoid dependence on specific domain objects on the client and server side. So produces json strings from PdxInstance s stored in the cache.","Add what you want to achieve","well_formed","no_means","high",False
25180,"Enhancements to Gemfire CQ Source The Gemfire CQ source needs some enhancements enable locator configuration consider decoupling from JSON. Currently designed to work with to avoid dependence on specific domain objects on the client and server side. So produces json strings from PdxInstance s stored in the cache. ",NULL,NULL,"Source The Gemfire CQ source needs some enhancements enable locator configuration consider decoupling from JSON. Currently designed to work with to avoid dependence on specific domain objects on the client and server side. So produces json strings from PdxInstance s stored in the cache.","Add for who this story is","well_formed","no_role","high",False
25180,"Enhancements to Gemfire CQ Source The Gemfire CQ source needs some enhancements enable locator configuration consider decoupling from JSON. Currently designed to work with to avoid dependence on specific domain objects on the client and server side. So produces json strings from PdxInstance s stored in the cache. ",NULL,NULL,"Source The Gemfire CQ source needs some enhancements enable locator configuration consider decoupling from JSON. Currently designed to work with to avoid dependence on specific domain objects on the client and server side. So produces json strings from PdxInstance s stored in the cache.","Enhancements to Gemfire CQ Source The Gemfire CQ source needs some enhancements enable locator configuration consider decoupling from JSON<span class='highlight-text severity-high'>. Currently designed to work with to avoid dependence on specific domain objects on the client and server side. So produces json strings from PdxInstance s stored in the cache. </span>","minimal","punctuation","high",False
25180,"Enhancements to Gemfire CQ Source The Gemfire CQ source needs some enhancements enable locator configuration consider decoupling from JSON. Currently designed to work with to avoid dependence on specific domain objects on the client and server side. So produces json strings from PdxInstance s stored in the cache. ",NULL,NULL,"Source The Gemfire CQ source needs some enhancements enable locator configuration consider decoupling from JSON. Currently designed to work with to avoid dependence on specific domain objects on the client and server side. So produces json strings from PdxInstance s stored in the cache.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25202,"Create custom help command for xd shell so that hadoopDistro option is listed xd shell is using the default spring shell help command. Need to create a help command specific to XD so that it can list the hadoopDistro command line option. Note, the hadoopDistro command line option is actually processed by the xd shell bash script",NULL,"Create custom help command for xd shell","so that hadoopDistro option is listed xd shell is using the default spring shell help command. Need to create a help command specific to XD so that it can list the hadoopDistro command line option. Note, the hadoopDistro command line option is actually processed by the xd shell bash script","Add for who this story is","well_formed","no_role","high",False
25202,"Create custom help command for xd shell so that hadoopDistro option is listed xd shell is using the default spring shell help command. Need to create a help command specific to XD so that it can list the hadoopDistro command line option. Note, the hadoopDistro command line option is actually processed by the xd shell bash script",NULL,"Create custom help command for xd shell","so that hadoopDistro option is listed xd shell is using the default spring shell help command. Need to create a help command specific to XD so that it can list the hadoopDistro command line option. Note, the hadoopDistro command line option is actually processed by the xd shell bash script","Create custom help command for xd shell so that hadoopDistro option is listed xd shell is using the default spring shell help command<span class='highlight-text severity-high'>. Need to create a help command specific to XD so that it can list the hadoopDistro command line option. Note, the hadoopDistro command line option is actually processed by the xd shell bash script</span>","minimal","punctuation","high",False
25202,"Create custom help command for xd shell so that hadoopDistro option is listed xd shell is using the default spring shell help command. Need to create a help command specific to XD so that it can list the hadoopDistro command line option. Note, the hadoopDistro command line option is actually processed by the xd shell bash script",NULL,"Create custom help command for xd shell","so that hadoopDistro option is listed xd shell is using the default spring shell help command. Need to create a help command specific to XD so that it can list the hadoopDistro command line option. Note, the hadoopDistro command line option is actually processed by the xd shell bash script","Create custom help command for xd shell<span class='highlight-text severity-high'> so that </span>hadoopDistro option is listed xd shell is using the default spring shell help command. Need to create a help command specific to XD<span class='highlight-text severity-high'> so that </span>it can list the hadoopDistro command line option. Note, the hadoopDistro command line option is actually processed by the xd shell bash script","minimal","indicator_repetition","high",False
25202,"Create custom help command for xd shell so that hadoopDistro option is listed xd shell is using the default spring shell help command. Need to create a help command specific to XD so that it can list the hadoopDistro command line option. Note, the hadoopDistro command line option is actually processed by the xd shell bash script",NULL,"Create custom help command for xd shell","so that hadoopDistro option is listed xd shell is using the default spring shell help command. Need to create a help command specific to XD so that it can list the hadoopDistro command line option. Note, the hadoopDistro command line option is actually processed by the xd shell bash script","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25232,"Add to Acceptance Test EC2 job a stage that uses XD distributed mode with redis See Stages are comprised of one or more Jobs, which run in parallel we would like the tests across the rabbit and redis transport to occur in parallel.",NULL,"Add to Acceptance Test EC2 job a stage that uses XD distributed mode with redis See Stages are comprised of one or more Jobs, which run in parallel we would like the tests across the rabbit and redis transport to occur in parallel.",NULL,"Add for who this story is","well_formed","no_role","high",False
25232,"Add to Acceptance Test EC2 job a stage that uses XD distributed mode with redis See Stages are comprised of one or more Jobs, which run in parallel we would like the tests across the rabbit and redis transport to occur in parallel.",NULL,"Add to Acceptance Test EC2 job a stage that uses XD distributed mode with redis See Stages are comprised of one or more Jobs, which run in parallel we would like the tests across the rabbit and redis transport to occur in parallel.",NULL,"Add to Acceptance Test EC2 job a stage that uses XD distributed mode with redis See Stages are comprised of one<span class='highlight-text severity-high'> or </span>more Jobs, which run in parallel we would like the tests across the rabbit<span class='highlight-text severity-high'> and </span>redis transport to occur in parallel.","atomic","conjunctions","high",False
25384,"Add initial support for DeploymentManifest The REST API for deploy should accept parameters, which provide manifest key value pairs e.g. Ultimately we will want to support passing a named manifest which had been stored previously. The stream deploy shell command should support passing these as options. Initially we should support and .group.",NULL,"Add initial support for DeploymentManifest The REST API for deploy should accept parameters, which provide manifest key value pairs e.g. Ultimately we will want to support passing a named manifest which had been stored previously. The stream deploy shell command should support passing these as options. Initially we should support and .group.",NULL,"Add for who this story is","well_formed","no_role","high",False
25384,"Add initial support for DeploymentManifest The REST API for deploy should accept parameters, which provide manifest key value pairs e.g. Ultimately we will want to support passing a named manifest which had been stored previously. The stream deploy shell command should support passing these as options. Initially we should support and .group.",NULL,"Add initial support for DeploymentManifest The REST API for deploy should accept parameters, which provide manifest key value pairs e.g. Ultimately we will want to support passing a named manifest which had been stored previously. The stream deploy shell command should support passing these as options. Initially we should support and .group.",NULL,"Add initial support for DeploymentManifest The REST API for deploy should accept parameters, which provide manifest key value pairs e<span class='highlight-text severity-high'>.g. Ultimately we will want to support passing a named manifest which had been stored previously. The stream deploy shell command should support passing these as options. Initially we should support and .group.</span>","minimal","punctuation","high",False
25408,"Create a dedicated plugin for and similar The setting of the xd.stream.name property is currently duplicated in StreamPlugin and JobPlugin, etc Moreover, there is no strong String constant to reference it Create a plugin dedicated to those matters namely making bits of DeploymentMetadata available to the module environment ",NULL,"Create a dedicated plugin for and similar The setting of the xd.stream.name property is currently duplicated in StreamPlugin and JobPlugin, etc Moreover, there is no strong String constant to reference it Create a plugin dedicated to those matters namely making bits of DeploymentMetadata available to the module environment ",NULL,"Add for who this story is","well_formed","no_role","high",False
25408,"Create a dedicated plugin for and similar The setting of the xd.stream.name property is currently duplicated in StreamPlugin and JobPlugin, etc Moreover, there is no strong String constant to reference it Create a plugin dedicated to those matters namely making bits of DeploymentMetadata available to the module environment ",NULL,"Create a dedicated plugin for and similar The setting of the xd.stream.name property is currently duplicated in StreamPlugin and JobPlugin, etc Moreover, there is no strong String constant to reference it Create a plugin dedicated to those matters namely making bits of DeploymentMetadata available to the module environment ",NULL,"Create a dedicated plugin for<span class='highlight-text severity-high'> and </span>similar The setting of the xd.stream.name property is currently duplicated in StreamPlugin and JobPlugin, etc Moreover, there is no strong String constant to reference it Create a plugin dedicated to those matters namely making bits of DeploymentMetadata available to the module environment ","atomic","conjunctions","high",False
25423,"When using transform shell displays error When trying to create the stream for the gemfire example stream create hashtags definition tap stream tweets transform gemfire server deploy The shell displays Command failed Error with option s for module transform of type processor valid the script and expression options are mutually exclusive I get the following error ",NULL,"When using transform shell displays error When trying to create the stream for the gemfire example stream create hashtags definition tap stream tweets transform gemfire server deploy The shell displays Command failed Error with option s for module transform of type processor valid the script and expression options are mutually exclusive I get the following error ",NULL,"Add for who this story is","well_formed","no_role","high",False
25423,"When using transform shell displays error When trying to create the stream for the gemfire example stream create hashtags definition tap stream tweets transform gemfire server deploy The shell displays Command failed Error with option s for module transform of type processor valid the script and expression options are mutually exclusive I get the following error ",NULL,"When using transform shell displays error When trying to create the stream for the gemfire example stream create hashtags definition tap stream tweets transform gemfire server deploy The shell displays Command failed Error with option s for module transform of type processor valid the script and expression options are mutually exclusive I get the following error ",NULL,"When using transform shell displays error When trying to create the stream for the gemfire example stream create hashtags definition tap stream tweets transform gemfire server deploy The shell displays Command failed Error with option s for module transform of type processor valid the script<span class='highlight-text severity-high'> and </span>expression options are mutually exclusive I get the following error ","atomic","conjunctions","high",False
25244,"Out of the box batch jobs should add and To show best practice, our batch jobs should include these listeners so that notifications can be sent. In particular it is desirable that jobs with file item readers can send the files that were processed so another stream can be sent the file name when the job completes to move delete the file",NULL,"Out of the box batch jobs should add and To show best practice, our batch jobs should include these listeners","so that notifications can be sent. In particular it is desirable that jobs with file item readers can send the files that were processed so another stream can be sent the file name when the job completes to move delete the file","Add for who this story is","well_formed","no_role","high",False
25244,"Out of the box batch jobs should add and To show best practice, our batch jobs should include these listeners so that notifications can be sent. In particular it is desirable that jobs with file item readers can send the files that were processed so another stream can be sent the file name when the job completes to move delete the file",NULL,"Out of the box batch jobs should add and To show best practice, our batch jobs should include these listeners","so that notifications can be sent. In particular it is desirable that jobs with file item readers can send the files that were processed so another stream can be sent the file name when the job completes to move delete the file","Out of the box batch jobs should add<span class='highlight-text severity-high'> and </span>To show best practice, our batch jobs should include these listeners so that notifications can be sent. In particular it is desirable that jobs with file item readers can send the files that were processed so another stream can be sent the file name when the job completes to move delete the file","atomic","conjunctions","high",False
25244,"Out of the box batch jobs should add and To show best practice, our batch jobs should include these listeners so that notifications can be sent. In particular it is desirable that jobs with file item readers can send the files that were processed so another stream can be sent the file name when the job completes to move delete the file",NULL,"Out of the box batch jobs should add and To show best practice, our batch jobs should include these listeners","so that notifications can be sent. In particular it is desirable that jobs with file item readers can send the files that were processed so another stream can be sent the file name when the job completes to move delete the file","Out of the box batch jobs should add and To show best practice, our batch jobs should include these listeners so that notifications can be sent<span class='highlight-text severity-high'>. In particular it is desirable that jobs with file item readers can send the files that were processed so another stream can be sent the file name when the job completes to move delete the file</span>","minimal","punctuation","high",False
25244,"Out of the box batch jobs should add and To show best practice, our batch jobs should include these listeners so that notifications can be sent. In particular it is desirable that jobs with file item readers can send the files that were processed so another stream can be sent the file name when the job completes to move delete the file",NULL,"Out of the box batch jobs should add and To show best practice, our batch jobs should include these listeners","so that notifications can be sent. In particular it is desirable that jobs with file item readers can send the files that were processed so another stream can be sent the file name when the job completes to move delete the file","Out of the box batch jobs should add and To show best practice, our batch jobs should include these listeners<span class='highlight-text severity-high'> so that </span>notifications can be sent. In particular it is desirable that jobs with file item readers can send the files that were processed<span class='highlight-text severity-high'> so </span>another stream can be sent the file name when the job completes to move delete the file","minimal","indicator_repetition","high",False
25244,"Out of the box batch jobs should add and To show best practice, our batch jobs should include these listeners so that notifications can be sent. In particular it is desirable that jobs with file item readers can send the files that were processed so another stream can be sent the file name when the job completes to move delete the file",NULL,"Out of the box batch jobs should add and To show best practice, our batch jobs should include these listeners","so that notifications can be sent. In particular it is desirable that jobs with file item readers can send the files that were processed so another stream can be sent the file name when the job completes to move delete the file","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25262,"Add documentation for using FTP HDFS partitioned jobs ",NULL,"Add documentation for using FTP HDFS partitioned jobs ",NULL,"Add for who this story is","well_formed","no_role","high",False
25257,"module delete command should only provide completions with composed modules There is no point in providing completion with something that will fail when the user tries it. The information about a module being a composed is now available at the REST layer, so should be used",NULL,"module delete command should only provide completions with composed modules There is no point in providing completion with","something that will fail when the user tries it. The information about a module being a composed is now available at the REST layer, so should be used","Add for who this story is","well_formed","no_role","high",False
25257,"module delete command should only provide completions with composed modules There is no point in providing completion with something that will fail when the user tries it. The information about a module being a composed is now available at the REST layer, so should be used",NULL,"module delete command should only provide completions with composed modules There is no point in providing completion with","something that will fail when the user tries it. The information about a module being a composed is now available at the REST layer, so should be used","module delete command should only provide completions with composed modules There is no point in providing completion with something that will fail when the user tries it<span class='highlight-text severity-high'>. The information about a module being a composed is now available at the REST layer, so should be used</span>","minimal","punctuation","high",False
25257,"module delete command should only provide completions with composed modules There is no point in providing completion with something that will fail when the user tries it. The information about a module being a composed is now available at the REST layer, so should be used",NULL,"module delete command should only provide completions with composed modules There is no point in providing completion with","something that will fail when the user tries it. The information about a module being a composed is now available at the REST layer, so should be used","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25272,"Job execution restart fails with NPE Create a job, launch it but make it fail eg filejdbc with missing file job execution list it s there, as FAILED. Good job execution restart theid Fails with NPE 16 59 42,160 ERROR Caught exception while handling a request at at at at at Source at at at at at at at at at Source at at at at Method at at at at org.springfram ",NULL,"Job execution restart fails with NPE Create a job, launch it but make it fail eg filejdbc with missing file job execution list it s there, as FAILED. Good job execution restart theid Fails with NPE 16 59 42,160 ERROR Caught exception while handling a request at at at at at Source at at at at at at at at at Source at at at at Method at at at at org.springfram ",NULL,"Add for who this story is","well_formed","no_role","high",False
25272,"Job execution restart fails with NPE Create a job, launch it but make it fail eg filejdbc with missing file job execution list it s there, as FAILED. Good job execution restart theid Fails with NPE 16 59 42,160 ERROR Caught exception while handling a request at at at at at Source at at at at at at at at at Source at at at at Method at at at at org.springfram ",NULL,"Job execution restart fails with NPE Create a job, launch it but make it fail eg filejdbc with missing file job execution list it s there, as FAILED. Good job execution restart theid Fails with NPE 16 59 42,160 ERROR Caught exception while handling a request at at at at at Source at at at at at at at at at Source at at at at Method at at at at org.springfram ",NULL,"Job execution restart fails with NPE Create a job, launch it but make it fail eg filejdbc with missing file job execution list it s there, as FAILED<span class='highlight-text severity-high'>. Good job execution restart theid Fails with NPE 16 59 42,160 ERROR Caught exception while handling a request at at at at at Source at at at at at at at at at Source at at at at Method at at at at org.springfram </span>","minimal","punctuation","high",False
25287,"STS Gradle Import Broken When importing XD as a gradle project into STS, it fails with Missing directories and spring xd yarn mkdir on these directories solves the problem. The hdp20 case relates to XD 599 it is not clear why spring xd yarn is needed. ",NULL,"STS Gradle Import Broken When importing XD as a gradle project into STS, it fails with Missing directories and spring xd yarn mkdir on these directories solves the problem. The hdp20 case relates to XD 599 it is not clear why spring xd yarn is needed. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25287,"STS Gradle Import Broken When importing XD as a gradle project into STS, it fails with Missing directories and spring xd yarn mkdir on these directories solves the problem. The hdp20 case relates to XD 599 it is not clear why spring xd yarn is needed. ",NULL,"STS Gradle Import Broken When importing XD as a gradle project into STS, it fails with Missing directories and spring xd yarn mkdir on these directories solves the problem. The hdp20 case relates to XD 599 it is not clear why spring xd yarn is needed. ",NULL,"STS Gradle Import Broken When importing XD as a gradle project into STS, it fails with Missing directories<span class='highlight-text severity-high'> and </span>spring xd yarn mkdir on these directories solves the problem. The hdp20 case relates to XD 599 it is not clear why spring xd yarn is needed. ","atomic","conjunctions","high",False
25287,"STS Gradle Import Broken When importing XD as a gradle project into STS, it fails with Missing directories and spring xd yarn mkdir on these directories solves the problem. The hdp20 case relates to XD 599 it is not clear why spring xd yarn is needed. ",NULL,"STS Gradle Import Broken When importing XD as a gradle project into STS, it fails with Missing directories and spring xd yarn mkdir on these directories solves the problem. The hdp20 case relates to XD 599 it is not clear why spring xd yarn is needed. ",NULL,"STS Gradle Import Broken When importing XD as a gradle project into STS, it fails with Missing directories and spring xd yarn mkdir on these directories solves the problem<span class='highlight-text severity-high'>. The hdp20 case relates to XD 599 it is not clear why spring xd yarn is needed. </span>","minimal","punctuation","high",False
25293,"Allow end users to configure Rabbit MQ properties on the MessageBus for acks, txs, etc . This requires exposing properties to the ListenerContainer. Probably cleaner to inject the ListenerContainer into the RabbitMessageBus and expose property placeholders on the LC. Maybe do the same for RabbitAdmin as well. ",NULL,"Allow end users to configure Rabbit MQ properties on the MessageBus for acks, txs, etc . This requires exposing properties to the ListenerContainer. Probably cleaner to inject the ListenerContainer into the RabbitMessageBus and expose property placeholders on the LC. Maybe do the same for RabbitAdmin as well. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25293,"Allow end users to configure Rabbit MQ properties on the MessageBus for acks, txs, etc . This requires exposing properties to the ListenerContainer. Probably cleaner to inject the ListenerContainer into the RabbitMessageBus and expose property placeholders on the LC. Maybe do the same for RabbitAdmin as well. ",NULL,"Allow end users to configure Rabbit MQ properties on the MessageBus for acks, txs, etc . This requires exposing properties to the ListenerContainer. Probably cleaner to inject the ListenerContainer into the RabbitMessageBus and expose property placeholders on the LC. Maybe do the same for RabbitAdmin as well. ",NULL,"Allow end users to configure Rabbit MQ properties on the MessageBus for acks, txs, etc . This requires exposing properties to the ListenerContainer. Probably cleaner to inject the ListenerContainer into the RabbitMessageBus<span class='highlight-text severity-high'> and </span>expose property placeholders on the LC. Maybe do the same for RabbitAdmin as well. ","atomic","conjunctions","high",False
25293,"Allow end users to configure Rabbit MQ properties on the MessageBus for acks, txs, etc . This requires exposing properties to the ListenerContainer. Probably cleaner to inject the ListenerContainer into the RabbitMessageBus and expose property placeholders on the LC. Maybe do the same for RabbitAdmin as well. ",NULL,"Allow end users to configure Rabbit MQ properties on the MessageBus for acks, txs, etc . This requires exposing properties to the ListenerContainer. Probably cleaner to inject the ListenerContainer into the RabbitMessageBus and expose property placeholders on the LC. Maybe do the same for RabbitAdmin as well. ",NULL,"Allow end users to configure Rabbit MQ properties on the MessageBus for acks, txs, etc <span class='highlight-text severity-high'>. This requires exposing properties to the ListenerContainer. Probably cleaner to inject the ListenerContainer into the RabbitMessageBus and expose property placeholders on the LC. Maybe do the same for RabbitAdmin as well. </span>","minimal","punctuation","high",False
25301,"Create an embedded ZooKeeper server process This will be used by if no ZooKeeper process is available based on the provided client connect string. It will still be recommended that user s run ZooKeeper externally, at least in standalone mode, when running We should clarify that in the documentation and logs. It should implement SmartLifecycle so that it can be managed as a bean within an ApplicationContext.",NULL,"Create an embedded ZooKeeper server process This will be used by if no ZooKeeper process is available based on the provided client connect string. It will still be recommended that user s run ZooKeeper externally, at least in standalone mode, when running We should clarify that in the documentation and logs. It should implement SmartLifecycle","so that it can be managed as a bean within an ApplicationContext.","Add for who this story is","well_formed","no_role","high",False
25301,"Create an embedded ZooKeeper server process This will be used by if no ZooKeeper process is available based on the provided client connect string. It will still be recommended that user s run ZooKeeper externally, at least in standalone mode, when running We should clarify that in the documentation and logs. It should implement SmartLifecycle so that it can be managed as a bean within an ApplicationContext.",NULL,"Create an embedded ZooKeeper server process This will be used by if no ZooKeeper process is available based on the provided client connect string. It will still be recommended that user s run ZooKeeper externally, at least in standalone mode, when running We should clarify that in the documentation and logs. It should implement SmartLifecycle","so that it can be managed as a bean within an ApplicationContext.","Create an embedded ZooKeeper server process This will be used by if no ZooKeeper process is available based on the provided client connect string<span class='highlight-text severity-high'>. It will still be recommended that user s run ZooKeeper externally, at least in standalone mode, when running We should clarify that in the documentation and logs. It should implement SmartLifecycle so that it can be managed as a bean within an ApplicationContext.</span>","minimal","punctuation","high",False
25301,"Create an embedded ZooKeeper server process This will be used by if no ZooKeeper process is available based on the provided client connect string. It will still be recommended that user s run ZooKeeper externally, at least in standalone mode, when running We should clarify that in the documentation and logs. It should implement SmartLifecycle so that it can be managed as a bean within an ApplicationContext.",NULL,"Create an embedded ZooKeeper server process This will be used by if no ZooKeeper process is available based on the provided client connect string. It will still be recommended that user s run ZooKeeper externally, at least in standalone mode, when running We should clarify that in the documentation and logs. It should implement SmartLifecycle","so that it can be managed as a bean within an ApplicationContext.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25323,"Container fails to start if JMX is enabled and manage port is set The container will not start with JMX enabled and the management port set. The stacktrace is attached and the settings for the container are enumerated below export export export export export ",NULL,"Container fails to start if JMX is enabled and manage port is set The container will not start with JMX enabled and the management port set. The stacktrace is attached and the settings for the container are enumerated below export export export export export ",NULL,"Add for who this story is","well_formed","no_role","high",False
25323,"Container fails to start if JMX is enabled and manage port is set The container will not start with JMX enabled and the management port set. The stacktrace is attached and the settings for the container are enumerated below export export export export export ",NULL,"Container fails to start if JMX is enabled and manage port is set The container will not start with JMX enabled and the management port set. The stacktrace is attached and the settings for the container are enumerated below export export export export export ",NULL,"Container fails to start if JMX is enabled<span class='highlight-text severity-high'> and </span>manage port is set The container will not start with JMX enabled and the management port set. The stacktrace is attached and the settings for the container are enumerated below export export export export export ","atomic","conjunctions","high",False
25323,"Container fails to start if JMX is enabled and manage port is set The container will not start with JMX enabled and the management port set. The stacktrace is attached and the settings for the container are enumerated below export export export export export ",NULL,"Container fails to start if JMX is enabled and manage port is set The container will not start with JMX enabled and the management port set. The stacktrace is attached and the settings for the container are enumerated below export export export export export ",NULL,"Container fails to start if JMX is enabled and manage port is set The container will not start with JMX enabled and the management port set<span class='highlight-text severity-high'>. The stacktrace is attached and the settings for the container are enumerated below export export export export export </span>","minimal","punctuation","high",False
25325,"Admin servers should write streams to and delete them from ZooKeeper This should also enable removal of any code. The state should be written as a data node at the stream level e.g. For now we at least need to support the boolean flag. If that is true, then the leader Admin will deploy the modules of the stream across available containers XD 1399 ",NULL,"Admin servers should write streams to and delete them from ZooKeeper This should also enable removal of any code. The state should be written as a data node at the stream level e.g. For now we at least need to support the boolean flag. If that is true, then the leader Admin will deploy the modules of the stream across available containers XD 1399 ",NULL,"Add for who this story is","well_formed","no_role","high",False
25325,"Admin servers should write streams to and delete them from ZooKeeper This should also enable removal of any code. The state should be written as a data node at the stream level e.g. For now we at least need to support the boolean flag. If that is true, then the leader Admin will deploy the modules of the stream across available containers XD 1399 ",NULL,"Admin servers should write streams to and delete them from ZooKeeper This should also enable removal of any code. The state should be written as a data node at the stream level e.g. For now we at least need to support the boolean flag. If that is true, then the leader Admin will deploy the modules of the stream across available containers XD 1399 ",NULL,"Admin servers should write streams to<span class='highlight-text severity-high'> and </span>delete them from ZooKeeper This should also enable removal of any code. The state should be written as a data node at the stream level e.g. For now we at least need to support the boolean flag. If that is true, then the leader Admin will deploy the modules of the stream across available containers XD 1399 ","atomic","conjunctions","high",False
25325,"Admin servers should write streams to and delete them from ZooKeeper This should also enable removal of any code. The state should be written as a data node at the stream level e.g. For now we at least need to support the boolean flag. If that is true, then the leader Admin will deploy the modules of the stream across available containers XD 1399 ",NULL,"Admin servers should write streams to and delete them from ZooKeeper This should also enable removal of any code. The state should be written as a data node at the stream level e.g. For now we at least need to support the boolean flag. If that is true, then the leader Admin will deploy the modules of the stream across available containers XD 1399 ",NULL,"Admin servers should write streams to and delete them from ZooKeeper This should also enable removal of any code<span class='highlight-text severity-high'>. The state should be written as a data node at the stream level e.g. For now we at least need to support the boolean flag. If that is true, then the leader Admin will deploy the modules of the stream across available containers XD 1399 </span>","minimal","punctuation","high",False
25339,"Create RPM for distribution Package SpringXD into an RPM install path with symlink current version init.d scripts to service springxd admin start stop status service springxd container start stop status user group springxd pivotal Host springxd rpm in Pivotal repo yum install springxd Support RHEL CentOS version 5 and 6? tested on latest updates Support for 32 and 64 bits Support Java 1.6 and 1.7 ",NULL,"Create RPM for distribution Package SpringXD into an RPM install path with symlink current version init.d scripts to service springxd admin start stop status service springxd container start stop status user group springxd pivotal Host springxd rpm in Pivotal repo yum install springxd Support RHEL CentOS version 5 and 6? tested on latest updates Support for 32 and 64 bits Support Java 1.6 and 1.7 ",NULL,"Add for who this story is","well_formed","no_role","high",False
25339,"Create RPM for distribution Package SpringXD into an RPM install path with symlink current version init.d scripts to service springxd admin start stop status service springxd container start stop status user group springxd pivotal Host springxd rpm in Pivotal repo yum install springxd Support RHEL CentOS version 5 and 6? tested on latest updates Support for 32 and 64 bits Support Java 1.6 and 1.7 ",NULL,"Create RPM for distribution Package SpringXD into an RPM install path with symlink current version init.d scripts to service springxd admin start stop status service springxd container start stop status user group springxd pivotal Host springxd rpm in Pivotal repo yum install springxd Support RHEL CentOS version 5 and 6? tested on latest updates Support for 32 and 64 bits Support Java 1.6 and 1.7 ",NULL,"Create RPM for distribution Package SpringXD into an RPM install path with symlink current version init.d scripts to service springxd admin start stop status service springxd container start stop status user group springxd pivotal Host springxd rpm in Pivotal repo yum install springxd Support RHEL CentOS version 5 and 6<span class='highlight-text severity-high'>? tested on latest updates Support for 32 and 64 bits Support Java 1.6 and 1.7 </span>","minimal","punctuation","high",False
25356,"Allow re use of a module classloader See report at It would be good indeed to allow this eg by having a type name map in the global context . The caveat though, is that any statics used by the module would be shared too. We can make this an opt out though I think that sharing by default makes sense by having a flag in the module .properties manifest",NULL,"Allow re use of a module classloader See report at It would be good indeed to allow this eg by having a type name map in the global context . The caveat though, is that any statics used by the module would be shared too. We can make this an opt out though I think that sharing by default makes sense by having a flag in the module .properties manifest",NULL,"Add for who this story is","well_formed","no_role","high",False
25356,"Allow re use of a module classloader See report at It would be good indeed to allow this eg by having a type name map in the global context . The caveat though, is that any statics used by the module would be shared too. We can make this an opt out though I think that sharing by default makes sense by having a flag in the module .properties manifest",NULL,"Allow re use of a module classloader See report at It would be good indeed to allow this eg by having a type name map in the global context . The caveat though, is that any statics used by the module would be shared too. We can make this an opt out though I think that sharing by default makes sense by having a flag in the module .properties manifest",NULL,"Allow re use of a module classloader See report at It would be good indeed to allow this eg by having a type name map in the global context <span class='highlight-text severity-high'>. The caveat though, is that any statics used by the module would be shared too. We can make this an opt out though I think that sharing by default makes sense by having a flag in the module .properties manifest</span>","minimal","punctuation","high",False
25436,"Update to Spring AMQP 1.3.2 If the rabbit source receives a message it can t convert, a is thrown and the message is rejected and requeued , causing an endless loop. Add an . Also consider adding a retry interceptor to do the same for exceptions in modules when using local transport .",NULL,"Update to Spring AMQP 1.3.2 If the rabbit source receives a message it can t convert, a is thrown and the message is rejected and requeued , causing an endless loop. Add an . Also consider adding a retry interceptor to do the same for exceptions in modules when using local transport .",NULL,"Add for who this story is","well_formed","no_role","high",False
25436,"Update to Spring AMQP 1.3.2 If the rabbit source receives a message it can t convert, a is thrown and the message is rejected and requeued , causing an endless loop. Add an . Also consider adding a retry interceptor to do the same for exceptions in modules when using local transport .",NULL,"Update to Spring AMQP 1.3.2 If the rabbit source receives a message it can t convert, a is thrown and the message is rejected and requeued , causing an endless loop. Add an . Also consider adding a retry interceptor to do the same for exceptions in modules when using local transport .",NULL,"Update to Spring AMQP 1.3.2 If the rabbit source receives a message it can t convert, a is thrown<span class='highlight-text severity-high'> and </span>the message is rejected and requeued , causing an endless loop. Add an . Also consider adding a retry interceptor to do the same for exceptions in modules when using local transport .","atomic","conjunctions","high",False
25436,"Update to Spring AMQP 1.3.2 If the rabbit source receives a message it can t convert, a is thrown and the message is rejected and requeued , causing an endless loop. Add an . Also consider adding a retry interceptor to do the same for exceptions in modules when using local transport .",NULL,"Update to Spring AMQP 1.3.2 If the rabbit source receives a message it can t convert, a is thrown and the message is rejected and requeued , causing an endless loop. Add an . Also consider adding a retry interceptor to do the same for exceptions in modules when using local transport .",NULL,"Update to Spring AMQP 1<span class='highlight-text severity-high'>.3.2 If the rabbit source receives a message it can t convert, a is thrown and the message is rejected and requeued , causing an endless loop. Add an . Also consider adding a retry interceptor to do the same for exceptions in modules when using local transport .</span>","minimal","punctuation","high",False
25457,"Update HDFS sink to use unique id GUID as part of file name HDFS sink needs to have unique identifier for container id added as part of file name. Part of the file name in the directory will be the container id GUID like ",NULL,"Update HDFS sink to use unique id GUID as part of file name HDFS sink needs to have unique identifier for container id added as part of file name. Part of the file name in the directory will be the container id GUID like ",NULL,"Add for who this story is","well_formed","no_role","high",False
25457,"Update HDFS sink to use unique id GUID as part of file name HDFS sink needs to have unique identifier for container id added as part of file name. Part of the file name in the directory will be the container id GUID like ",NULL,"Update HDFS sink to use unique id GUID as part of file name HDFS sink needs to have unique identifier for container id added as part of file name. Part of the file name in the directory will be the container id GUID like ",NULL,"Update HDFS sink to use unique id GUID as part of file name HDFS sink needs to have unique identifier for container id added as part of file name<span class='highlight-text severity-high'>. Part of the file name in the directory will be the container id GUID like </span>","minimal","punctuation","high",False
25470,"Pluralization of admin nodes leadership selector group path Currently, the admin nodes that participate in the leadership election are grouped under xd admin. Since, there are multiple lock nodes that correspond to all the admin servers that participate in leadership election, we can pluralize this node name to xd admins.",NULL,"Pluralization of admin nodes leadership selector group path Currently, the admin nodes that participate in the leadership election are grouped under xd admin. Since, there are multiple lock nodes that correspond to all the admin servers that participate in leadership election, we can pluralize this node name to xd admins.",NULL,"Add for who this story is","well_formed","no_role","high",False
25470,"Pluralization of admin nodes leadership selector group path Currently, the admin nodes that participate in the leadership election are grouped under xd admin. Since, there are multiple lock nodes that correspond to all the admin servers that participate in leadership election, we can pluralize this node name to xd admins.",NULL,"Pluralization of admin nodes leadership selector group path Currently, the admin nodes that participate in the leadership election are grouped under xd admin. Since, there are multiple lock nodes that correspond to all the admin servers that participate in leadership election, we can pluralize this node name to xd admins.",NULL,"Pluralization of admin nodes leadership selector group path Currently, the admin nodes that participate in the leadership election are grouped under xd admin<span class='highlight-text severity-high'>. Since, there are multiple lock nodes that correspond to all the admin servers that participate in leadership election, we can pluralize this node name to xd admins.</span>","minimal","punctuation","high",False
25479,"Add admin and container memory settings to servers.yml We should add an easy way to configure the memory. Currently we only have the number of YARN containers configurable without diving into Spring YARN Boot specific config options. xd adminServers 1 containers 1 Proposing we do xd adminServers 1 adminMemory 512M containers 1 containerMemory 512M ",NULL,"Add admin and container memory settings to servers.yml We should add an easy way to configure the memory. Currently we only have the number of YARN containers configurable without diving into Spring YARN Boot specific config options. xd adminServers 1 containers 1 Proposing we do xd adminServers 1 adminMemory 512M containers 1 containerMemory 512M ",NULL,"Add for who this story is","well_formed","no_role","high",False
25479,"Add admin and container memory settings to servers.yml We should add an easy way to configure the memory. Currently we only have the number of YARN containers configurable without diving into Spring YARN Boot specific config options. xd adminServers 1 containers 1 Proposing we do xd adminServers 1 adminMemory 512M containers 1 containerMemory 512M ",NULL,"Add admin and container memory settings to servers.yml We should add an easy way to configure the memory. Currently we only have the number of YARN containers configurable without diving into Spring YARN Boot specific config options. xd adminServers 1 containers 1 Proposing we do xd adminServers 1 adminMemory 512M containers 1 containerMemory 512M ",NULL,"Add admin<span class='highlight-text severity-high'> and </span>container memory settings to servers.yml We should add an easy way to configure the memory. Currently we only have the number of YARN containers configurable without diving into Spring YARN Boot specific config options. xd adminServers 1 containers 1 Proposing we do xd adminServers 1 adminMemory 512M containers 1 containerMemory 512M ","atomic","conjunctions","high",False
25479,"Add admin and container memory settings to servers.yml We should add an easy way to configure the memory. Currently we only have the number of YARN containers configurable without diving into Spring YARN Boot specific config options. xd adminServers 1 containers 1 Proposing we do xd adminServers 1 adminMemory 512M containers 1 containerMemory 512M ",NULL,"Add admin and container memory settings to servers.yml We should add an easy way to configure the memory. Currently we only have the number of YARN containers configurable without diving into Spring YARN Boot specific config options. xd adminServers 1 containers 1 Proposing we do xd adminServers 1 adminMemory 512M containers 1 containerMemory 512M ",NULL,"Add admin and container memory settings to servers<span class='highlight-text severity-high'>.yml We should add an easy way to configure the memory. Currently we only have the number of YARN containers configurable without diving into Spring YARN Boot specific config options. xd adminServers 1 containers 1 Proposing we do xd adminServers 1 adminMemory 512M containers 1 containerMemory 512M </span>","minimal","punctuation","high",False
25503,"Modules that use tomcat connection pool need to expose configurations filejdbc, hdfsjdbc, jdbchdfs jdbc modules each support a tomcat connection pool. At this time none of the configurations allowed by the tomcat connection pool are available unless the user adds them to the appropriate module xml file. We need to allow the user to configure them via yml, property file and environment variables. ",NULL,"Modules that use tomcat connection pool need to expose configurations filejdbc, hdfsjdbc, jdbchdfs jdbc modules each support a tomcat connection pool. At this time none of the configurations allowed by the tomcat connection pool are available unless the user adds them to the appropriate module xml file. We need to allow the user to configure them via yml, property file and environment variables. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25503,"Modules that use tomcat connection pool need to expose configurations filejdbc, hdfsjdbc, jdbchdfs jdbc modules each support a tomcat connection pool. At this time none of the configurations allowed by the tomcat connection pool are available unless the user adds them to the appropriate module xml file. We need to allow the user to configure them via yml, property file and environment variables. ",NULL,"Modules that use tomcat connection pool need to expose configurations filejdbc, hdfsjdbc, jdbchdfs jdbc modules each support a tomcat connection pool. At this time none of the configurations allowed by the tomcat connection pool are available unless the user adds them to the appropriate module xml file. We need to allow the user to configure them via yml, property file and environment variables. ",NULL,"Modules that use tomcat connection pool need to expose configurations filejdbc, hdfsjdbc, jdbchdfs jdbc modules each support a tomcat connection pool<span class='highlight-text severity-high'>. At this time none of the configurations allowed by the tomcat connection pool are available unless the user adds them to the appropriate module xml file. We need to allow the user to configure them via yml, property file and environment variables. </span>","minimal","punctuation","high",False
25531,"Add global Http Interceptor in order to centralize error logging Theoretically I would have liked to centralize logging of Http Resource calls global more substantially but see this limitation ",NULL,"Add global Http Interceptor","in order to centralize error logging Theoretically I would have liked to centralize logging of Http Resource calls global more substantially but see this limitation","Add for who this story is","well_formed","no_role","high",False
25531,"Add global Http Interceptor in order to centralize error logging Theoretically I would have liked to centralize logging of Http Resource calls global more substantially but see this limitation ",NULL,"Add global Http Interceptor","in order to centralize error logging Theoretically I would have liked to centralize logging of Http Resource calls global more substantially but see this limitation","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25556,"Combine JobDefinition info and BatchJobInfo endpoints Currently, jobs definitions and batch jobs offer similar info related to the job configuration info. The former comes from while the latter comes from Batch Job Repository. We need to combine this together so that it is not confusing to the end user.",NULL,"Combine JobDefinition info and BatchJobInfo endpoints Currently, jobs definitions and batch jobs offer similar info related to the job configuration info. The former comes from while the latter comes from Batch Job Repository. We need to combine this together","so that it is not confusing to the end user.","Add for who this story is","well_formed","no_role","high",False
26216,"Add CI workflow to build, bundle and upload module launcher image to DockerHub As a s c s developer, I'd like to setup a CI workflow to build, bundle and upload the image to DockerHub, so I don t have to worry about having a local private docker registry for It could be nice to have the image uploaded to existing spring cloud DockerHub location. ",NULL,"Add CI workflow to build, bundle and upload module launcher image to DockerHub As a s c s developer, I'd like to setup a CI workflow to build, bundle and upload the image to DockerHub,","so I don t have to worry about having a local private docker registry for It could be nice to have the image uploaded to existing spring cloud DockerHub location.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25556,"Combine JobDefinition info and BatchJobInfo endpoints Currently, jobs definitions and batch jobs offer similar info related to the job configuration info. The former comes from while the latter comes from Batch Job Repository. We need to combine this together so that it is not confusing to the end user.",NULL,"Combine JobDefinition info and BatchJobInfo endpoints Currently, jobs definitions and batch jobs offer similar info related to the job configuration info. The former comes from while the latter comes from Batch Job Repository. We need to combine this together","so that it is not confusing to the end user.","Combine JobDefinition info<span class='highlight-text severity-high'> and </span>BatchJobInfo endpoints Currently, jobs definitions and batch jobs offer similar info related to the job configuration info. The former comes from while the latter comes from Batch Job Repository. We need to combine this together so that it is not confusing to the end user.","atomic","conjunctions","high",False
25556,"Combine JobDefinition info and BatchJobInfo endpoints Currently, jobs definitions and batch jobs offer similar info related to the job configuration info. The former comes from while the latter comes from Batch Job Repository. We need to combine this together so that it is not confusing to the end user.",NULL,"Combine JobDefinition info and BatchJobInfo endpoints Currently, jobs definitions and batch jobs offer similar info related to the job configuration info. The former comes from while the latter comes from Batch Job Repository. We need to combine this together","so that it is not confusing to the end user.","Combine JobDefinition info and BatchJobInfo endpoints Currently, jobs definitions and batch jobs offer similar info related to the job configuration info<span class='highlight-text severity-high'>. The former comes from while the latter comes from Batch Job Repository. We need to combine this together so that it is not confusing to the end user.</span>","minimal","punctuation","high",False
25556,"Combine JobDefinition info and BatchJobInfo endpoints Currently, jobs definitions and batch jobs offer similar info related to the job configuration info. The former comes from while the latter comes from Batch Job Repository. We need to combine this together so that it is not confusing to the end user.",NULL,"Combine JobDefinition info and BatchJobInfo endpoints Currently, jobs definitions and batch jobs offer similar info related to the job configuration info. The former comes from while the latter comes from Batch Job Repository. We need to combine this together","so that it is not confusing to the end user.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25566,"Add directory to classpath in server startup scripts so groovy based processors can be easily referenced by name without a resource uri prefix a stream such as time filter file would load the groovy script that is located in the directory modules processor or perhaps in Not sure the benefit of having a subdirectory below processor just for scripts.",NULL,"Add directory to classpath in server startup scripts","so groovy based processors can be easily referenced by name without a resource uri prefix a stream such as time filter file would load the groovy script that is located in the directory modules processor or perhaps in Not sure the benefit of having a subdirectory below processor just for scripts.","Add for who this story is","well_formed","no_role","high",False
25566,"Add directory to classpath in server startup scripts so groovy based processors can be easily referenced by name without a resource uri prefix a stream such as time filter file would load the groovy script that is located in the directory modules processor or perhaps in Not sure the benefit of having a subdirectory below processor just for scripts.",NULL,"Add directory to classpath in server startup scripts","so groovy based processors can be easily referenced by name without a resource uri prefix a stream such as time filter file would load the groovy script that is located in the directory modules processor or perhaps in Not sure the benefit of having a subdirectory below processor just for scripts.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25581,"Handle deploying state at the Admin UI When the job is in deploying state, until we decide whether the job is actually deployed or there is no way to know if it is fine to launch schedule though the launching requests are going to go to the job launch request queue . We could either disable both until the state changes from deploying ?",NULL,"Handle deploying state at the Admin UI When the job is in deploying state, until we decide whether the job is actually deployed or there is no way to know if it is fine to launch schedule though the launching requests are going to go to the job launch request queue . We could either disable both until the state changes from deploying ?",NULL,"Add for who this story is","well_formed","no_role","high",False
25581,"Handle deploying state at the Admin UI When the job is in deploying state, until we decide whether the job is actually deployed or there is no way to know if it is fine to launch schedule though the launching requests are going to go to the job launch request queue . We could either disable both until the state changes from deploying ?",NULL,"Handle deploying state at the Admin UI When the job is in deploying state, until we decide whether the job is actually deployed or there is no way to know if it is fine to launch schedule though the launching requests are going to go to the job launch request queue . We could either disable both until the state changes from deploying ?",NULL,"Handle deploying state at the Admin UI When the job is in deploying state, until we decide whether the job is actually deployed<span class='highlight-text severity-high'> or </span>there is no way to know if it is fine to launch schedule though the launching requests are going to go to the job launch request queue . We could either disable both until the state changes from deploying ?","atomic","conjunctions","high",False
25581,"Handle deploying state at the Admin UI When the job is in deploying state, until we decide whether the job is actually deployed or there is no way to know if it is fine to launch schedule though the launching requests are going to go to the job launch request queue . We could either disable both until the state changes from deploying ?",NULL,"Handle deploying state at the Admin UI When the job is in deploying state, until we decide whether the job is actually deployed or there is no way to know if it is fine to launch schedule though the launching requests are going to go to the job launch request queue . We could either disable both until the state changes from deploying ?",NULL,"Handle deploying state at the Admin UI When the job is in deploying state, until we decide whether the job is actually deployed or there is no way to know if it is fine to launch schedule though the launching requests are going to go to the job launch request queue <span class='highlight-text severity-high'>. We could either disable both until the state changes from deploying ?</span>","minimal","punctuation","high",False
25608,"Module info for jdbc sink and jobs are unreadable The module info command renders text that is pretty much unreadable on a reasonably sized screen. See attached screen shot. Also all the jdbc pool settings are mixed in with module settings making for a confusing list of options. What the heck does fairQueue have to do with filejdbc jobs?",NULL,"Module info for jdbc sink and jobs are unreadable The module info command renders text that is pretty much unreadable on a reasonably sized screen. See attached screen shot. Also all the jdbc pool settings are mixed in with module settings making for a confusing list of options. What the heck does fairQueue have to do with filejdbc jobs?",NULL,"Add for who this story is","well_formed","no_role","high",False
25608,"Module info for jdbc sink and jobs are unreadable The module info command renders text that is pretty much unreadable on a reasonably sized screen. See attached screen shot. Also all the jdbc pool settings are mixed in with module settings making for a confusing list of options. What the heck does fairQueue have to do with filejdbc jobs?",NULL,"Module info for jdbc sink and jobs are unreadable The module info command renders text that is pretty much unreadable on a reasonably sized screen. See attached screen shot. Also all the jdbc pool settings are mixed in with module settings making for a confusing list of options. What the heck does fairQueue have to do with filejdbc jobs?",NULL,"Module info for jdbc sink and jobs are unreadable The module info command renders text that is pretty much unreadable on a reasonably sized screen<span class='highlight-text severity-high'>. See attached screen shot. Also all the jdbc pool settings are mixed in with module settings making for a confusing list of options. What the heck does fairQueue have to do with filejdbc jobs?</span>","minimal","punctuation","high",False
25621,"Add comprehensive tests for The were created to satisfy XD 1462, but currently they only have a couple tests to validate the time field processing. More comprehensive tests need to be added including the testing of the Redis based implementation in addition to in memory . For more info, see the comment here ",NULL,"Add comprehensive tests for The were created to satisfy XD 1462, but currently they only have a couple tests to validate the time field processing. More comprehensive tests need to be added including the testing of the Redis based implementation in addition to in memory . For more info, see the comment here ",NULL,"Add for who this story is","well_formed","no_role","high",False
25621,"Add comprehensive tests for The were created to satisfy XD 1462, but currently they only have a couple tests to validate the time field processing. More comprehensive tests need to be added including the testing of the Redis based implementation in addition to in memory . For more info, see the comment here ",NULL,"Add comprehensive tests for The were created to satisfy XD 1462, but currently they only have a couple tests to validate the time field processing. More comprehensive tests need to be added including the testing of the Redis based implementation in addition to in memory . For more info, see the comment here ",NULL,"Add comprehensive tests for The were created to satisfy XD 1462, but currently they only have a couple tests to validate the time field processing<span class='highlight-text severity-high'>. More comprehensive tests need to be added including the testing of the Redis based implementation in addition to in memory . For more info, see the comment here </span>","minimal","punctuation","high",False
25644,"Investigate long running tests The goal is to optimize the build process and at the same time validate the feature capabilities as quickly as we can. Investigate the long running tests. Look for long timeout window declarations. ",NULL,"Investigate long running tests The goal is to optimize the build process and at the same time validate the feature capabilities as quickly as we can. Investigate the long running tests. Look for long timeout window declarations. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25644,"Investigate long running tests The goal is to optimize the build process and at the same time validate the feature capabilities as quickly as we can. Investigate the long running tests. Look for long timeout window declarations. ",NULL,"Investigate long running tests The goal is to optimize the build process and at the same time validate the feature capabilities as quickly as we can. Investigate the long running tests. Look for long timeout window declarations. ",NULL,"Investigate long running tests The goal is to optimize the build process<span class='highlight-text severity-high'> and </span>at the same time validate the feature capabilities as quickly as we can. Investigate the long running tests. Look for long timeout window declarations. ","atomic","conjunctions","high",False
25644,"Investigate long running tests The goal is to optimize the build process and at the same time validate the feature capabilities as quickly as we can. Investigate the long running tests. Look for long timeout window declarations. ",NULL,"Investigate long running tests The goal is to optimize the build process and at the same time validate the feature capabilities as quickly as we can. Investigate the long running tests. Look for long timeout window declarations. ",NULL,"Investigate long running tests The goal is to optimize the build process and at the same time validate the feature capabilities as quickly as we can<span class='highlight-text severity-high'>. Investigate the long running tests. Look for long timeout window declarations. </span>","minimal","punctuation","high",False
25659,"List Streams Jobs based with deployed modules Currently, there is a stream list job list which shows the status of a given stream job along with the DSL. and, there is runtime modules which shows all the deployed modules with their container info. We need a better REST endpoint that gives all the deployed modules for a given stream job along with the status.",NULL,"List Streams Jobs based with deployed modules Currently, there is a stream list job list which shows the status of a given stream job along with the DSL. and, there is runtime modules which shows all the deployed modules with their container info. We need a better REST endpoint that gives all the deployed modules for a given stream job along with the status.",NULL,"Add for who this story is","well_formed","no_role","high",False
25659,"List Streams Jobs based with deployed modules Currently, there is a stream list job list which shows the status of a given stream job along with the DSL. and, there is runtime modules which shows all the deployed modules with their container info. We need a better REST endpoint that gives all the deployed modules for a given stream job along with the status.",NULL,"List Streams Jobs based with deployed modules Currently, there is a stream list job list which shows the status of a given stream job along with the DSL. and, there is runtime modules which shows all the deployed modules with their container info. We need a better REST endpoint that gives all the deployed modules for a given stream job along with the status.",NULL,"List Streams Jobs based with deployed modules Currently, there is a stream list job list which shows the status of a given stream job along with the DSL<span class='highlight-text severity-high'>. and, there is runtime modules which shows all the deployed modules with their container info. We need a better REST endpoint that gives all the deployed modules for a given stream job along with the status.</span>","minimal","punctuation","high",False
25681,"Deployment properties should use label instead of name stream create foo definition label bar xxxx stream deploy foo properties seems to work but it does not. The pre validation is correct, but downstream, deployment logic still looks for module.bar instead of module.label ",NULL,"Deployment properties should use label instead of name stream create foo definition label bar xxxx stream deploy foo properties seems to work but it does not. The pre validation is correct, but downstream, deployment logic still looks for module.bar instead of module.label ",NULL,"Add for who this story is","well_formed","no_role","high",False
25681,"Deployment properties should use label instead of name stream create foo definition label bar xxxx stream deploy foo properties seems to work but it does not. The pre validation is correct, but downstream, deployment logic still looks for module.bar instead of module.label ",NULL,"Deployment properties should use label instead of name stream create foo definition label bar xxxx stream deploy foo properties seems to work but it does not. The pre validation is correct, but downstream, deployment logic still looks for module.bar instead of module.label ",NULL,"Deployment properties should use label instead of name stream create foo definition label bar xxxx stream deploy foo properties seems to work but it does not<span class='highlight-text severity-high'>. The pre validation is correct, but downstream, deployment logic still looks for module.bar instead of module.label </span>","minimal","punctuation","high",False
25675,"Secure endpoints using either ROLE VIEWER and ROLE ADMIN As a user, I'd like to have the option to configure default access control for endpoints so that I can grant access by Admin or Viewer roles.",NULL,"Secure endpoints using either ROLE VIEWER and ROLE ADMIN As a user, I'd like to have the option to configure default access control for endpoints","so that I can grant access by Admin or Viewer roles.","Add for who this story is","well_formed","no_role","high",False
25675,"Secure endpoints using either ROLE VIEWER and ROLE ADMIN As a user, I'd like to have the option to configure default access control for endpoints so that I can grant access by Admin or Viewer roles.",NULL,"Secure endpoints using either ROLE VIEWER and ROLE ADMIN As a user, I'd like to have the option to configure default access control for endpoints","so that I can grant access by Admin or Viewer roles.","Secure endpoints using either ROLE VIEWER<span class='highlight-text severity-high'> and </span>ROLE ADMIN As a user, I'd like to have the option to configure default access control for endpoints so that I can grant access by Admin<span class='highlight-text severity-high'> or </span>Viewer roles.","atomic","conjunctions","high",False
25675,"Secure endpoints using either ROLE VIEWER and ROLE ADMIN As a user, I'd like to have the option to configure default access control for endpoints so that I can grant access by Admin or Viewer roles.",NULL,"Secure endpoints using either ROLE VIEWER and ROLE ADMIN As a user, I'd like to have the option to configure default access control for endpoints","so that I can grant access by Admin or Viewer roles.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25687,"Research REST endpoint approach to push custom module As a user, I'd like to have a REST API to point and push an archive that includes custom module definitions and configurations so that I don t have to manually move and set it up. Scope of this spike Assess customer requirement, brainstorm, and document options Socialize with the team to collect feedback Identify phases Create new stories",NULL,"Research REST endpoint approach to push custom module As a user, I'd like to have a REST API to point and push an archive that includes custom module definitions and configurations","so that I don t have to manually move and set it up. Scope of this spike Assess customer requirement, brainstorm, and document options Socialize with the team to collect feedback Identify phases Create new stories","Add for who this story is","well_formed","no_role","high",False
25687,"Research REST endpoint approach to push custom module As a user, I'd like to have a REST API to point and push an archive that includes custom module definitions and configurations so that I don t have to manually move and set it up. Scope of this spike Assess customer requirement, brainstorm, and document options Socialize with the team to collect feedback Identify phases Create new stories",NULL,"Research REST endpoint approach to push custom module As a user, I'd like to have a REST API to point and push an archive that includes custom module definitions and configurations","so that I don t have to manually move and set it up. Scope of this spike Assess customer requirement, brainstorm, and document options Socialize with the team to collect feedback Identify phases Create new stories","Research REST endpoint approach to push custom module As a user, I'd like to have a REST API to point<span class='highlight-text severity-high'> and </span>push an archive that includes custom module definitions and configurations so that I don t have to manually move and set it up. Scope of this spike Assess customer requirement, brainstorm, and document options Socialize with the team to collect feedback Identify phases Create new stories","atomic","conjunctions","high",False
25687,"Research REST endpoint approach to push custom module As a user, I'd like to have a REST API to point and push an archive that includes custom module definitions and configurations so that I don t have to manually move and set it up. Scope of this spike Assess customer requirement, brainstorm, and document options Socialize with the team to collect feedback Identify phases Create new stories",NULL,"Research REST endpoint approach to push custom module As a user, I'd like to have a REST API to point and push an archive that includes custom module definitions and configurations","so that I don t have to manually move and set it up. Scope of this spike Assess customer requirement, brainstorm, and document options Socialize with the team to collect feedback Identify phases Create new stories","Research REST endpoint approach to push custom module As a user, I'd like to have a REST API to point and push an archive that includes custom module definitions and configurations so that I don t have to manually move and set it up<span class='highlight-text severity-high'>. Scope of this spike Assess customer requirement, brainstorm, and document options Socialize with the team to collect feedback Identify phases Create new stories</span>","minimal","punctuation","high",False
25687,"Research REST endpoint approach to push custom module As a user, I'd like to have a REST API to point and push an archive that includes custom module definitions and configurations so that I don t have to manually move and set it up. Scope of this spike Assess customer requirement, brainstorm, and document options Socialize with the team to collect feedback Identify phases Create new stories",NULL,"Research REST endpoint approach to push custom module As a user, I'd like to have a REST API to point and push an archive that includes custom module definitions and configurations","so that I don t have to manually move and set it up. Scope of this spike Assess customer requirement, brainstorm, and document options Socialize with the team to collect feedback Identify phases Create new stories","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25730,"Upgrade to Spring Boot 1.2.0 As to prepare for 1.1 release, we would like to upgrade to Spring Boot 1.2.0 RC1 depends on Spring 4.1.2 so that we can leverage the new features, enhancement and bug fixes. Spring Boot Milestones ",NULL,"Upgrade to Spring Boot 1.2.0 As to prepare for 1.1 release, we would like to upgrade to Spring Boot 1.2.0 RC1 depends on Spring 4.1.2","so that we can leverage the new features, enhancement and bug fixes. Spring Boot Milestones","Add for who this story is","well_formed","no_role","high",False
25730,"Upgrade to Spring Boot 1.2.0 As to prepare for 1.1 release, we would like to upgrade to Spring Boot 1.2.0 RC1 depends on Spring 4.1.2 so that we can leverage the new features, enhancement and bug fixes. Spring Boot Milestones ",NULL,"Upgrade to Spring Boot 1.2.0 As to prepare for 1.1 release, we would like to upgrade to Spring Boot 1.2.0 RC1 depends on Spring 4.1.2","so that we can leverage the new features, enhancement and bug fixes. Spring Boot Milestones","Upgrade to Spring Boot 1<span class='highlight-text severity-high'>.2.0 As to prepare for 1.1 release, we would like to upgrade to Spring Boot 1.2.0 RC1 depends on Spring 4.1.2 so that we can leverage the new features, enhancement and bug fixes. Spring Boot Milestones </span>","minimal","punctuation","high",False
25730,"Upgrade to Spring Boot 1.2.0 As to prepare for 1.1 release, we would like to upgrade to Spring Boot 1.2.0 RC1 depends on Spring 4.1.2 so that we can leverage the new features, enhancement and bug fixes. Spring Boot Milestones ",NULL,"Upgrade to Spring Boot 1.2.0 As to prepare for 1.1 release, we would like to upgrade to Spring Boot 1.2.0 RC1 depends on Spring 4.1.2","so that we can leverage the new features, enhancement and bug fixes. Spring Boot Milestones","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25726,"Vary producers size ECB 5 Use the number of consumers gave a maximum throughput in the previous test say 10 consumers , message size 100 bytes, Prefetch 100. Send 1M messages Vary the number of producers. Measure the msg sec rate and calculate the data transfer rate in MB sec. Number of producers 2 4 6 10 50 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",NULL,"Vary producers size ECB 5 Use the number of consumers gave a maximum throughput in the previous test say 10 consumers , message size 100 bytes, Prefetch 100. Send 1M messages Vary the number of producers. Measure the msg sec rate and calculate the data transfer rate in MB sec. Number of producers 2 4 6 10 50 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",NULL,"Add for who this story is","well_formed","no_role","high",False
25726,"Vary producers size ECB 5 Use the number of consumers gave a maximum throughput in the previous test say 10 consumers , message size 100 bytes, Prefetch 100. Send 1M messages Vary the number of producers. Measure the msg sec rate and calculate the data transfer rate in MB sec. Number of producers 2 4 6 10 50 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",NULL,"Vary producers size ECB 5 Use the number of consumers gave a maximum throughput in the previous test say 10 consumers , message size 100 bytes, Prefetch 100. Send 1M messages Vary the number of producers. Measure the msg sec rate and calculate the data transfer rate in MB sec. Number of producers 2 4 6 10 50 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",NULL,"Vary producers size ECB 5 Use the number of consumers gave a maximum throughput in the previous test say 10 consumers , message size 100 bytes, Prefetch 100. Send 1M messages Vary the number of producers. Measure the msg sec rate<span class='highlight-text severity-high'> and </span>calculate the data transfer rate in MB sec. Number of producers 2 4 6 10 50 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.","atomic","conjunctions","high",False
25726,"Vary producers size ECB 5 Use the number of consumers gave a maximum throughput in the previous test say 10 consumers , message size 100 bytes, Prefetch 100. Send 1M messages Vary the number of producers. Measure the msg sec rate and calculate the data transfer rate in MB sec. Number of producers 2 4 6 10 50 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",NULL,"Vary producers size ECB 5 Use the number of consumers gave a maximum throughput in the previous test say 10 consumers , message size 100 bytes, Prefetch 100. Send 1M messages Vary the number of producers. Measure the msg sec rate and calculate the data transfer rate in MB sec. Number of producers 2 4 6 10 50 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",NULL,"Vary producers size ECB 5 Use the number of consumers gave a maximum throughput in the previous test say 10 consumers , message size 100 bytes, Prefetch 100<span class='highlight-text severity-high'>. Send 1M messages Vary the number of producers. Measure the msg sec rate and calculate the data transfer rate in MB sec. Number of producers 2 4 6 10 50 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.</span>","minimal","punctuation","high",False
25733,"Vary prefecth size EC DB 3 Use a single producer, single consumer, message size of 1000 bytes. Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes. Vary the prefetch size. Measure the msg sec rate and calculate the data transfer rate in MB sec. Prefetch Sizes 1 10 50 100 10000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",NULL,"Vary prefecth size EC DB 3 Use a single producer, single consumer, message size of 1000 bytes. Send 1M messages and increase or decrease","so that a given test iteration takes about 2 minutes. Vary the prefetch size. Measure the msg sec rate and calculate the data transfer rate in MB sec. Prefetch Sizes 1 10 50 100 10000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.","Add for who this story is","well_formed","no_role","high",False
25733,"Vary prefecth size EC DB 3 Use a single producer, single consumer, message size of 1000 bytes. Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes. Vary the prefetch size. Measure the msg sec rate and calculate the data transfer rate in MB sec. Prefetch Sizes 1 10 50 100 10000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",NULL,"Vary prefecth size EC DB 3 Use a single producer, single consumer, message size of 1000 bytes. Send 1M messages and increase or decrease","so that a given test iteration takes about 2 minutes. Vary the prefetch size. Measure the msg sec rate and calculate the data transfer rate in MB sec. Prefetch Sizes 1 10 50 100 10000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.","Vary prefecth size EC DB 3 Use a single producer, single consumer, message size of 1000 bytes. Send 1M messages<span class='highlight-text severity-high'> and </span>increase<span class='highlight-text severity-high'> or </span>decrease so that a given test iteration takes about 2 minutes. Vary the prefetch size. Measure the msg sec rate and calculate the data transfer rate in MB sec. Prefetch Sizes 1 10 50 100 10000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.","atomic","conjunctions","high",False
25733,"Vary prefecth size EC DB 3 Use a single producer, single consumer, message size of 1000 bytes. Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes. Vary the prefetch size. Measure the msg sec rate and calculate the data transfer rate in MB sec. Prefetch Sizes 1 10 50 100 10000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",NULL,"Vary prefecth size EC DB 3 Use a single producer, single consumer, message size of 1000 bytes. Send 1M messages and increase or decrease","so that a given test iteration takes about 2 minutes. Vary the prefetch size. Measure the msg sec rate and calculate the data transfer rate in MB sec. Prefetch Sizes 1 10 50 100 10000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.","Vary prefecth size EC DB 3 Use a single producer, single consumer, message size of 1000 bytes<span class='highlight-text severity-high'>. Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes. Vary the prefetch size. Measure the msg sec rate and calculate the data transfer rate in MB sec. Prefetch Sizes 1 10 50 100 10000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.</span>","minimal","punctuation","high",False
25733,"Vary prefecth size EC DB 3 Use a single producer, single consumer, message size of 1000 bytes. Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes. Vary the prefetch size. Measure the msg sec rate and calculate the data transfer rate in MB sec. Prefetch Sizes 1 10 50 100 10000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",NULL,"Vary prefecth size EC DB 3 Use a single producer, single consumer, message size of 1000 bytes. Send 1M messages and increase or decrease","so that a given test iteration takes about 2 minutes. Vary the prefetch size. Measure the msg sec rate and calculate the data transfer rate in MB sec. Prefetch Sizes 1 10 50 100 10000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25763,"Remove external config properties for modules There are some modules that use external config properties kafka producer consumer, hadoop properties etc., . We need to avoid using such properties and have them configured inside module so that module and its properties are self contained. ",NULL,"Remove external config properties for modules There are some modules that use external config properties kafka producer consumer, hadoop properties etc., . We need to avoid using such properties and have them configured inside module","so that module and its properties are self contained.","Add for who this story is","well_formed","no_role","high",False
25763,"Remove external config properties for modules There are some modules that use external config properties kafka producer consumer, hadoop properties etc., . We need to avoid using such properties and have them configured inside module so that module and its properties are self contained. ",NULL,"Remove external config properties for modules There are some modules that use external config properties kafka producer consumer, hadoop properties etc., . We need to avoid using such properties and have them configured inside module","so that module and its properties are self contained.","Remove external config properties for modules There are some modules that use external config properties kafka producer consumer, hadoop properties etc., . We need to avoid using such properties<span class='highlight-text severity-high'> and </span>have them configured inside module so that module and its properties are self contained. ","atomic","conjunctions","high",False
25763,"Remove external config properties for modules There are some modules that use external config properties kafka producer consumer, hadoop properties etc., . We need to avoid using such properties and have them configured inside module so that module and its properties are self contained. ",NULL,"Remove external config properties for modules There are some modules that use external config properties kafka producer consumer, hadoop properties etc., . We need to avoid using such properties and have them configured inside module","so that module and its properties are self contained.","Remove external config properties for modules There are some modules that use external config properties kafka producer consumer, hadoop properties etc<span class='highlight-text severity-high'>., . We need to avoid using such properties and have them configured inside module so that module and its properties are self contained. </span>","minimal","punctuation","high",False
25763,"Remove external config properties for modules There are some modules that use external config properties kafka producer consumer, hadoop properties etc., . We need to avoid using such properties and have them configured inside module so that module and its properties are self contained. ",NULL,"Remove external config properties for modules There are some modules that use external config properties kafka producer consumer, hadoop properties etc., . We need to avoid using such properties and have them configured inside module","so that module and its properties are self contained.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25771,"Pre allocate partitions for Kafka message bus As a user, I want Spring XD s message bus to be able to pre allocate partitions between nodes when a stream is deployed, so that rebalancing doesn t happen when a container crashes and or it s redeployed.",NULL,"Pre allocate partitions for Kafka message bus As a user, I want Spring XD s message bus to be able to pre allocate partitions between nodes when a stream is deployed,","so that rebalancing doesn t happen when a container crashes and or it s redeployed.","Add for who this story is","well_formed","no_role","high",False
25771,"Pre allocate partitions for Kafka message bus As a user, I want Spring XD s message bus to be able to pre allocate partitions between nodes when a stream is deployed, so that rebalancing doesn t happen when a container crashes and or it s redeployed.",NULL,"Pre allocate partitions for Kafka message bus As a user, I want Spring XD s message bus to be able to pre allocate partitions between nodes when a stream is deployed,","so that rebalancing doesn t happen when a container crashes and or it s redeployed.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25777,"Research reactor stream integration options As a user, I'd like to have a reactor stream processor module so that I can ingest data using XD source modules and process them as time window operations. Example 1 http reactor stream timeWindow 10s This would give you 10 second time window of the min and avg values. Example 2 Reactor as a module Example 3 Integration with Spark streaming and reactor",NULL,"Research reactor stream integration options As a user, I'd like to have a reactor stream processor module","so that I can ingest data using XD source modules and process them as time window operations. Example 1 http reactor stream timeWindow 10s This would give you 10 second time window of the min and avg values. Example 2 Reactor as a module Example 3 Integration with Spark streaming and reactor","Add for who this story is","well_formed","no_role","high",False
25777,"Research reactor stream integration options As a user, I'd like to have a reactor stream processor module so that I can ingest data using XD source modules and process them as time window operations. Example 1 http reactor stream timeWindow 10s This would give you 10 second time window of the min and avg values. Example 2 Reactor as a module Example 3 Integration with Spark streaming and reactor",NULL,"Research reactor stream integration options As a user, I'd like to have a reactor stream processor module","so that I can ingest data using XD source modules and process them as time window operations. Example 1 http reactor stream timeWindow 10s This would give you 10 second time window of the min and avg values. Example 2 Reactor as a module Example 3 Integration with Spark streaming and reactor","Research reactor stream integration options As a user, I'd like to have a reactor stream processor module so that I can ingest data using XD source modules and process them as time window operations<span class='highlight-text severity-high'>. Example 1 http reactor stream timeWindow 10s This would give you 10 second time window of the min and avg values. Example 2 Reactor as a module Example 3 Integration with Spark streaming and reactor</span>","minimal","punctuation","high",False
25777,"Research reactor stream integration options As a user, I'd like to have a reactor stream processor module so that I can ingest data using XD source modules and process them as time window operations. Example 1 http reactor stream timeWindow 10s This would give you 10 second time window of the min and avg values. Example 2 Reactor as a module Example 3 Integration with Spark streaming and reactor",NULL,"Research reactor stream integration options As a user, I'd like to have a reactor stream processor module","so that I can ingest data using XD source modules and process them as time window operations. Example 1 http reactor stream timeWindow 10s This would give you 10 second time window of the min and avg values. Example 2 Reactor as a module Example 3 Integration with Spark streaming and reactor","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25789,"Spike Study elastic instances and scheduling in Bamboo to create Windows CI infrastructure As a build manager, I'd like to setup CI infrastructure so that I can run integration tests in Windows OS automatically as we commit trigger new builds. Scope Use the environment where Bamboo is running Gain access to powershell Setup services redis, rabbit, etc. Kick off CI task",NULL,"Spike Study elastic instances and scheduling in Bamboo to create Windows CI infrastructure As a build manager, I'd like to setup CI infrastructure","so that I can run integration tests in Windows OS automatically as we commit trigger new builds. Scope Use the environment where Bamboo is running Gain access to powershell Setup services redis, rabbit, etc. Kick off CI task","Add for who this story is","well_formed","no_role","high",False
25789,"Spike Study elastic instances and scheduling in Bamboo to create Windows CI infrastructure As a build manager, I'd like to setup CI infrastructure so that I can run integration tests in Windows OS automatically as we commit trigger new builds. Scope Use the environment where Bamboo is running Gain access to powershell Setup services redis, rabbit, etc. Kick off CI task",NULL,"Spike Study elastic instances and scheduling in Bamboo to create Windows CI infrastructure As a build manager, I'd like to setup CI infrastructure","so that I can run integration tests in Windows OS automatically as we commit trigger new builds. Scope Use the environment where Bamboo is running Gain access to powershell Setup services redis, rabbit, etc. Kick off CI task","Spike Study elastic instances and scheduling in Bamboo to create Windows CI infrastructure As a build manager, I'd like to setup CI infrastructure so that I can run integration tests in Windows OS automatically as we commit trigger new builds<span class='highlight-text severity-high'>. Scope Use the environment where Bamboo is running Gain access to powershell Setup services redis, rabbit, etc. Kick off CI task</span>","minimal","punctuation","high",False
25789,"Spike Study elastic instances and scheduling in Bamboo to create Windows CI infrastructure As a build manager, I'd like to setup CI infrastructure so that I can run integration tests in Windows OS automatically as we commit trigger new builds. Scope Use the environment where Bamboo is running Gain access to powershell Setup services redis, rabbit, etc. Kick off CI task",NULL,"Spike Study elastic instances and scheduling in Bamboo to create Windows CI infrastructure As a build manager, I'd like to setup CI infrastructure","so that I can run integration tests in Windows OS automatically as we commit trigger new builds. Scope Use the environment where Bamboo is running Gain access to powershell Setup services redis, rabbit, etc. Kick off CI task","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25806,"Create a Trigger Create a Trigger As the XD system, I need to be able to execute a job or potentially a stream based on a given condition time, data existence, etc . This story is intended is for a local trigger implementation but remote triggers will also need to exist. ",NULL,"Create a Trigger Create a Trigger As the XD system, I need to be able to execute a job or potentially a stream based on a given condition time, data existence, etc . This story is intended is for a local trigger implementation but remote triggers will also need to exist. ",NULL,"Add for who this story is","well_formed","no_role","high",False
25806,"Create a Trigger Create a Trigger As the XD system, I need to be able to execute a job or potentially a stream based on a given condition time, data existence, etc . This story is intended is for a local trigger implementation but remote triggers will also need to exist. ",NULL,"Create a Trigger Create a Trigger As the XD system, I need to be able to execute a job or potentially a stream based on a given condition time, data existence, etc . This story is intended is for a local trigger implementation but remote triggers will also need to exist. ",NULL,"Create a Trigger Create a Trigger As the XD system, I need to be able to execute a job<span class='highlight-text severity-high'> or </span>potentially a stream based on a given condition time, data existence, etc . This story is intended is for a local trigger implementation but remote triggers will also need to exist. ","atomic","conjunctions","high",False
25806,"Create a Trigger Create a Trigger As the XD system, I need to be able to execute a job or potentially a stream based on a given condition time, data existence, etc . This story is intended is for a local trigger implementation but remote triggers will also need to exist. ",NULL,"Create a Trigger Create a Trigger As the XD system, I need to be able to execute a job or potentially a stream based on a given condition time, data existence, etc . This story is intended is for a local trigger implementation but remote triggers will also need to exist. ",NULL,"Create a Trigger Create a Trigger As the XD system, I need to be able to execute a job or potentially a stream based on a given condition time, data existence, etc <span class='highlight-text severity-high'>. This story is intended is for a local trigger implementation but remote triggers will also need to exist. </span>","minimal","punctuation","high",False
25815,"Kafka Bus Concurrency and compression support As a user, I'd like to have concurrency and compression support for Kafka so that I can increase performance throughput and or increase responsiveness Things to consider make global configuration options be defaults and allow per deployment overrides add options for concurrency compression support",NULL,"Kafka Bus Concurrency and compression support As a user, I'd like to have concurrency and compression support for Kafka","so that I can increase performance throughput and or increase responsiveness Things to consider make global configuration options be defaults and allow per deployment overrides add options for concurrency compression support","Add for who this story is","well_formed","no_role","high",False
25815,"Kafka Bus Concurrency and compression support As a user, I'd like to have concurrency and compression support for Kafka so that I can increase performance throughput and or increase responsiveness Things to consider make global configuration options be defaults and allow per deployment overrides add options for concurrency compression support",NULL,"Kafka Bus Concurrency and compression support As a user, I'd like to have concurrency and compression support for Kafka","so that I can increase performance throughput and or increase responsiveness Things to consider make global configuration options be defaults and allow per deployment overrides add options for concurrency compression support","Kafka Bus Concurrency<span class='highlight-text severity-high'> and </span>compression support As a user, I'd like to have concurrency and compression support for Kafka so that I can increase performance throughput and<span class='highlight-text severity-high'> or </span>increase responsiveness Things to consider make global configuration options be defaults and allow per deployment overrides add options for concurrency compression support","atomic","conjunctions","high",False
25815,"Kafka Bus Concurrency and compression support As a user, I'd like to have concurrency and compression support for Kafka so that I can increase performance throughput and or increase responsiveness Things to consider make global configuration options be defaults and allow per deployment overrides add options for concurrency compression support",NULL,"Kafka Bus Concurrency and compression support As a user, I'd like to have concurrency and compression support for Kafka","so that I can increase performance throughput and or increase responsiveness Things to consider make global configuration options be defaults and allow per deployment overrides add options for concurrency compression support","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25834,"Document metadata attribute As a user, I'd like to use attribute for jobs that inherit strategy but it is not exposed as a metadata attribute in the wiki. Note The property should be available for all the jobs that import; 3 OOTB jobs have it imported ref. attachment ",NULL,"Document metadata attribute As a user, I'd like to use attribute for jobs that inherit strategy but it is not exposed as a metadata attribute in the wiki. Note The property should be available for all the jobs that import; 3 OOTB jobs have it imported ref. attachment ",NULL,"Add for who this story is","well_formed","no_role","high",False
25834,"Document metadata attribute As a user, I'd like to use attribute for jobs that inherit strategy but it is not exposed as a metadata attribute in the wiki. Note The property should be available for all the jobs that import; 3 OOTB jobs have it imported ref. attachment ",NULL,"Document metadata attribute As a user, I'd like to use attribute for jobs that inherit strategy but it is not exposed as a metadata attribute in the wiki. Note The property should be available for all the jobs that import; 3 OOTB jobs have it imported ref. attachment ",NULL,"Document metadata attribute As a user, I'd like to use attribute for jobs that inherit strategy but it is not exposed as a metadata attribute in the wiki<span class='highlight-text severity-high'>. Note The property should be available for all the jobs that import; 3 OOTB jobs have it imported ref. attachment </span>","minimal","punctuation","high",False
25842,"Clean up spring xd batch sub project We should move the and to the project",NULL,"Clean up spring xd batch sub project We should move the and to the project",NULL,"Add for who this story is","well_formed","no_role","high",False
25852,"Set up a project for XD Shell Set up a basic Spring Shell project for XD Shell",NULL,"Set up a project for XD Shell Set up a basic Spring Shell project for XD Shell",NULL,"Add for who this story is","well_formed","no_role","high",False
25845,"Add support to extend message compression As a user, I'd like to have the option to extend compression support so that I can override the defaults and customize as needed. Follow up from this PR ",NULL,"Add support to extend message compression As a user, I'd like to have the option to extend compression support","so that I can override the defaults and customize as needed. Follow up from this PR","Add for who this story is","well_formed","no_role","high",False
26240,"Return full ModuleStatus information Remove all stubs and check all required information is returned accurately.",NULL,"Return full ModuleStatus information Remove all stubs and check all required information is returned accurately.",NULL,"Add for who this story is","well_formed","no_role","high",False
26251,"Implement undeploy operation for singlenode SPI As a s c d developer, I'd like to implement undeploy operation for single JVM , so I can use this target to undeploy a running stream. More details in this PR Note Its a prerequisite to determine consistent undeploy strategy for both . ",NULL,"Implement undeploy operation for singlenode SPI As a s c d developer, I'd like to implement undeploy operation for single JVM ,","so I can use this target to undeploy a running stream. More details in this PR Note Its a prerequisite to determine consistent undeploy strategy for both .","Add for who this story is","well_formed","no_role","high",False
25871,"Create MessageConverter interface to allow user extensions As a user, I'd like to have the option to extend the default message handling behavior for HTTP source module so that I can override the settings via servers.yml to control the default message size. Notes The adapter currently has that hard coded 1MB limit in the We will have to expose this property for overrides. Related PR ",NULL,"Create MessageConverter interface to allow user extensions As a user, I'd like to have the option to extend the default message handling behavior for HTTP source module","so that I can override the settings via servers.yml to control the default message size. Notes The adapter currently has that hard coded 1MB limit in the We will have to expose this property for overrides. Related PR","Create MessageConverter interface to allow user extensions As a user, I'd like to have the option to extend the default message handling behavior for HTTP source module so that I can override the settings via servers<span class='highlight-text severity-high'>.yml to control the default message size. Notes The adapter currently has that hard coded 1MB limit in the We will have to expose this property for overrides. Related PR </span>","minimal","punctuation","high",False
25871,"Create MessageConverter interface to allow user extensions As a user, I'd like to have the option to extend the default message handling behavior for HTTP source module so that I can override the settings via servers.yml to control the default message size. Notes The adapter currently has that hard coded 1MB limit in the We will have to expose this property for overrides. Related PR ",NULL,"Create MessageConverter interface to allow user extensions As a user, I'd like to have the option to extend the default message handling behavior for HTTP source module","so that I can override the settings via servers.yml to control the default message size. Notes The adapter currently has that hard coded 1MB limit in the We will have to expose this property for overrides. Related PR","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25888,"Add Ambari plugin beta to build and install Spring XD As a developer, I'd like to use Ambari plugin so that I can provision, manage, and monitor Spring XD cluster using the same tool I use for Hadoop clusters.",NULL,"Add Ambari plugin beta to build and install Spring XD As a developer, I'd like to use Ambari plugin","so that I can provision, manage, and monitor Spring XD cluster using the same tool I use for Hadoop clusters.","Add for who this story is","well_formed","no_role","high",False
25888,"Add Ambari plugin beta to build and install Spring XD As a developer, I'd like to use Ambari plugin so that I can provision, manage, and monitor Spring XD cluster using the same tool I use for Hadoop clusters.",NULL,"Add Ambari plugin beta to build and install Spring XD As a developer, I'd like to use Ambari plugin","so that I can provision, manage, and monitor Spring XD cluster using the same tool I use for Hadoop clusters.","Add Ambari plugin beta to build<span class='highlight-text severity-high'> and </span>install Spring XD As a developer, I'd like to use Ambari plugin so that I can provision, manage, and monitor Spring XD cluster using the same tool I use for Hadoop clusters.","atomic","conjunctions","high",False
25888,"Add Ambari plugin beta to build and install Spring XD As a developer, I'd like to use Ambari plugin so that I can provision, manage, and monitor Spring XD cluster using the same tool I use for Hadoop clusters.",NULL,"Add Ambari plugin beta to build and install Spring XD As a developer, I'd like to use Ambari plugin","so that I can provision, manage, and monitor Spring XD cluster using the same tool I use for Hadoop clusters.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25900,"Create java client lib over REST API So that clients e.g. Shell or custom user program are insulated from REST details ala Cloud Foundry . May go even further if we want a Java DSL for stream definitions that may reuse Batch command POJOs btw Difference between http port 9000 file and import static stuff. ; StreamDef stream stream ;",NULL,"Create java client lib over REST API","So that clients e.g. Shell or custom user program are insulated from REST details ala Cloud Foundry . May go even further if we want a Java DSL for stream definitions that may reuse Batch command POJOs btw Difference between http port 9000 file and import static stuff. ; StreamDef stream stream ;","Add for who this story is","well_formed","no_role","high",False
25900,"Create java client lib over REST API So that clients e.g. Shell or custom user program are insulated from REST details ala Cloud Foundry . May go even further if we want a Java DSL for stream definitions that may reuse Batch command POJOs btw Difference between http port 9000 file and import static stuff. ; StreamDef stream stream ;",NULL,"Create java client lib over REST API","So that clients e.g. Shell or custom user program are insulated from REST details ala Cloud Foundry . May go even further if we want a Java DSL for stream definitions that may reuse Batch command POJOs btw Difference between http port 9000 file and import static stuff. ; StreamDef stream stream ;","Create java client lib over REST API So that clients e<span class='highlight-text severity-high'>.g. Shell or custom user program are insulated from REST details ala Cloud Foundry . May go even further if we want a Java DSL for stream definitions that may reuse Batch command POJOs btw Difference between http port 9000 file and import static stuff. ; StreamDef stream stream ;</span>","minimal","punctuation","high",False
25900,"Create java client lib over REST API So that clients e.g. Shell or custom user program are insulated from REST details ala Cloud Foundry . May go even further if we want a Java DSL for stream definitions that may reuse Batch command POJOs btw Difference between http port 9000 file and import static stuff. ; StreamDef stream stream ;",NULL,"Create java client lib over REST API","So that clients e.g. Shell or custom user program are insulated from REST details ala Cloud Foundry . May go even further if we want a Java DSL for stream definitions that may reuse Batch command POJOs btw Difference between http port 9000 file and import static stuff. ; StreamDef stream stream ;","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25910,"Streamline command line arg management Command line arguments and especially their default values are currently scattered around different places. The aim is to regroup those in a common place Options classes make sense . Also, not very happy with how System properties are used as a vehicle for options.transport options.home",NULL,"Streamline command line arg management Command line arguments and especially their default values are currently scattered around different places. The aim is to regroup those in a common place Options classes make sense . Also, not very happy with how System properties are used as a vehicle for options.transport options.home",NULL,"Add for who this story is","well_formed","no_role","high",False
25910,"Streamline command line arg management Command line arguments and especially their default values are currently scattered around different places. The aim is to regroup those in a common place Options classes make sense . Also, not very happy with how System properties are used as a vehicle for options.transport options.home",NULL,"Streamline command line arg management Command line arguments and especially their default values are currently scattered around different places. The aim is to regroup those in a common place Options classes make sense . Also, not very happy with how System properties are used as a vehicle for options.transport options.home",NULL,"Streamline command line arg management Command line arguments<span class='highlight-text severity-high'> and </span>especially their default values are currently scattered around different places. The aim is to regroup those in a common place Options classes make sense . Also, not very happy with how System properties are used as a vehicle for options.transport options.home","atomic","conjunctions","high",False
25910,"Streamline command line arg management Command line arguments and especially their default values are currently scattered around different places. The aim is to regroup those in a common place Options classes make sense . Also, not very happy with how System properties are used as a vehicle for options.transport options.home",NULL,"Streamline command line arg management Command line arguments and especially their default values are currently scattered around different places. The aim is to regroup those in a common place Options classes make sense . Also, not very happy with how System properties are used as a vehicle for options.transport options.home",NULL,"Streamline command line arg management Command line arguments and especially their default values are currently scattered around different places<span class='highlight-text severity-high'>. The aim is to regroup those in a common place Options classes make sense . Also, not very happy with how System properties are used as a vehicle for options.transport options.home</span>","minimal","punctuation","high",False
25926,"Create Kafka data pipeline example As a developer, I'd like to build data pipeline using Kafka as as message bus in XD so that we can demonstrate some of the capabilities. Use case to consider Log aggregation and analysis Lambda architecture how to avoid code duplication how to eliminate tight coupling of business logic how Kafka can be used for reliable reprocessing ",NULL,"Create Kafka data pipeline example As a developer, I'd like to build data pipeline using Kafka as as message bus in XD","so that we can demonstrate some of the capabilities. Use case to consider Log aggregation and analysis Lambda architecture how to avoid code duplication how to eliminate tight coupling of business logic how Kafka can be used for reliable reprocessing","Add for who this story is","well_formed","no_role","high",False
25926,"Create Kafka data pipeline example As a developer, I'd like to build data pipeline using Kafka as as message bus in XD so that we can demonstrate some of the capabilities. Use case to consider Log aggregation and analysis Lambda architecture how to avoid code duplication how to eliminate tight coupling of business logic how Kafka can be used for reliable reprocessing ",NULL,"Create Kafka data pipeline example As a developer, I'd like to build data pipeline using Kafka as as message bus in XD","so that we can demonstrate some of the capabilities. Use case to consider Log aggregation and analysis Lambda architecture how to avoid code duplication how to eliminate tight coupling of business logic how Kafka can be used for reliable reprocessing","Create Kafka data pipeline example As a developer, I'd like to build data pipeline using Kafka as as message bus in XD so that we can demonstrate some of the capabilities<span class='highlight-text severity-high'>. Use case to consider Log aggregation and analysis Lambda architecture how to avoid code duplication how to eliminate tight coupling of business logic how Kafka can be used for reliable reprocessing </span>","minimal","punctuation","high",False
25926,"Create Kafka data pipeline example As a developer, I'd like to build data pipeline using Kafka as as message bus in XD so that we can demonstrate some of the capabilities. Use case to consider Log aggregation and analysis Lambda architecture how to avoid code duplication how to eliminate tight coupling of business logic how Kafka can be used for reliable reprocessing ",NULL,"Create Kafka data pipeline example As a developer, I'd like to build data pipeline using Kafka as as message bus in XD","so that we can demonstrate some of the capabilities. Use case to consider Log aggregation and analysis Lambda architecture how to avoid code duplication how to eliminate tight coupling of business logic how Kafka can be used for reliable reprocessing","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25944,"Move out of the way Since the refactoring of the module registry that does not look inside a module, it can t know that the scripts directory is not a module. Everything that is a direct child of source, processor, sink, job should be a module archive. Everything else supporting that should be moved out, e.g. in modules common",NULL,"Move out of the way Since the refactoring of the module registry that does not look inside a module, it can t know that the scripts directory is not a module. Everything that is a direct child of source, processor, sink, job should be a module archive. Everything else supporting that should be moved out, e.g. in modules common",NULL,"Add for who this story is","well_formed","no_role","high",False
25944,"Move out of the way Since the refactoring of the module registry that does not look inside a module, it can t know that the scripts directory is not a module. Everything that is a direct child of source, processor, sink, job should be a module archive. Everything else supporting that should be moved out, e.g. in modules common",NULL,"Move out of the way Since the refactoring of the module registry that does not look inside a module, it can t know that the scripts directory is not a module. Everything that is a direct child of source, processor, sink, job should be a module archive. Everything else supporting that should be moved out, e.g. in modules common",NULL,"Move out of the way Since the refactoring of the module registry that does not look inside a module, it can t know that the scripts directory is not a module<span class='highlight-text severity-high'>. Everything that is a direct child of source, processor, sink, job should be a module archive. Everything else supporting that should be moved out, e.g. in modules common</span>","minimal","punctuation","high",False
25950,"Redis sink should default to using spring.redis configuration in servers.yml The configuration for the redis sink must be provided for explicitly instead of falling back to values defined in servers.yml. The default behavior configuration should be address in a manner consistent with the default behavior of module config for rabbit source sink, jdbc sink....",NULL,"Redis sink should default to using spring.redis configuration in servers.yml The configuration for the redis sink must be provided for explicitly instead of falling back to values defined in servers.yml. The default behavior configuration should be address in a manner consistent with the default behavior of module config for rabbit source sink, jdbc sink....",NULL,"Add for who this story is","well_formed","no_role","high",False
25950,"Redis sink should default to using spring.redis configuration in servers.yml The configuration for the redis sink must be provided for explicitly instead of falling back to values defined in servers.yml. The default behavior configuration should be address in a manner consistent with the default behavior of module config for rabbit source sink, jdbc sink....",NULL,"Redis sink should default to using spring.redis configuration in servers.yml The configuration for the redis sink must be provided for explicitly instead of falling back to values defined in servers.yml. The default behavior configuration should be address in a manner consistent with the default behavior of module config for rabbit source sink, jdbc sink....",NULL,"Redis sink should default to using spring<span class='highlight-text severity-high'>.redis configuration in servers.yml The configuration for the redis sink must be provided for explicitly instead of falling back to values defined in servers.yml. The default behavior configuration should be address in a manner consistent with the default behavior of module config for rabbit source sink, jdbc sink....</span>","minimal","punctuation","high",False
25959,"Return description for each module in the JSON response As a developer, I'd like to have the high level description for each of the modules so that I can use the description presumably what is captured in javadoc for the module definition to understand the purpose of the module itself. ",NULL,"Return description for each module in the JSON response As a developer, I'd like to have the high level description for each of the modules","so that I can use the description presumably what is captured in javadoc for the module definition to understand the purpose of the module itself.","Add for who this story is","well_formed","no_role","high",False
25959,"Return description for each module in the JSON response As a developer, I'd like to have the high level description for each of the modules so that I can use the description presumably what is captured in javadoc for the module definition to understand the purpose of the module itself. ",NULL,"Return description for each module in the JSON response As a developer, I'd like to have the high level description for each of the modules","so that I can use the description presumably what is captured in javadoc for the module definition to understand the purpose of the module itself.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25965,"Document the changes to Message Headers in 1.1 As a developer, I'd like to document the changes to message headers so that users can refer to the troubleshooting section if there are any serialization errors when reusing the 1.0 batch jobs in 1.1 release. Perhaps this could be part of troubleshooting section in our wiki.",NULL,"Document the changes to Message Headers in 1.1 As a developer, I'd like to document the changes to message headers","so that users can refer to the troubleshooting section if there are any serialization errors when reusing the 1.0 batch jobs in 1.1 release. Perhaps this could be part of troubleshooting section in our wiki.","Add for who this story is","well_formed","no_role","high",False
25965,"Document the changes to Message Headers in 1.1 As a developer, I'd like to document the changes to message headers so that users can refer to the troubleshooting section if there are any serialization errors when reusing the 1.0 batch jobs in 1.1 release. Perhaps this could be part of troubleshooting section in our wiki.",NULL,"Document the changes to Message Headers in 1.1 As a developer, I'd like to document the changes to message headers","so that users can refer to the troubleshooting section if there are any serialization errors when reusing the 1.0 batch jobs in 1.1 release. Perhaps this could be part of troubleshooting section in our wiki.","Document the changes to Message Headers in 1<span class='highlight-text severity-high'>.1 As a developer, I'd like to document the changes to message headers so that users can refer to the troubleshooting section if there are any serialization errors when reusing the 1.0 batch jobs in 1.1 release. Perhaps this could be part of troubleshooting section in our wiki.</span>","minimal","punctuation","high",False
25965,"Document the changes to Message Headers in 1.1 As a developer, I'd like to document the changes to message headers so that users can refer to the troubleshooting section if there are any serialization errors when reusing the 1.0 batch jobs in 1.1 release. Perhaps this could be part of troubleshooting section in our wiki.",NULL,"Document the changes to Message Headers in 1.1 As a developer, I'd like to document the changes to message headers","so that users can refer to the troubleshooting section if there are any serialization errors when reusing the 1.0 batch jobs in 1.1 release. Perhaps this could be part of troubleshooting section in our wiki.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25973,"Complete CI setup for Windows As a build manager, I'd like to schedule CI builds for windows so that I can verify XD runtime The scope is to isolate the remaining test failures; perhaps, experiment with new AMI images until we have a solid infrastructure to fix the failing tests.",NULL,"Complete CI setup for Windows As a build manager, I'd like to schedule CI builds for windows","so that I can verify XD runtime The scope is to isolate the remaining test failures; perhaps, experiment with new AMI images until we have a solid infrastructure to fix the failing tests.","Add for who this story is","well_formed","no_role","high",False
25973,"Complete CI setup for Windows As a build manager, I'd like to schedule CI builds for windows so that I can verify XD runtime The scope is to isolate the remaining test failures; perhaps, experiment with new AMI images until we have a solid infrastructure to fix the failing tests.",NULL,"Complete CI setup for Windows As a build manager, I'd like to schedule CI builds for windows","so that I can verify XD runtime The scope is to isolate the remaining test failures; perhaps, experiment with new AMI images until we have a solid infrastructure to fix the failing tests.","Complete CI setup for Windows As a build manager, I'd like to schedule CI builds for windows so that I can verify XD runtime The scope is to isolate the remaining test failures<span class='highlight-text severity-high'>; perhaps, experiment with new AMI images until we have a solid infrastructure to fix the failing tests.</span>","minimal","punctuation","high",False
25973,"Complete CI setup for Windows As a build manager, I'd like to schedule CI builds for windows so that I can verify XD runtime The scope is to isolate the remaining test failures; perhaps, experiment with new AMI images until we have a solid infrastructure to fix the failing tests.",NULL,"Complete CI setup for Windows As a build manager, I'd like to schedule CI builds for windows","so that I can verify XD runtime The scope is to isolate the remaining test failures; perhaps, experiment with new AMI images until we have a solid infrastructure to fix the failing tests.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25986,"Refactor job launcher to not depend on execution context As a developer, I'd like to decouple execution context from job launch lifecycle so that we can avoid CL and serialization errors. This fix needs to be formally applied in Spring Batch itself. XD will upgrade to Batch release in order to inherit this functionality; hence, the current workaround with XD 2486 needs reafctored. ",NULL,"Refactor job launcher to not depend on execution context As a developer, I'd like to decouple execution context from job launch lifecycle so that we can avoid CL and serialization errors. This fix needs to be formally applied in Spring Batch itself. XD will upgrade to Batch release","in order to inherit this functionality; hence, the current workaround with XD 2486 needs reafctored.","Add for who this story is","well_formed","no_role","high",False
25986,"Refactor job launcher to not depend on execution context As a developer, I'd like to decouple execution context from job launch lifecycle so that we can avoid CL and serialization errors. This fix needs to be formally applied in Spring Batch itself. XD will upgrade to Batch release in order to inherit this functionality; hence, the current workaround with XD 2486 needs reafctored. ",NULL,"Refactor job launcher to not depend on execution context As a developer, I'd like to decouple execution context from job launch lifecycle so that we can avoid CL and serialization errors. This fix needs to be formally applied in Spring Batch itself. XD will upgrade to Batch release","in order to inherit this functionality; hence, the current workaround with XD 2486 needs reafctored.","Refactor job launcher to not depend on execution context As a developer, I'd like to decouple execution context from job launch lifecycle so that we can avoid CL and serialization errors<span class='highlight-text severity-high'>. This fix needs to be formally applied in Spring Batch itself. XD will upgrade to Batch release in order to inherit this functionality; hence, the current workaround with XD 2486 needs reafctored. </span>","minimal","punctuation","high",False
25986,"Refactor job launcher to not depend on execution context As a developer, I'd like to decouple execution context from job launch lifecycle so that we can avoid CL and serialization errors. This fix needs to be formally applied in Spring Batch itself. XD will upgrade to Batch release in order to inherit this functionality; hence, the current workaround with XD 2486 needs reafctored. ",NULL,"Refactor job launcher to not depend on execution context As a developer, I'd like to decouple execution context from job launch lifecycle so that we can avoid CL and serialization errors. This fix needs to be formally applied in Spring Batch itself. XD will upgrade to Batch release","in order to inherit this functionality; hence, the current workaround with XD 2486 needs reafctored.","Refactor job launcher to not depend on execution context As a developer, I'd like to decouple execution context from job launch lifecycle<span class='highlight-text severity-high'> so that </span>we can avoid CL and serialization errors. This fix needs to be formally applied in Spring Batch itself. XD will upgrade to Batch release<span class='highlight-text severity-high'> in order to </span>inherit this functionality; hence, the current workaround with XD 2486 needs reafctored. ","minimal","indicator_repetition","high",False
25986,"Refactor job launcher to not depend on execution context As a developer, I'd like to decouple execution context from job launch lifecycle so that we can avoid CL and serialization errors. This fix needs to be formally applied in Spring Batch itself. XD will upgrade to Batch release in order to inherit this functionality; hence, the current workaround with XD 2486 needs reafctored. ",NULL,"Refactor job launcher to not depend on execution context As a developer, I'd like to decouple execution context from job launch lifecycle so that we can avoid CL and serialization errors. This fix needs to be formally applied in Spring Batch itself. XD will upgrade to Batch release","in order to inherit this functionality; hence, the current workaround with XD 2486 needs reafctored.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
25994,"Add support to create custom jobs using Java Config As a developer, I'd like to create a custom job module using Java Config so that I don t have to deal with XML configurations. While the following job, I get the error attached below. job create name CDK Global definition customBatchJob deploy job launch name CDK Global Error I m getting an exception that the job doesn t exist asking if it s deployed",NULL,"Add support to create custom jobs using Java Config As a developer, I'd like to create a custom job module using Java Config","so that I don t have to deal with XML configurations. While the following job, I get the error attached below. job create name CDK Global definition customBatchJob deploy job launch name CDK Global Error I m getting an exception that the job doesn t exist asking if it s deployed","Add for who this story is","well_formed","no_role","high",False
26651,"Test composition parameterize composition of modules DSL should be able to parse what is below, need tests CLI integration tests to ensure it is being mapped to an executeable stream. myIntricateFlow transform transform http myIntricateFlow file obfuscateName transform ,XXX twitter query Bieber obfuscateName name Justin file ",NULL,"Test composition parameterize composition of modules DSL should be able to parse what is below, need tests CLI integration tests to ensure it is being mapped to an executeable stream. myIntricateFlow transform transform http myIntricateFlow file obfuscateName transform ,XXX twitter query Bieber obfuscateName name Justin file ",NULL,"Add for who this story is","well_formed","no_role","high",False
25994,"Add support to create custom jobs using Java Config As a developer, I'd like to create a custom job module using Java Config so that I don t have to deal with XML configurations. While the following job, I get the error attached below. job create name CDK Global definition customBatchJob deploy job launch name CDK Global Error I m getting an exception that the job doesn t exist asking if it s deployed",NULL,"Add support to create custom jobs using Java Config As a developer, I'd like to create a custom job module using Java Config","so that I don t have to deal with XML configurations. While the following job, I get the error attached below. job create name CDK Global definition customBatchJob deploy job launch name CDK Global Error I m getting an exception that the job doesn t exist asking if it s deployed","Add support to create custom jobs using Java Config As a developer, I'd like to create a custom job module using Java Config so that I don t have to deal with XML configurations<span class='highlight-text severity-high'>. While the following job, I get the error attached below. job create name CDK Global definition customBatchJob deploy job launch name CDK Global Error I m getting an exception that the job doesn t exist asking if it s deployed</span>","minimal","punctuation","high",False
25994,"Add support to create custom jobs using Java Config As a developer, I'd like to create a custom job module using Java Config so that I don t have to deal with XML configurations. While the following job, I get the error attached below. job create name CDK Global definition customBatchJob deploy job launch name CDK Global Error I m getting an exception that the job doesn t exist asking if it s deployed",NULL,"Add support to create custom jobs using Java Config As a developer, I'd like to create a custom job module using Java Config","so that I don t have to deal with XML configurations. While the following job, I get the error attached below. job create name CDK Global definition customBatchJob deploy job launch name CDK Global Error I m getting an exception that the job doesn t exist asking if it s deployed","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26011,"Support writing to HDFS using Protocol Buffers See ",NULL,"Support writing to HDFS using Protocol Buffers See ",NULL,"Add for who this story is","well_formed","no_role","high",False
26023,"Improve HA support for Rabbit As a developer, I would like to connect to the broker that hosts the Rabbit queue, so I can connect to a Rabbit cluster that s setup for HA FT. Perhaps consider having this feature natively supported in spring amqp itself.",NULL,"Improve HA support for Rabbit As a developer, I would like to connect to the broker that hosts the Rabbit queue,","so I can connect to a Rabbit cluster that s setup for HA FT. Perhaps consider having this feature natively supported in spring amqp itself.","Add for who this story is","well_formed","no_role","high",False
26023,"Improve HA support for Rabbit As a developer, I would like to connect to the broker that hosts the Rabbit queue, so I can connect to a Rabbit cluster that s setup for HA FT. Perhaps consider having this feature natively supported in spring amqp itself.",NULL,"Improve HA support for Rabbit As a developer, I would like to connect to the broker that hosts the Rabbit queue,","so I can connect to a Rabbit cluster that s setup for HA FT. Perhaps consider having this feature natively supported in spring amqp itself.","Improve HA support for Rabbit As a developer, I would like to connect to the broker that hosts the Rabbit queue, so I can connect to a Rabbit cluster that s setup for HA FT<span class='highlight-text severity-high'>. Perhaps consider having this feature natively supported in spring amqp itself.</span>","minimal","punctuation","high",False
26023,"Improve HA support for Rabbit As a developer, I would like to connect to the broker that hosts the Rabbit queue, so I can connect to a Rabbit cluster that s setup for HA FT. Perhaps consider having this feature natively supported in spring amqp itself.",NULL,"Improve HA support for Rabbit As a developer, I would like to connect to the broker that hosts the Rabbit queue,","so I can connect to a Rabbit cluster that s setup for HA FT. Perhaps consider having this feature natively supported in spring amqp itself.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26030,"Acceptance Tests needs to wait for to be populated After the Introduction to XD 2861 the acquisition of JobResources takes more time. We have to introduce a pause to wait for to be populated. ",NULL,"Acceptance Tests needs to wait for to be populated After the Introduction to XD 2861 the acquisition of JobResources takes more time. We have to introduce a pause to wait for to be populated. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26030,"Acceptance Tests needs to wait for to be populated After the Introduction to XD 2861 the acquisition of JobResources takes more time. We have to introduce a pause to wait for to be populated. ",NULL,"Acceptance Tests needs to wait for to be populated After the Introduction to XD 2861 the acquisition of JobResources takes more time. We have to introduce a pause to wait for to be populated. ",NULL,"Acceptance Tests needs to wait for to be populated After the Introduction to XD 2861 the acquisition of JobResources takes more time<span class='highlight-text severity-high'>. We have to introduce a pause to wait for to be populated. </span>","minimal","punctuation","high",False
26047,"Get rid of Code that is in there could be moved to the Then, as part of a later refactoring, that plugin should be made part of the module and loaded by the module classloader ",NULL,"Get rid of Code that is in there could be moved to the Then, as part of a later refactoring, that plugin should be made part of the module and loaded by the module classloader ",NULL,"Add for who this story is","well_formed","no_role","high",False
26047,"Get rid of Code that is in there could be moved to the Then, as part of a later refactoring, that plugin should be made part of the module and loaded by the module classloader ",NULL,"Get rid of Code that is in there could be moved to the Then, as part of a later refactoring, that plugin should be made part of the module and loaded by the module classloader ",NULL,"Get rid of Code that is in there could be moved to the Then, as part of a later refactoring, that plugin should be made part of the module<span class='highlight-text severity-high'> and </span>loaded by the module classloader ","atomic","conjunctions","high",False
26061,"Create Boot based ModuleRunner phase 2 As a user, I'd like to use Boot based for use in container managed environments, so I can run XD without xd containers . Scope Complete the remaining deployment properties work",NULL,"Create Boot based ModuleRunner phase 2 As a user, I'd like to use Boot based for use in container managed environments,","so I can run XD without xd containers . Scope Complete the remaining deployment properties work","Add for who this story is","well_formed","no_role","high",False
26061,"Create Boot based ModuleRunner phase 2 As a user, I'd like to use Boot based for use in container managed environments, so I can run XD without xd containers . Scope Complete the remaining deployment properties work",NULL,"Create Boot based ModuleRunner phase 2 As a user, I'd like to use Boot based for use in container managed environments,","so I can run XD without xd containers . Scope Complete the remaining deployment properties work","Create Boot based ModuleRunner phase 2 As a user, I'd like to use Boot based for use in container managed environments, so I can run XD without xd containers <span class='highlight-text severity-high'>. Scope Complete the remaining deployment properties work</span>","minimal","punctuation","high",False
26061,"Create Boot based ModuleRunner phase 2 As a user, I'd like to use Boot based for use in container managed environments, so I can run XD without xd containers . Scope Complete the remaining deployment properties work",NULL,"Create Boot based ModuleRunner phase 2 As a user, I'd like to use Boot based for use in container managed environments,","so I can run XD without xd containers . Scope Complete the remaining deployment properties work","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26073,"Detailed module list performance improvement The call to that was introduced for Flo proves to be a performance hog, most certainly because of all the metadata resolution that has to occur there and no caching takes place ",NULL,"Detailed module list performance improvement The call to that was introduced for Flo proves to be a performance hog, most certainly because of all the metadata resolution that has to occur there and no caching takes place ",NULL,"Add for who this story is","well_formed","no_role","high",False
26073,"Detailed module list performance improvement The call to that was introduced for Flo proves to be a performance hog, most certainly because of all the metadata resolution that has to occur there and no caching takes place ",NULL,"Detailed module list performance improvement The call to that was introduced for Flo proves to be a performance hog, most certainly because of all the metadata resolution that has to occur there and no caching takes place ",NULL,"Detailed module list performance improvement The call to that was introduced for Flo proves to be a performance hog, most certainly because of all the metadata resolution that has to occur there<span class='highlight-text severity-high'> and </span>no caching takes place ","atomic","conjunctions","high",False
26079,"Update to spring data hadoop 2.2.0.M1 We should update to use spring data hadoop 2.2.0.M1in order to use the fixes available for the HDFS writing there syncable writes, timeout . A few things to keep in mind this updates Cloudera CDH to 5.3.3 Kite version is now 1.0 need to test the hdfs dataset sink ",NULL,"Update to spring data hadoop 2.2.0.M1 We should update to use spring data hadoop 2.2.0.M1in order to use the fixes available for the HDFS writing there syncable writes, timeout . A few things to keep in mind this updates Cloudera CDH to 5.3.3 Kite version is now 1.0 need to test the hdfs dataset sink ",NULL,"Add for who this story is","well_formed","no_role","high",False
26079,"Update to spring data hadoop 2.2.0.M1 We should update to use spring data hadoop 2.2.0.M1in order to use the fixes available for the HDFS writing there syncable writes, timeout . A few things to keep in mind this updates Cloudera CDH to 5.3.3 Kite version is now 1.0 need to test the hdfs dataset sink ",NULL,"Update to spring data hadoop 2.2.0.M1 We should update to use spring data hadoop 2.2.0.M1in order to use the fixes available for the HDFS writing there syncable writes, timeout . A few things to keep in mind this updates Cloudera CDH to 5.3.3 Kite version is now 1.0 need to test the hdfs dataset sink ",NULL,"Update to spring data hadoop 2<span class='highlight-text severity-high'>.2.0.M1 We should update to use spring data hadoop 2.2.0.M1in order to use the fixes available for the HDFS writing there syncable writes, timeout . A few things to keep in mind this updates Cloudera CDH to 5.3.3 Kite version is now 1.0 need to test the hdfs dataset sink </span>","minimal","punctuation","high",False
26098,"Add Property maxMessagesPerPoll to All Polled Sources Polled message sources return only one message per poll by default. When polling, say, a file directory with many files, files will be emitted once per . As a user I need to configure a limit for the number of messages that will be emitted per poll.",NULL,"Add Property maxMessagesPerPoll to All Polled Sources Polled message sources return only one message per poll by default. When polling, say, a file directory with many files, files will be emitted once per . As a user I need to configure a limit for the number of messages that will be emitted per poll.",NULL,"Add for who this story is","well_formed","no_role","high",False
26098,"Add Property maxMessagesPerPoll to All Polled Sources Polled message sources return only one message per poll by default. When polling, say, a file directory with many files, files will be emitted once per . As a user I need to configure a limit for the number of messages that will be emitted per poll.",NULL,"Add Property maxMessagesPerPoll to All Polled Sources Polled message sources return only one message per poll by default. When polling, say, a file directory with many files, files will be emitted once per . As a user I need to configure a limit for the number of messages that will be emitted per poll.",NULL,"Add Property maxMessagesPerPoll to All Polled Sources Polled message sources return only one message per poll by default<span class='highlight-text severity-high'>. When polling, say, a file directory with many files, files will be emitted once per . As a user I need to configure a limit for the number of messages that will be emitted per poll.</span>","minimal","punctuation","high",False
26129,"Fail fast on Kryo registration conflicts Currently kryo class registration is hard coded in spring xd codec. Users may register their own classes using an extension mechanism, but it is possible to conflict with internal XD class registration, e.g., Tuple. Exposing this using the same extension mechanism will make it more transparent. ",NULL,"Fail fast on Kryo registration conflicts Currently kryo class registration is hard coded in spring xd codec. Users may register their own classes using an extension mechanism, but it is possible to conflict with internal XD class registration, e.g., Tuple. Exposing this using the same extension mechanism will make it more transparent. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26129,"Fail fast on Kryo registration conflicts Currently kryo class registration is hard coded in spring xd codec. Users may register their own classes using an extension mechanism, but it is possible to conflict with internal XD class registration, e.g., Tuple. Exposing this using the same extension mechanism will make it more transparent. ",NULL,"Fail fast on Kryo registration conflicts Currently kryo class registration is hard coded in spring xd codec. Users may register their own classes using an extension mechanism, but it is possible to conflict with internal XD class registration, e.g., Tuple. Exposing this using the same extension mechanism will make it more transparent. ",NULL,"Fail fast on Kryo registration conflicts Currently kryo class registration is hard coded in spring xd codec<span class='highlight-text severity-high'>. Users may register their own classes using an extension mechanism, but it is possible to conflict with internal XD class registration, e.g., Tuple. Exposing this using the same extension mechanism will make it more transparent. </span>","minimal","punctuation","high",False
26146,"Create a common exception framework for XD Need to capture exceptions from the various projects that make up XD and wrap them in XD Specific exceptions. An example of this is when leaving out the channels in the module definitions, we see and thrown based on which module and what channel is missing. ",NULL,"Create a common exception framework for XD Need to capture exceptions from the various projects that make up XD and wrap them in XD Specific exceptions. An example of this is when leaving out the channels in the module definitions, we see and thrown based on which module and what channel is missing. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26146,"Create a common exception framework for XD Need to capture exceptions from the various projects that make up XD and wrap them in XD Specific exceptions. An example of this is when leaving out the channels in the module definitions, we see and thrown based on which module and what channel is missing. ",NULL,"Create a common exception framework for XD Need to capture exceptions from the various projects that make up XD and wrap them in XD Specific exceptions. An example of this is when leaving out the channels in the module definitions, we see and thrown based on which module and what channel is missing. ",NULL,"Create a common exception framework for XD Need to capture exceptions from the various projects that make up XD<span class='highlight-text severity-high'> and </span>wrap them in XD Specific exceptions. An example of this is when leaving out the channels in the module definitions, we see and thrown based on which module and what channel is missing. ","atomic","conjunctions","high",False
26146,"Create a common exception framework for XD Need to capture exceptions from the various projects that make up XD and wrap them in XD Specific exceptions. An example of this is when leaving out the channels in the module definitions, we see and thrown based on which module and what channel is missing. ",NULL,"Create a common exception framework for XD Need to capture exceptions from the various projects that make up XD and wrap them in XD Specific exceptions. An example of this is when leaving out the channels in the module definitions, we see and thrown based on which module and what channel is missing. ",NULL,"Create a common exception framework for XD Need to capture exceptions from the various projects that make up XD and wrap them in XD Specific exceptions<span class='highlight-text severity-high'>. An example of this is when leaving out the channels in the module definitions, we see and thrown based on which module and what channel is missing. </span>","minimal","punctuation","high",False
26177,"Spike Kickoff singlenode implementation of Admin SPI As a developer, I'd like to develop a singlenode in a single JVM implementation of XD Admin SPI based on Module Launcher , so I can run data pipeline use cases locally. ",NULL,"Spike Kickoff singlenode implementation of Admin SPI As a developer, I'd like to develop a singlenode in a single JVM implementation of XD Admin SPI based on Module Launcher ,","so I can run data pipeline use cases locally.","Add for who this story is","well_formed","no_role","high",False
26177,"Spike Kickoff singlenode implementation of Admin SPI As a developer, I'd like to develop a singlenode in a single JVM implementation of XD Admin SPI based on Module Launcher , so I can run data pipeline use cases locally. ",NULL,"Spike Kickoff singlenode implementation of Admin SPI As a developer, I'd like to develop a singlenode in a single JVM implementation of XD Admin SPI based on Module Launcher ,","so I can run data pipeline use cases locally.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26185,"Remove XML REST Endpoints The XML REST endpoints are not working correctly interfere with security are not used ",NULL,"Remove XML REST Endpoints The XML REST endpoints are not working correctly interfere with security are not used ",NULL,"Add for who this story is","well_formed","no_role","high",False
26195,"Add s as part of the Sqoop job submission to YARN for Avro we need for Snappy we need note the 1.1.0.1 version from xd lib doesn t work We s option or automatically include them. ",NULL,"Add s as part of the Sqoop job submission to YARN for Avro we need for Snappy we need note the 1.1.0.1 version from xd lib doesn t work We s option or automatically include them. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26195,"Add s as part of the Sqoop job submission to YARN for Avro we need for Snappy we need note the 1.1.0.1 version from xd lib doesn t work We s option or automatically include them. ",NULL,"Add s as part of the Sqoop job submission to YARN for Avro we need for Snappy we need note the 1.1.0.1 version from xd lib doesn t work We s option or automatically include them. ",NULL,"Add s as part of the Sqoop job submission to YARN for Avro we need for Snappy we need note the 1.1.0.1 version from xd lib doesn t work We s option<span class='highlight-text severity-high'> or </span>automatically include them. ","atomic","conjunctions","high",False
26211,"Replace controller calls with respective SPI implementation As a Spring XD developer, I'd like to refactor current controller with SPI calls, so I can invoke the respective Admin SPI implementation based on the deployment. Controllers to Refactor StreamsController ModulesController JobsController ",NULL,"Replace controller calls with respective SPI implementation As a Spring XD developer, I'd like to refactor current controller with SPI calls,","so I can invoke the respective Admin SPI implementation based on the deployment. Controllers to Refactor StreamsController ModulesController JobsController","Add for who this story is","well_formed","no_role","high",False
26211,"Replace controller calls with respective SPI implementation As a Spring XD developer, I'd like to refactor current controller with SPI calls, so I can invoke the respective Admin SPI implementation based on the deployment. Controllers to Refactor StreamsController ModulesController JobsController ",NULL,"Replace controller calls with respective SPI implementation As a Spring XD developer, I'd like to refactor current controller with SPI calls,","so I can invoke the respective Admin SPI implementation based on the deployment. Controllers to Refactor StreamsController ModulesController JobsController","Replace controller calls with respective SPI implementation As a Spring XD developer, I'd like to refactor current controller with SPI calls, so I can invoke the respective Admin SPI implementation based on the deployment<span class='highlight-text severity-high'>. Controllers to Refactor StreamsController ModulesController JobsController </span>","minimal","punctuation","high",False
26211,"Replace controller calls with respective SPI implementation As a Spring XD developer, I'd like to refactor current controller with SPI calls, so I can invoke the respective Admin SPI implementation based on the deployment. Controllers to Refactor StreamsController ModulesController JobsController ",NULL,"Replace controller calls with respective SPI implementation As a Spring XD developer, I'd like to refactor current controller with SPI calls,","so I can invoke the respective Admin SPI implementation based on the deployment. Controllers to Refactor StreamsController ModulesController JobsController","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26216,"Add CI workflow to build, bundle and upload module launcher image to DockerHub As a s c s developer, I'd like to setup a CI workflow to build, bundle and upload the image to DockerHub, so I don t have to worry about having a local private docker registry for It could be nice to have the image uploaded to existing spring cloud DockerHub location. ",NULL,"Add CI workflow to build, bundle and upload module launcher image to DockerHub As a s c s developer, I'd like to setup a CI workflow to build, bundle and upload the image to DockerHub,","so I don t have to worry about having a local private docker registry for It could be nice to have the image uploaded to existing spring cloud DockerHub location.","Add for who this story is","well_formed","no_role","high",False
26216,"Add CI workflow to build, bundle and upload module launcher image to DockerHub As a s c s developer, I'd like to setup a CI workflow to build, bundle and upload the image to DockerHub, so I don t have to worry about having a local private docker registry for It could be nice to have the image uploaded to existing spring cloud DockerHub location. ",NULL,"Add CI workflow to build, bundle and upload module launcher image to DockerHub As a s c s developer, I'd like to setup a CI workflow to build, bundle and upload the image to DockerHub,","so I don t have to worry about having a local private docker registry for It could be nice to have the image uploaded to existing spring cloud DockerHub location.","Add CI workflow to build, bundle<span class='highlight-text severity-high'> and </span>upload module launcher image to DockerHub As a s c s developer, I'd like to setup a CI workflow to build, bundle and upload the image to DockerHub, so I don t have to worry about having a local private docker registry for It could be nice to have the image uploaded to existing spring cloud DockerHub location. ","atomic","conjunctions","high",False
26251,"Implement undeploy operation for singlenode SPI As a s c d developer, I'd like to implement undeploy operation for single JVM , so I can use this target to undeploy a running stream. More details in this PR Note Its a prerequisite to determine consistent undeploy strategy for both . ",NULL,"Implement undeploy operation for singlenode SPI As a s c d developer, I'd like to implement undeploy operation for single JVM ,","so I can use this target to undeploy a running stream. More details in this PR Note Its a prerequisite to determine consistent undeploy strategy for both .","Implement undeploy operation for singlenode SPI As a s c d developer, I'd like to implement undeploy operation for single JVM , so I can use this target to undeploy a running stream<span class='highlight-text severity-high'>. More details in this PR Note Its a prerequisite to determine consistent undeploy strategy for both . </span>","minimal","punctuation","high",False
26251,"Implement undeploy operation for singlenode SPI As a s c d developer, I'd like to implement undeploy operation for single JVM , so I can use this target to undeploy a running stream. More details in this PR Note Its a prerequisite to determine consistent undeploy strategy for both . ",NULL,"Implement undeploy operation for singlenode SPI As a s c d developer, I'd like to implement undeploy operation for single JVM ,","so I can use this target to undeploy a running stream. More details in this PR Note Its a prerequisite to determine consistent undeploy strategy for both .","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26306,"Add registry to lookup module coordinates by name As a s c d developer, I'd like to create implementation, so I can use this infrastructure to lookup module coordinates by name.",NULL,"Add registry to lookup module coordinates by name As a s c d developer, I'd like to create implementation,","so I can use this infrastructure to lookup module coordinates by name.","Add for who this story is","well_formed","no_role","high",False
26306,"Add registry to lookup module coordinates by name As a s c d developer, I'd like to create implementation, so I can use this infrastructure to lookup module coordinates by name.",NULL,"Add registry to lookup module coordinates by name As a s c d developer, I'd like to create implementation,","so I can use this infrastructure to lookup module coordinates by name.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26312,"Add support for deployment properties As a s c d developer, I'd like to provide optional key value pairs as deployment properties, so I could leverage them at the runtime to instruct how the modules will be deployed. The scope of this story is to specifically support instances of modules that share the same environment variables. ",NULL,"Add support for deployment properties As a s c d developer, I'd like to provide optional key value pairs as deployment properties,","so I could leverage them at the runtime to instruct how the modules will be deployed. The scope of this story is to specifically support instances of modules that share the same environment variables.","Add for who this story is","well_formed","no_role","high",False
26312,"Add support for deployment properties As a s c d developer, I'd like to provide optional key value pairs as deployment properties, so I could leverage them at the runtime to instruct how the modules will be deployed. The scope of this story is to specifically support instances of modules that share the same environment variables. ",NULL,"Add support for deployment properties As a s c d developer, I'd like to provide optional key value pairs as deployment properties,","so I could leverage them at the runtime to instruct how the modules will be deployed. The scope of this story is to specifically support instances of modules that share the same environment variables.","Add support for deployment properties As a s c d developer, I'd like to provide optional key value pairs as deployment properties, so I could leverage them at the runtime to instruct how the modules will be deployed<span class='highlight-text severity-high'>. The scope of this story is to specifically support instances of modules that share the same environment variables. </span>","minimal","punctuation","high",False
26312,"Add support for deployment properties As a s c d developer, I'd like to provide optional key value pairs as deployment properties, so I could leverage them at the runtime to instruct how the modules will be deployed. The scope of this story is to specifically support instances of modules that share the same environment variables. ",NULL,"Add support for deployment properties As a s c d developer, I'd like to provide optional key value pairs as deployment properties,","so I could leverage them at the runtime to instruct how the modules will be deployed. The scope of this story is to specifically support instances of modules that share the same environment variables.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26314,"Update documentation for module launcher The document requires update for running it on standalone, docker, lattice. Also, the docker compose yml requires fix so that modules in there are bound together.",NULL,"Update documentation for module launcher The document requires update for running it on standalone, docker, lattice. Also, the docker compose yml requires fix","so that modules in there are bound together.","Add for who this story is","well_formed","no_role","high",False
26314,"Update documentation for module launcher The document requires update for running it on standalone, docker, lattice. Also, the docker compose yml requires fix so that modules in there are bound together.",NULL,"Update documentation for module launcher The document requires update for running it on standalone, docker, lattice. Also, the docker compose yml requires fix","so that modules in there are bound together.","Update documentation for module launcher The document requires update for running it on standalone, docker, lattice<span class='highlight-text severity-high'>. Also, the docker compose yml requires fix so that modules in there are bound together.</span>","minimal","punctuation","high",False
26314,"Update documentation for module launcher The document requires update for running it on standalone, docker, lattice. Also, the docker compose yml requires fix so that modules in there are bound together.",NULL,"Update documentation for module launcher The document requires update for running it on standalone, docker, lattice. Also, the docker compose yml requires fix","so that modules in there are bound together.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26346,"Move Cassandra sink to XD proper ",NULL,"Move Cassandra sink to XD proper ",NULL,"Add for who this story is","well_formed","no_role","high",False
26332,"Improve resilience of route creation removal The CF implementation requires that a route be created for each new app. This works fine on the happy path, but is brittle. For example, it will fail if the route required already exists.",NULL,"Improve resilience of route creation removal The CF implementation requires that a route be created for each new app. This works fine on the happy path, but is brittle. For example, it will fail if the route required already exists.",NULL,"Add for who this story is","well_formed","no_role","high",False
26332,"Improve resilience of route creation removal The CF implementation requires that a route be created for each new app. This works fine on the happy path, but is brittle. For example, it will fail if the route required already exists.",NULL,"Improve resilience of route creation removal The CF implementation requires that a route be created for each new app. This works fine on the happy path, but is brittle. For example, it will fail if the route required already exists.",NULL,"Improve resilience of route creation removal The CF implementation requires that a route be created for each new app<span class='highlight-text severity-high'>. This works fine on the happy path, but is brittle. For example, it will fail if the route required already exists.</span>","minimal","punctuation","high",False
26350,"Create CI process for XD build bamboo based",NULL,"Create CI process for XD build bamboo based",NULL,"Add for who this story is","well_formed","no_role","high",False
26364,"Port JMS as s c s source As a Spring XD developer, I'd like to move module from XD to s c s m repo, so I can use it as source to build streaming pipeline. ",NULL,NULL,"source As a Spring XD developer, I'd like to move module from XD to s c s m repo, so I can use it as source to build streaming pipeline.","Add what you want to achieve","well_formed","no_means","high",False
26364,"Port JMS as s c s source As a Spring XD developer, I'd like to move module from XD to s c s m repo, so I can use it as source to build streaming pipeline. ",NULL,NULL,"source As a Spring XD developer, I'd like to move module from XD to s c s m repo, so I can use it as source to build streaming pipeline.","Add for who this story is","well_formed","no_role","high",False
26364,"Port JMS as s c s source As a Spring XD developer, I'd like to move module from XD to s c s m repo, so I can use it as source to build streaming pipeline. ",NULL,NULL,"source As a Spring XD developer, I'd like to move module from XD to s c s m repo, so I can use it as source to build streaming pipeline.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26370,"Port syslog as s c s source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline. ",NULL,NULL,"source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.","Add what you want to achieve","well_formed","no_means","high",False
26370,"Port syslog as s c s source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline. ",NULL,NULL,"source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.","Add for who this story is","well_formed","no_role","high",False
26370,"Port syslog as s c s source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline. ",NULL,NULL,"source As a Spring XD developer, I'd like to move module from XD to s c s repo, so I can use it as source to build streaming pipeline.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26393,"Improve automated documentation generation process for modules to handle array arguments For example the generated value for the cassandra sink results in where the default value changes each time the build is run. ",NULL,"Improve automated documentation generation process for modules to handle array arguments For example the generated value for the cassandra sink results in where the default value changes each time the build is run. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26419,"Move Redis Rule to a separate repo As an s c d developer, I'd like to move redis to a separate repo, so I can consume the test fixtures in different projects.",NULL,"Move Redis Rule to a separate repo As an s c d developer, I'd like to move redis to a separate repo,","so I can consume the test fixtures in different projects.","Add for who this story is","well_formed","no_role","high",False
26419,"Move Redis Rule to a separate repo As an s c d developer, I'd like to move redis to a separate repo, so I can consume the test fixtures in different projects.",NULL,"Move Redis Rule to a separate repo As an s c d developer, I'd like to move redis to a separate repo,","so I can consume the test fixtures in different projects.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26429,"SI Outbound HDFS Channel Adapter ",NULL,NULL,NULL,"Add what you want to achieve","well_formed","no_means","high",False
26429,"SI Outbound HDFS Channel Adapter ",NULL,NULL,NULL,"Add for who this story is","well_formed","no_role","high",False
26431,"JMX MBean name clash when using labels with s c d deployment We need to make sure that JMX MBean names are unique, even in the case of labeled modules. The following stream fails for example http filter filter2 filter log A good candidate could be stream name group module label.",NULL,"JMX MBean name clash when using labels with s c d deployment We need to make sure that JMX MBean names are unique, even in the case of labeled modules. The following stream fails for example http filter filter2 filter log A good candidate could be stream name group module label.",NULL,"Add for who this story is","well_formed","no_role","high",False
26431,"JMX MBean name clash when using labels with s c d deployment We need to make sure that JMX MBean names are unique, even in the case of labeled modules. The following stream fails for example http filter filter2 filter log A good candidate could be stream name group module label.",NULL,"JMX MBean name clash when using labels with s c d deployment We need to make sure that JMX MBean names are unique, even in the case of labeled modules. The following stream fails for example http filter filter2 filter log A good candidate could be stream name group module label.",NULL,"JMX MBean name clash when using labels with s c d deployment We need to make sure that JMX MBean names are unique, even in the case of labeled modules<span class='highlight-text severity-high'>. The following stream fails for example http filter filter2 filter log A good candidate could be stream name group module label.</span>","minimal","punctuation","high",False
26456,"Make SpEL usage consistent across all including custom modules As a user, I'd like to use SpEL expressions inline at the stream definition level, so I can operate on the payload consistently while using any OOTB, including the custom modules. ",NULL,"Make SpEL usage consistent across all including custom modules As a user, I'd like to use SpEL expressions inline at the stream definition level,","so I can operate on the payload consistently while using any OOTB, including the custom modules.","Add for who this story is","well_formed","no_role","high",False
26456,"Make SpEL usage consistent across all including custom modules As a user, I'd like to use SpEL expressions inline at the stream definition level, so I can operate on the payload consistently while using any OOTB, including the custom modules. ",NULL,"Make SpEL usage consistent across all including custom modules As a user, I'd like to use SpEL expressions inline at the stream definition level,","so I can operate on the payload consistently while using any OOTB, including the custom modules.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26511,"Update Getting Started chapter to use Shell commands instead of curl See ",NULL,"Update Getting Started chapter to use Shell commands instead of curl See ",NULL,"Add for who this story is","well_formed","no_role","high",False
26516,"Create a command to browse the HDFS file system Create a command to browse the HDFS file system There are existing commands that can be taken from or that can be used for this There are existing commands that can be taken from or that can be used for this",NULL,"Create a command to browse the HDFS file system Create a command to browse the HDFS file system There are existing commands that can be taken from or that can be used for this There are existing commands that can be taken from or that can be used for this",NULL,"Add for who this story is","well_formed","no_role","high",False
26516,"Create a command to browse the HDFS file system Create a command to browse the HDFS file system There are existing commands that can be taken from or that can be used for this There are existing commands that can be taken from or that can be used for this",NULL,"Create a command to browse the HDFS file system Create a command to browse the HDFS file system There are existing commands that can be taken from or that can be used for this There are existing commands that can be taken from or that can be used for this",NULL,"Create a command to browse the HDFS file system Create a command to browse the HDFS file system There are existing commands that can be taken from<span class='highlight-text severity-high'> or </span>that can be used for this There are existing commands that can be taken from or that can be used for this","atomic","conjunctions","high",False
26532,"Taps introduction section should show use of shell to create a real stream and a real tap using the shell See The existing docs should be made to show a real stream being created with filter and or transformer and then a tap that goes to logging. The shell syntax to also stop undeploy a tap should be shown here as well since the lifecycle is discussed.",NULL,"Taps introduction section should show use of shell to create a real stream and a real tap using the shell See The existing docs should be made to show a real stream being created with filter and or transformer and then a tap that goes to logging. The shell syntax to also stop undeploy a tap should be shown here as well since the lifecycle is discussed.",NULL,"Add for who this story is","well_formed","no_role","high",False
26532,"Taps introduction section should show use of shell to create a real stream and a real tap using the shell See The existing docs should be made to show a real stream being created with filter and or transformer and then a tap that goes to logging. The shell syntax to also stop undeploy a tap should be shown here as well since the lifecycle is discussed.",NULL,"Taps introduction section should show use of shell to create a real stream and a real tap using the shell See The existing docs should be made to show a real stream being created with filter and or transformer and then a tap that goes to logging. The shell syntax to also stop undeploy a tap should be shown here as well since the lifecycle is discussed.",NULL,"Taps introduction section should show use of shell to create a real stream<span class='highlight-text severity-high'> and </span>a real tap using the shell See The existing docs should be made to show a real stream being created with filter and<span class='highlight-text severity-high'> or </span>transformer and then a tap that goes to logging. The shell syntax to also stop undeploy a tap should be shown here as well since the lifecycle is discussed.","atomic","conjunctions","high",False
26532,"Taps introduction section should show use of shell to create a real stream and a real tap using the shell See The existing docs should be made to show a real stream being created with filter and or transformer and then a tap that goes to logging. The shell syntax to also stop undeploy a tap should be shown here as well since the lifecycle is discussed.",NULL,"Taps introduction section should show use of shell to create a real stream and a real tap using the shell See The existing docs should be made to show a real stream being created with filter and or transformer and then a tap that goes to logging. The shell syntax to also stop undeploy a tap should be shown here as well since the lifecycle is discussed.",NULL,"Taps introduction section should show use of shell to create a real stream and a real tap using the shell See The existing docs should be made to show a real stream being created with filter and or transformer and then a tap that goes to logging<span class='highlight-text severity-high'>. The shell syntax to also stop undeploy a tap should be shown here as well since the lifecycle is discussed.</span>","minimal","punctuation","high",False
26590,"Disable Collection to Object conversion in DefaultTuple provides Collection Object conversion which will produce the first item if the target type matches. Here, this results in an unfortunate side effect, list would return a Tuple which is misleading. In this case it is preferable to treat it as an error if the argument is not a Tuple.",NULL,"Disable Collection to Object conversion in DefaultTuple provides Collection Object conversion which will produce the first item if the target type matches. Here, this results in an unfortunate side effect, list would return a Tuple which is misleading. In this case it is preferable to treat it as an error if the argument is not a Tuple.",NULL,"Add for who this story is","well_formed","no_role","high",False
26590,"Disable Collection to Object conversion in DefaultTuple provides Collection Object conversion which will produce the first item if the target type matches. Here, this results in an unfortunate side effect, list would return a Tuple which is misleading. In this case it is preferable to treat it as an error if the argument is not a Tuple.",NULL,"Disable Collection to Object conversion in DefaultTuple provides Collection Object conversion which will produce the first item if the target type matches. Here, this results in an unfortunate side effect, list would return a Tuple which is misleading. In this case it is preferable to treat it as an error if the argument is not a Tuple.",NULL,"Disable Collection to Object conversion in DefaultTuple provides Collection Object conversion which will produce the first item if the target type matches<span class='highlight-text severity-high'>. Here, this results in an unfortunate side effect, list would return a Tuple which is misleading. In this case it is preferable to treat it as an error if the argument is not a Tuple.</span>","minimal","punctuation","high",False
26624,"Investigate using Redis txs and pipeline for Inbound Outbound Q Adapter perf improvements Investigate using transactions and pipelining to improve performance of both the inbound and outbound RedisQueue channel adapters. Involves testing against a pre release of SDR 1.1 M2.",NULL,"Investigate using Redis txs and pipeline for Inbound Outbound Q Adapter perf improvements Investigate using transactions and pipelining to improve performance of both the inbound and outbound RedisQueue channel adapters. Involves testing against a pre release of SDR 1.1 M2.",NULL,"Add for who this story is","well_formed","no_role","high",False
26624,"Investigate using Redis txs and pipeline for Inbound Outbound Q Adapter perf improvements Investigate using transactions and pipelining to improve performance of both the inbound and outbound RedisQueue channel adapters. Involves testing against a pre release of SDR 1.1 M2.",NULL,"Investigate using Redis txs and pipeline for Inbound Outbound Q Adapter perf improvements Investigate using transactions and pipelining to improve performance of both the inbound and outbound RedisQueue channel adapters. Involves testing against a pre release of SDR 1.1 M2.",NULL,"Investigate using Redis txs<span class='highlight-text severity-high'> and </span>pipeline for Inbound Outbound Q Adapter perf improvements Investigate using transactions and pipelining to improve performance of both the inbound and outbound RedisQueue channel adapters. Involves testing against a pre release of SDR 1.1 M2.","atomic","conjunctions","high",False
26624,"Investigate using Redis txs and pipeline for Inbound Outbound Q Adapter perf improvements Investigate using transactions and pipelining to improve performance of both the inbound and outbound RedisQueue channel adapters. Involves testing against a pre release of SDR 1.1 M2.",NULL,"Investigate using Redis txs and pipeline for Inbound Outbound Q Adapter perf improvements Investigate using transactions and pipelining to improve performance of both the inbound and outbound RedisQueue channel adapters. Involves testing against a pre release of SDR 1.1 M2.",NULL,"Investigate using Redis txs and pipeline for Inbound Outbound Q Adapter perf improvements Investigate using transactions and pipelining to improve performance of both the inbound and outbound RedisQueue channel adapters<span class='highlight-text severity-high'>. Involves testing against a pre release of SDR 1.1 M2.</span>","minimal","punctuation","high",False
26651,"Test composition parameterize composition of modules DSL should be able to parse what is below, need tests CLI integration tests to ensure it is being mapped to an executeable stream. myIntricateFlow transform transform http myIntricateFlow file obfuscateName transform ,XXX twitter query Bieber obfuscateName name Justin file ",NULL,"Test composition parameterize composition of modules DSL should be able to parse what is below, need tests CLI integration tests to ensure it is being mapped to an executeable stream. myIntricateFlow transform transform http myIntricateFlow file obfuscateName transform ,XXX twitter query Bieber obfuscateName name Justin file ",NULL,"Test composition parameterize composition of modules DSL should be able to parse what is below, need tests CLI integration tests to ensure it is being mapped to an executeable stream<span class='highlight-text severity-high'>. myIntricateFlow transform transform http myIntricateFlow file obfuscateName transform ,XXX twitter query Bieber obfuscateName name Justin file </span>","minimal","punctuation","high",False
26665,"Create that will destory streams that were created during test method execution Keep track of named streams that were create and use After to destroy them.",NULL,"Create that will destory streams that were created during test method execution Keep track of named streams that were create and use After to destroy them.",NULL,"Add for who this story is","well_formed","no_role","high",False
26665,"Create that will destory streams that were created during test method execution Keep track of named streams that were create and use After to destroy them.",NULL,"Create that will destory streams that were created during test method execution Keep track of named streams that were create and use After to destroy them.",NULL,"Create that will destory streams that were created during test method execution Keep track of named streams that were create<span class='highlight-text severity-high'> and </span>use After to destroy them.","atomic","conjunctions","high",False
26699,"HTTP source should emit raw payload Current implementation converts to a String. See if we can emit raw payload given that we also emit content type header Setting to 8 points, as this may have lots of implications down the line though",NULL,"HTTP source should emit raw payload Current implementation converts to a String. See if we can emit raw payload given that we also emit content type header Setting to 8 points, as this may have lots of implications down the line though",NULL,"Add for who this story is","well_formed","no_role","high",False
26699,"HTTP source should emit raw payload Current implementation converts to a String. See if we can emit raw payload given that we also emit content type header Setting to 8 points, as this may have lots of implications down the line though",NULL,"HTTP source should emit raw payload Current implementation converts to a String. See if we can emit raw payload given that we also emit content type header Setting to 8 points, as this may have lots of implications down the line though",NULL,"HTTP source should emit raw payload Current implementation converts to a String<span class='highlight-text severity-high'>. See if we can emit raw payload given that we also emit content type header Setting to 8 points, as this may have lots of implications down the line though</span>","minimal","punctuation","high",False
26706,"Trim output from http post shell command to two lines Instead of xd http post target data hello world POST hello world 200 OK Content Length 0 Connection keep alive Success sending data hello world to target have xd http post target data hello world POST hello world 200 OK or better yet xd http post target data hello world 200 OK POST hello world ",NULL,"Trim output from http post shell command to two lines Instead of xd http post target data hello world POST hello world 200 OK Content Length 0 Connection keep alive Success sending data hello world to target have xd http post target data hello world POST hello world 200 OK or better yet xd http post target data hello world 200 OK POST hello world ",NULL,"Add for who this story is","well_formed","no_role","high",False
26706,"Trim output from http post shell command to two lines Instead of xd http post target data hello world POST hello world 200 OK Content Length 0 Connection keep alive Success sending data hello world to target have xd http post target data hello world POST hello world 200 OK or better yet xd http post target data hello world 200 OK POST hello world ",NULL,"Trim output from http post shell command to two lines Instead of xd http post target data hello world POST hello world 200 OK Content Length 0 Connection keep alive Success sending data hello world to target have xd http post target data hello world POST hello world 200 OK or better yet xd http post target data hello world 200 OK POST hello world ",NULL,"Trim output from http post shell command to two lines Instead of xd http post target data hello world POST hello world 200 OK Content Length 0 Connection keep alive Success sending data hello world to target have xd http post target data hello world POST hello world 200 OK<span class='highlight-text severity-high'> or </span>better yet xd http post target data hello world 200 OK POST hello world ","atomic","conjunctions","high",False
26736,"Change JMX option to reference enableJmx instead of disableJmx Make the default value of enableJmx false until we have tested documented JMX functionality",NULL,"Change JMX option to reference enableJmx instead of disableJmx Make the default value of enableJmx false until we have tested documented JMX functionality",NULL,"Add for who this story is","well_formed","no_role","high",False
26729,"Change jmxDisabled option to jmxEnabled and do not enable by default also, the current behavior is broken; it checks if the property is set but does not actually check whether it s true or false",NULL,"Change jmxDisabled option to jmxEnabled and do not enable by default also, the current behavior is broken; it checks if the property is set but does not actually check whether it s true or false",NULL,"Add for who this story is","well_formed","no_role","high",False
26729,"Change jmxDisabled option to jmxEnabled and do not enable by default also, the current behavior is broken; it checks if the property is set but does not actually check whether it s true or false",NULL,"Change jmxDisabled option to jmxEnabled and do not enable by default also, the current behavior is broken; it checks if the property is set but does not actually check whether it s true or false",NULL,"Change jmxDisabled option to jmxEnabled<span class='highlight-text severity-high'> and </span>do not enable by default also, the current behavior is broken; it checks if the property is set but does not actually check whether it s true<span class='highlight-text severity-high'> or </span>false","atomic","conjunctions","high",False
26729,"Change jmxDisabled option to jmxEnabled and do not enable by default also, the current behavior is broken; it checks if the property is set but does not actually check whether it s true or false",NULL,"Change jmxDisabled option to jmxEnabled and do not enable by default also, the current behavior is broken; it checks if the property is set but does not actually check whether it s true or false",NULL,"Change jmxDisabled option to jmxEnabled and do not enable by default also, the current behavior is broken<span class='highlight-text severity-high'>; it checks if the property is set but does not actually check whether it s true or false</span>","minimal","punctuation","high",False
26746,"Remove UUID from Tuple class or replace with more efficient implementation The Java UUID class is known not to be the fasted implementation available. See and for high perf impls. ",NULL,"Remove UUID from Tuple class or replace with more efficient implementation The Java UUID class is known not to be the fasted implementation available. See and for high perf impls. ",NULL,"Add for who this story is","well_formed","no_role","high",False
26746,"Remove UUID from Tuple class or replace with more efficient implementation The Java UUID class is known not to be the fasted implementation available. See and for high perf impls. ",NULL,"Remove UUID from Tuple class or replace with more efficient implementation The Java UUID class is known not to be the fasted implementation available. See and for high perf impls. ",NULL,"Remove UUID from Tuple class<span class='highlight-text severity-high'> or </span>replace with more efficient implementation The Java UUID class is known not to be the fasted implementation available. See<span class='highlight-text severity-high'> and </span>for high perf impls. ","atomic","conjunctions","high",False
26746,"Remove UUID from Tuple class or replace with more efficient implementation The Java UUID class is known not to be the fasted implementation available. See and for high perf impls. ",NULL,"Remove UUID from Tuple class or replace with more efficient implementation The Java UUID class is known not to be the fasted implementation available. See and for high perf impls. ",NULL,"Remove UUID from Tuple class or replace with more efficient implementation The Java UUID class is known not to be the fasted implementation available<span class='highlight-text severity-high'>. See and for high perf impls. </span>","minimal","punctuation","high",False
26756,"Test sink module in isolation Register the module under test Send a message to the sink using a test source and verify the sink contents this requires checking an external resource depends on the sink ",NULL,"Test sink module in isolation Register the module under test Send a message to the sink using a test source and verify the sink contents this requires checking an external resource depends on the sink ",NULL,"Add for who this story is","well_formed","no_role","high",False
26756,"Test sink module in isolation Register the module under test Send a message to the sink using a test source and verify the sink contents this requires checking an external resource depends on the sink ",NULL,"Test sink module in isolation Register the module under test Send a message to the sink using a test source and verify the sink contents this requires checking an external resource depends on the sink ",NULL,"Test sink module in isolation Register the module under test Send a message to the sink using a test source<span class='highlight-text severity-high'> and </span>verify the sink contents this requires checking an external resource depends on the sink ","atomic","conjunctions","high",False
26764,"Expose restful services that allow users to view job statuses This story utilizes BatchAdmin and its restful interfaces to show the state of jobs in Spring XD. Steps Create a Branch in the BatchAdmin we don t want to lose history Update the restful API s to XD standards. s to artifactory s. Expose the restful calls.",NULL,"Expose restful services that allow users to view job statuses This story utilizes BatchAdmin and its restful interfaces to show the state of jobs in Spring XD. Steps Create a Branch in the BatchAdmin we don t want to lose history Update the restful API s to XD standards. s to artifactory s. Expose the restful calls.",NULL,"Add for who this story is","well_formed","no_role","high",False
26764,"Expose restful services that allow users to view job statuses This story utilizes BatchAdmin and its restful interfaces to show the state of jobs in Spring XD. Steps Create a Branch in the BatchAdmin we don t want to lose history Update the restful API s to XD standards. s to artifactory s. Expose the restful calls.",NULL,"Expose restful services that allow users to view job statuses This story utilizes BatchAdmin and its restful interfaces to show the state of jobs in Spring XD. Steps Create a Branch in the BatchAdmin we don t want to lose history Update the restful API s to XD standards. s to artifactory s. Expose the restful calls.",NULL,"Expose restful services that allow users to view job statuses This story utilizes BatchAdmin<span class='highlight-text severity-high'> and </span>its restful interfaces to show the state of jobs in Spring XD. Steps Create a Branch in the BatchAdmin we don t want to lose history Update the restful API s to XD standards. s to artifactory s. Expose the restful calls.","atomic","conjunctions","high",False
26764,"Expose restful services that allow users to view job statuses This story utilizes BatchAdmin and its restful interfaces to show the state of jobs in Spring XD. Steps Create a Branch in the BatchAdmin we don t want to lose history Update the restful API s to XD standards. s to artifactory s. Expose the restful calls.",NULL,"Expose restful services that allow users to view job statuses This story utilizes BatchAdmin and its restful interfaces to show the state of jobs in Spring XD. Steps Create a Branch in the BatchAdmin we don t want to lose history Update the restful API s to XD standards. s to artifactory s. Expose the restful calls.",NULL,"Expose restful services that allow users to view job statuses This story utilizes BatchAdmin and its restful interfaces to show the state of jobs in Spring XD<span class='highlight-text severity-high'>. Steps Create a Branch in the BatchAdmin we don t want to lose history Update the restful API s to XD standards. s to artifactory s. Expose the restful calls.</span>","minimal","punctuation","high",False
26797,"Add Warning level log to if Job name is not job Should it be fatal vs. warning?",NULL,"Add Warning level log to if Job name is not job Should it be fatal vs. warning?",NULL,"Add for who this story is","well_formed","no_role","high",False
26797,"Add Warning level log to if Job name is not job Should it be fatal vs. warning?",NULL,"Add Warning level log to if Job name is not job Should it be fatal vs. warning?",NULL,"Add Warning level log to if Job name is not job Should it be fatal vs<span class='highlight-text severity-high'>. warning?</span>","minimal","punctuation","high",False
26815,"Add Named Channel API We need an abstraction in place to retrieve messages from a named channel programmatically. Right now there is no implementation agnostic way of doing this such as receiveMessage , queueSize . This could be quite useful for integration tests of streams. E.g. to do more focussed tests without resorting to temp files and non essential sinks or sources etc. e.g. routeit router ",NULL,"Add Named Channel API We need an abstraction in place to retrieve messages from a named channel programmatically. Right now there is no implementation agnostic way of doing this such as receiveMessage , queueSize . This could be quite useful for integration tests of streams. E.g. to do more focussed tests without resorting to temp files and non essential sinks or sources etc. e.g. routeit router ",NULL,"Add for who this story is","well_formed","no_role","high",False
26815,"Add Named Channel API We need an abstraction in place to retrieve messages from a named channel programmatically. Right now there is no implementation agnostic way of doing this such as receiveMessage , queueSize . This could be quite useful for integration tests of streams. E.g. to do more focussed tests without resorting to temp files and non essential sinks or sources etc. e.g. routeit router ",NULL,"Add Named Channel API We need an abstraction in place to retrieve messages from a named channel programmatically. Right now there is no implementation agnostic way of doing this such as receiveMessage , queueSize . This could be quite useful for integration tests of streams. E.g. to do more focussed tests without resorting to temp files and non essential sinks or sources etc. e.g. routeit router ",NULL,"Add Named Channel API We need an abstraction in place to retrieve messages from a named channel programmatically. Right now there is no implementation agnostic way of doing this such as receiveMessage , queueSize . This could be quite useful for integration tests of streams. E.g. to do more focussed tests without resorting to temp files<span class='highlight-text severity-high'> and </span>non essential sinks<span class='highlight-text severity-high'> or </span>sources etc. e.g. routeit router ","atomic","conjunctions","high",False
26815,"Add Named Channel API We need an abstraction in place to retrieve messages from a named channel programmatically. Right now there is no implementation agnostic way of doing this such as receiveMessage , queueSize . This could be quite useful for integration tests of streams. E.g. to do more focussed tests without resorting to temp files and non essential sinks or sources etc. e.g. routeit router ",NULL,"Add Named Channel API We need an abstraction in place to retrieve messages from a named channel programmatically. Right now there is no implementation agnostic way of doing this such as receiveMessage , queueSize . This could be quite useful for integration tests of streams. E.g. to do more focussed tests without resorting to temp files and non essential sinks or sources etc. e.g. routeit router ",NULL,"Add Named Channel API We need an abstraction in place to retrieve messages from a named channel programmatically<span class='highlight-text severity-high'>. Right now there is no implementation agnostic way of doing this such as receiveMessage , queueSize . This could be quite useful for integration tests of streams. E.g. to do more focussed tests without resorting to temp files and non essential sinks or sources etc. e.g. routeit router </span>","minimal","punctuation","high",False
26818,"Shell Standardize counter name parameter The parameters are not optimal for the counter name between Aggregate Counter Field Value Counter counterName versus name",NULL,"Shell Standardize counter name parameter The parameters are not optimal for the counter name between Aggregate Counter Field Value Counter counterName versus name",NULL,"Add for who this story is","well_formed","no_role","high",False
26834,"Rename ChannelRegistry My current thinking is... ChannelRegistry MessageBus RabbitMessageBus ... Then, method names change like so createInbound registerConsumer createOutbound registerProducer ",NULL,"Rename ChannelRegistry My current thinking is... ChannelRegistry MessageBus RabbitMessageBus ... Then, method names change like","so createInbound registerConsumer createOutbound registerProducer","Add for who this story is","well_formed","no_role","high",False
26834,"Rename ChannelRegistry My current thinking is... ChannelRegistry MessageBus RabbitMessageBus ... Then, method names change like so createInbound registerConsumer createOutbound registerProducer ",NULL,"Rename ChannelRegistry My current thinking is... ChannelRegistry MessageBus RabbitMessageBus ... Then, method names change like","so createInbound registerConsumer createOutbound registerProducer","Rename ChannelRegistry My current thinking is<span class='highlight-text severity-high'>... ChannelRegistry MessageBus RabbitMessageBus ... Then, method names change like so createInbound registerConsumer createOutbound registerProducer </span>","minimal","punctuation","high",False
26834,"Rename ChannelRegistry My current thinking is... ChannelRegistry MessageBus RabbitMessageBus ... Then, method names change like so createInbound registerConsumer createOutbound registerProducer ",NULL,"Rename ChannelRegistry My current thinking is... ChannelRegistry MessageBus RabbitMessageBus ... Then, method names change like","so createInbound registerConsumer createOutbound registerProducer","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26850,"Remove support for the leading on items that have a declared namespace When using jobs, taps we no longer need to have the leading . i.e. tap foo. We should only support tap foo.",NULL,"Remove support for the leading on items that have a declared namespace When using jobs, taps we no longer need to have the leading . i.e. tap foo. We should only support tap foo.",NULL,"Add for who this story is","well_formed","no_role","high",False
26850,"Remove support for the leading on items that have a declared namespace When using jobs, taps we no longer need to have the leading . i.e. tap foo. We should only support tap foo.",NULL,"Remove support for the leading on items that have a declared namespace When using jobs, taps we no longer need to have the leading . i.e. tap foo. We should only support tap foo.",NULL,"Remove support for the leading on items that have a declared namespace When using jobs, taps we no longer need to have the leading <span class='highlight-text severity-high'>. i.e. tap foo. We should only support tap foo.</span>","minimal","punctuation","high",False
26863,"First class JSON Path support Similar to xpath with XML, there are now some initial support in SI that enable the use of filter routers based on JSON Path expressions. That support needs to be reviewed and then brought up to the level of exposure in Spring XD so that router filter modules could use JSON Path. are components that need to be created, perhaps others. This story needs to be broken down further.",NULL,"First class JSON Path support Similar to xpath with XML, there are now some initial support in SI that enable the use of filter routers based on JSON Path expressions. That support needs to be reviewed and then brought up to the level of exposure in Spring XD","so that router filter modules could use JSON Path. are components that need to be created, perhaps others. This story needs to be broken down further.","Add for who this story is","well_formed","no_role","high",False
26863,"First class JSON Path support Similar to xpath with XML, there are now some initial support in SI that enable the use of filter routers based on JSON Path expressions. That support needs to be reviewed and then brought up to the level of exposure in Spring XD so that router filter modules could use JSON Path. are components that need to be created, perhaps others. This story needs to be broken down further.",NULL,"First class JSON Path support Similar to xpath with XML, there are now some initial support in SI that enable the use of filter routers based on JSON Path expressions. That support needs to be reviewed and then brought up to the level of exposure in Spring XD","so that router filter modules could use JSON Path. are components that need to be created, perhaps others. This story needs to be broken down further.","First class JSON Path support Similar to xpath with XML, there are now some initial support in SI that enable the use of filter routers based on JSON Path expressions. That support needs to be reviewed<span class='highlight-text severity-high'> and </span>then brought up to the level of exposure in Spring XD so that router filter modules could use JSON Path. are components that need to be created, perhaps others. This story needs to be broken down further.","atomic","conjunctions","high",False
26863,"First class JSON Path support Similar to xpath with XML, there are now some initial support in SI that enable the use of filter routers based on JSON Path expressions. That support needs to be reviewed and then brought up to the level of exposure in Spring XD so that router filter modules could use JSON Path. are components that need to be created, perhaps others. This story needs to be broken down further.",NULL,"First class JSON Path support Similar to xpath with XML, there are now some initial support in SI that enable the use of filter routers based on JSON Path expressions. That support needs to be reviewed and then brought up to the level of exposure in Spring XD","so that router filter modules could use JSON Path. are components that need to be created, perhaps others. This story needs to be broken down further.","First class JSON Path support Similar to xpath with XML, there are now some initial support in SI that enable the use of filter routers based on JSON Path expressions<span class='highlight-text severity-high'>. That support needs to be reviewed and then brought up to the level of exposure in Spring XD so that router filter modules could use JSON Path. are components that need to be created, perhaps others. This story needs to be broken down further.</span>","minimal","punctuation","high",False
26863,"First class JSON Path support Similar to xpath with XML, there are now some initial support in SI that enable the use of filter routers based on JSON Path expressions. That support needs to be reviewed and then brought up to the level of exposure in Spring XD so that router filter modules could use JSON Path. are components that need to be created, perhaps others. This story needs to be broken down further.",NULL,"First class JSON Path support Similar to xpath with XML, there are now some initial support in SI that enable the use of filter routers based on JSON Path expressions. That support needs to be reviewed and then brought up to the level of exposure in Spring XD","so that router filter modules could use JSON Path. are components that need to be created, perhaps others. This story needs to be broken down further.","Use the most common template: As a, I want to, So","uniform","uniform","medium",False
26886,"XD UI Job Parameters tool tips display needs to aligned When clicking on a specific job execution from the job executions bar chart, the tool tips display isn t aligned with the job parameters. Please see the attachment.",NULL,"XD UI Job Parameters tool tips display needs to aligned When clicking on a specific job execution from the job executions bar chart, the tool tips display isn t aligned with the job parameters. Please see the attachment.",NULL,"Add for who this story is","well_formed","no_role","high",False
26886,"XD UI Job Parameters tool tips display needs to aligned When clicking on a specific job execution from the job executions bar chart, the tool tips display isn t aligned with the job parameters. Please see the attachment.",NULL,"XD UI Job Parameters tool tips display needs to aligned When clicking on a specific job execution from the job executions bar chart, the tool tips display isn t aligned with the job parameters. Please see the attachment.",NULL,"XD UI Job Parameters tool tips display needs to aligned When clicking on a specific job execution from the job executions bar chart, the tool tips display isn t aligned with the job parameters<span class='highlight-text severity-high'>. Please see the attachment.</span>","minimal","punctuation","high",False
26906,"Convert modules to be CP aware Once XD 887 is merged, gradually convert more modules. Recipe 1 Move the module .xml file to 2 Declare a gradle project 3 Move dependencies from dirt project to newly created module project 4 gradle build picks it up. gradle clean build manual test Also have a look at gradle cleanEclipse eclipse",NULL,"Convert modules to be CP aware Once XD 887 is merged, gradually convert more modules. Recipe 1 Move the module .xml file to 2 Declare a gradle project 3 Move dependencies from dirt project to newly created module project 4 gradle build picks it up. gradle clean build manual test Also have a look at gradle cleanEclipse eclipse",NULL,"Add for who this story is","well_formed","no_role","high",False
26906,"Convert modules to be CP aware Once XD 887 is merged, gradually convert more modules. Recipe 1 Move the module .xml file to 2 Declare a gradle project 3 Move dependencies from dirt project to newly created module project 4 gradle build picks it up. gradle clean build manual test Also have a look at gradle cleanEclipse eclipse",NULL,"Convert modules to be CP aware Once XD 887 is merged, gradually convert more modules. Recipe 1 Move the module .xml file to 2 Declare a gradle project 3 Move dependencies from dirt project to newly created module project 4 gradle build picks it up. gradle clean build manual test Also have a look at gradle cleanEclipse eclipse",NULL,"Convert modules to be CP aware Once XD 887 is merged, gradually convert more modules<span class='highlight-text severity-high'>. Recipe 1 Move the module .xml file to 2 Declare a gradle project 3 Move dependencies from dirt project to newly created module project 4 gradle build picks it up. gradle clean build manual test Also have a look at gradle cleanEclipse eclipse</span>","minimal","punctuation","high",False
26923,"Remove work around Spring HATEOAS 89 See Updating HATEOAS version and removing in a lot of controllers should be possible now. See eg ",NULL,"Remove work around Spring HATEOAS 89 See Updating HATEOAS version and removing in a lot of controllers should be possible now. See eg ",NULL,"Add for who this story is","well_formed","no_role","high",False
26923,"Remove work around Spring HATEOAS 89 See Updating HATEOAS version and removing in a lot of controllers should be possible now. See eg ",NULL,"Remove work around Spring HATEOAS 89 See Updating HATEOAS version and removing in a lot of controllers should be possible now. See eg ",NULL,"Remove work around Spring HATEOAS 89 See Updating HATEOAS version<span class='highlight-text severity-high'> and </span>removing in a lot of controllers should be possible now. See eg ","atomic","conjunctions","high",False
26923,"Remove work around Spring HATEOAS 89 See Updating HATEOAS version and removing in a lot of controllers should be possible now. See eg ",NULL,"Remove work around Spring HATEOAS 89 See Updating HATEOAS version and removing in a lot of controllers should be possible now. See eg ",NULL,"Remove work around Spring HATEOAS 89 See Updating HATEOAS version and removing in a lot of controllers should be possible now<span class='highlight-text severity-high'>. See eg </span>","minimal","punctuation","high",False
26949,"Create OOTB file to HDFS batch import job that is launched by a stream. Same processing as XD 984, but the job instacne is launched via an event from the input file source. Supporting a single file per job launch is OK. job create blah definition filehdfs stream create csvStream definition file ref true pattern .csv job blah the job should be documented ",NULL,"Create OOTB file to HDFS batch import job that is launched by a stream. Same processing as XD 984, but the job instacne is launched via an event from the input file source. Supporting a single file per job launch is OK. job create blah definition filehdfs stream create csvStream definition file ref true pattern .csv job blah the job should be documented ",NULL,"Add for who this story is","well_formed","no_role","high",False
26949,"Create OOTB file to HDFS batch import job that is launched by a stream. Same processing as XD 984, but the job instacne is launched via an event from the input file source. Supporting a single file per job launch is OK. job create blah definition filehdfs stream create csvStream definition file ref true pattern .csv job blah the job should be documented ",NULL,"Create OOTB file to HDFS batch import job that is launched by a stream. Same processing as XD 984, but the job instacne is launched via an event from the input file source. Supporting a single file per job launch is OK. job create blah definition filehdfs stream create csvStream definition file ref true pattern .csv job blah the job should be documented ",NULL,"Create OOTB file to HDFS batch import job that is launched by a stream<span class='highlight-text severity-high'>. Same processing as XD 984, but the job instacne is launched via an event from the input file source. Supporting a single file per job launch is OK. job create blah definition filehdfs stream create csvStream definition file ref true pattern .csv job blah the job should be documented </span>","minimal","punctuation","high",False
